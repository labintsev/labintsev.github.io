<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Заметки по ML, DL</title><link>https://mldl.ru/</link><description>Заметки по machine learning, deep learning.</description><atom:link href="https://mldl.ru/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>ru</language><copyright>Contents © 2025 &lt;a href="mailto:andrej.labintsev@yandex.ru"&gt;Андрей Лабинцев&lt;/a&gt; </copyright><lastBuildDate>Fri, 03 Oct 2025 10:16:32 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Эпиполярная геометрия </title><link>https://mldl.ru/posts/epipolar-geometry/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;h4&gt;Введение&lt;/h4&gt;
&lt;p&gt;В предыдущих разделах мы изучали методы расчёта внутренних и внешних параметров камеры. Это можно сделать с помощью стандартной процедуры калибровки камеры или используя знания о перпендикулярных плоскостях по одному изображению. В результате этих вычислений мы смогли получить определённые характеристики трёхмерного пространства.&lt;/p&gt;
&lt;p&gt;Однако в общем случае невозможно восстановить полную структуру трёхмерного мира, опираясь только на одно изображение. Причина этого кроется во внутренней неоднозначности процесса отображения трёхмерного пространства на двумерную плоскость — часть информации неизбежно теряется при таком преобразовании.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 1: Проблема неоднозначности" src="https://storage.yandexcloud.net/yahosting/epipolar/1.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 1: Проблема неоднозначности&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Рассмотрим характерный пример, показанный на рисунке 1. На первый взгляд может показаться, что человек действительно удерживает Пизанскую башню. Только при внимательном изучении изображения становится понятно, что это всего лишь оптическая иллюзия, возникшая из-за проецирования объектов с разной глубиной на плоскость изображения.&lt;/p&gt;
&lt;p&gt;Если же рассмотреть эту сцену с совершенно другой точки зрения, иллюзия исчезает, и мы можем определить правильное расположение объектов в пространстве. Именно поэтому использование нескольких точек обзора является ключевым для точного понимания структуры сцены.&lt;/p&gt;
&lt;h4&gt;1. Эпиполярная геометрия&lt;/h4&gt;
&lt;p&gt;Эпиполярная геометрия представляет собой раздел компьютерной геометрии, который изучает взаимосвязь между точками на разных изображениях, ограничения на их расположение при проецировании и геометрические соотношения между камерами.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 2: Основные элементы эпиполярной геометрии" src="https://storage.yandexcloud.net/yahosting/epipolar/2.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 2: Основные элементы эпиполярной геометрии&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Рассмотрим основные элементы эпиполярной геометрии, изображённые на рисунке 2:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Две камеры наблюдают одну и ту же трёхмерную точку $P$  &lt;/li&gt;
&lt;li&gt;Проекции точки $P$ на плоскости изображений находятся в точках $p$ и $p'$  &lt;/li&gt;
&lt;li&gt;Центры камер расположены в точках $O_1$ и $O_2$  &lt;/li&gt;
&lt;li&gt;Линия, соединяющая центры камер, называется &lt;strong&gt;базисом&lt;/strong&gt; (оранжевая линия)  &lt;/li&gt;
&lt;li&gt;Плоскость, образованная двумя центрами камер и точкой $P$, называется &lt;strong&gt;эпиполярной плоскостью&lt;/strong&gt; (изображена серым цветом)  &lt;/li&gt;
&lt;li&gt;Эпиполы — точки пересечения базиса с плоскостями изображений ($e$ и $e'$)   &lt;/li&gt;
&lt;li&gt;Эпиполярные линии — прямые, образованные пересечением эпиполярной плоскости с плоскостями изображений (голубые отрезки)  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="Рисунок 3: Пример расположения эпиполярных линий и ключевых точек" src="https://storage.yandexcloud.net/yahosting/epipolar/3.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 3: Пример расположения эпиполярных линий и ключевых точек&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;На рисунке 3 показан пример эпиполярных линий и соответствующих ключевых точек, нанесённых на пару изображений. Эта визуализация демонстрирует, как эпиполярная геометрия помогает установить связь между точками на разных снимках.&lt;/p&gt;
&lt;p&gt;Таким образом, эпиполярная геометрия помогает установить связи между изображениями одной и той же сцены, снятыми с разных точек зрения, и восстанавливать трёхмерную структуру.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 4: Частный случай эпиполярной геометрии" src="https://storage.yandexcloud.net/yahosting/epipolar/4.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 4: Частный случай эпиполярной геометрии&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;Рассмотрим интересную ситуацию, когда плоскости изображений расположены параллельны друг другу (см. рисунок 4). 
В этом случае эпиполы $e$ и $e'$ располагаются в бесконечности. 
Это происходит потому, что &lt;strong&gt;базис&lt;/strong&gt;, соединяющий центры камер $O_1$ и $O_2$, параллелен плоскостям изображений. 
Эпиполярные линии становятся параллельными оси $u$ на плоскости изображения. &lt;/p&gt;
&lt;p&gt;Этот частный случай имеет важное практическое значение, особенно при работе с выравниванием изображений, о чём будет подробно рассказано в следующем разделе.&lt;/p&gt;
&lt;p&gt;В практических ситуациях точное расположение трёхмерной точки $P$ неизвестно. 
Но мы можем определить её проекции $p, p'$ на плоскости изображений, местоположение, ориентацию и внутренние параметры камер. &lt;/p&gt;
&lt;p&gt;Кроме того, зная положения камер $O_1$, $O_2$ и положение проекции точки $p$ на одном изображении, можно определить эпиполярную плоскость и найти эпиполярные линии на основе этой плоскости. Это существенно упрощает поиск соответствующей ключевой точки на других изображениях. Это свойство делает эпиполярную геометрию мощным инструментом в задачах компьютерного зрения и трёхмерной реконструкции сцены.&lt;/p&gt;
&lt;h4&gt;2. Эссенциальная матрица&lt;/h4&gt;
&lt;p&gt;Для создания эффективного способа отображения точек и эпиполярных линий между разными видами сцены мы используем базовую структуру эпиполярной геометрии. 
В этой системе матрицы проекции $M$ и $M'$ отвечают за преобразование трёхмерных точек в двумерные координаты на плоскостях изображений.
Мировая система координат связывается с первой камерой, при этом вторая камера смещается относительно первой через последовательное применение поворота $R$ и переноса $T$.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 5: Расположение второй камеры относительно первой" src="https://storage.yandexcloud.net/yahosting/epipolar/5.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 5: Расположение второй камеры относительно первой&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;В результате того, что за точку отсчета мировых координат мы принимаем центр камеры $O_1$, матрицы проекции принимают следующий вид:&lt;/p&gt;
&lt;p&gt;$M = K \begin{bmatrix} I &amp;amp; 0 \end{bmatrix}$ (2)&lt;/p&gt;
&lt;p&gt;$M' = K' \begin{bmatrix} R &amp;amp; -RT \end{bmatrix}$&lt;/p&gt;
&lt;p&gt;где $K$ и $K'$ представляют внутренние параметры камер, $I$ — единичная матрица, $R$ отвечает за поворот, а $T$ — за перенос (вектор $O_1 O_2$).&lt;/p&gt;
&lt;p&gt;Рассмотрим частный случай с каноническими камерами:  &lt;/p&gt;
&lt;p&gt;$K = K' = I$  &lt;/p&gt;
&lt;p&gt;$p'$ - это координаты проекции точки в системе координат второй камеры. 
Координаты точки $p'$ в системе координат первой камеры определяются как $Rp' + T$.  &lt;/p&gt;
&lt;p&gt;Поскольку векторы $Rp' + T$ и $T$ лежат в эпиполярной плоскости, их векторное произведение даёт вектор, перпендикулярный этой плоскости.&lt;br&gt;
Благодаря свойствам дистрибутивности векторного произведения получаем результат: &lt;/p&gt;
&lt;p&gt;$T \times (Rp' + T) = T \times (Rp')$ &lt;/p&gt;
&lt;p&gt;Точка $p$, лежащая в эпиполярной плоскости, ортогональна вектору $T \times (Rp')$, что даёт ограничение:&lt;/p&gt;
&lt;p&gt;$p^T \cdot [T \times (Rp')] = 0$ (3)&lt;/p&gt;
&lt;p&gt;Напомним, &lt;strong&gt;векторное произведение&lt;/strong&gt; — это операция над двумя векторами в трёхмерном пространстве, результатом которой является новый вектор.
Результат — вектор, перпендикулярный обоим исходным векторам, его длина равна площади параллелограмма, построенного на исходных векторах, а направление определяется правилом правой руки&lt;/p&gt;
&lt;p&gt;Пусть даны два вектора:&lt;/p&gt;
&lt;p&gt;$\vec{a} = (a_1, a_2, a_3)$&lt;/p&gt;
&lt;p&gt;$\vec{b} = (b_1, b_2, b_3)$&lt;/p&gt;
&lt;p&gt;Их векторное произведение:&lt;/p&gt;
&lt;p&gt;$\vec{a} \times \vec{b} = \begin{vmatrix}
\vec{i} &amp;amp; \vec{j} &amp;amp; \vec{k} \
a_1 &amp;amp; a_2 &amp;amp; a_3 \
b_1 &amp;amp; b_2 &amp;amp; b_3
\end{vmatrix}$&lt;/p&gt;
&lt;p&gt;где $\vec{i}, \vec{j}, \vec{k}$ — единичные векторы по осям координат.&lt;/p&gt;
&lt;p&gt;Формула для вычисления имеет вид: &lt;/p&gt;
&lt;p&gt;$\vec{a} \times \vec{b} = (a_2b_3 - a_3b_2, a_3b_1 - a_1b_3, a_1b_2 - a_2b_1)$&lt;/p&gt;
&lt;p&gt;Вернемся к эпиполярной геометрии. &lt;/p&gt;
&lt;p&gt;Используя аппарат линейной алгебры, векторное произведение можно представить в виде матрично-векторного умножения:&lt;/p&gt;
&lt;p&gt;$a \times b = \begin{bmatrix} 0 &amp;amp; -a_z &amp;amp; a_y \ a_z &amp;amp; 0 &amp;amp; -a_x \ -a_y &amp;amp; a_x &amp;amp; 0 \end{bmatrix} \begin{bmatrix} b_x \ b_y \ b_z \end{bmatrix} = [a\times]b$ (4)&lt;/p&gt;
&lt;p&gt;Преобразуя выражение с учётом этого представления, получаем:&lt;/p&gt;
&lt;p&gt;$p^T[T\times]Rp' = 0$ (5)&lt;/p&gt;
&lt;p&gt;Матрица $E = [T\times]R$ называется &lt;strong&gt;эссенциальной матрицей&lt;/strong&gt; и даёт компактную форму эпиполярного ограничения:&lt;/p&gt;
&lt;p&gt;$p^TEp' = 0$ (6)&lt;/p&gt;
&lt;p&gt;Эссенциальная матрица — это матрица размером $3 \times 3$, содержащая 5 степеней свободы. Она имеет ранг 2 и является сингулярной.&lt;/p&gt;
&lt;p&gt;Эта матрица полезна для вычисления эпиполярных линий. Например, $l' = E^Tp$ даёт эпиполярную линию в плоскости изображения второй камеры, а $l = Ep'$ — в плоскости первой камеры.&lt;/p&gt;
&lt;p&gt;Важные свойства эссенциальной матрицы:
* Её скалярное произведение с эпиполями равно нулю: $E^Te = Ee' = 0$
* Для любой точки $x$ (кроме $e$) в изображении первой камеры соответствующая эпиполярная линия во второй камере содержит эпиполь $e'$&lt;/p&gt;
&lt;p&gt;Таким образом, эссенциальная матрица является фундаментальным инструментом для работы с эпиполярной геометрией и установления связей между точками на разных изображениях. &lt;/p&gt;
&lt;h4&gt;3. Фундаментальная матрица&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Фундаментальная матрица&lt;/strong&gt; — это важный инструмент в эпиполярной геометрии, который обобщает концепцию эссенциальной матрицы на случай камер с нетривиальными внутренними параметрами.&lt;/p&gt;
&lt;p&gt;Рассмотрим матрицы проекции для двух камер:&lt;/p&gt;
&lt;p&gt;$M = K \begin{bmatrix} I &amp;amp; 0 \end{bmatrix}$&lt;/p&gt;
&lt;p&gt;$M' = K' \begin{bmatrix} R &amp;amp; -RT \end{bmatrix}$ (7)&lt;/p&gt;
&lt;p&gt;Для работы с неканоническими камерами введём обозначения:
* $p_c = K^{-1}p$ — проекция точки $p$ для канонической камеры
* $p'_c = K'^{-1}p'$ — проекция точки $p'$ для канонической камеры&lt;/p&gt;
&lt;p&gt;В каноническом случае (единичная матрица $K$) выполняется соотношение:&lt;/p&gt;
&lt;p&gt;$p_c^T [T \times] R p'_c = 0$ (8)&lt;/p&gt;
&lt;p&gt;Однако, с учетом преобразований внутренних параметров камеры, получаем:&lt;/p&gt;
&lt;p&gt;$p^T K^{-T} [T \times] R K'^{-1} p' = 0$ (9)&lt;/p&gt;
&lt;p&gt;Матрица $F = K'^{-T} [T \times] R K^{-1}$ называется &lt;strong&gt;фундаментальной матрицей&lt;/strong&gt;.&lt;br&gt;
Она обобщает свойства эссенциальной матрицы, учитывает параметры камер $K$ и $K'$ и содержит информацию о взаимном положении камер. (вращение $R$ и перенос $T$).
очками на разных изображениях
Фундаментальная матрица имеет 7 степеней свободы (против 5 у эссенциальной матрицы), позволяет находить эпиполярные линии без знания 3D-координат точек и работает даже при неизвестных параметрах камер. &lt;/p&gt;
&lt;p&gt;Таким образом, фундаментальная матрица даёт мощный инструмент для установления связей между точками на разных изображениях, не требуя полной информации о параметрах камер или трёхмерных координатах точек.&lt;/p&gt;
&lt;h4&gt;4. Алгоритм восьми точек для вычисления фундаментальной матрицы&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Алгоритм восьми точек&lt;/strong&gt; — это метод оценки фундаментальной матрицы по двум изображениям сцены без знания параметров камер. Метод был предложен Лонге-Хиггинсом в 1981 году и расширен Хартли в 1995 году.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 6: Ключевые точки и их соответствие на двух изображениях" src="https://storage.yandexcloud.net/yahosting/epipolar/6.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 6: Ключевые точки и их соответствие на двух изображениях&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Для работы алгоритма требуется минимум 8 пар соответствующих точек между двумя изображениями. 
Каждая пара точек $p_i = (u_i, v_i, 1)$ и $p'_i = (u'_i, v'_i, 1)$ даёт ограничение $p_i^TFp'_i = 0$. &lt;/p&gt;
&lt;p&gt;Математически ограничение можно представить в виде:&lt;/p&gt;
&lt;p&gt;$\begin{bmatrix}
u_iu'&lt;em 11&gt;i &amp;amp; v'_iu_i &amp;amp; u_iu'_i &amp;amp; v_iu'_i &amp;amp; v_iv'_i &amp;amp; v_iu'_i &amp;amp; v'_i &amp;amp; 1
\end{bmatrix}
\begin{bmatrix}
F&lt;/em&gt;
\end{bmatrix} = 0$} \ F_{12} \ F_{13} \ F_{21} \ F_{22} \ F_{23} \ F_{31} \ F_{32} \ F_{33&lt;/p&gt;
&lt;p&gt;Практическая реализация для $N ≥ 8$ соответствий формируется система уравнений:&lt;/p&gt;
&lt;p&gt;$Wf = 0$,&lt;/p&gt;
&lt;p&gt;где:
* $W$ — матрица размером $N × 9$
* $f$ — вектор элементов фундаментальной матрицы&lt;/p&gt;
&lt;p&gt;На практике эффективнее использовать больше восьми соответствий и создавать более крупную матрицу W, поскольку это снижает влияние зашумлённых измерений. &lt;/p&gt;
&lt;p&gt;Решение этой системы однородных уравнений можно найти методом наименьших квадратов с помощью сингулярного разложения (SVD), так как матрица W является дефектной по рангу. &lt;/p&gt;
&lt;p&gt;SVD даёт оценку фундаментальной матрицы $\hat{F}$, которая может иметь полный ранг. Однако истинная фундаментальная матрица имеет ранг 2, поэтому нужно искать решение, которое является наилучшим приближением ранга 2 для $\hat{F}$.&lt;/p&gt;
&lt;p&gt;Математически это формулируется как задача оптимизации:&lt;/p&gt;
&lt;p&gt;$\min_F ||F - \hat{F}||_F$ при условии $\det(F) = 0$&lt;/p&gt;
&lt;p&gt;где:
* $||\cdot||_F$ — норма Фробениуса
* $\det(F) = 0$ — условие, обеспечивающее ранг матрицы равный 2&lt;/p&gt;
&lt;p&gt;Напомним, сингулярное разложение (SVD) для приблизительной оценки матрицы имеет вид:&lt;/p&gt;
&lt;p&gt;$\hat{F} = U\Sigma V^T$&lt;/p&gt;
&lt;p&gt;Искомая матрица $F$ будет иметь наилучшее приближение 2 ранга:&lt;/p&gt;
&lt;p&gt;$F = U
   \begin{bmatrix}
   \sigma_1 &amp;amp; 0 &amp;amp; 0 \
   0 &amp;amp; \sigma_2 &amp;amp; 0 \
   0 &amp;amp; 0 &amp;amp; 0
   \end{bmatrix}
   V^T$&lt;/p&gt;
&lt;p&gt;где $\sigma_1$ и $\sigma_2$ — первые два сингулярных числа матрицы $\hat{F}$.&lt;/p&gt;
&lt;p&gt;Такой подход гарантирует схранение геометрических свойств фундаментальной матрицы, минимизацию отклонения от исходной оценки и сохранение ранга 2. &lt;/p&gt;
&lt;p&gt;Таким образом, алгоритм позволяет оценить фундаментальную матрицу без знания параметров камер и является основой для многих задач стереовидения и трёхмерной реконструкции. &lt;/p&gt;
&lt;h4&gt;5. Нормализованный алгоритм восьми точек&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Стандартная реализация&lt;/strong&gt; алгоритма восьми точек часто даёт неточные результаты. Обычное расстояние между точкой $p_i$ и соответствующей эпиполярной линией $l_i = Fp'_i$ может достигать 10 и более пикселей.&lt;/p&gt;
&lt;p&gt;Основная проблема заключается в том, что матрица $W$ плохо обусловлена, это создает проблемы для алгоритма SVD. 
Основная причина - большие абсолютные значения координат точек (например, $p_i = (1832, 1023, 1)$)
Проблема усугубляется, если  точки $p_i$ и $p'_i$ находятся в небольшой области изображения, при наличии одного большого сингулярного значения при малых остальных. &lt;/p&gt;
&lt;p&gt;Для решения этой проблемы и улучшения точности используется &lt;strong&gt;нормализация координат&lt;/strong&gt;. 
1. Сдвиг координат так, чтобы начало новой системы находилось в центре масс точек
2. Масштабирование координат так, чтобы среднеквадратичное расстояние от начала координат равнялось 2 пикселям&lt;/p&gt;
&lt;p&gt;Для реализации используются матрицы преобразования $T$ и $T'$, которые выполняют сдвиг на центроид и применяют масштабирующий коэффициент $\left(\frac{2N}{\sum_{i=1}^N||x_i - \bar{x}||^2}\right)^{1/2}$&lt;/p&gt;
&lt;p&gt;Нормализованные координаты вычисляются как:&lt;br&gt;
$q_i = Tp_i$&lt;br&gt;
$q'_i = T'p'_i$  &lt;/p&gt;
&lt;p&gt;Далее, используя нормализованные координаты, вычисляется матрица $F_q$ стандартным методом и производится денормализация:  &lt;/p&gt;
&lt;p&gt;$F = T'^TF_qT$&lt;/p&gt;
&lt;p&gt;Нормализованный алгоритм обеспечивает:&lt;br&gt;
- Более точные результаты в реальных приложениях&lt;br&gt;
- Улучшенную обусловленность матрицы $W$&lt;br&gt;
- Снижение влияния больших значений координат&lt;br&gt;
- Повышение точности оценки фундаментальной матрицы  &lt;/p&gt;
&lt;p&gt;Такой подход значительно улучшает качество оценки фундаментальной матрицы и является предпочтительным методом для практического применения. &lt;/p&gt;
&lt;h4&gt;6. Выравнивание изображений (Image Rectification)&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Особое свойство эпиполярной геометрии&lt;/strong&gt; проявляется, когда два изображения параллельны друг другу. 
Рассмотрим частный случай параллельных плоскостей изображений.&lt;/p&gt;
&lt;p&gt;Камеры имеют одинаковую матрицу $K$, отсутствует относительное вращение ($R = I$) и есть только перенос вдоль оси $x$ ($T = (T_x, 0, 0)$)&lt;/p&gt;
&lt;p&gt;В этом случае эссенциальная матрица принимает вид:&lt;/p&gt;
&lt;p&gt;$E = [T×]R = \begin{bmatrix} 
0 &amp;amp; 0 &amp;amp; 0 \ 
0 &amp;amp; 0 &amp;amp; -T_x \ 
0 &amp;amp; T_x &amp;amp; 0 
\end{bmatrix}$ (17)&lt;/p&gt;
&lt;p&gt;Направление эпиполярной линии для точки $p' = (u', v', 1)$ вычисляется как:&lt;/p&gt;
&lt;p&gt;$l = Ep' = \begin{bmatrix} 
0 &amp;amp; 0 &amp;amp; 0 \ 
0 &amp;amp; 0 &amp;amp; -T_x \ 
0 &amp;amp; T_x &amp;amp; 0 
\end{bmatrix}
\begin{bmatrix} 
u' \ 
v' \ 
1 
\end{bmatrix} = 
\begin{bmatrix} 
0 \ 
-T_x \ 
T_xv' 
\end{bmatrix}$ (18)&lt;/p&gt;
&lt;p&gt;В этом случае направление эпиполярной линии $l$ горизонтально. 
Аналогично, направление $l'$ также горизонтально, а все эпиполярные линии параллельны друг другу.&lt;br&gt;
Такое выравнивание изображений позволяет значительно упростить поиск соответствий между точками и упрощает стереообработку и трёхмерную реконструкцию сцены.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 7: Ректификация (выравнивание) изображений" src="https://storage.yandexcloud.net/yahosting/epipolar/7.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 7: Ректификация (выравнивание) изображений&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Если мы используем &lt;strong&gt;эпиполярное ограничение&lt;/strong&gt; $p^T E p' = 0$, то приходим к тому, что $v = v'$. Это показывает, что точки $p$ и $p'$ имеют одинаковую координату $v$.&lt;/p&gt;
&lt;p&gt;Следовательно, между соответствующими точками существует очень простая взаимосвязь. Поэтому &lt;strong&gt;выравнивание&lt;/strong&gt; (процесс приведения любых двух заданных изображений к параллельному виду) становится полезным при определении взаимосвязей между соответствующими точками на изображениях.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 8: Вычисление гомографий ректификации" src="https://storage.yandexcloud.net/yahosting/epipolar/8.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 8: Вычисление гомографий ректификации&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Выравнивание пары изображений не требует знания матриц камер $K$ и $K'$ или относительного преобразования $R$, $T$ между ними. Вместо этого можно использовать &lt;strong&gt;фундаментальную матрицу&lt;/strong&gt;, оценённую с помощью &lt;strong&gt;нормализованного алгоритма восьми точек&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;После получения фундаментальной матрицы можно вычислить &lt;strong&gt;эпиполярные линии&lt;/strong&gt; $l_i$ и $l'_i$ для каждой пары соответствующих точек $p_i$ и $p'_i$.&lt;/p&gt;
&lt;p&gt;На основе набора эпиполярных линий можно оценить &lt;strong&gt;эпиполи&lt;/strong&gt; $e$ и $e'$ для каждого изображения. Это возможно потому, что эпиполь лежит в точке пересечения всех эпиполярных линий.&lt;/p&gt;
&lt;p&gt;В реальных условиях из-за зашумлённых измерений все эпиполярные линии не пересекаются в одной точке. Поэтому вычисление эпиполя можно найти путём минимизации среднеквадратичной ошибки подгонки точки ко всем эпиполярным линиям.&lt;/p&gt;
&lt;p&gt;Каждая эпиполярная линия может быть представлена в виде вектора $l$ так, что все точки на линии (в однородных координатах) принадлежат множеству ${x | l^T x = 0}$. 
Если определить каждую эпиполярную линию как $l_i = [l_{i,1}, l_{i,2}, l_{i,3}]^T$, то можно сформулировать линейную систему уравнений и решить её с помощью &lt;strong&gt;сингулярного разложения&lt;/strong&gt; (SVD) для нахождения эпиполя $e$.&lt;/p&gt;
&lt;p&gt;$\begin{bmatrix}
l^T_1 \
\vdots \
l^T_n
\end{bmatrix} e = 0$&lt;/p&gt;
&lt;p&gt;После нахождения эпиполей $e$ и $e'$, мы, скорее всего, обнаружим, что они не являются точками на бесконечности вдоль горизонтальной оси. Если бы это было так, то изображения уже были бы параллельными по определению.&lt;/p&gt;
&lt;p&gt;Это наводит на мысль: можно ли найти &lt;strong&gt;гомографию&lt;/strong&gt;, которая отобразит эпиполь $e$ в бесконечность вдоль горизонтальной оси?&lt;/p&gt;
&lt;p&gt;Все что нам нужно - это найти пару гомографий $H_1$ и $H_2$, применить их к изображениям и отобразить эпиполи в бесконечность. &lt;/p&gt;
&lt;p&gt;Начнём с поиска гомографии $H_2$, которая отображает второй эпиполь $e'$ в точку на горизонтальной оси в бесконечности $(f, 0, 0)$.&lt;/p&gt;
&lt;p&gt;Хотя существует множество вариантов такой гомографии, на практике хорошо работает условие, при котором гомография действует как преобразование и применяет перенос и поворот к точкам около центра изображения. &lt;/p&gt;
&lt;p&gt;Первый шаг — сдвиг второго изображения так, чтобы его центр оказался в точке $(0, 0, 1)$ в однородных координатах. Это достигается применением матрицы переноса.&lt;/p&gt;
&lt;p&gt;$T = \begin{bmatrix}
1 &amp;amp; 0 &amp;amp; -\frac{width}{2} \
0 &amp;amp; 1 &amp;amp; -\frac{height}{2} \
0 &amp;amp; 0 &amp;amp; 1
\end{bmatrix}$ (20)&lt;/p&gt;
&lt;p&gt;После применения переноса мы выполняем поворот, чтобы разместить эпиполь на горизонтальной оси в некоторой точке $(f, 0, 1)$.&lt;/p&gt;
&lt;p&gt;Если перенесённый эпиполь $T e'$ находится в однородных координатах $(e'_1, e'_2, 1)$, то применяемый поворот определяется следующим образом:&lt;/p&gt;
&lt;p&gt;$R = \begin{bmatrix}
\alpha\frac{e'_1}{\sqrt{e'^2_1 + e'^2_2}} &amp;amp; \alpha\frac{e'_2}{\sqrt{e'^2_1 + e'^2_2}} &amp;amp; 0 \
-\alpha\frac{e'_2}{\sqrt{e'^2_1 + e'^2_2}} &amp;amp; \alpha\frac{e'_1}{\sqrt{e'^2_1 + e'^2_2}} &amp;amp; 0 \
0 &amp;amp; 0 &amp;amp; 1
\end{bmatrix}$ (21) &lt;/p&gt;
&lt;p&gt;где параметр $\alpha$ определяется следующим образом:&lt;br&gt;
$\alpha = 1$, если $e'_1 \geq 0$&lt;br&gt;
$\alpha = -1$ в противном случае. &lt;/p&gt;
&lt;p&gt;После применения этого поворота заметим, что для любой точки $(f, 0, 1)$ перевод её в точку на бесконечности по горизонтальной оси $(f, 0, 0)$ требует применения преобразования:&lt;/p&gt;
&lt;p&gt;$G = \begin{bmatrix} 
1 &amp;amp; 0 &amp;amp; 0 \ 
0 &amp;amp; 1 &amp;amp; 0 \ 
-\frac{1}{f} &amp;amp; 0 &amp;amp; 1 
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;После применения этого преобразования мы наконец получаем эпиполь в бесконечности, поэтому можем вернуться к обычному пространству изображения.&lt;/p&gt;
&lt;p&gt;Таким образом, гомография $H_2$, которую мы применяем ко второму изображению для его выравнивания, имеет вид:&lt;/p&gt;
&lt;p&gt;$H_2 = T^{-1}GRT$ (23)&lt;/p&gt;
&lt;p&gt;Теперь, когда мы нашли допустимую $H_2$, нам нужно найти подходящую гомографию $H_1$ для первого изображения. Мы делаем это путём поиска такого преобразования $H_1$, которое минимизирует сумму квадратов расстояний между соответствующими точками изображений:&lt;/p&gt;
&lt;p&gt;$\arg\min_{H_1} \sum_{i} ||H_1p_i - H_2p'_i||^2$&lt;/p&gt;
&lt;p&gt;В результате мы получаем пару гомографий ($H_1$, $H_2$), которые позволяют выровнять изображения, сделать эпиполярные линии горизонтальными и упростить поиск соответствий между точками. &lt;/p&gt;
&lt;p&gt;Можно доказать, что подходящая гомография $H_1$ имеет следующий вид:&lt;/p&gt;
&lt;p&gt;$H_1 = H_A H_2 M$ (25)&lt;/p&gt;
&lt;p&gt;где:
* $F = [e]\times M$
* $H_A$ — специальная матрица вида:&lt;/p&gt;
&lt;p&gt;$H_A = \begin{bmatrix} 
a_1 &amp;amp; a_2 &amp;amp; a_3 \ 
0 &amp;amp; 1 &amp;amp; 0 \ 
0 &amp;amp; 0 &amp;amp; 1 
\end{bmatrix}$ (26)&lt;/p&gt;
&lt;p&gt;Здесь $(a_1, a_2, a_3)$ — компоненты определённого вектора $a$, который будет вычислен позже.&lt;/p&gt;
&lt;p&gt;Разберём структуру этого выражения:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Матрица $H_A$&lt;/strong&gt; представляет собой линейное преобразование вдоль оси $x$, координаты $y$ и $z$ остаются неизменными. 
$H_2$ — уже известная гомография для второго изображения&lt;br&gt;
$M$ — вспомогательная матрица, связанная с фундаментальной матрицей $F$&lt;br&gt;
$[e]\times$ — кососимметричная матрица, построенная на векторе $e$  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Кососимметричная матрица&lt;/strong&gt; обладает свойством $A = A^3$ с точностью до масштаба.&lt;/p&gt;
&lt;p&gt;Поскольку:
* Матрица векторного произведения $[e]\times$ — кососимметричная
* Фундаментальная матрица $F$ известна только с точностью до масштаба&lt;/p&gt;
&lt;p&gt;Получаем:&lt;/p&gt;
&lt;p&gt;$F = [e]\times M = [e]\times[e]\times[e]\times M = [e]\times[e]\times F$ (27)&lt;/p&gt;
&lt;p&gt;Отсюда следует:&lt;/p&gt;
&lt;p&gt;$M = [e]\times F$ (28)&lt;/p&gt;
&lt;p&gt;Важно заметить: если к столбцам $M$ добавить любое скалярное кратное вектора $e$, равенство $F = [e]\times M$ сохраняется.&lt;/p&gt;
&lt;p&gt;Поэтому более общий вид $M$:&lt;/p&gt;
&lt;p&gt;$M = [e]\times F + ev^T$ (29)&lt;/p&gt;
&lt;p&gt;На практике хорошо работает выбор $v^T = [1, 1, 1]$.&lt;/p&gt;
&lt;p&gt;Для нахождения $H_1$ нужно вычислить значения вектора $a$ в матрице $H_A$.&lt;/p&gt;
&lt;p&gt;Задача сводится к минимизации:&lt;/p&gt;
&lt;p&gt;$\arg\min_{H_A} \sum_{i} ||H_A\hat{p}_i - \hat{p}'_i||^2$ (30)&lt;/p&gt;
&lt;p&gt;где:
* $\hat{p}_i = H_2Mp_i$
* $\hat{p}'_i = H_2p'_i$&lt;/p&gt;
&lt;p&gt;При этом $H_2$ и $M$ уже известны. &lt;/p&gt;</description><category>cs231a</category><guid>https://mldl.ru/posts/epipolar-geometry/</guid><pubDate>Thu, 02 Oct 2025 11:00:00 GMT</pubDate></item><item><title>Измерение углов </title><link>https://mldl.ru/posts/single-view-metrology/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;h4&gt;Введение&lt;/h4&gt;
&lt;p&gt;На предыдущих лекциях мы обсуждали, как можно преобразовывать точки из реального трёхмерного мира в цифровые изображения, используя внешние и внутренние характеристики камер. Мы рассмотрели, как можно использовать известную структуру калибровочной установки и соответствующие изображения для определения характеристик камеры. &lt;/p&gt;
&lt;p&gt;Теперь мы обратимся к смежной проблеме: можно ли восстановить известную структуру трёхмерного мира, если у нас есть единственное изображение и известны свойства камеры, которой это изображение было сделано? И наконец мы рассмотрим алгоритм калибровки камеры и измерения углов между плоскостями на одиночном изображении. &lt;/p&gt;
&lt;h4&gt;1. Преобразования в 2D пространстве&lt;/h4&gt;
&lt;p&gt;Чтобы лучше понять, как мы можем извлекать информацию из изображений, сначала необходимо разобраться с различными преобразованиями в двумерном пространстве.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Изометрические преобразования&lt;/strong&gt; — это преобразования, сохраняющие расстояния. В своей базовой форме изометрия может быть описана как вращение $R$ и перенос $t$. Математически они определяются следующим образом:&lt;/p&gt;
&lt;p&gt;$\begin{bmatrix}
x' \\
y' \\
1
\end{bmatrix} = 
\begin{bmatrix}
R &amp;amp; t \\
0 &amp;amp; 1
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
1
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;где $(x', y', 1)^T$ — точка, полученная после изометрического преобразования.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Преобразования подобия&lt;/strong&gt; — это преобразования, сохраняющие форму. Интуитивно они могут выполнять всё то же, что и изометрические преобразования, плюс масштабирование. Математически они обозначаются так:&lt;/p&gt;
&lt;p&gt;$\begin{bmatrix}
x' \\
y' \\
1
\end{bmatrix} = 
\begin{bmatrix}
SR &amp;amp; t \\
0 &amp;amp; 1
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
1
\end{bmatrix} $  &lt;/p&gt;
&lt;p&gt;$ S = 
\begin{bmatrix}
s &amp;amp; 0 \\
0 &amp;amp; s
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Преобразования подобия&lt;/strong&gt; сохраняют форму объектов, а значит, сохраняют:&lt;br&gt;
&lt;em&gt; Отношения длин отрезков&lt;br&gt;
&lt;/em&gt; Величины углов  &lt;/p&gt;
&lt;p&gt;Важно отметить, что любое &lt;strong&gt;изометрическое преобразование&lt;/strong&gt; является частным случаем преобразования подобия при $s = 1$. Однако обратное утверждение неверно.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Аффинные преобразования&lt;/strong&gt; сохраняют:&lt;br&gt;
&lt;em&gt; Точки&lt;br&gt;
&lt;/em&gt; Прямые линии&lt;br&gt;
* Параллельность прямых  &lt;/p&gt;
&lt;p&gt;Для вектора $v$ аффинное преобразование $T$ определяется как:
$T(v) = Av + t$, где $A$ — линейное преобразование пространства $R^n$&lt;/p&gt;
&lt;p&gt;В однородных координатах аффинные преобразования записываются так:  &lt;/p&gt;
&lt;p&gt;$\begin{bmatrix}
x' \\
y' \\
1
\end{bmatrix} = 
\begin{bmatrix}
A &amp;amp; t \\
0 &amp;amp; 1
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
1
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;Из этого уравнения видно, что все преобразования подобия (и, следовательно, изометрии) являются частным случаем аффинных преобразований.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Проективные преобразования&lt;/strong&gt; (или гомографии) — это преобразования, которые переводят прямые в прямые, но не обязательно сохраняют параллельность.&lt;/p&gt;
&lt;p&gt;В однородных координатах проективные преобразования представляются как: &lt;/p&gt;
&lt;p&gt;$\begin{bmatrix}
x' \\
y' \\
1
\end{bmatrix} = 
\begin{bmatrix}
A &amp;amp; t \\
v &amp;amp; b
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
1
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;Это представление является обобщением аффинных преобразований за счёт добавления вектора $v$, который вводит дополнительные степени свободы.&lt;/p&gt;
&lt;p&gt;Несмотря на то, что проективные преобразования не сохраняют параллельность, они сохраняют:&lt;br&gt;
&lt;em&gt; Коллинеарность точек (прямые переходят в прямые)&lt;br&gt;
&lt;/em&gt; Перекрестное отношение четырёх коллинеарных точек.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Перекрестное отношение&lt;/strong&gt; четырёх точек $P_1, P_2, P_3, P_4$, лежащих на одной прямой, вычисляется по формуле:  &lt;/p&gt;
&lt;p&gt;$cross\ ratio = \frac{||P_3 - P_1||\ ||P_4 - P_2||}{||P_3 - P_2||\ ||P_4 - P_1||}$ (1)&lt;/p&gt;
&lt;p&gt;Доказательство инвариантности перекрестного отношения при проективных преобразованиях предлагается выполнить в качестве учебного упражнения. &lt;/p&gt;
&lt;h4&gt;2. Точки и прямые в бесконечности&lt;/h4&gt;
&lt;p&gt;Прямые играют важную роль в определении структуры изображений, поэтому важно понимать их представление как в 2D, так и в 3D пространстве.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Прямая на плоскости&lt;/strong&gt; может быть представлена однородным вектором $\ell = \begin{bmatrix} a &amp;amp; b &amp;amp; c \end{bmatrix}^T$.  &lt;/p&gt;
&lt;p&gt;Отношение $-\frac{a}{b}$ определяет наклон прямой, а отношение $-\frac{c}{b}$ — точку пересечения с осью $y$.  &lt;/p&gt;
&lt;p&gt;Для любой точки, лежащей на прямой, справедливо уравнение:&lt;/p&gt;
&lt;p&gt;$\forall p = \begin{bmatrix} x \\ y \end{bmatrix} \in \ell, \quad \begin{bmatrix} a &amp;amp; b &amp;amp; c \end{bmatrix} \begin{bmatrix} x \\ y \\ 1 \end{bmatrix} = 0$ (2)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Пересечение прямых&lt;/strong&gt;&lt;br&gt;
В общем случае две прямые $\ell$ и $\ell'$ пересекаются в точке $x$, которая определяется как векторное произведение этих прямых.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Доказательство: если две прямые пересекаются, точка пересечения $x$ должна лежать на обеих прямых. Следовательно, $x^T\ell = 0$ и $x^T\ell' = 0$. Если мы положим $x = \ell \times \ell'$, то по определению векторного произведения вектор $x$ будет ортогонален обоим векторам $\ell$ и $\ell'$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Параллельные прямые&lt;/strong&gt;&lt;br&gt;
В школьной геометрии считается, что параллельные прямые не пересекаются. Однако в однородных координатах можно сказать, что они пересекаются в бесконечности.  &lt;/p&gt;
&lt;p&gt;Рассмотрим две параллельные прямые $\ell$ и $\ell'$. Когда прямые параллельны, их наклоны равны: $\frac{a}{b} = \frac{a'}{b'}$. Если вычислить точку пересечения в однородных координатах, получим:&lt;/p&gt;
&lt;p&gt;$\ell \times \ell' \propto \begin{bmatrix} b \\ -a \\ 0 \end{bmatrix} = x_\infty$ (3)&lt;/p&gt;
&lt;p&gt;Это подтверждает, что параллельные прямые пересекаются в бесконечности. Точка пересечения параллельных прямых в бесконечности называется &lt;strong&gt;идеальной точкой&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;В однородных координатах идеальная точка в бесконечности представляется как:&lt;/p&gt;
&lt;p&gt;$\begin{bmatrix} x \ y \ 0 \end{bmatrix}^T$ &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Свойство идеальных точек&lt;/strong&gt;
Все параллельные прямые с одинаковым наклоном $-\frac{a}{b}$ проходят через идеальную точку:&lt;/p&gt;
&lt;p&gt;$\ell^T x_\infty = \begin{bmatrix} a &amp;amp; b &amp;amp; c \end{bmatrix} \begin{bmatrix} b \\ -a \\ 0 \end{bmatrix} = 0$ (4)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Бесконечно удалённые точки&lt;/strong&gt; позволяют определить прямую в бесконечности. Рассмотрим несколько пар параллельных прямых. Каждая пара пересекается в своей точке бесконечности $x_{\infty,i}$. Прямая $\ell_\infty$, проходящая через все эти точки, должна удовлетворять условию:&lt;/p&gt;
&lt;p&gt;$\forall i, \ell_\infty^T x_{\infty,i} = 0$&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 1: Точки в бесконечности образуют прямые в бесконечности" src="https://storage.yandexcloud.net/yahosting/photo_metro/1.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 1: Точки в бесконечности образуют прямые в бесконечности&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;Такая прямая имеет вид $\ell_\infty = \begin{bmatrix} 0 &amp;amp; 0 &amp;amp; c \end{bmatrix}^T$. Поскольку $c$ — произвольное значение, можно принять:&lt;/p&gt;
&lt;p&gt;$\ell_\infty = \begin{bmatrix} 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix}^T$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Проективное преобразование&lt;/strong&gt; точки в бесконечности:&lt;/p&gt;
&lt;p&gt;При применении проективного преобразования $H$ к точке в бесконечности $p_\infty$ получаем:&lt;/p&gt;
&lt;p&gt;$p' = Hp_\infty = \begin{bmatrix} A &amp;amp; t \\ v &amp;amp; b \end{bmatrix} \begin{bmatrix} 1 \\ 1 \\ 0 \end{bmatrix} = \begin{bmatrix} p'_x \\ p'_y \\ p'_z \end{bmatrix}$ (5)&lt;/p&gt;
&lt;p&gt;Заметим, что последний элемент $p'$ может стать ненулевым. Это означает, что проективное преобразование обычно переводит точки в бесконечности в точки, которые уже не находятся в бесконечности. Т.е. имеют конечные евклидовы координаты, пусть и за пределами изображения. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Аффинные преобразования&lt;/strong&gt; ведут себя иначе и всегда переводят точку из бесконечности в бесконечность:&lt;/p&gt;
&lt;p&gt;$p' = Hp_\infty = \begin{bmatrix} A &amp;amp; t \\ 0 &amp;amp; 1 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \\ 0 \end{bmatrix} = \begin{bmatrix} p'_x \\ p'_y \\ 0 \end{bmatrix}$ (6)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Преобразование прямых&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;При применении проективного преобразования $H$ к прямой $\ell$ получаем новую прямую $\ell'$. Все точки $x$, лежащие на прямой, должны удовлетворять условию $x^T\ell = 0$. В преобразованном пространстве прямые переходят в прямые, то есть $x'^T\ell' = 0$. Используя свойство тождественного преобразования, получаем:&lt;/p&gt;
&lt;p&gt;$x^TI\ell = x^TH^TH^{-T}\ell = 0$&lt;/p&gt;
&lt;p&gt;При применении &lt;strong&gt;проективного преобразования&lt;/strong&gt; к прямой происходит преобразование всех точек, лежащих на ней. Если $x$ — точка исходной прямой, то после преобразования получаем:&lt;/p&gt;
&lt;p&gt;$x' = Hx$&lt;/p&gt;
&lt;p&gt;Используя это преобразование, можно записать:&lt;/p&gt;
&lt;p&gt;$x^TH^TH^{-T}\ell = x'^T\ell'$,&lt;/p&gt;
&lt;p&gt;откуда следует, что проективное преобразование прямой имеет вид:&lt;/p&gt;
&lt;p&gt;$\ell' = H^{-T}\ell$&lt;/p&gt;
&lt;p&gt;Важные выводы:&lt;br&gt;
&lt;em&gt; При проективном преобразовании прямая в бесконечности не обязательно переходит в другую прямую в бесконечности&lt;br&gt;
&lt;/em&gt; В отличие от этого, &lt;strong&gt;аффинные преобразования&lt;/strong&gt; сохраняют прямые в бесконечности, переводя их в прямые в бесконечности.  &lt;/p&gt;
&lt;p&gt;Эти свойства имеют важное значение для понимания того, как различные типы преобразований влияют на структуру изображения и геометрию сцены. Особенно это касается работы с бесконечно удалёнными точками и прямыми, которые играют ключевую роль в проективной геометрии и компьютерном зрении.&lt;/p&gt;
&lt;p&gt;Таким образом, при работе с проективными преобразованиями необходимо учитывать, что они могут существенно изменять геометрию сцены, в том числе расположение прямых и точек в бесконечности, в то время как аффинные преобразования сохраняют некоторые геометрические свойства. &lt;/p&gt;
&lt;h4&gt;3. Точки и линии схода&lt;/h4&gt;
&lt;p&gt;В трёхмерном пространстве вводится понятие &lt;strong&gt;плоскости&lt;/strong&gt;, которая представляется вектором $\begin{bmatrix} a &amp;amp; b &amp;amp; c &amp;amp; d \end{bmatrix}^T$. 
Здесь $(a, b, c)$ образуют вектор нормали, а $d$ — расстояние от начала координат до плоскости в направлении этого вектора. Формально плоскость определяется как множество точек $x$, удовлетворяющих уравнению:&lt;/p&gt;
&lt;p&gt;$x^T \begin{bmatrix} a \\ b \\ c \\ d \end{bmatrix} = ax_1 + bx_2 + cx_3 + d = 0$ (7)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Прямые в 3D&lt;/strong&gt; определяются как пересечение двух плоскостей. Они имеют четыре степени свободы (точка пересечения и наклоны в трёх измерениях).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Точки в бесконечности&lt;/strong&gt; в 3D определяются как точки пересечения параллельных прямых. При проективном преобразовании таких точек получается &lt;strong&gt;точка схода&lt;/strong&gt; $p_\infty$ на плоскости изображения.&lt;/p&gt;
&lt;p&gt;Существует полезное соотношение между параллельными прямыми в 3D, их точкой схода на изображении и параметрами камеры $K$, $R$, $T$.&lt;/p&gt;
&lt;p&gt;Пусть $d = (a, b, c)$ — направление набора параллельных прямых в системе координат камеры. Тогда точка схода $v$ определяется как:&lt;/p&gt;
&lt;p&gt;$v = Kd$ (8)&lt;/p&gt;
&lt;p&gt;Отсюда можно выразить направление $d$:&lt;/p&gt;
&lt;p&gt;$d = \frac{K^{-1}v}{|K^{-1}v|}$ (9)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Линия горизонта&lt;/strong&gt; (или линия схода) $l_{horiz}$ — это проекция линии в бесконечности на плоскость изображения. Она проходит через соответствующие точки схода на изображении и вычисляется по формуле:&lt;/p&gt;
&lt;p&gt;$l_{horiz} = H^{-T}P l_\infty$ (10)&lt;/p&gt;
&lt;p&gt;Точки и линии схода являются важными инструментами для анализа структуры сцены и определения параметров камеры по изображению, т.к. они позволяют восстанавливать трёхмерную геометрию по двумерной проекции. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 2: Линия горизонта как множество точек схода" src="https://storage.yandexcloud.net/yahosting/photo_metro/2.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Линия горизонта&lt;/strong&gt; позволяет нам интуитивно определять свойства изображения, которые могут быть неочевидны с математической точки зрения. Например,  линии на земле не выглядят параллельными на изображении (как показано на рисунке 2), но интуитивно мы все же понимаем, что в трёхмерном пространстве они параллельны.&lt;/p&gt;
&lt;p&gt;Линия горизонта позволяет &lt;strong&gt;вычислять&lt;/strong&gt; важные характеристики сцены. Существует интересное соотношение между нормалью $n$ плоскости в 3D и соответствующей линией горизонта $l_{horiz}$ на изображении:&lt;/p&gt;
&lt;p&gt;$n = K^Tl_{horiz}$ (11)&lt;/p&gt;
&lt;p&gt;Это означает, что если мы можем определить линию горизонта, связанную с плоскостью, и знаем внутренние характеристики камеры $K$, мы можем оценить ориентацию этой плоскости.&lt;/p&gt;
&lt;p&gt;Теперь давайте рассмотрим понятие &lt;strong&gt;плоскость в бесконечности&lt;/strong&gt;.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 3: Плоскость в бесконечности" src="https://storage.yandexcloud.net/yahosting/photo_metro/3.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 3: Плоскость в бесконечности&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Эта плоскость определяется набором из двух или более линий схода. В однородных координатах плоскость описывается вектором:&lt;/p&gt;
&lt;p&gt;$Π_\infty = \begin{bmatrix} 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix}^T$ &lt;/p&gt;
&lt;p&gt;Плоскость в бесконечности поможет нам понять важное свойство, связывающее линии и плоскости в 3D с соответствующими точками и линиями схода на плоскости изображения.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 4: Определение угла между линиями" src="https://storage.yandexcloud.net/yahosting/photo_metro/4.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 4: Определение угла между линиями&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;Пусть две пары параллельных линий в 3D имеют направления $d_1$ и $d_2$, связанные с точками в бесконечности $x_{1,\infty}$ и $x_{2,\infty}$. 
Пусть $v_1$ и $v_2$ — соответствующие точки схода. 
Тогда угол $θ$ между $d_1$ и $d_2$ определяется по формуле:&lt;/p&gt;
&lt;p&gt;$\cos θ = \frac{d_1 \cdot d_2}{|d_1||d_2|} = \frac{v_1^T \omega v_2}{\sqrt{v_1^T \omega v_1} \sqrt{v_2^T \omega v_2}}$ (12)&lt;/p&gt;
&lt;p&gt;где $\omega = (KK^T)^{-1}$.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Матрица $\omega$&lt;/strong&gt; определяется через матрицу камеры $K$ следующим образом:&lt;/p&gt;
&lt;p&gt;$\omega = (K K^T)^{-1}$&lt;/p&gt;
&lt;p&gt;Эта матрица имеет важные свойства:  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Симметричность: матрица $\omega$ является симметричной, так как $K K^T$ — симметричная матрица, а обратная к симметричной матрице также симметрична&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Связь с параметрами камеры: содержит информацию о внутренних параметрах камеры, зависит от фокусных расстояний, координат главной точки и коэффициента скоса (skew).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;При стандартных предположениях о камере (нулевой скос, квадратные пиксели) матрица $\omega$ имеет вид:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$\omega = \begin{bmatrix}
\omega_1 &amp;amp; 0 &amp;amp; \omega_4 \\
0 &amp;amp; \omega_1 &amp;amp; \omega_5 \\
\omega_4 &amp;amp; \omega_5 &amp;amp; \omega_6
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;Матрица $\omega$ определяется с точностью до масштабного множителя, что влияет на количество независимых переменных при решении системы уравнений. Это свойство учитывается при калибровке камеры и восстановлении 3D-структуры сцены.&lt;/p&gt;
&lt;p&gt;Это соотношение показывает, как можно определить угол между направлениями в пространстве, используя только точки схода на изображении и параметры камеры.&lt;/p&gt;
&lt;p&gt;И наконец, расширим рассмотренную концепцию на случай трёхмерных плоскостей, чтобы установить связь между различными плоскостями в 3D пространстве.&lt;/p&gt;
&lt;p&gt;Для любой плоскости мы можем:&lt;br&gt;
&lt;em&gt; Вычислить соответствующую линию горизонта $l_{horiz}$&lt;br&gt;
&lt;/em&gt; Определить нормаль к плоскости $n = K^\ l_{horiz}$  &lt;/p&gt;
&lt;p&gt;Угол $\theta$ между двумя плоскостями можно определить через угол между их нормалями $n_1$ и $n_2$. 
Рассмотрим две плоскости с линиями горизонта $l_1$ и $l_2$ соответственно. 
Угол между нормалями этих плоскостей определяется формулой:&lt;/p&gt;
&lt;p&gt;$\cos \theta = \frac{n_1 \cdot n_2}{|n_1||n_2|} = \frac{l_1^T \omega^{-1} l_2}{\sqrt{l_1^T \omega^{-1} l_1} \sqrt{l_2^T \omega^{-1} l_2}}$ (13)&lt;/p&gt;
&lt;p&gt;Таким образом, используя линии горизонта и параметры камеры, мы можем восстанавливать пространственные отношения между плоскостями в сцене, что является важным инструментом в компьютерном зрении и трёхмерной реконструкции.&lt;/p&gt;
&lt;h4&gt;4. Алгоритм калибровки камеры и измерения углов&lt;/h4&gt;
&lt;p&gt;Рассмотрим пример решения задачи калибровки камеры по одной фотографии. 
Для этого нам понадобится изображение трёхмерного мира, на котором мы можем выполнить следующие операции:&lt;br&gt;
&lt;em&gt; Определить три плоскости и на каждой из этих плоскостей пару параллельных линий&lt;br&gt;
&lt;/em&gt; Идентифицировать точки схода $v_1$ $v_2$ и $v_3$&lt;br&gt;
* Использовать априорное знание и том, что плоскости перпендикулярны в 3D пространстве.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 5: Точки схода на перпендикулярных плоскостях" src="https://storage.yandexcloud.net/yahosting/photo_metro/6.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 5: Точки схода на перпендикулярных плоскостях&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Из уравнения (12) мы знаем, что для перпендикулярных плоскостей выполняется соотношение $v_1\omega v_2 = 0$. &lt;/p&gt;
&lt;p&gt;Если мы имеем три точки схода для трех взаимно перпендикулярной плоскости, то получаем систему: &lt;/p&gt;
&lt;p&gt;$v_1\omega v_2 = 0$&lt;br&gt;
 $v_1\omega v_3 = 0$&lt;br&gt;
 $v_2\omega v_3 = 0$  &lt;/p&gt;
&lt;p&gt;При предположении об отсутствии скоса камеры и квадратных пикселях, мы можем решить эту систему относительно элементов матрицы $\omega_1, \omega_4, \omega_5, \omega_6$ (с точностью до масштаба).  &lt;/p&gt;
&lt;p&gt;Зная матрицу $\omega$, можно вычислить элементы матрицы камеры $K$ с помощью разложения Холецкого. &lt;/p&gt;
&lt;p&gt;Таким образом, мы выполняем калибровку камеры всего по одному изображению. 
После определения $K$ мы можем восстановить 3D-геометрию сцены, вычислить ориентацию всех идентифицированных плоскостей, а также получить обширную информацию о снимаемой сцене с точностью до масштабного коэффициента. &lt;/p&gt;</description><category>cs231a</category><guid>https://mldl.ru/posts/single-view-metrology/</guid><pubDate>Wed, 01 Oct 2025 11:00:00 GMT</pubDate></item><item><title>Калибровка камеры </title><link>https://mldl.ru/posts/camera-calibration/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;p&gt;&lt;strong&gt;Калибровка камеры&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Чтобы точно знать преобразование из реального трёхмерного мира в цифровые изображения, необходимо заранее знать многие внутренние параметры камеры. Если у нас есть произвольная камера, мы можем как иметь доступ к этим параметрам, так и не иметь его. Однако у нас есть доступ к изображениям, которые делает камера.&lt;/p&gt;
&lt;p&gt;Возникает вопрос: можем ли мы найти способ вывести эти параметры из изображений? Эта задача оценки внешних и внутренних параметров камеры известна как &lt;strong&gt;калибровка камеры&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Калибровка камеры&lt;/strong&gt; — это фундаментальный процесс в компьютерном зрении и обработке изображений, который позволяет нам переходить от наблюдаемых пикселей к реальным координатам в пространстве.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 1: Пример калибровочной установки" src="https://storage.yandexcloud.net/yahosting/calibrate/1.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 1: Пример калибровочной установки&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Процесс калибровки камеры заключается в определении &lt;strong&gt;внутренней матрицы камеры&lt;/strong&gt; $K$ и &lt;strong&gt;внешних параметров&lt;/strong&gt; $R$, $T$ из уравнения (1).  &lt;/p&gt;
&lt;p&gt;$P' = K \begin{bmatrix} R &amp;amp; T \end{bmatrix} P_w = MP_w$     (1)&lt;/p&gt;
&lt;p&gt;Рассмотрим этот процесс в контексте калибровочной установки, подобной показанной на рисунке 1.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Калибровочная установка&lt;/strong&gt; обычно состоит из простого шаблона (например, шахматной доски) с известными размерами. Кроме того, установка определяет нашу мировую систему координат с началом $O_w$ и осями $i_w$, $j_w$, $k_w$.&lt;/p&gt;
&lt;p&gt;Из известного шаблона мы получаем точки в мировой системе координат $P_1, ..., P_n$. Найдя эти точки на изображении, полученном с камеры, мы получаем соответствующие точки изображения $p_1, ..., p_n$.&lt;/p&gt;
&lt;p&gt;Мы составляем линейную систему уравнений из $n$ соответствий, таких что для каждого соответствия $P_i$, $p_i$ и матрицы камеры $M$, строки которой $m_1$, $m_2$, $m_3$:&lt;/p&gt;
&lt;p&gt;$p_i = \begin{pmatrix} u_i \\ v_i \end{pmatrix} = MP_i = \begin{pmatrix} \frac{m_1P_i}{m_3P_i} \\ \frac{m_2P_i}{m_3P_i} \end{pmatrix}$ (2)&lt;/p&gt;
&lt;p&gt;Уравнение (2) даёт нам два ограничения для нахождения неизвестных параметров, содержащихся в $m$.&lt;/p&gt;
&lt;p&gt;Мы знаем, что матрица камеры имеет 11 неизвестных параметров (6 внешних и 5 внутренних). Это означает, что нам нужно как минимум 6 соответствий для решения. Однако в реальном мире мы часто используем больше соответствий, поскольку измерения часто зашумлены.&lt;/p&gt;
&lt;p&gt;Для каждой точки $P_i$ мы можем вывести пару уравнений, связывающих координаты на плоскости $u_i, v_i$ с 3D координатами:&lt;/p&gt;
&lt;p&gt;$u_i(m_3P_i) − m_1P_i = 0$&lt;br&gt;
$v_i(m_3P_i) − m_2P_i = 0$&lt;/p&gt;
&lt;p&gt;При наличии $n$ таких соответствующих точек вся линейная система уравнений принимает вид:&lt;/p&gt;
&lt;p&gt;$u_1(m_3P_1)−m_1P_1 = 0$&lt;br&gt;
$v_1(m_3P_1)−m_2P_1 = 0$&lt;br&gt;
...&lt;br&gt;
$u_n(m_3P_n)−m_1P_n = 0$&lt;br&gt;
$v_n(m_3P_n)−m_2P_n = 0$  &lt;/p&gt;
&lt;p&gt;Мы можем вынести вектора $m_1 , m_2, m_3$ и представить эту систему уравнений в виде матричного произведения:&lt;/p&gt;
&lt;p&gt;$\begin{bmatrix}
P_1^T &amp;amp; 0^T &amp;amp; -u_1P_1^T  \\
0^T &amp;amp; P_1^T &amp;amp; -v_1P_1^T  \\
\vdots &amp;amp; \vdots &amp;amp; \vdots \\
P_n^T &amp;amp; 0^T &amp;amp; -u_nP_n^T  \\
0^T &amp;amp; P_n^T &amp;amp; -v_nP_n^T
\end{bmatrix}
\begin{bmatrix}
m_1^T \\
m_2^T \\
m_3^T
\end{bmatrix} = Pm = 0$ (3)&lt;/p&gt;
&lt;p&gt;Когда $2n &amp;gt; 11$, наша однородная линейная система является переопределённой. Для такой системы $m = 0$ всегда является тривиальным решением. Более того, даже если существует ненулевое решение $m$, то для любого $\rho \in \mathbb{R}$, $km$ также будет решением.&lt;/p&gt;
&lt;p&gt;Поэтому для ограничения решения мы выполняем следующую минимизацию:&lt;/p&gt;
&lt;p&gt;$\min_{m} |Pm|^2 \quad \text{при условии} \quad |m|^2 = 1$ (4)&lt;/p&gt;
&lt;p&gt;Для решения этой задачи минимизации используется сингулярное разложение. Если обозначить $P = UDV^T$, то решение задачи минимизации заключается в том, чтобы установить $m$ равным последнему столбцу матрицы $V$.
Обоснование данного решения выходит за рамки этого курса. Для более подробного изучения вы можете обратиться к разделу 5.3 книги Hartley &amp;amp; Zisserman стр. 592–593. &lt;/p&gt;
&lt;p&gt;В этом разделе вы найдёте:&lt;br&gt;
- Математическое обоснование метода&lt;br&gt;
- Подробное доказательство решения&lt;br&gt;
- Дополнительные технические детали  &lt;/p&gt;
&lt;p&gt;После преобразования вектора $m$ в матрицу $M$ мы хотим явно найти внешние и внутренние параметры камеры.&lt;/p&gt;
&lt;p&gt;C помощью SVD мы вычислили матрицу $M$, с точностью до масштабного множителя $\rho$. &lt;/p&gt;
&lt;p&gt;$\rho M = \begin{bmatrix}
\alpha r_1^T - \alpha \cot \theta r_2^T + c_x r_3^T &amp;amp; \alpha t_x - \alpha \cot \theta t_y + c_x t_z \\
\frac{\beta}{\sin \theta} r_2^T + c_y r_3^T &amp;amp; \frac{\beta}{\sin \theta} t_y + c_y t_z \\
r_3^T &amp;amp; t_z
\end{bmatrix}$ (5)&lt;/p&gt;
&lt;p&gt;где $r_1^T$, $r_2^T$, и $r_3^T$ — это три строки матрицы вращения $R$.&lt;/p&gt;
&lt;p&gt;Разделим на скаляр $\rho$ и обозначим первый столбец как матрицу $A$, а второй столбец как вектор $b$:&lt;/p&gt;
&lt;p&gt;$M = \frac{1}{\rho} \begin{bmatrix}
\alpha r_1^T - \alpha \cot \theta r_2^T + c_x r_3^T &amp;amp; \alpha t_x - \alpha \cot \theta t_y + c_x t_z \\
\frac{\beta}{\sin \theta} r_2^T + c_y r_3^T &amp;amp; \frac{\beta}{\sin \theta} t_y + c_y t_z \\
r_3^T &amp;amp; t_z
\end{bmatrix} =
\begin{bmatrix}
A &amp;amp; b
\end{bmatrix} =
\begin{bmatrix}
a_1^T &amp;amp; b_1 \\
a_2^T &amp;amp; b_2 \\
a_3^T &amp;amp; b_3
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;Теперь мы можем вычислить внутренние параметры камеры через элементы известной матрицы $M$, она же $A$ и $b$: (6)&lt;/p&gt;
&lt;p&gt;Масштабный множитель:&lt;br&gt;
$\rho = \pm \frac{1}{|a_3|}$  &lt;/p&gt;
&lt;p&gt;Координаты главной точки:&lt;br&gt;
$c_x = \rho^2 (a_1 \cdot a_3)$&lt;br&gt;
$c_y = \rho^2 (a_2 \cdot a_3)$  &lt;/p&gt;
&lt;p&gt;Угол скоса:&lt;br&gt;
$\theta = \cos^{-1} \left( -\frac{(a_1 \times a_3) \cdot (a_2 \times a_3)}{|a_1 \times a_3| \cdot |a_2 \times a_3|} \right)$ &lt;/p&gt;
&lt;p&gt;Масштабные коэффициенты:&lt;br&gt;
$\alpha = \rho^2 |a_1 \times a_3| \sin \theta$&lt;br&gt;
$\beta = \rho^2 |a_2 \times a_3| \sin \theta$  &lt;/p&gt;
&lt;p&gt;Формулы для вычисления внешних параметров (7)&lt;/p&gt;
&lt;p&gt;Матрица вращения:&lt;br&gt;
  $r_1 = \frac{a_2 \times a_3}{|a_2 \times a_3|}$&lt;br&gt;
  $r_2 = r_3 \times r_1$&lt;br&gt;
  $r_3 = \rho a_3$  &lt;/p&gt;
&lt;p&gt;Вектор переноса:&lt;br&gt;
  $T = \rho K^{-1} b$&lt;/p&gt;
&lt;p&gt;При подготовке данных для процедуры калибровки важно учитывать особые случаи, при которых процесс может дать некорректные результаты. 
 &lt;strong&gt;Вырожденные конфигурации&lt;/strong&gt; возникают, когда точки $P_i$ располагаются в одной плоскости или лежат на кривой пересечения двух квадрик. В таких случаях система уравнений становится неразрешимой, что приводит к невозможности корректного определения параметров камеры.
Чтобы избежать подобных проблем, следует тщательно подходить к процессу калибровки. Необходимо использовать точки с различной глубиной расположения, обеспечивать разнообразие положений калибровочной мишени в пространстве и внимательно следить за распределением точек. Важно также проверять качество получаемых данных и анализировать корректность результатов на тестовых наборах.
Для более глубокого понимания теоретических аспектов рекомендуется обратиться к разделу 1.3.1 учебника Forsyth &amp;amp; Ponce, где подробно рассматриваются вырожденные конфигурации и методы их предотвращения.&lt;/p&gt;
&lt;h4&gt;2. Компенсация искажений при калибровке камеры&lt;/h4&gt;
&lt;p&gt;До этого момента мы рассматривали идеальные линзы, свободные от любых искажений. Однако в реальности объективы могут отклоняться от прямолинейной проекции, что требует применения более сложных методов обработки. В этом разделе мы кратко рассмотрим подходы к работе с искажениями.&lt;/p&gt;
&lt;p&gt;Благодаря физической симметрии линзы &lt;strong&gt;радиальные искажения&lt;/strong&gt; тоже обладают симметрией. 
 Для моделирования радиальных искажений используется изотропное преобразование $Q$:&lt;/p&gt;
&lt;p&gt;$Q P_i =
\begin{bmatrix}
q_1 \\ q_2 \\ q_3
\end{bmatrix} P_i = 
\begin{bmatrix}
\frac{1}{\lambda} &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; \frac{1}{\lambda} &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 1
\end{bmatrix} M P_i = 
\begin{bmatrix}
u_i \\
v_i
\end{bmatrix} = p_i$ (8)&lt;/p&gt;
&lt;p&gt;Переписав в систему векторных уравнений, получаем:  &lt;/p&gt;
&lt;p&gt;$u_i q_3 P_i = q_1 P_i$ &lt;br&gt;
$v_i q_3 P_i = q_2 P_i$   &lt;/p&gt;
&lt;p&gt;Однако такая система перестаёт быть линейной, и для её решения требуются методы &lt;strong&gt;нелинейной оптимизации&lt;/strong&gt;, которые подробно рассматриваются в разделе 22.2 учебника Forsyth &amp;amp; Ponce.&lt;/p&gt;
&lt;p&gt;Упростить процесс нелинейной оптимизации при калибровке можно, сделав определённые допущения. В случае радиальных искажений важно отметить, что соотношение между координатами $u_i$ и $v_i$ остаётся неизменным. Это соотношение можно вычислить следующим образом:&lt;/p&gt;
&lt;p&gt;$\frac{u_i}{v_i} = \frac{\frac{m_1P_i}{m_3P_i}}{\frac{m_2P_i}{m_3P_i}} = \frac{m_1P_i}{m_2P_i}$ (18)&lt;/p&gt;
&lt;p&gt;При наличии $n$ соответствий мы можем составить систему линейных уравнений следующего вида:&lt;/p&gt;
&lt;p&gt;$v_1(m_1P_1) - u_1(m_2P_1) = 0$&lt;br&gt;
$\vdots$&lt;br&gt;
$v_n(m_1P_n) - u_n(m_2P_n) = 0$  &lt;/p&gt;
&lt;p&gt;Эта система может быть представлена в виде матрично-векторного произведения, решаемого с помощью &lt;strong&gt;сингулярного разложения (SVD)&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;$L n = \begin{bmatrix}
v_1P_1^T &amp;amp; -u_1P_1^T \\
\vdots &amp;amp; \vdots \\
v_nP_n^T &amp;amp; -u_nP_n^T
\end{bmatrix}
\begin{bmatrix}
m_1^T \\
m_2^T
\end{bmatrix}$ (19)&lt;/p&gt;
&lt;p&gt;После оценки векторов $m_1$ и $m_2$ вектор $m_3$ может быть выражен как &lt;strong&gt;нелинейная функция&lt;/strong&gt; от $m_1$, $m_2$ и $\lambda$. Это приводит к необходимости решения задачи &lt;strong&gt;нелинейной оптимизации&lt;/strong&gt;, которая значительно проще исходной задачи оценки элементов матрицы $Q$.&lt;/p&gt;
&lt;p&gt;Процесс решения включает следующие этапы:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Формирование матрицы $L n$ на основе известных соответствий между точками  &lt;/li&gt;
&lt;li&gt;Применение SVD для нахождения $m_1$ и $m_2$  &lt;/li&gt;
&lt;li&gt;Вычисление $m_3$ через нелинейную зависимость  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Используем условие ортогональности:  &lt;/p&gt;
&lt;p&gt;$m_1 \cdot m_3 = 0$ и $m_2 \cdot m_3 = 0$  &lt;/p&gt;
&lt;p&gt;Учитываем нормировку:  &lt;/p&gt;
&lt;p&gt;$|m_3| = 1$&lt;/p&gt;
&lt;p&gt;Вводим зависимость от параметра $\lambda$, итоговая формула для вычисления $m_3$ имеет вид:  &lt;/p&gt;
&lt;p&gt;$m_3 = \frac{m_1 \times m_2}{|m_1 \times m_2|} \cdot g(\lambda)$  &lt;/p&gt;
&lt;p&gt;где $g(\lambda)$ — некоторая функция от параметра $\lambda$, зависящая от конкретной модели искажений.&lt;/p&gt;
&lt;p&gt;Вид функции $g(\lambda)$ зависит от требуемой точности модели. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Полиномиальная модель&lt;/strong&gt; общего вида: &lt;/p&gt;
&lt;p&gt;$g(\lambda) = 1 + k_1\lambda^2 + k_2\lambda^4 + k_3\lambda^6 + ...$  &lt;/p&gt;
&lt;p&gt;где $k_1, k_2, k_3$ — коэффициенты радиальных искажений.&lt;/p&gt;
&lt;p&gt;На практике используют вычислительно несложные модели:  &lt;/p&gt;
&lt;p&gt;$g(\lambda) = 1 + k_1\lambda^2$&lt;/p&gt;
&lt;p&gt;или&lt;/p&gt;
&lt;p&gt;$g(\lambda) = 1 + k_1\lambda^2 + k_2\lambda^4$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Модель Брауна&lt;/strong&gt; включает как радиальные, так и тангенциальные искажения:&lt;/p&gt;
&lt;p&gt;$x_{distorted} = x(1 + k_1r^2 + k_2r^4) + 2p_1xy + p_2(r^2 + 2x^2)$  &lt;/p&gt;
&lt;p&gt;$y_{distorted} = y(1 + k_1r^2 + k_2r^4) + p_1(r^2 + 2y^2) + 2p_2xy$  &lt;/p&gt;
&lt;p&gt;где $r^2 = x^2 + y^2$  &lt;/p&gt;
&lt;h4&gt;Резюме&lt;/h4&gt;
&lt;p&gt;Калибровка камеры — это комплексный процесс определения внутренних и внешних параметров оптической системы для точного преобразования координат между трёхмерным пространством и двумерным изображением. 
В основе калибровки лежит использование калибровочной мишени с известными координатами, что позволяет установить соответствие между мировыми и экранными координатами. Процесс включает определение матрицы камеры, которая содержит информацию о фокусном расстоянии, координатах главной точки и коэффициентах искажения.&lt;/p&gt;
&lt;p&gt;Важным этапом является учёт искажений, которые неизбежно присутствуют в реальных объективах. Для их компенсации применяются специальные математические модели, чаще всего основанные на полиномиальных функциях радиальных искажений. 
При калибровке необходимо избегать вырожденных конфигураций, когда точки располагаются в одной плоскости, что делает невозможным корректное определение параметров. 
Практическая реализация требует достаточного количества калибровочных изображений с разнообразным расположением мишени относительно камеры. После завершения калибровки получается набор параметров, позволяющий компенсировать искажения и восстанавливать пространственные координаты по изображениям с точностью до удаления $z$. &lt;/p&gt;
&lt;p&gt;Качество калибровки напрямую влияет на точность последующих измерений и является критически важным этапом в системах компьютерного зрения и машинного обучения.&lt;/p&gt;</description><category>cs231a</category><guid>https://mldl.ru/posts/camera-calibration/</guid><pubDate>Tue, 30 Sep 2025 11:00:00 GMT</pubDate></item><item><title>Основы трехмерного компьютерного зрения </title><link>https://mldl.ru/posts/base-3d/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;h4&gt;1. Введение&lt;/h4&gt;
&lt;p&gt;Камера является одним из важнейших инструментов в компьютерном зрении. Это механизм, с помощью которого мы можем фиксировать окружающий мир и использовать получаемые результаты — фотографии — для различных приложений. Поэтому один из фундаментальных вопросов трехмерного компьютерного зрения звучит так: как мы можем смоделировать камеру? &lt;/p&gt;
&lt;h4&gt;2. Камера-обскура&lt;/h4&gt;
&lt;p&gt;Камера-обскура — это простейшая система, которая позволяет фиксировать изображение объекта или сцены в трёхмерном мире. Такая система может быть создана путём размещения преграды с небольшим отверстием (апертурой) между трёхмерным объектом и фотоплёнкой или светочувствительным сенсором.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 1: Модель камеры обскуры" src="https://storage.yandexcloud.net/yahosting/3d/1.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 1: Модель камеры обскуры&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Как показано на рисунке 1, каждая точка на трёхмерном объекте испускает множество световых лучей во все стороны. Без преграды каждая точка на плёнке подвергалась бы воздействию световых лучей, исходящих от каждой точки трёхмерного объекта. Благодаря наличию преграды через отверстие проходит только один (или несколько) из этих лучей света и попадает на плёнку.&lt;/p&gt;
&lt;p&gt;Таким образом, мы можем установить взаимно-однозначное соответствие между точками на трёхмерном объекте и точками на плёнке. В результате плёнка получает «изображение» трёхмерного объекта посредством такого отображения. Эта простая модель известна как модель камеры-обскуры.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 2: Формальная модель камеры-обскуры" src="https://storage.yandexcloud.net/yahosting/3d/2.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 2: Формальная модель модели камеры-обскуры&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Более формальное построение камеры-обскуры показано на рисунке 2. В этой конструкции плёнка обычно называется &lt;strong&gt;плоскостью изображения&lt;/strong&gt; или &lt;strong&gt;сетчаткой&lt;/strong&gt;. Отверстие называется &lt;strong&gt;точечным отверстием&lt;/strong&gt; O или центром камеры. Расстояние между плоскостью изображения и точечным отверстием O называется &lt;strong&gt;фокусным расстоянием&lt;/strong&gt; f.&lt;/p&gt;
&lt;p&gt;Иногда плоскость сетчатки размещается между точкой O и трёхмерным объектом на расстоянии f от O. В этом случае она называется &lt;strong&gt;виртуальной плоскостью изображения&lt;/strong&gt; или &lt;strong&gt;виртуальной плоскостью сетчатки&lt;/strong&gt;. Важно отметить, что проекция объекта на плоскость изображения и изображение объекта на виртуальной плоскости изображения идентичны с точностью до масштабного (подобного) преобразования.&lt;/p&gt;
&lt;p&gt;Теперь рассмотрим, как использовать камеры-обскуры. Пусть P = [x y z]ᵀ — точка на некотором трёхмерном объекте, видимом для камеры-обскуры. Точка P будет отображена или спроецирована на плоскость изображения Π', в результате чего получится точка P' = [x' y']ᵀ.&lt;/p&gt;
&lt;p&gt;Аналогично, само точечное отверстие может быть спроецировано на плоскость изображения, что даст новую точку C'. Здесь мы можем определить систему координат [i j k], центрированную в точке отверстия O, так что ось k перпендикулярна плоскости изображения и направлена к ней. Эта система координат часто известна как &lt;strong&gt;система отсчёта камеры&lt;/strong&gt; или &lt;strong&gt;система координат камеры&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Линия, определяемая точками C' и O, называется &lt;strong&gt;оптической осью&lt;/strong&gt; системы камеры. &lt;/p&gt;
&lt;p&gt;Напомним, что точка $P_0$ получается в результате проекции трёхмерной точки $P$ на плоскость изображения $Π'$. 
Следовательно, если мы выведем соотношение между трёхмерной точкой $P$ и точкой $P'$ на плоскости изображения, мы сможем понять, как трёхмерный мир отображается на снимке, сделанном камерой-обскурой.&lt;/p&gt;
&lt;p&gt;Обратите внимание, что треугольник $P' C'O$ подобен треугольнику, образованному точками $P$, $O$ и $(0, 0, z)$. 
Используя теорему о подобных треугольниках, мы получаем:&lt;/p&gt;
&lt;p&gt;$P' = \begin{pmatrix} x' \\ y' \end{pmatrix} = \begin{pmatrix} \frac{fx}{z} \\ \frac{fy}{z} \end{pmatrix}$ (1)&lt;/p&gt;
&lt;p&gt;Важно отметить, что в этой модели камеры-обскуры мы делаем одно существенное допущение: апертура (отверстие) считается одной точкой. Однако в большинстве реальных ситуаций мы не можем предполагать, что апертура может быть бесконечно малой. Возникает вопрос: как влияет изменение размера апертуры на результат?&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 3: Влияние размера апертуры на изображение" src="https://storage.yandexcloud.net/yahosting/3d/3.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 3: Влияние размера апертуры на изображение&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;При уменьшении размера апертуры изображение становится более резким, но более тёмным.&lt;/p&gt;
&lt;p&gt;По мере увеличения размера апертуры количество световых лучей, проходящих через преграду, соответственно возрастает. При большем количестве проходящих лучей каждая точка на плёнке может подвергаться воздействию световых лучей от нескольких точек в трёхмерном пространстве, что приводит к размытию изображения.&lt;/p&gt;
&lt;p&gt;Хотя может показаться заманчивым сделать апертуру как можно меньше, следует помнить, что меньший размер апертуры пропускает меньше световых лучей, в результате чего изображение получается более чётким, но более тёмным.&lt;/p&gt;
&lt;p&gt;Таким образом, мы приходим к фундаментальной проблеме, возникающей при использовании  камеры-обскуры: возможно ли создать камеру, которая делает одновременно чёткие и яркие изображения?&lt;/p&gt;
&lt;h4&gt;3. Камеры и линзы&lt;/h4&gt;
&lt;p&gt;В современных камерах указанное противоречие между резкостью и яркостью изображения решается с помощью &lt;strong&gt;линз&lt;/strong&gt; — устройств, способных фокусировать или рассеивать свет.&lt;/p&gt;
&lt;p&gt;Если заменить отверстие (апертуру) камеры-обскуры на линзу, которая правильно расположена и имеет подходящий размер, то она будет обладать следующим свойством: все световые лучи, испускаемые некоторой точкой $P$, преломляются линзой таким образом, что они сходятся в одной точке $P'$. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 4: Схема простой модели линзы" src="https://storage.yandexcloud.net/yahosting/3d/4.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 4: Схема простой модели линзы&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;На рисунке 4 показано, как лучи от верхней точки дерева хорошо сходятся на плёнке. Однако точка, находящаяся на другом расстоянии от линзы, приводит к тому, что лучи не сходятся идеально на плёнке.&lt;/p&gt;
&lt;p&gt;Благодаря линзе проблема блокировки большинства световых лучей из-за малого отверстия устраняется (см. рисунок 4). Однако важно отметить, что это свойство выполняется не для всех точек трёхмерного пространства, а только для определённой точки $P$.&lt;/p&gt;
&lt;p&gt;Рассмотрим другую точку $Q$, которая находится ближе или дальше от плоскости изображения, чем точка $P$. Соответствующая проекция на изображение будет размытой или не в фокусе. Таким образом, у линз есть определённое расстояние, на котором объекты находятся «в фокусе».
Эффективный диапазон, в пределах которого камеры могут делать чёткие снимки называется &lt;strong&gt;глубина резкости&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 5: Фокусировка световых лучей с помощью линзы" src="https://storage.yandexcloud.net/yahosting/3d/5.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 5: Фокусировка световых лучей с помощью линзы&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;На данном рисунке демонстрируется, как линза фокусирует световые лучи, параллельные оптической оси, в &lt;strong&gt;фокусе&lt;/strong&gt; (фокальной точке). Эта схема также иллюстрирует &lt;strong&gt;модель параксиального преломления&lt;/strong&gt; — упрощённую модель, которая помогает установить взаимосвязь между точками на плоскости изображения и объектами в трёхмерном пространстве для камер с линзами.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Параксиальное преломление&lt;/strong&gt; — это приближение, используемое в оптике, которое позволяет:&lt;br&gt;
- точно рассчитывать траектории световых лучей;&lt;br&gt;
- определять положение точек в пространстве;&lt;br&gt;
- вычислять параметры фокусировки;&lt;br&gt;
- моделировать работу оптических систем.  &lt;/p&gt;
&lt;p&gt;Такая модель является фундаментальной для понимания принципов работы современных камер и систем компьютерного зрения. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Объективы камер&lt;/strong&gt; обладают ещё одним важным свойством: они фокусируют все световые лучи, движущиеся параллельно оптической оси, в одну точку, известную как &lt;strong&gt;фокусная точка&lt;/strong&gt; (см. рисунок 5). Расстояние между фокусной точкой и центром линзы называется &lt;strong&gt;фокусным расстоянием&lt;/strong&gt; $f$.&lt;/p&gt;
&lt;p&gt;Кроме того, световые лучи, проходящие через центр линзы, не отклоняются. Благодаря этому мы можем построить конструкцию, аналогичную модели камеры-обскуры, которая связывает точку $P$ в трёхмерном пространстве с соответствующей точкой $P'$ на плоскости изображения:&lt;/p&gt;
&lt;p&gt;$P' = \begin{pmatrix} x' \\ y' \end{pmatrix} = \begin{pmatrix} z' \frac{x}{z} \\ z' \frac{y}{z} \end{pmatrix}$ (2)&lt;/p&gt;
&lt;p&gt;Важно отметить следующие различия между моделями:&lt;br&gt;
- В модели камеры-обскуры $z' = f$&lt;br&gt;
- В модели с линзой $z' = f + z_0$  &lt;/p&gt;
&lt;p&gt;Данное соотношение основано на &lt;strong&gt;параксиальном приближении&lt;/strong&gt; (или предположении о «тонкой линзе»), а такая модель называется &lt;strong&gt;моделью параксиального преломления&lt;/strong&gt;. Подробное доказательство этой модели выходит за рамки данного курса. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 6: Подушкообразное и бочкообразное искажение изображения" src="https://storage.yandexcloud.net/yahosting/3d/6.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 6: Подушкообразное и бочкообразное искажение изображения&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Поскольку модель параксиального преломления использует приближение тонкой линзы, может возникать ряд аберраций. Наиболее распространённой из них является &lt;strong&gt;радиальное искажение&lt;/strong&gt;, которое приводит к уменьшению или увеличению увеличения изображения в зависимости от расстояния до оптической оси.&lt;/p&gt;
&lt;p&gt;Мы классифицируем радиальное искажение следующим образом:&lt;br&gt;
- &lt;strong&gt;Подушкообразное искажение&lt;/strong&gt; — когда увеличение возрастает&lt;br&gt;
- &lt;strong&gt;Бочкообразное искажение&lt;/strong&gt; — когда увеличение уменьшается.  &lt;/p&gt;
&lt;p&gt;Радиальное искажение возникает из-за того, что различные участки линзы имеют разные фокусные расстояния. Это явление наглядно показано на рисунке 6, где можно увидеть, как эти типы искажений влияют на конечное изображение.&lt;/p&gt;
&lt;p&gt;Такие искажения особенно заметны:
- По краям кадра
- При использовании широкоугольных объективов
- В системах компьютерного зрения, где важна точность геометрических измерений &lt;/p&gt;
&lt;h4&gt;4. Матричная модель камеры&lt;/h4&gt;
&lt;p&gt;В этом разделе мы рассмотрим детали параметров, которые необходимо учитывать при моделировании проекции из трёхмерного пространства на известные нам цифровые изображения. Все полученные результаты будут использовать модель камеры-обскуры, но они также применимы и к модели параксиального преломления.&lt;/p&gt;
&lt;p&gt;Как обсуждалось ранее, точка $P$ в трёхмерном пространстве может быть отображена (или спроецирована) в двумерную точку $P'$ на плоскости изображения $Π'$. Такое отображение $R^3 → R^2$ называется &lt;strong&gt;проективным преобразованием&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Однако такая проекция трёхмерных точек на плоскость изображения не соответствует напрямую тому, что мы видим в реальных цифровых изображениях по нескольким причинам:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Точки в цифровых изображениях, как правило, находятся в другой системе отсчёта, чем точки в плоскости изображения.&lt;/li&gt;
&lt;li&gt;Цифровые изображения разделены на дискретные пиксели, тогда как точки в плоскости изображения являются непрерывными.&lt;/li&gt;
&lt;li&gt;Физические датчики могут вносить нелинейные искажения в отображение.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Чтобы учесть эти различия, мы введём ряд дополнительных преобразований, которые позволят нам отображать любую точку из трёхмерного мира в координаты пикселей.&lt;/p&gt;
&lt;p&gt;Таким образом, нам необходимо: &lt;br&gt;
- Учесть различия в системах координат;&lt;br&gt;
- Преобразовать непрерывные координаты в дискретные пиксельные;&lt;br&gt;
- Компенсировать возможные искажения сенсора.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Матричная модель камеры&lt;/strong&gt; описывает набор важных параметров, влияющих на то, как точка мира $P$ отображается в координаты изображения $P'$. Как следует из названия, эти параметры представлены в матричной форме.&lt;/p&gt;
&lt;p&gt;Рассмотрим основные параметры:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Параметры $c_x$ и $c_y$&lt;/strong&gt; описывают разницу между координатами плоскости изображения и цифровыми координатами изображения через перенос.&lt;br&gt;
   - Координаты плоскости изображения имеют начало координат $C_0$ в центре изображения, где ось $k$ пересекает плоскость изображения.&lt;br&gt;
   - Цифровые координаты изображения обычно имеют начало в левом нижнем углу изображения.&lt;br&gt;
   - Таким образом, 2D точки на плоскости изображения и 2D точки в цифровом изображении смещаются на вектор переноса $\begin{pmatrix} c_x \\ c_y \end{pmatrix}^T$.  &lt;/p&gt;
&lt;p&gt;С учётом этого изменения систем координат отображение теперь выглядит так:&lt;/p&gt;
&lt;p&gt;$P' = \begin{pmatrix} x' \\ y' \end{pmatrix} = \begin{pmatrix} \frac{f}{z}x + c_x \\ \frac{f}{z}y + c_y \end{pmatrix}$ (3)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Второй важный эффект&lt;/strong&gt; — это то, что точки в цифровых изображениях выражаются в пикселях, в то время как точки на плоскости изображения представлены в физических измерениях (например, сантиметрах).&lt;/p&gt;
&lt;p&gt;Для учёта этого изменения единиц измерения необходимо ввести два новых параметра $k$ и $l$. Эти параметры имеют размерность [пиксель на сантиметр], соответствуют изменению единиц измерения по двум осям плоскости изображения. Важно отметить, что $k$ и $l$ могут быть разными, поскольку соотношение сторон пикселя не обязательно равно единице. Если $k = l$, мы говорим, что камера имеет квадратные пиксели. 
Мы модифицируем наше предыдущее отображение следующим образом:&lt;/p&gt;
&lt;p&gt;$P_0 = \begin{pmatrix} x' \\ y' \end{pmatrix} = \begin{pmatrix} f k \frac{x}{z} + c_x \\ f l \frac{y}{z} + c_y \end{pmatrix} = \begin{pmatrix} \alpha\frac{x}{z} + c_x \\ \beta\frac{y}{z} + c_y \end{pmatrix}$ (4)&lt;/p&gt;
&lt;p&gt;где&lt;br&gt;
$\alpha = f \cdot k$&lt;br&gt;
$\beta = f \cdot l$&lt;br&gt;
$f$ — фокусное расстояние в мм,&lt;br&gt;
$k$ — размер пикселя по оси x, пикс/мм. &lt;br&gt;
$l$ — размер пикселя по оси x, пикс/мм.  &lt;/p&gt;
&lt;p&gt;Сокращение размерностей приводит к тому, что параметры $\alpha$ и $\beta$ выражаются в пикселях.&lt;br&gt;
Это логично, так как коэффициенты связывают физические измерения (метры) с дискретными единицами цифрового изображения (пиксели).&lt;/p&gt;
&lt;p&gt;Геометрический смысл состоит в том, сколько в пикселях будет объект, размер которого на плоскости проекции равен фокусному расстоянию камеры. &lt;/p&gt;
&lt;p&gt;Таким образом, измерение $\alpha$ и $\beta$ в пикселях является необходимым для:&lt;br&gt;
- Точного проецирования точек;&lt;br&gt;
- Корректной калибровки камеры;&lt;br&gt;
- Работы алгоритмов обработки изображений;&lt;br&gt;
- Взаимодействия между физическим и цифровым пространством.  &lt;/p&gt;
&lt;h4&gt;5. Однородные координаты&lt;/h4&gt;
&lt;p&gt;Теперь рассмотрим вопрос: существует ли линейный способ представления проецирования $P \rightarrow P'$?&lt;/p&gt;
&lt;p&gt;Линейное преобразование на практике является более удобным, т.к. его можно представить как произведение входного вектора $P$ на некоторую матрицу. 
Из уравнения (4) видно, что  проецирование $P \rightarrow P'$ не является линейным, поскольку операция включает деление на один из входных параметров, а именно на $z$.
Тем не менее, представление этого проецирования в виде произведения вектора на матрицу возможно.
Решение заключается в использовании &lt;strong&gt;однородных координат&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;Рассмотрим этот подход:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Введение новой координаты&lt;/strong&gt;:&lt;br&gt;
Любая точка на плоскости $P' = (x', y')$ преобразуется в $(x', y', 1)$&lt;br&gt;
Любая точка в трехмерном пространстве $P = (x, y, z)$ преобразуется в $(x, y, z, 1)$  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Такое расширенное пространство называется &lt;strong&gt;системой однородных координат&lt;/strong&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Преобразование координат&lt;/strong&gt;:&lt;br&gt;
Для преобразования евклидова вектора $(v_1, ..., v_n)$ в однородные координаты мы просто добавляем 1 в новое измерение, получая $(v_1, ..., v_n, 1)$&lt;br&gt;
Важно отметить: равенство между вектором и его однородными координатами выполняется только когда последняя координата равна единице&lt;br&gt;
При обратном преобразовании из произвольных однородных координат $(v_1, ..., v_n, w)$ мы получаем евклидовы координаты $(\frac{v_1}{w}, ..., \frac{v_n}{w})$  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Используя однородные координаты, мы можем сформулировать преобразование следующим образом:&lt;/p&gt;
&lt;p&gt;$P'_h = \begin{bmatrix} \alpha x + c_x z \\ \beta y + c_y z \\ z \end{bmatrix} = \begin{bmatrix} \alpha &amp;amp; 0 &amp;amp; c_x &amp;amp; 0 \\ 0 &amp;amp; \beta &amp;amp; c_y &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{bmatrix} \begin{bmatrix} x \\ y \\ z \\ 1 \end{bmatrix} = \begin{bmatrix} \alpha &amp;amp; 0 &amp;amp; c_x &amp;amp; 0 \\ 0 &amp;amp; \beta &amp;amp; c_y &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{bmatrix} P_h$ (5)&lt;/p&gt;
&lt;p&gt;Преимущества использования однородных координат:&lt;br&gt;
- Позволяют представить нелинейное преобразование в виде матричного умножения;&lt;br&gt;
- Упрощают дальнейшие математические выкладки;&lt;br&gt;
- Обеспечивают единый способ работы с проективными преобразованиями.  &lt;/p&gt;
&lt;p&gt;С этого момента будем работать преимущественно в &lt;strong&gt;однородных координатах&lt;/strong&gt;, если не указано иное. Индекс $h$ опустим, подразумевая, что любая точка $P$ или $P'$ задана в однородных координатах.&lt;/p&gt;
&lt;p&gt;Как видно из уравнения (5), мы можем представить связь между точкой в трёхмерном пространстве и её координатами изображения в виде матрично-векторного соотношения:&lt;/p&gt;
&lt;p&gt;$P' = \begin{bmatrix} x' \\ y' \\ z \end{bmatrix} = \begin{bmatrix} \alpha &amp;amp; 0 &amp;amp; c_x &amp;amp; 0 \\ 0 &amp;amp; \beta &amp;amp; c_y &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{bmatrix} \begin{bmatrix} x \\ y \\ z \\ 1 \end{bmatrix} = \begin{bmatrix} \alpha &amp;amp; 0 &amp;amp; c_x &amp;amp; 0 \\ 0 &amp;amp; \beta &amp;amp; c_y &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{bmatrix} P = MP$ (6)&lt;/p&gt;
&lt;p&gt;где:
- $M$ — &lt;strong&gt;матрица камеры&lt;/strong&gt;&lt;br&gt;
- $P$ — точка в однородных координатах трёхмерного пространства&lt;br&gt;
- $P'$ — проекция точки на плоскость изображения  &lt;/p&gt;
&lt;h4&gt;6. Внутренние параметры камеры&lt;/h4&gt;
&lt;p&gt;Важные параметры матрицы камеры:&lt;br&gt;
- $\alpha$ и $\beta$ — масштабные коэффициенты в направлениях $x$ и $y$&lt;br&gt;
- $c_x$ и $c_y$ — координаты главной точки (principal point)&lt;br&gt;
- Последний столбец матрицы $M$ содержит нули, что характерно для проективных преобразований.  &lt;/p&gt;
&lt;p&gt;Давайте разберем это матричное разложение более подробно:&lt;/p&gt;
&lt;p&gt;Мы можем представить преобразование в виде:&lt;/p&gt;
&lt;p&gt;$P' = MP = \begin{bmatrix} \alpha &amp;amp; 0 &amp;amp; c_x \\ 0 &amp;amp; \beta &amp;amp; c_y \\ 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix} \begin{bmatrix} I &amp;amp; 0 \end{bmatrix} P = K \begin{bmatrix} I &amp;amp; 0 \end{bmatrix} P$ (7)&lt;/p&gt;
&lt;p&gt;где:
- $P'$ — координаты точки на плоскости изображения&lt;br&gt;
- $M$ — полная матрица преобразования&lt;br&gt;
- $K$ — *&lt;em&gt;матрица камеры&lt;/em&gt;- (внутренняя калибровка)&lt;br&gt;
- $I$ — единичная матрица размером 3×3&lt;br&gt;
- $0$ — нулевой вектор размером 3×1&lt;br&gt;
- $P$ — координаты точки в пространстве в однородных координатах.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 7: Проекция точки с помощью матрицы камеры" src="https://storage.yandexcloud.net/yahosting/3d/7.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 7: Проекция точки с помощью матрицы камеры&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Матрица камеры $K$ имеет следующий вид:&lt;/p&gt;
&lt;p&gt;$K = \begin{bmatrix} \alpha &amp;amp; 0 &amp;amp; c_x \\ 0 &amp;amp; \beta &amp;amp; c_y \\ 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix}$&lt;/p&gt;
&lt;p&gt;где:
- $\alpha$ и $\beta$ — масштабные коэффициенты, связанные с фокусным расстоянием&lt;br&gt;
- $c_x$ и $c_y$ — координаты главной точки (principal point)&lt;br&gt;
- Последняя строка [0 0 1] обеспечивает сохранение однородных координат  &lt;/p&gt;
&lt;p&gt;Такое разложение позволяет:
- Выделить внутренние параметры камеры и работать с ними отдельно от внешних;&lt;br&gt;
- Упрощать вычисления при работе с проективными преобразованиями;&lt;br&gt;
- Более эффективно выполнять калибровку камеры;&lt;br&gt;
- Разделять влияние различных параметров на процесс проецирования.  &lt;/p&gt;
&lt;p&gt;Матрица $K$ содержит всю необходимую информацию об &lt;strong&gt;внутренней калибровке&lt;/strong&gt; камеры, что делает её ключевым элементом в задачах компьютерного зрения и обработки изображений. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 8: Расположение главной точки С'" src="https://storage.yandexcloud.net/yahosting/3d/8.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 8: Расположение главной точки С'&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Полная матричная модель камеры $K$ содержит ключевые параметры, описывающие характеристики камеры и её модель, включая параметры $c_x$, $c_y$, $k$ и $l$, как обсуждалось ранее.&lt;/p&gt;
&lt;p&gt;В текущей формулировке отсутствуют два важных параметра:
* &lt;strong&gt;Скос (skewness)&lt;/strong&gt;
* &lt;strong&gt;Дисторсия (distortion)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Скос изображения&lt;/strong&gt; возникает, когда система координат камеры имеет неточный угол между осями (отличающийся от 90 градусов). Большинство камер имеют нулевой скос, однако некоторое его значение может появиться из-за погрешностей при производстве сенсора.&lt;/p&gt;
&lt;p&gt;Матрица камеры с учётом скоса имеет вид:&lt;/p&gt;
&lt;p&gt;$K = \begin{bmatrix} x' \\ y' \\ z \end{bmatrix} = \begin{bmatrix} \alpha &amp;amp; -\alpha \cot \theta &amp;amp; c_x \\ 0 &amp;amp; \frac{\beta}{\sin \theta} &amp;amp; c_y \\ 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix}$ (8)&lt;/p&gt;
&lt;p&gt;где:&lt;br&gt;
- $\alpha$ и $\beta$ — масштабные коэффициенты&lt;br&gt;
- $\theta$ — угол скоса&lt;br&gt;
- $c_x$ и $c_y$ — координаты главной точки  &lt;/p&gt;
&lt;p&gt;В рамках данного курса мы рассматриваем матрицу камеры $K$ с 5 степенями свободы:&lt;br&gt;
- 2 параметра для фокусного расстояния &lt;br&gt;
- 2 параметра для смещения&lt;br&gt;
- 1 параметр для скоса  &lt;/p&gt;
&lt;p&gt;Эти параметры называются &lt;strong&gt;внутренними параметрами камеры&lt;/strong&gt; (intrinsic parameters), так как они:&lt;br&gt;
- Уникальны для каждой конкретной камеры&lt;br&gt;
- Связаны с её конструктивными особенностями&lt;br&gt;
- Определяются при производстве  &lt;/p&gt;
&lt;p&gt;Важно отметить, что большинство методов компьютерного зрения игнорируют эффекты дисторсии, позволяя состедоточиться на 4 основных параметрах камеры.&lt;/p&gt;
&lt;h4&gt;7. Внешние параметры камеры&lt;/h4&gt;
&lt;p&gt;До сих пор мы описывали отображение точки $P$ из трёхмерной системы координат камеры в точку $P'$ на двумерной плоскости изображения, используя внутренние параметры камеры в матричной форме.&lt;/p&gt;
&lt;p&gt;Однако возникает вопрос: что делать, если информация о трёхмерном мире представлена в другой системе координат? В этом случае необходимо добавить дополнительное преобразование, связывающее точки из мировой системы координат с системой координат камеры.&lt;/p&gt;
&lt;p&gt;Это преобразование описывается:
- &lt;strong&gt;Матрицей вращения&lt;/strong&gt; $R$
- &lt;strong&gt;Вектором переноса&lt;/strong&gt; $T$&lt;/p&gt;
&lt;p&gt;Таким образом, для точки $P_w$ в мировой системе координат её координаты в системе камеры можно вычислить следующим образом:&lt;/p&gt;
&lt;p&gt;$P = \begin{bmatrix} R &amp;amp; T \\ 0 &amp;amp; 1 \end{bmatrix} P_w$ (9)&lt;/p&gt;
&lt;p&gt;где:
- $R$ — матрица вращения размером 3×3&lt;br&gt;
- $T$ — вектор переноса размером 3×1&lt;br&gt;
- $P_w$ — координаты точки в мировой системе&lt;br&gt;
- $P$ — координаты точки в системе камеры  &lt;/p&gt;
&lt;p&gt;Подставляя это в уравнение (7) и упрощая, получаем:&lt;/p&gt;
&lt;p&gt;$P' = K \begin{bmatrix} R &amp;amp; T \end{bmatrix} P_w = MP_w$ (10)&lt;/p&gt;
&lt;p&gt;Параметры $R$ и $T$ называются &lt;strong&gt;внешними параметрами&lt;/strong&gt;, поскольку они:&lt;br&gt;
- Находятся вне камеры&lt;br&gt;
- Не зависят от характеристик камеры  &lt;/p&gt;
&lt;p&gt;Это завершает описание отображения трёхмерной точки $P$ из произвольной мировой системы координат на плоскость изображения.&lt;/p&gt;
&lt;h4&gt;Резюме&lt;/h4&gt;
&lt;p&gt;Полная матрица проекции $M$ состоит из двух типов параметров:
- &lt;strong&gt;Внутренние параметры&lt;/strong&gt; (intrinsic parameters) — содержатся в матрице камеры $K$, меняются при смене типа камеры&lt;br&gt;
- &lt;strong&gt;Внешние параметры&lt;/strong&gt; (extrinsic parameters) — включают вращение и перенос, не зависят от конструкции камеры  &lt;/p&gt;
&lt;p&gt;Полная матрица проекции $M$ размером 3×4 имеет 11 степеней свободы:&lt;br&gt;
- 5 степеней свободы от внутренней матрицы камеры&lt;br&gt;
- 3 степени свободы от внешнего вращения&lt;br&gt;
- 3 степени свободы от внешнего переноса  &lt;/p&gt;
&lt;p&gt;Таким образом, мы получили полное описание процесса проецирования точки из трёхмерного пространства на плоскость изображения, учитывающее как характеристики самой камеры, так и её положение в пространстве относительно наблюдаемой сцены.&lt;/p&gt;</description><category>cs231a</category><guid>https://mldl.ru/posts/base-3d/</guid><pubDate>Mon, 29 Sep 2025 11:00:00 GMT</pubDate></item><item><title>Настройка программного обеспечения </title><link>https://mldl.ru/posts/software-setup/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;h2&gt;Настройка программного обеспечения&lt;/h2&gt;
&lt;p&gt;Для работы с нейросетями можно работать через &lt;a href="https://colab.research.google.com/"&gt;Google Colaboratory&lt;/a&gt;. Однако, если у вас уже есть хорошая видеокарта (Nvidia) и вы предпочитаете работать локально, здесь вы найдет инструкции по настройке виртуальной среды.&lt;br&gt;
- &lt;a href="https://mldl.ru/posts/software-setup/"&gt;Удаленная работа в Google Colaboratory&lt;/a&gt;&lt;br&gt;
- &lt;a href="https://mldl.ru/posts/software-setup/"&gt;Работа локально на вашем компьютере&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/software-setup/"&gt;Виртуальная среда Anaconda&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/software-setup/"&gt;Python venv&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/software-setup/"&gt;Установка пакетов&lt;/a&gt;  &lt;/p&gt;
&lt;h4&gt;Удаленная работа в Google Colaboratory&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Google Colaboratory&lt;/em&gt; — это, по сути, комбинация &lt;em&gt;Jupyter notebook&lt;/em&gt; и &lt;em&gt;Google Drive&lt;/em&gt;. 
Он полностью работает в облаке и поставляется с множеством предустановленных заранее пакетами (например, &lt;em&gt;PyTorch&lt;/em&gt; и &lt;em&gt;Tensorflow&lt;/em&gt;), поэтому у всех есть доступ к одному и тому же широкому перечню библиотек. 
Кроме того, &lt;em&gt;Google Colab&lt;/em&gt; дает бесплатный доступ к аппаратным ускорителям например, &lt;em&gt;K80&lt;/em&gt;, &lt;em&gt;P100&lt;/em&gt; и TPU (Tensor Processing Unit).  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Требования&lt;/strong&gt;. 
Чтобы использовать &lt;em&gt;Colab&lt;/em&gt;, у вас должен быть аккаунт &lt;em&gt;Google&lt;/em&gt; со связанным &lt;strong&gt;Google диском&lt;/strong&gt;. 
Предполагается, что у вас есть и то, и другое, вы можете подключить &lt;em&gt;Colab&lt;/em&gt; к &lt;strong&gt;G-drive&lt;/strong&gt;, выполнив следующие действия:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Нажмите на колесико в правом верхнем углу и выберите &lt;code&gt;Settings&lt;/code&gt;.  &lt;/li&gt;
&lt;li&gt;Нажмите на вкладку &lt;code&gt;Manage Apps&lt;/code&gt;.  &lt;/li&gt;
&lt;li&gt;Вверху выберите &lt;code&gt;Connect more apps&lt;/code&gt;, что должно вызвать окно &lt;code&gt;GSuite Marketplace&lt;/code&gt;.  &lt;/li&gt;
&lt;li&gt;Найдите &lt;strong&gt;Colab&lt;/strong&gt; и нажмите &lt;code&gt;Add&lt;/code&gt;.  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Рекомендации&lt;/strong&gt;. Есть несколько вещей, о которых вы должны знать при работе с &lt;em&gt;Colab&lt;/em&gt;:  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Постоянное наличие ресурсов не гарантировано (это плата за бесплатность).  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Если вы бездействуете в течение определенного времени или общее время подключения превышает максимально допустимое время (&lt;em&gt;~12 часов&lt;/em&gt;), виртуальная машина &lt;em&gt;Colab&lt;/em&gt; будет отключена. Это означает, что любой несохраненный прогресс будет потерян. &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;font color="red"&gt;&lt;strong&gt;&lt;br&gt;
Таким образом, выработайте привычку часто сохранять свой код и веса моделей во время работы! 
&lt;/strong&gt;&lt;/font&gt;  &lt;/p&gt;
&lt;p&gt;Чтобы узнать больше об ограничениях ресурсов в &lt;em&gt;Colab&lt;/em&gt;, ознакомьтесь с их часто задаваемыми вопросами &lt;a href="https://research.google.com/colaboratory/faq.html"&gt;здесь&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Использование графического процессора (GPU)&lt;/strong&gt;. 
Использовать графический процессор очень просто, нужно просто переключить среду выполнения в &lt;em&gt;Colab&lt;/em&gt;. 
Перейдите в настройки по следующему пути: &lt;code&gt;Runtime -&amp;gt; Change runtime type -&amp;gt; Hardware Accelerator -&amp;gt; GPU&lt;/code&gt; , и &lt;em&gt;Colab&lt;/em&gt; будет автоматически подкреплен вычислительными мощностями графического процессора.  &lt;/p&gt;
&lt;p&gt;Если вы хотите узнать больше о &lt;em&gt;Colab&lt;/em&gt;, рекомендую вам посетить следующие ресурсы:
- &lt;a href="https://www.youtube.com/watch?v=inN8seMm7UI"&gt;Введение в Google Colab&lt;/a&gt;
- &lt;a href="https://colab.research.google.com/notebooks/intro.ipynb"&gt;Добро пожаловать в Colab&lt;/a&gt;
- &lt;a href="https://colab.research.google.com/notebooks/basic_features_overview.ipynb"&gt;Обзор функций Colab&lt;/a&gt;  &lt;/p&gt;
&lt;h4&gt;Работа на локальном компьютере&lt;/h4&gt;
&lt;p&gt;Если вы хотите работать локально, вам следует использовать виртуальную среду &lt;code&gt;venv&lt;/code&gt;. 
Вы можете установить ее через &lt;em&gt;Anaconda&lt;/em&gt; или через модуль &lt;em&gt;python -m venv&lt;/em&gt;. &lt;/p&gt;
&lt;h5&gt;Виртуальная среда Anaconda&lt;/h5&gt;
&lt;p&gt;Бесплатный &lt;a href="https://www.anaconda.com/download/"&gt;дистрибутив Anaconda Python&lt;/a&gt; предоставляет собой набор пакетов для научных вычислений. 
Приятная вещь в &lt;em&gt;Anaconda&lt;/em&gt; заключается в том, что она поставляется с &lt;a href="https://docs.anaconda.com/mkl-optimizations/"&gt;оптимизацией MKL&lt;/a&gt; по умолчанию, 
Это означает, что ваши библиотеки &lt;code&gt;numpy&lt;/code&gt; и &lt;code&gt;scipy&lt;/code&gt; код получают значительное ускорение без необходимости изменять ни одной строки кода. &lt;/p&gt;
&lt;p&gt;После установки Anaconda имеет смысл создать виртуальную среду для отдельного проекта. 
Если вы не не будете использовать виртуальную среду (&lt;em&gt;настоятельно не рекомендуется!&lt;/em&gt;), все зависимости будут установлены глобально на вашем компьютере. 
Чтобы настроить виртуальную среду с именем &lt;code&gt;mldl&lt;/code&gt;, выполните следующие действия в терминале:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;conda create -n mldl python=3.12
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Чтобы активировать и войти в среду, запустите &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;conda activate mldl
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Чтобы отключить среду, закройте терминал или используйте команду&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;conda deactivate
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Вы можете обратиться к &lt;a href="https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html"&gt;этой странице&lt;/a&gt; за более подробными инструкциями по управлению виртуальными средами с помощью Anaconda.  &lt;/p&gt;
&lt;h4&gt;Python venv&lt;/h4&gt;
&lt;p&gt;Начиная с версии &lt;em&gt;3.3&lt;/em&gt;, &lt;em&gt;Python&lt;/em&gt; поставляется с облегченным модулем виртуальной среды под названием &lt;a href="https://docs.python.org/3/library/venv.html"&gt;venv&lt;/a&gt;. 
Каждая виртуальная среда упаковывает свой собственный независимый набор установленных пакетов (библиотек) &lt;em&gt;Python&lt;/em&gt;.
Это позволяет изолировать проект от общесистемных пакетов &lt;em&gt;Python&lt;/em&gt; и запускать нужную версию &lt;em&gt;Python&lt;/em&gt;. 
Чтобы настроить виртуальную среду с именем &lt;code&gt;mldl&lt;/code&gt;, выполните команду в терминале:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;python3.12 -m venv mldl
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Чтобы активировать и войти в среду, запустите &lt;code&gt;source mldl/bin/activate&lt;/code&gt;. 
Чтобы отключить среду, запустите в терминале &lt;code&gt;deactivate&lt;/code&gt; или выйдите из него. 
Обратите внимание, что каждый раз, когда вы хотите поработать над проектом, вы должны повторно активировать среду. &lt;/p&gt;
&lt;h4&gt;Установка пакетов&lt;/h4&gt;
&lt;p&gt;После того как вы &lt;strong&gt;настроили&lt;/strong&gt; и &lt;strong&gt;активировали&lt;/strong&gt; свою виртуальную среду (с помощью &lt;code&gt;conda&lt;/code&gt; или &lt;code&gt;venv&lt;/code&gt;), вы должны установить библиотеки, необходимые для выполнения назначений с помощью &lt;code&gt;pip&lt;/code&gt;. 
Для этого выполните команду:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;pip install -r requirements.txt  
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;Python IDE&lt;/h3&gt;
&lt;p&gt;Использование Ide для работы над проектами очень упрощает создание и настройку python. 
Кроме того, интеграция с Git и другие полезные утилиты позволяют повысить эффективность разработки, не отвлекаясь на рутинные операции. 
Используйте PyCharm, VsCode или любую другую IDE на ваш вкус. 
Мой выбор - VsCode с расширениями (Extentions): Python (Microsoft), Black Formatter, JetBrains IDE KeyMapping. &lt;/p&gt;</description><guid>https://mldl.ru/posts/software-setup/</guid><pubDate>Wed, 02 Jul 2025 11:00:00 GMT</pubDate></item><item><title>Tutorial python Numpy</title><link>https://mldl.ru/posts/numpy-tutorial/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;h2&gt;Python numpy (с Jupyter и Colab)&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://colab.research.google.com/github/cs231n/cs231n.github.io/blob/master/python-colab.ipynb"&gt;Блокнот Colab&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Этот урок был первоначально предоставлен &lt;a href="http://cs.stanford.edu/people/jcjohns/"&gt;Джастином Джонсоном&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;Мы будем использовать язык программирования &lt;em&gt;python&lt;/em&gt; для всех заданий этого курса. 
&lt;em&gt;Python&lt;/em&gt; сам по себе является отличным языком программирования общего назначения, но с помощью нескольких популярных библиотек (&lt;em&gt;numpy&lt;/em&gt;, &lt;em&gt;scipy&lt;/em&gt;, &lt;em&gt;matplotlib&lt;/em&gt;) он становится мощной средой для научных вычислений.&lt;/p&gt;
&lt;p&gt;Мы ожидаем, что многие из вас имеют некоторый опыт работы с &lt;em&gt;python&lt;/em&gt; и &lt;em&gt;numpy&lt;/em&gt;. 
Если нет, то этот раздел послужит кратким ускоренным курсом по обоим направлениям языка программирования &lt;em&gt;python&lt;/em&gt; и его использованию для научных исследований и вычислений. 
Мы также познакомимся с Jupyter-notebooks, которые являются очень удобным способом работы с кодом на &lt;em&gt;python&lt;/em&gt;. &lt;/p&gt;
&lt;p&gt;Ссылки на полезные ресурсы: 
- &lt;a href="https://stepik.org/course/67/promo"&gt;Stepic курс по python&lt;/a&gt;
- &lt;a href="https://numpy.org/doc/stable/user/numpy-for-matlab-users.html"&gt;NumPy для пользователей Matlab&lt;/a&gt;, 
- &lt;a href="http://www.data-analysis-in-python.org/python_for_r.html"&gt;python для пользователей R&lt;/a&gt; ,
- &lt;a href="https://nbviewer.jupyter.org/github/RandyBetancourt/pythonForSASUsers/tree/master/"&gt;python для пользователей SAS&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;Содержание
- &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Блокноты Jupyter и Colab&lt;/a&gt;&lt;br&gt;
- &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Питон&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Версии python&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Основные типы данных&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Контейнеры&lt;/a&gt;&lt;br&gt;
        - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Списках&lt;/a&gt;&lt;br&gt;
        - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Словари&lt;/a&gt;&lt;br&gt;
        - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Множество&lt;/a&gt;&lt;br&gt;
        - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Кортежи&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Функции&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Классы&lt;/a&gt;&lt;br&gt;
- &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Numpy&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Массивы&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Индексация массивов&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Типы данных&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Математические операции с массивами&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Broadcasting&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Документация Numpy&lt;/a&gt; &lt;br&gt;
- &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;SciPy&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Операции с изображениями&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Файлы MATLAB&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Расстояние между точками&lt;/a&gt;&lt;br&gt;
- &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Matplotlib&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Постоение кривой&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Побочные сюжеты&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/numpy-tutorial/"&gt;Изображения&lt;/a&gt;  &lt;/p&gt;
&lt;h2&gt;Блокноты Jupyter и Colab&lt;/h2&gt;
&lt;p&gt;Прежде чем мы углубимся в &lt;em&gt;python&lt;/em&gt;, мы хотели бы кратко поговорить о &lt;em&gt;блокнотах&lt;/em&gt;. 
Блокнот &lt;em&gt;Jupyter&lt;/em&gt; позволяет писать и выполнять код &lt;em&gt;python&lt;/em&gt; &lt;em&gt;локально&lt;/em&gt; в вашем веб-браузере. 
&lt;em&gt;Jupyter notebooks&lt;/em&gt; yпрощает работу с кодом и выполняет его по блокам. 
По этой причине он широко используется в научных вычислениях. 
&lt;em&gt;Colab&lt;/em&gt;, с другой стороны, является разновидностью &lt;em&gt;Google-блокнота&lt;/em&gt; &lt;em&gt;Jupyter&lt;/em&gt;, который особенно подходит для машинных алгоритмов обучения и анализа данных, которые сохраняют функционал в &lt;em&gt;облаке&lt;/em&gt;. 
&lt;em&gt;Colab&lt;/em&gt; — это, по сути, &lt;em&gt;Jupyter&lt;/em&gt; notebook на стероидах: он бесплатный, не требует настройки, поставляется с предустановленными пакетами, им легко поделиться со всем миром. 
В нем присутствуют преимущества бесплатного доступа к аппаратным ускорителям, таким как графические процессоры и &lt;em&gt;TPU&lt;/em&gt; (с некоторыми оговорками).  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Запустите Tutorial в Colab (рекомендуется)&lt;/strong&gt;. Если вы хотите выполнить это руководство полностью в &lt;em&gt;Colab&lt;/em&gt;, нажмите на значок &lt;code&gt;Open in Colab&lt;/code&gt; в самом верху этой страницы.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Запустите Tutorial в блокноте Jupyter&lt;/strong&gt;. Если вы хотите запустить блокнот локально с помощью &lt;em&gt;Jupyter&lt;/em&gt;, убедитесь, что ваша виртуальная среда установлена правильно (в соответствии с &lt;a href="https://cs231n.github.io/setup-instructions/"&gt;инструкциями по настройке&lt;/a&gt;), активируйте ее, а затем запустите &lt;code&gt;pip install notebook&lt;/code&gt; для установки блокнота &lt;em&gt;Jupyter&lt;/em&gt;. Затем &lt;a href="https://raw.githubusercontent.com/cs231n/cs231n.github.io/master/jupyter-notebook-tutorial.ipynb"&gt;откройте блокнот&lt;/a&gt; и загрузите его в каталог по вашему выбору, щелкнув правой кнопкой мыши по странице и выбрав &lt;code&gt;Save Page As&lt;/code&gt;. Затем &lt;code&gt;cd&lt;/code&gt; в этот каталог и запустите &lt;code&gt;jupyter notebook&lt;/code&gt;.     &lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/ipython-tutorial/file-browser.png"&gt;  &lt;/p&gt;
&lt;p&gt;Это должно автоматически запустить сервер блокнотов по адресу &lt;code&gt;http://localhost:8888&lt;/code&gt;. Если все работало правильно, вы должны увидеть такой экран, показывающий все доступные записные книжки в текущем каталоге. Нажмите &lt;code&gt;jupyter-notebook-tutorial.ipynb&lt;/code&gt; и следуйте инструкциям в блокноте. В противном случае вы можете продолжить чтение туториала с фрагментами кода ниже.   &lt;/p&gt;
&lt;h2&gt;Python&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Python&lt;/strong&gt; — это высокоуровневый, динамически типизированный мультипарадигмальный язык программирования. О коде на &lt;em&gt;python&lt;/em&gt; часто говорят, что он похож на псевдокод, поскольку он позволяет вам выражать очень мощные идеи в очень немногих строках кода, оставаясь при этом очень удобочитаемый. В качестве примера приведем реализацию алгоритма классической быстрой сортировки на &lt;em&gt;python&lt;/em&gt;:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="k"&gt;def&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;quicksort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;arr&lt;/span&gt;
    &lt;span class="n"&gt;pivot&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;arr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;//&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;left&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;arr&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="n"&gt;pivot&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;middle&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;arr&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;pivot&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;right&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;arr&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;pivot&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;quicksort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;left&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;middle&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;quicksort&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;right&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;quicksort&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;span class="c1"&gt;# Prints "[1, 1, 2, 3, 6, 8, 10]"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;Версии python&lt;/h3&gt;
&lt;p&gt;С 1 января 2020 года python &lt;a href="https://www.python.org/doc/sunset-python-2/"&gt;официально прекратил поддержку&lt;/a&gt; второй версии. 
&lt;strong&gt;Поэтому во всех примерах код написан на python 3.7&lt;/strong&gt;. Убедитесь, что вы правильно установили виртуальную среду, прежде чем продолжить работу с этим руководством. Вы можете проверить свою версию в командной строке после активации среды, запустив команду: &lt;code&gt;python --version&lt;/code&gt;  &lt;/p&gt;
&lt;h3&gt;Основные типы данных&lt;/h3&gt;
&lt;p&gt;Как и большинство языков, &lt;em&gt;python&lt;/em&gt; имеет ряд основных типов: &lt;em&gt;int&lt;/em&gt;, &lt;em&gt;floats&lt;/em&gt;, &lt;em&gt;booleans&lt;/em&gt; и &lt;em&gt;strings&lt;/em&gt;. 
Эти типы данных ведут себя так же, как и в большинстве других языков программирования.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Числа&lt;/strong&gt;:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# Prints "&amp;lt;class 'int'&amp;gt;"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;       &lt;span class="c1"&gt;# Prints "3"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# Addition; prints "4"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# Subtraction; prints "2"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# Multiplication; prints "6"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Exponentiation; prints "9"&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "4"&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*=&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "8"&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;2.5&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# Prints "&amp;lt;class 'float'&amp;gt;"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# Prints "2.5 3.5 5.0 6.25"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Обратите внимание, что в отличие от многих языков, в python нет унарного инкремента (&lt;code&gt;x++&lt;/code&gt;) или декремента (&lt;code&gt;x--&lt;/code&gt;).   &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Python&lt;/em&gt; также имеет встроенные типы для комплексных чисел; 
Все подробности можно найти &lt;a href="https://docs.python.org/3.9/library/stdtypes.html#numeric-types-int-float-complex"&gt;в документации&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Логический тип данных&lt;/strong&gt;: &lt;em&gt;python&lt;/em&gt; реализует все обычные операторы для булевой логики, но использует английские слова, а не символы (&lt;code&gt;&amp;amp;&amp;amp;&lt;/code&gt;, &lt;code&gt;||&lt;/code&gt; , и т. д.):   &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;True&lt;/span&gt;
&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;False&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# Prints "&amp;lt;class 'bool'&amp;gt;"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;and&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# Logical AND; prints "False"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Logical OR; prints "True"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# Logical NOT; prints "False"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Logical XOR; prints "True"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Строки&lt;/strong&gt;: &lt;em&gt;python&lt;/em&gt; имеет отличную поддержку строк:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;hello&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'hello'&lt;/span&gt;    &lt;span class="c1"&gt;# String literals can use single quotes&lt;/span&gt;
&lt;span class="n"&gt;world&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"world"&lt;/span&gt;    &lt;span class="c1"&gt;# or double quotes; it does not matter.&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hello&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;       &lt;span class="c1"&gt;# Prints "hello"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hello&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  &lt;span class="c1"&gt;# String length; prints "5"&lt;/span&gt;
&lt;span class="n"&gt;hw&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;hello&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;' '&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;world&lt;/span&gt;  &lt;span class="c1"&gt;# String concatenation&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hw&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# prints "hello world"&lt;/span&gt;
&lt;span class="n"&gt;hw12&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt; &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt; &lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hello&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;world&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# sprintf style string formatting&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hw12&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# prints "hello world 12"  &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Строковые объекты имеют множество полезных методов:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;s&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;"hello"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;capitalize&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;  &lt;span class="c1"&gt;# Capitalize a string; prints "Hello"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;upper&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;       &lt;span class="c1"&gt;# Convert a string to uppercase; prints "HELLO"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rjust&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;      &lt;span class="c1"&gt;# Right-justify a string, padding with spaces; prints "  hello"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;center&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;     &lt;span class="c1"&gt;# Center a string, padding with spaces; prints " hello "&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'l'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'(ell)'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  &lt;span class="c1"&gt;# Replace all instances of one substring with another;&lt;/span&gt;
                                &lt;span class="c1"&gt;# prints "he(ell)(ell)o"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'  world '&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;  &lt;span class="c1"&gt;# Strip leading and trailing whitespace; prints "world"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Список всех строковых методов можно найти &lt;a href="https://docs.python.org/3.9/library/stdtypes.html#string-methods"&gt;в документации&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Контейнеры&lt;/h3&gt;
&lt;p&gt;Python включает в себя несколько встроенных типов контейнеров: списки, словари, наборы и кортежи.&lt;/p&gt;
&lt;h4&gt;Списки&lt;/h4&gt;
&lt;p&gt;Список в &lt;em&gt;python&lt;/em&gt; является эквивалентом массива, но его размер можно изменять и он можетё содержать элементы разных типов:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;xs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;    &lt;span class="c1"&gt;# Create a list&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "[3, 1, 2] 2"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;     &lt;span class="c1"&gt;# Negative indices count from the end of the list; prints "2"&lt;/span&gt;
&lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'foo'&lt;/span&gt;     &lt;span class="c1"&gt;# Lists can contain elements of different types&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;         &lt;span class="c1"&gt;# Prints "[3, 1, 'foo']"&lt;/span&gt;
&lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'bar'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Add a new element to the end of the list&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;         &lt;span class="c1"&gt;# Prints "[3, 1, 'foo', 'bar']"&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pop&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;      &lt;span class="c1"&gt;# Remove and return the last element of the list&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;xs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;      &lt;span class="c1"&gt;# Prints "bar [3, 1, 'foo']"  &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Как обычно, вы можете найти подробности о &lt;a href="https://docs.python.org/3.9/tutorial/datastructures.html#more-on-lists"&gt;списках в документации&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Разрезание на ломтики&lt;/strong&gt;: В дополнение к доступу к элементам списка по одному, &lt;em&gt;python&lt;/em&gt; предоставляет лаконичный синтаксис для доступа к подспискам; Это называется нарезкой:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;nums&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;list&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;     &lt;span class="c1"&gt;# range is a built-in function that creates a list of integers&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nums&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;               &lt;span class="c1"&gt;# Prints "[0, 1, 2, 3, 4]"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nums&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;          &lt;span class="c1"&gt;# Get a slice from index 2 to 4 (exclusive); prints "[2, 3]"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nums&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:])&lt;/span&gt;           &lt;span class="c1"&gt;# Get a slice from index 2 to the end; prints "[2, 3, 4]"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nums&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;           &lt;span class="c1"&gt;# Get a slice from the start to index 2 (exclusive); prints "[0, 1]"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nums&lt;/span&gt;&lt;span class="p"&gt;[:])&lt;/span&gt;            &lt;span class="c1"&gt;# Get a slice of the whole list; prints "[0, 1, 2, 3, 4]"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nums&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;          &lt;span class="c1"&gt;# Slice indices can be negative; prints "[0, 1, 2, 3]"&lt;/span&gt;
&lt;span class="n"&gt;nums&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;        &lt;span class="c1"&gt;# Assign a new sublist to a slice&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nums&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;               &lt;span class="c1"&gt;# Prints "[0, 1, 8, 9, 4]" &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Мы снова увидим нарезку в контексте массивов numpy.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Петли&lt;/strong&gt;: Вы можете перебирать элементы списка следующим образом:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;animals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'cat'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'dog'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'monkey'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;animal&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;animals&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;animal&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Prints "cat", "dog", "monkey", each on its own line.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Если вы хотите получить доступ к индексу каждого элемента в теле цикла, воспользуйтесь встроенной функцией:&lt;code&gt;enumerate&lt;/code&gt;  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;animals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'cat'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'dog'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'monkey'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;animal&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;animals&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'#&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt;: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;animal&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;# Prints "#1: cat", "#2: dog", "#3: monkey", each on its own line  &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Список включений&lt;/strong&gt;: при программировании мы часто хотим преобразовать один тип данных в другой. В качестве простого примера рассмотрим следующий код, который вычисляет квадратные числа:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;nums&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;squares&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;nums&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;squares&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;squares&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# Prints [0, 1, 4, 9, 16]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Вы можете упростить этот код с помощью &lt;strong&gt;спискового понимания&lt;/strong&gt;:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;nums&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;squares&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;nums&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;squares&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# Prints [0, 1, 4, 9, 16]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Включения списка также могут содержать условия:    &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;nums&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;even_squares&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;nums&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;even_squares&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "[0, 4, 16]"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h4&gt;Словари&lt;/h4&gt;
&lt;p&gt;Словарь хранит пары (ключ, значение), аналогично &lt;code&gt;Map&lt;/code&gt; в &lt;em&gt;Java&lt;/em&gt; или объекту в &lt;em&gt;Javascript&lt;/em&gt;. Вы можете использовать его следующим образом:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'cat'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'cute'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'dog'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'furry'&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;  &lt;span class="c1"&gt;# Create a new dictionary with some data&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'cat'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;       &lt;span class="c1"&gt;# Get an entry from a dictionary; prints "cute"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'cat'&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;     &lt;span class="c1"&gt;# Check if a dictionary has a given key; prints "True"&lt;/span&gt;
&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'fish'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'wet'&lt;/span&gt;     &lt;span class="c1"&gt;# Set an entry in a dictionary&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'fish'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;      &lt;span class="c1"&gt;# Prints "wet"&lt;/span&gt;
&lt;span class="c1"&gt;# print(d['monkey'])  # KeyError: 'monkey' not a key of d&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'monkey'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'N/A'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  &lt;span class="c1"&gt;# Get an element with a default; prints "N/A"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'fish'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'N/A'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;    &lt;span class="c1"&gt;# Get an element with a default; prints "wet"&lt;/span&gt;
&lt;span class="k"&gt;del&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;'fish'&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;         &lt;span class="c1"&gt;# Remove an element from a dictionary&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'fish'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'N/A'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="c1"&gt;# "fish" is no longer a key; prints "N/A"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Все, что вам нужно знать о словарях, вы можете найти &lt;a href="https://docs.python.org/3.9/library/stdtypes.html#dict"&gt;в документации&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Петли&lt;/strong&gt;: Перебирать ключи в словаре очень просто:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'person'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'cat'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'spider'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;animal&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;legs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;animal&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'A &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt; has &lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt; legs'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;animal&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;legs&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;# Prints "A person has 2 legs", "A cat has 4 legs", "A spider has 8 legs" &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Если вы хотите получить доступ к ключам и их соответствующим значениям, используйте метод:&lt;code&gt;items&lt;/code&gt;  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'person'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'cat'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'spider'&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;animal&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;legs&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'A &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt; has &lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt; legs'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;animal&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;legs&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;# Prints "A person has 2 legs", "A cat has 4 legs", "A spider has 8 legs"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Словарное понимание&lt;/strong&gt;: Они похожи на включения списков, но позволяют легко создавать cловари. Например:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;nums&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;even_num_to_square&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;nums&lt;/span&gt; &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;even_num_to_square&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "{0: 0, 2: 4, 4: 16}"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h4&gt;Наборы&lt;/h4&gt;
&lt;p&gt;Наборы — это неупорядоченное множество отдельных элементов. В качестве простого примера рассмотрим следующее:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;animals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'cat'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'dog'&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'cat'&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;animals&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# Check if an element is in a set; prints "True"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'fish'&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;animals&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# prints "False"&lt;/span&gt;
&lt;span class="n"&gt;animals&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'fish'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;       &lt;span class="c1"&gt;# Add an element to a set&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'fish'&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;animals&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "True"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;animals&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;       &lt;span class="c1"&gt;# Number of elements in a set; prints "3"&lt;/span&gt;
&lt;span class="n"&gt;animals&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'cat'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;        &lt;span class="c1"&gt;# Adding an element that is already in the set does nothing&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;animals&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;       &lt;span class="c1"&gt;# Prints "3"&lt;/span&gt;
&lt;span class="n"&gt;animals&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;remove&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'cat'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;     &lt;span class="c1"&gt;# Remove an element from a set&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;animals&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;       &lt;span class="c1"&gt;# Prints "2"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Как обычно, все, что вы хотите знать о множествах, можно найти &lt;a href="https://docs.python.org/3.9/library/stdtypes.html#set"&gt;в документации&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Петли&lt;/strong&gt;: Перебор набора имеет тот же синтаксис, что и перебор списка; 
Однако, поскольку наборы не упорядочены, вы не можете делать предположения о порядке, в которых вы посещаете элементы набора:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;animals&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s1"&gt;'cat'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'dog'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'fish'&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;idx&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;animal&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;enumerate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;animals&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'#&lt;/span&gt;&lt;span class="si"&gt;%d&lt;/span&gt;&lt;span class="s1"&gt;: &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;idx&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;animal&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;# Prints "#1: fish", "#2: dog", "#3: cat"  &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Набор понятий&lt;/strong&gt;: подобно спискам и словарям, мы можем легко создавать наборы, используя включения множеств:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;from&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;math&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;sqrt&lt;/span&gt;
&lt;span class="n"&gt;nums&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;30&lt;/span&gt;&lt;span class="p"&gt;)}&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nums&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "{0, 1, 2, 3, 4, 5}"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;h4&gt;Кортежи&lt;/h4&gt;
&lt;p&gt;Кортеж — это (&lt;em&gt;неизменяемый&lt;/em&gt;) упорядоченный список значений. Кортеж во многом похож на список; Одним из наиболее важных отличий является то, что кортежи можно использовать как ключи в словарях и как элементы множеств, а списки — нет. Вот банальный пример:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;)}&lt;/span&gt;  &lt;span class="c1"&gt;# Create a dictionary with tuple keys&lt;/span&gt;
&lt;span class="n"&gt;t&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;        &lt;span class="c1"&gt;# Create a tuple&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;    &lt;span class="c1"&gt;# Prints "&amp;lt;class 'tuple'&amp;gt;"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;       &lt;span class="c1"&gt;# Prints "5"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "1"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href="https://docs.python.org/3.9/tutorial/datastructures.html#tuples-and-sequences"&gt;В документации&lt;/a&gt; есть больше информации о кортежах.  &lt;/p&gt;
&lt;h3&gt;Функции&lt;/h3&gt;
&lt;p&gt;Функции python определяются с помощью ключевого слова. Например:&lt;code&gt;def&lt;/code&gt;  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="k"&gt;def&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;sign&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;'positive'&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;'negative'&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="s1"&gt;'zero'&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
    &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;sign&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;# Prints "negative", "zero", "positive"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Мы часто определяем функции, принимающие необязательные аргументы ключевых слов, например:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="k"&gt;def&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;hello&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loud&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;loud&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'HELLO, &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;!'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;upper&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Hello, &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;hello&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Bob'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# Prints "Hello, Bob"&lt;/span&gt;
&lt;span class="n"&gt;hello&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Fred'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loud&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "HELLO, FRED!" &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;В &lt;a href="https://docs.python.org/3.9/tutorial/controlflow.html#defining-functions"&gt;документации&lt;/a&gt; есть гораздо больше информации о функциях &lt;em&gt;python&lt;/em&gt;.  &lt;/p&gt;
&lt;h4&gt;Классы&lt;/h4&gt;
&lt;p&gt;Синтаксис для определения классов в &lt;em&gt;python&lt;/em&gt; прост:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="k"&gt;class&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;Greeter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

    &lt;span class="c1"&gt;# Constructor&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;init&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;name&lt;/span&gt;  &lt;span class="c1"&gt;# Create an instance variable&lt;/span&gt;

    &lt;span class="c1"&gt;# Instance method&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;greet&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;loud&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;False&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;loud&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'HELLO, &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;!'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;upper&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Hello, &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;g&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Greeter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Fred'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Construct an instance of the Greeter class&lt;/span&gt;
&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;greet&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;            &lt;span class="c1"&gt;# Call an instance method; prints "Hello, Fred"&lt;/span&gt;
&lt;span class="n"&gt;g&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;greet&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loud&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# Call an instance method; prints "HELLO, FRED!"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Вы можете прочитать гораздо больше о классах &lt;em&gt;python&lt;/em&gt; &lt;a href="https://docs.python.org/3.9/tutorial/classes.html"&gt;в документации&lt;/a&gt;.  &lt;/p&gt;
&lt;h2&gt;Numpy&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://www.numpy.org/"&gt;Numpy&lt;/a&gt; — это основная библиотека для научных вычислений на языке &lt;em&gt;python&lt;/em&gt;. Она предоставляет высокопроизводительный многомерный массив объектов и инструменты для работы с ними Массивы. Если вы уже знакомы с &lt;em&gt;MATLAB&lt;/em&gt;, &lt;a href="https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html"&gt;то этот урок может быть вам полезен&lt;/a&gt; для начала работы с &lt;em&gt;Numpy&lt;/em&gt;.  &lt;/p&gt;
&lt;h3&gt;Массивы&lt;/h3&gt;
&lt;p&gt;Массив numpy представляет собой сетку значений одного и того же типа, индексирующую кортежем неотрицательные целые числа. Количество измерений — это ранг массива; Форма массива представляет собой кортеж целых чисел, задающий размер массива вдоль каждого измерения.  &lt;/p&gt;
&lt;p&gt;Мы можем инициализировать массивы &lt;em&gt;numpy&lt;/em&gt; из вложенных списков &lt;em&gt;python&lt;/em&gt;, и получить доступ к элементам с помощью квадратных скобок:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt; &lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;   &lt;span class="c1"&gt;# Create a rank 1 array&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;type&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;            &lt;span class="c1"&gt;# Prints "&amp;lt;class 'numpy.ndarray'&amp;gt;"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;            &lt;span class="c1"&gt;# Prints "(3,)"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;   &lt;span class="c1"&gt;# Prints "1 2 3"&lt;/span&gt;
&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;                  &lt;span class="c1"&gt;# Change an element of the array&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                  &lt;span class="c1"&gt;# Prints "[5, 2, 3]"&lt;/span&gt;

&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;    &lt;span class="c1"&gt;# Create a rank 2 array&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                     &lt;span class="c1"&gt;# Prints "(2, 3)"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;   &lt;span class="c1"&gt;# Prints "1 2 4"  &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Numpy&lt;/em&gt; также предоставляет множество функций для создания массивов:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;   &lt;span class="c1"&gt;# Create an array of all zeros&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;              &lt;span class="c1"&gt;# Prints "[[ 0.  0.]&lt;/span&gt;
                      &lt;span class="c1"&gt;#          [ 0.  0.]]"&lt;/span&gt;

&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;    &lt;span class="c1"&gt;# Create an array of all ones&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;              &lt;span class="c1"&gt;# Prints "[[ 1.  1.]]"&lt;/span&gt;

&lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;full&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Create a constant array&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;               &lt;span class="c1"&gt;# Prints "[[ 7.  7.]&lt;/span&gt;
                       &lt;span class="c1"&gt;#          [ 7.  7.]]"&lt;/span&gt;

&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;eye&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;         &lt;span class="c1"&gt;# Create a 2x2 identity matrix&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;              &lt;span class="c1"&gt;# Prints "[[ 1.  0.]&lt;/span&gt;
                      &lt;span class="c1"&gt;#          [ 0.  1.]]"&lt;/span&gt;

&lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  &lt;span class="c1"&gt;# Create an array filled with random values&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                     &lt;span class="c1"&gt;# Might print "[[ 0.91940167  0.08143941]&lt;/span&gt;
                             &lt;span class="c1"&gt;#               [ 0.68744134  0.87236687]]"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;О других способах создания массивов вы можете прочитать&lt;/strong&gt; &lt;a href="http://docs.scipy.org/doc/numpy/user/basics.creation.html#arrays-creation"&gt;в документации&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Индексация массивов&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Numpy&lt;/em&gt; предлагает несколько способов индексации в массивы.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Разрезание на ломтики&lt;/strong&gt;: как и в случае со списками &lt;em&gt;python&lt;/em&gt;, массивы numpy могут быть разделены на срезы. Поскольку массивы могут быть многомерными, необходимо указать срез для каждого измерения массива:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="c1"&gt;# Create the following rank 2 array with shape (3, 4)&lt;/span&gt;
&lt;span class="c1"&gt;# [[ 1  2  3  4]&lt;/span&gt;
&lt;span class="c1"&gt;#  [ 5  6  7  8]&lt;/span&gt;
&lt;span class="c1"&gt;#  [ 9 10 11 12]]&lt;/span&gt;
&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

&lt;span class="c1"&gt;# Use slicing to pull out the subarray consisting of the first 2 rows&lt;/span&gt;
&lt;span class="c1"&gt;# and columns 1 and 2; b is the following array of shape (2, 2):&lt;/span&gt;
&lt;span class="c1"&gt;# [[2 3]&lt;/span&gt;
&lt;span class="c1"&gt;#  [6 7]]&lt;/span&gt;
&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# A slice of an array is a view into the same data, so modifying it&lt;/span&gt;
&lt;span class="c1"&gt;# will modify the original array.&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;   &lt;span class="c1"&gt;# Prints "2"&lt;/span&gt;
&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;77&lt;/span&gt;     &lt;span class="c1"&gt;# b[0, 0] is the same piece of data as a[0, 1]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;   &lt;span class="c1"&gt;# Prints "77"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Вы также можете сочетать целочисленное индексирование с индексированием срезов. Однако это приведет к получению массива более низкого ранга, чем исходный массив. Обратите внимание, что это сильно отличается от способа, которым &lt;em&gt;MATLAB&lt;/em&gt; работает с массивами при разрезании на ломтики:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="c1"&gt;# Create the following rank 2 array with shape (3, 4)&lt;/span&gt;
&lt;span class="c1"&gt;# [[ 1  2  3  4]&lt;/span&gt;
&lt;span class="c1"&gt;#  [ 5  6  7  8]&lt;/span&gt;
&lt;span class="c1"&gt;#  [ 9 10 11 12]]&lt;/span&gt;
&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

&lt;span class="c1"&gt;# Two ways of accessing the data in the middle row of the array.&lt;/span&gt;
&lt;span class="c1"&gt;# Mixing integer indexing with slices yields an array of lower rank,&lt;/span&gt;
&lt;span class="c1"&gt;# while using only slices yields an array of the same rank as the&lt;/span&gt;
&lt;span class="c1"&gt;# original array:&lt;/span&gt;
&lt;span class="n"&gt;row_r1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;    &lt;span class="c1"&gt;# Rank 1 view of the second row of a&lt;/span&gt;
&lt;span class="n"&gt;row_r2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt;  &lt;span class="c1"&gt;# Rank 2 view of the second row of a&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row_r1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;row_r1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "[5 6 7 8] (4,)"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;row_r2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;row_r2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "[[5 6 7 8]] (1, 4)"&lt;/span&gt;

&lt;span class="c1"&gt;# We can make the same distinction when accessing columns of an array:&lt;/span&gt;
&lt;span class="n"&gt;col_r1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;col_r2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[:,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;col_r1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_r1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "[ 2  6 10] (3,)"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;col_r2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;col_r2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "[[ 2]&lt;/span&gt;
                             &lt;span class="c1"&gt;#          [ 6]&lt;/span&gt;
                             &lt;span class="c1"&gt;#          [10]] (3, 1)"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Индексация целочисленного массива&lt;/strong&gt;: Когда вы индексируете массивы &lt;em&gt;numpy&lt;/em&gt; с помощью слайсинга, результирующее представление массива всегда будет подмассивом исходного массива. В противоположность этому, индексация целочисленного массива позволяет создавать произвольные массивы, используя данные из другого массива. Вот пример:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

&lt;span class="c1"&gt;# An example of integer array indexing.&lt;/span&gt;
&lt;span class="c1"&gt;# The returned array will have shape (3,) and&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "[1 4 5]"&lt;/span&gt;

&lt;span class="c1"&gt;# The above example of integer array indexing is equivalent to this:&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]))&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "[1 4 5]"&lt;/span&gt;

&lt;span class="c1"&gt;# When using integer array indexing, you can reuse the same&lt;/span&gt;
&lt;span class="c1"&gt;# element from the source array:&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "[2 2]"&lt;/span&gt;

&lt;span class="c1"&gt;# Equivalent to the previous integer array indexing example&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]]))&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "[2 2]"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Одним из полезных приемов при индексации целочисленных массивов является выбор или изменение в одногм из них каждой строки матрицы:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="c1"&gt;# Create a new array from which we will select elements&lt;/span&gt;
&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# prints "array([[ 1,  2,  3],&lt;/span&gt;
          &lt;span class="c1"&gt;#                [ 4,  5,  6],&lt;/span&gt;
          &lt;span class="c1"&gt;#                [ 7,  8,  9],&lt;/span&gt;
          &lt;span class="c1"&gt;#                [10, 11, 12]])"&lt;/span&gt;

&lt;span class="c1"&gt;# Create an array of indices&lt;/span&gt;
&lt;span class="n"&gt;b&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="c1"&gt;# Select one element from each row of a using the indices in b&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "[ 1  6  7 11]"&lt;/span&gt;

&lt;span class="c1"&gt;# Mutate one element from each row of a using the indices in b&lt;/span&gt;
&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# prints "array([[11,  2,  3],&lt;/span&gt;
          &lt;span class="c1"&gt;#                [ 4,  5, 16],&lt;/span&gt;
          &lt;span class="c1"&gt;#                [17,  8,  9],&lt;/span&gt;
          &lt;span class="c1"&gt;#                [10, 21, 12]])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Индексация логических массивов&lt;/strong&gt;: Логическое индексирование массива позволяет выделять произвольные элементы массива. Часто этот тип индексации используется для выбора элементов массива которые удовлетворяют какому-либо условию. Вот пример:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

&lt;span class="n"&gt;bool_idx&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# Find the elements of a that are bigger than 2;&lt;/span&gt;
                     &lt;span class="c1"&gt;# this returns a numpy array of Booleans of the same&lt;/span&gt;
                     &lt;span class="c1"&gt;# shape as a, where each slot of bool_idx tells&lt;/span&gt;
                     &lt;span class="c1"&gt;# whether that element of a is &amp;gt; 2.&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;bool_idx&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;      &lt;span class="c1"&gt;# Prints "[[False False]&lt;/span&gt;
                     &lt;span class="c1"&gt;#          [ True  True]&lt;/span&gt;
                     &lt;span class="c1"&gt;#          [ True  True]]"&lt;/span&gt;

&lt;span class="c1"&gt;# We use boolean array indexing to construct a rank 1 array&lt;/span&gt;
&lt;span class="c1"&gt;# consisting of the elements of a corresponding to the True values&lt;/span&gt;
&lt;span class="c1"&gt;# of bool_idx&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bool_idx&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "[3 4 5 6]"&lt;/span&gt;

&lt;span class="c1"&gt;# We can do all of the above in a single concise statement:&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;     &lt;span class="c1"&gt;# Prints "[3 4 5 6]"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Для краткости мы опустили много подробностей об индексации массива &lt;em&gt;numpy&lt;/em&gt;; Если вы хотите узнать больше, вам следует &lt;a href="http://docs.scipy.org/doc/numpy/reference/arrays.indexing.html"&gt;прочитать документацию&lt;/a&gt;.  &lt;/p&gt;
&lt;h3&gt;Типы данных&lt;/h3&gt;
&lt;p&gt;Каждый массив &lt;em&gt;numpy&lt;/em&gt; представляет собой сетку элементов одного типа. &lt;em&gt;Numpy&lt;/em&gt; предоставляет большой набор числовых типов данных, которые можно использовать для создания массивов. &lt;em&gt;Numpy&lt;/em&gt; пытается определить тип данных при создании массива, но функции, создающие массивы, обычно также включают необязательный аргумент для явного указания типа данных. Вот пример:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;   &lt;span class="c1"&gt;# Let numpy choose the datatype&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;         &lt;span class="c1"&gt;# Prints "int64"&lt;/span&gt;

&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mf"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;2.0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;   &lt;span class="c1"&gt;# Let numpy choose the datatype&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;             &lt;span class="c1"&gt;# Prints "float64"&lt;/span&gt;

&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# Force a particular datatype&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                         &lt;span class="c1"&gt;# Prints "int64"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Вы можете прочитать все о типах данных &lt;em&gt;numpy&lt;/em&gt; &lt;a href="http://docs.scipy.org/doc/numpy/reference/arrays.dtypes.html"&gt;в документации&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Математические операции с массивами&lt;/h3&gt;
&lt;p&gt;Основные математические функции работают с массивами поэлементно и доступны как в виде перегрузок операторов, так и в виде функций в модуле &lt;em&gt;numpy&lt;/em&gt;:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float64&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float64&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Elementwise sum; both produce the array&lt;/span&gt;
&lt;span class="c1"&gt;# [[ 6.0  8.0]&lt;/span&gt;
&lt;span class="c1"&gt;#  [10.0 12.0]]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;add&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# Elementwise difference; both produce the array&lt;/span&gt;
&lt;span class="c1"&gt;# [[-4.0 -4.0]&lt;/span&gt;
&lt;span class="c1"&gt;#  [-4.0 -4.0]]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subtract&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# Elementwise product; both produce the array&lt;/span&gt;
&lt;span class="c1"&gt;# [[ 5.0 12.0]&lt;/span&gt;
&lt;span class="c1"&gt;#  [21.0 32.0]]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;multiply&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# Elementwise division; both produce the array&lt;/span&gt;
&lt;span class="c1"&gt;# [[ 0.2         0.33333333]&lt;/span&gt;
&lt;span class="c1"&gt;#  [ 0.42857143  0.5       ]]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;divide&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# Elementwise square root; produces the array&lt;/span&gt;
&lt;span class="c1"&gt;# [[ 1.          1.41421356]&lt;/span&gt;
&lt;span class="c1"&gt;#  [ 1.73205081  2.        ]]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Обратите внимание, что в отличие от &lt;em&gt;MATLAB&lt;/em&gt;,&lt;code&gt;*&lt;/code&gt;- это поэлементное умножение, а не матрица умножение. Вместо этого мы используем функцию &lt;code&gt;dot&lt;/code&gt; для вычисления скалярного произведения векторов, умножить вектор на матрицу, и умножения матриц. &lt;code&gt;dot&lt;/code&gt; доступен как функция в numpy и в качестве экземпляра метода объектов массива:    &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="c1"&gt;# Inner product of vectors; both produce 219&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# Matrix / vector product; both produce the rank 1 array [29 67]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# Matrix / matrix product; both produce the rank 2 array&lt;/span&gt;
&lt;span class="c1"&gt;# [[19 22]&lt;/span&gt;
&lt;span class="c1"&gt;#  [43 50]]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Numpy&lt;/em&gt; предоставляет множество полезных функций для выполнения вычислений на массивах; Одной из самых полезных является:&lt;code&gt;sum&lt;/code&gt;  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;

&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  &lt;span class="c1"&gt;# Compute sum of all elements; prints "10"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  &lt;span class="c1"&gt;# Compute sum of each column; prints "[4 6]"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;  &lt;span class="c1"&gt;# Compute sum of each row; prints "[3 7]"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Полный список математических функций, предоставляемых &lt;em&gt;numpy&lt;/em&gt;, вы можете найти &lt;a href="http://docs.scipy.org/doc/numpy/reference/routines.math.html"&gt;в документации&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Помимо вычисления математических функций с помощью массивов, мы часто должны изменять форму данных в массивах или иным образом манипулировать ими. Самый простой пример. Одним из таких видов операции является транспонирование матрицы; для транспонирования матрицы, просто используйте атрибут &lt;code&gt;T&lt;/code&gt; объекта массива:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;    &lt;span class="c1"&gt;# Prints "[[1 2]&lt;/span&gt;
            &lt;span class="c1"&gt;#          [3 4]]"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "[[1 3]&lt;/span&gt;
            &lt;span class="c1"&gt;#          [2 4]]"&lt;/span&gt;

&lt;span class="c1"&gt;# Note that taking the transpose of a rank 1 array does nothing:&lt;/span&gt;
&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;    &lt;span class="c1"&gt;# Prints "[1 2 3]"&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "[1 2 3]"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;em&gt;Numpy&lt;/em&gt; предоставляет гораздо больше функций для работы с массивами; С полным списком можно ознакомиться &lt;a href="http://docs.scipy.org/doc/numpy/reference/routines.array-manipulation.html"&gt;в документации&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Вещание&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Вещание&lt;/strong&gt; - это мощный механизм, который позволяет &lt;em&gt;numpy&lt;/em&gt; работать с массивами различных фигур при выполнении арифметических действий. Часто у нас есть меньший массив и больший массив, и мы хотим использовать меньший массив несколько раз для выполнения какой-либо операции на более крупном массиве.  &lt;/p&gt;
&lt;p&gt;Например, предположим, что мы хотим добавить вектор константы к каждой строке матрицы. Мы могли бы сделать это следующим образом:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="c1"&gt;# We will add the vector v to each row of the matrix x,&lt;/span&gt;
&lt;span class="c1"&gt;# storing the result in the matrix y&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;empty_like&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="c1"&gt;# Create an empty matrix with the same shape as x&lt;/span&gt;

&lt;span class="c1"&gt;# Add the vector v to each row of the matrix x with an explicit loop&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;

&lt;span class="c1"&gt;# Now y is the following&lt;/span&gt;
&lt;span class="c1"&gt;# [[ 2  2  4]&lt;/span&gt;
&lt;span class="c1"&gt;#  [ 5  5  7]&lt;/span&gt;
&lt;span class="c1"&gt;#  [ 8  8 10]&lt;/span&gt;
&lt;span class="c1"&gt;#  [11 11 13]]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Это работает, однако, когда матрица &lt;code&gt;x&lt;/code&gt; очень большая, вычисление явного цикла в &lt;em&gt;python&lt;/em&gt; может быть медленным. Обратите внимание, что добавление вектора &lt;code&gt;v&lt;/code&gt; к каждой строке матрицы &lt;code&gt;x&lt;/code&gt; эквивалентно формированию матрицы &lt;code&gt;vv&lt;/code&gt; путем наложения нескольких копий &lt;code&gt;v&lt;/code&gt; по вертикали, затем выполнение поэлементного суммирования &lt;code&gt;x&lt;/code&gt; и &lt;code&gt;vv&lt;/code&gt; мы могли бы реализовать этот подход следующим образом:        &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="c1"&gt;# We will add the vector v to each row of the matrix x,&lt;/span&gt;
&lt;span class="c1"&gt;# storing the result in the matrix y&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;vv&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;tile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;   &lt;span class="c1"&gt;# Stack 4 copies of v on top of each other&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vv&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                 &lt;span class="c1"&gt;# Prints "[[1 0 1]&lt;/span&gt;
                          &lt;span class="c1"&gt;#          [1 0 1]&lt;/span&gt;
                          &lt;span class="c1"&gt;#          [1 0 1]&lt;/span&gt;
                          &lt;span class="c1"&gt;#          [1 0 1]]"&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;vv&lt;/span&gt;  &lt;span class="c1"&gt;# Add x and vv elementwise&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "[[ 2  2  4&lt;/span&gt;
          &lt;span class="c1"&gt;#          [ 5  5  7]&lt;/span&gt;
          &lt;span class="c1"&gt;#          [ 8  8 10]&lt;/span&gt;
          &lt;span class="c1"&gt;#          [11 11 13]]"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Массивы Numpy позволяют выполнять вычисления без фактического создания нескольких копий &lt;code&gt;v&lt;/code&gt;. Рассмотрим эту версию с использованием массивов:&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="c1"&gt;# We will add the vector v to each row of the matrix x,&lt;/span&gt;
&lt;span class="c1"&gt;# storing the result in the matrix y&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;12&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;  &lt;span class="c1"&gt;# Add v to each row of x using broadcasting&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "[[ 2  2  4]&lt;/span&gt;
          &lt;span class="c1"&gt;#          [ 5  5  7]&lt;/span&gt;
          &lt;span class="c1"&gt;#          [ 8  8 10]&lt;/span&gt;
          &lt;span class="c1"&gt;#          [11 11 13]]"&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Строка &lt;code&gt;y = x + v&lt;/code&gt; работает, несмотря на то, что &lt;code&gt;x&lt;/code&gt; имеет форму  &lt;code&gt;(4, 3)&lt;/code&gt;и &lt;code&gt;v&lt;/code&gt; имеет форму &lt;code&gt;(3,)&lt;/code&gt; благодаря вещанию; Эта линия работает так, как будто &lt;code&gt;v&lt;/code&gt; на самом деле имеет форму &lt;code&gt;(4, 3)&lt;/code&gt;, где каждая строка была копией , а сумма &lt;code&gt;v&lt;/code&gt; выполнялась по элементам.     &lt;/p&gt;
&lt;p&gt;Трансляция двух массивов одновременно выполняется по следующим правилам:
1. Если массивы имеют разный ранг, добавьте в начало форму массива с меньшим рангом с &lt;strong&gt;1s&lt;/strong&gt; до тех пор, пока обе фигуры не будут иметь одинаковую длину.
2. Два массива считаются &lt;em&gt;совместимыми&lt;/em&gt; в размерности, если они имеют одинаковое значение size в измерении, или если один из массивов имеет размер &lt;strong&gt;1&lt;/strong&gt; в этом измерении.
3. Массивы могут транслироваться вместе, если они совместимы во всех измерениях.
4. После трансляции каждый массив ведет себя так, как если бы он имел форму, равную поэлементной максимальное количество форм двух входных массивов.
5. В любом измерении, где один массив имеет размер &lt;strong&gt;1&lt;/strong&gt;, а другой массив больше &lt;strong&gt;1&lt;/strong&gt;, первый массив ведет себя так, как если бы он был скопирован по этому размеру  &lt;/p&gt;
&lt;p&gt;Если это объяснение не имеет смысла, попробуйте прочитать объяснение &lt;a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html"&gt;из документации&lt;/a&gt; или &lt;a href="https://scipy.github.io/old-wiki/pages/EricsBroadcastingDoc"&gt;это объяснение&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;Функции, поддерживающие широковещательную рассылку, называются &lt;em&gt;универсальными функциями&lt;/em&gt;. Вы можете найти Список всех универсальных функций &lt;a href="http://docs.scipy.org/doc/numpy/reference/ufuncs.html#available-ufuncs"&gt;в документации&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;Вот некоторые области применения вещания:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="c1"&gt;# Compute outer product of vectors&lt;/span&gt;
&lt;span class="n"&gt;v&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;  &lt;span class="c1"&gt;# v has shape (3,)&lt;/span&gt;
&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;    &lt;span class="c1"&gt;# w has shape (2,)&lt;/span&gt;
&lt;span class="c1"&gt;# To compute an outer product, we first reshape v to be a column&lt;/span&gt;
&lt;span class="c1"&gt;# vector of shape (3, 1); we can then broadcast it against w to yield&lt;/span&gt;
&lt;span class="c1"&gt;# an output of shape (3, 2), which is the outer product of v and w:&lt;/span&gt;
&lt;span class="c1"&gt;# [[ 4  5]&lt;/span&gt;
&lt;span class="c1"&gt;#  [ 8 10]&lt;/span&gt;
&lt;span class="c1"&gt;#  [12 15]]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Add a vector to each row of a matrix&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;6&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="c1"&gt;# x has shape (2, 3) and v has shape (3,) so they broadcast to (2, 3),&lt;/span&gt;
&lt;span class="c1"&gt;# giving the following matrix:&lt;/span&gt;
&lt;span class="c1"&gt;# [[2 4 6]&lt;/span&gt;
&lt;span class="c1"&gt;#  [5 7 9]]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;v&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Add a vector to each column of a matrix&lt;/span&gt;
&lt;span class="c1"&gt;# x has shape (2, 3) and w has shape (2,).&lt;/span&gt;
&lt;span class="c1"&gt;# If we transpose x then it has shape (3, 2) and can be broadcast&lt;/span&gt;
&lt;span class="c1"&gt;# against w to yield a result of shape (3, 2); transposing this result&lt;/span&gt;
&lt;span class="c1"&gt;# yields the final result of shape (2, 3) which is the matrix x with&lt;/span&gt;
&lt;span class="c1"&gt;# the vector w added to each column. Gives the following matrix:&lt;/span&gt;
&lt;span class="c1"&gt;# [[ 5  6  7]&lt;/span&gt;
&lt;span class="c1"&gt;#  [ 9 10 11]]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Another solution is to reshape w to be a column vector of shape (2, 1);&lt;/span&gt;
&lt;span class="c1"&gt;# we can then broadcast it directly against x to produce the same&lt;/span&gt;
&lt;span class="c1"&gt;# output.&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="c1"&gt;# Multiply a matrix by a constant:&lt;/span&gt;
&lt;span class="c1"&gt;# x has shape (2, 3). Numpy treats scalars as arrays of shape ();&lt;/span&gt;
&lt;span class="c1"&gt;# these can be broadcast together to shape (2, 3), producing the&lt;/span&gt;
&lt;span class="c1"&gt;# following array:&lt;/span&gt;
&lt;span class="c1"&gt;# [[ 2  4  6]&lt;/span&gt;
&lt;span class="c1"&gt;#  [ 8 10 12]]&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Широковещательная рассылка обычно делает ваш код более кратким и быстрым, поэтому вы должен стремиться использовать ее там, где это возможно.  &lt;/p&gt;
&lt;h3&gt;Документация Numpy&lt;/h3&gt;
&lt;p&gt;Этот краткий обзор затронул многие важные вещи, которые вам необходимо знать о &lt;em&gt;numpy&lt;/em&gt;, но далеко не полны. Ознакомьтесь &lt;a href="http://docs.scipy.org/doc/numpy/reference/"&gt;со справочником numpy&lt;/a&gt;, чтобы узнать больше о numpy.&lt;/p&gt;
&lt;h2&gt;SciPy&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Numpy&lt;/em&gt; предоставляет высокопроизводительный многомерный массив и основные инструменты для выполняйте вычисления с помощью этих массивов и управляйте ими. 
&lt;a href="http://docs.scipy.org/doc/scipy/reference/"&gt;SciPy&lt;/a&gt; опирается на это и предоставляет большое количество функций, которые работают с массивами &lt;em&gt;numpy&lt;/em&gt; и полезны для различных видов научных и инженерных приложений.  &lt;/p&gt;
&lt;p&gt;Лучший способ познакомиться с &lt;em&gt;SciPy&lt;/em&gt; - &lt;a href="http://docs.scipy.org/doc/scipy/reference/index.html"&gt;это просмотреть документацию&lt;/a&gt;. 
Мы выделим некоторые части &lt;em&gt;SciPy&lt;/em&gt;, которые могут быть вам полезны для этого класса.&lt;/p&gt;
&lt;h3&gt;Операции с изображениями&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;SciPy&lt;/em&gt; предоставляет некоторые основные функции для работы с изображениями. 
Например, в нем есть функции чтения изображений с диска в массивы &lt;em&gt;numpy&lt;/em&gt;, для записи массивов &lt;em&gt;numpy&lt;/em&gt; на диск в виде изображений, а также для изменения размера изображений. 
Вот простой пример, демонстрирующий эти функции:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;from&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;scipy.misc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;imread&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;imsave&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;imresize&lt;/span&gt;

&lt;span class="c1"&gt;# Read an JPEG image into a numpy array&lt;/span&gt;
&lt;span class="n"&gt;img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;imread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'assets/cat.jpg'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# Prints "uint8 (400, 248, 3)"&lt;/span&gt;

&lt;span class="c1"&gt;# We can tint the image by scaling each of the color channels&lt;/span&gt;
&lt;span class="c1"&gt;# by a different scalar constant. The image has shape (400, 248, 3);&lt;/span&gt;
&lt;span class="c1"&gt;# we multiply it by the array [1, 0.95, 0.9] of shape (3,);&lt;/span&gt;
&lt;span class="c1"&gt;# numpy broadcasting means that this leaves the red channel unchanged,&lt;/span&gt;
&lt;span class="c1"&gt;# and multiplies the green and blue channels by 0.95 and 0.9&lt;/span&gt;
&lt;span class="c1"&gt;# respectively.&lt;/span&gt;
&lt;span class="n"&gt;img_tinted&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.95&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# Resize the tinted image to be 300 by 300 pixels.&lt;/span&gt;
&lt;span class="n"&gt;img_tinted&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;imresize&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img_tinted&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;300&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;300&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="c1"&gt;# Write the tinted image back to disk&lt;/span&gt;
&lt;span class="n"&gt;imsave&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'assets/cat_tinted.jpg'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;img_tinted&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/cat.jpg"&gt;&lt;br&gt;
&lt;img alt="" src="https://cs231n.github.io/assets/cat_tinted.jpg"&gt;&lt;br&gt;
&lt;strong&gt;Сверху&lt;/strong&gt;: исходное изображение. &lt;strong&gt;Снизу&lt;/strong&gt;: Затемненное изображение с измененным размером.  &lt;/p&gt;
&lt;h3&gt;Файлы MATLAB&lt;/h3&gt;
&lt;p&gt;Функции &lt;code&gt;scipy.io.loadmat&lt;/code&gt; и &lt;code&gt;scipy.io.savemat&lt;/code&gt; позволяют считывать и писать файлы &lt;em&gt;MATLAB&lt;/em&gt;. О них можно прочитать в &lt;a href="http://docs.scipy.org/doc/scipy/reference/io.html"&gt;документации&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Расстояние между точками&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;SciPy&lt;/em&gt; определяет некоторые полезные функции для вычисления расстояний между наборами точек.  &lt;/p&gt;
&lt;p&gt;Функция &lt;code&gt;scipy.spatial.distance.pdist&lt;/code&gt; вычисляет расстояние между всеми парами точек в заданном наборе:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;scipy.spatial.distance&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;pdist&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;squareform&lt;/span&gt;

&lt;span class="c1"&gt;# Create the following array where each row is a point in 2D space:&lt;/span&gt;
&lt;span class="c1"&gt;# [[0 1]&lt;/span&gt;
&lt;span class="c1"&gt;#  [1 0]&lt;/span&gt;
&lt;span class="c1"&gt;#  [2 0]]&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;array&lt;/span&gt;&lt;span class="p"&gt;([[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Compute the Euclidean distance between all rows of x.&lt;/span&gt;
&lt;span class="c1"&gt;# d[i, j] is the Euclidean distance between x[i, :] and x[j, :],&lt;/span&gt;
&lt;span class="c1"&gt;# and d is the following array:&lt;/span&gt;
&lt;span class="c1"&gt;# [[ 0.          1.41421356  2.23606798]&lt;/span&gt;
&lt;span class="c1"&gt;#  [ 1.41421356  0.          1.        ]&lt;/span&gt;
&lt;span class="c1"&gt;#  [ 2.23606798  1.          0.        ]]&lt;/span&gt;
&lt;span class="n"&gt;d&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;squareform&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pdist&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'euclidean'&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Все подробности об этой функции вы можете прочитать в &lt;a href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.pdist.html"&gt;документации&lt;/a&gt;.  &lt;/p&gt;
&lt;p&gt;Аналогичная функция (&lt;code&gt;scipy.spatial.distance.cdist&lt;/code&gt;) вычисляет расстояние между всеми парами по двум группам точек; Вы можете прочитать об этом &lt;a href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.cdist.html"&gt;в документации&lt;/a&gt; .&lt;/p&gt;
&lt;h2&gt;Matplotlib&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://matplotlib.org/"&gt;Matplotlib&lt;/a&gt; — библиотека для построения графиков. В этом разделе дается краткое введение в модуль &lt;code&gt;matplotlib.pyplot&lt;/code&gt;, который обеспечивает систему построения графиков, аналогичную системе &lt;em&gt;MATLAB&lt;/em&gt;.&lt;/p&gt;
&lt;h3&gt;Постоение графиков&lt;/h3&gt;
&lt;p&gt;Наиболее важной функцией в &lt;em&gt;matplotlib&lt;/em&gt; является &lt;code&gt;plot&lt;/code&gt;, что позволяет строить графики &lt;em&gt;2D&lt;/em&gt; данных. Вот простой пример:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;plt&lt;/span&gt;

&lt;span class="c1"&gt;# Compute the x and y coordinates for points on a sine curve&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Plot the points using matplotlib&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;  &lt;span class="c1"&gt;# You must call plt.show() to make graphics appear.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Выполнение этого кода создает следующий график:  &lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/sine.png"&gt;  &lt;/p&gt;
&lt;p&gt;Приложив немного дополнительной работы, мы можем легко построить несколько линий и добавить заголовок, легенду и подписи осям:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;plt&lt;/span&gt;

&lt;span class="c1"&gt;# Compute the x and y coordinates for points on sine and cosine curves&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y_sin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y_cos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Plot the points using matplotlib&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_sin&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_cos&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'x axis label'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'y axis label'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Sine and Cosine'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;legend&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s1"&gt;'Sine'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'Cosine'&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/sine_cosine.png"&gt;  &lt;/p&gt;
&lt;p&gt;Гораздо больше о функции &lt;code&gt;plot&lt;/code&gt; вы можете прочитать &lt;a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.plot"&gt;в документации&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Подзаголовки&lt;/h3&gt;
&lt;p&gt;С помощью &lt;code&gt;subplot&lt;/code&gt; функции на одном и том же рисунке можно изобразить разные объекты. Вот пример:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;plt&lt;/span&gt;

&lt;span class="c1"&gt;# Compute the x and y coordinates for points on sine and cosine curves&lt;/span&gt;
&lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;pi&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y_sin&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y_cos&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cos&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Set up a subplot grid that has height 2 and width 1,&lt;/span&gt;
&lt;span class="c1"&gt;# and set the first such subplot as active.&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Make the first plot&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_sin&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Sine'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Set the second subplot as active, and make the second plot.&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;plot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y_cos&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'Cosine'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Show the figure.&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/sine_cosine_subplot.png"&gt;  &lt;/p&gt;
&lt;p&gt;Гораздо больше о функции &lt;code&gt;subplot&lt;/code&gt; вы можете прочитать &lt;a href="http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.subplot"&gt;в документации&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Изображения&lt;/h3&gt;
&lt;p&gt;Вы можете использовать функцию &lt;code&gt;imshow&lt;/code&gt; для показа изображений. Вот пример:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;scipy.misc&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;imread&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;imresize&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;plt&lt;/span&gt;

&lt;span class="n"&gt;img&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;imread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'assets/cat.jpg'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;img_tinted&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;img&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.95&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mf"&gt;0.9&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# Show the original image&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# Show the tinted image&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;subplot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;# A slight gotcha with imshow is that it might give strange results&lt;/span&gt;
&lt;span class="c1"&gt;# if presented with data that is not uint8. To work around this, we&lt;/span&gt;
&lt;span class="c1"&gt;# explicitly cast the image to uint8 before displaying it.&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;uint8&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;img_tinted&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/cat_tinted_imshow.png"&gt;  &lt;/p&gt;</description><guid>https://mldl.ru/posts/numpy-tutorial/</guid><pubDate>Wed, 02 Jul 2025 06:42:16 GMT</pubDate></item><item><title>Классификация изображений </title><link>https://mldl.ru/posts/image-classification/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;h2&gt;Классификация изображений&lt;/h2&gt;
&lt;p&gt;В этой лекции мы познакомимся с проблемой классификации изображений. 
Решение проблемы заключается в подходе, основанном на большом объеме размеченных данных.   &lt;/p&gt;
&lt;p&gt;Содержание:&lt;br&gt;
- &lt;a href="https://mldl.ru/posts/image-classification/#%D0%B2%D0%B2%D0%B5%D0%B4%D0%B5%D0%BD%D0%B8%D0%B5-%D0%B2-%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8E-%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B9"&gt;Введение в классификацию изображений&lt;/a&gt;&lt;br&gt;
  - &lt;a href="https://mldl.ru/posts/image-classification/#%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%82%D0%BE%D1%80-%D0%B1%D0%BB%D0%B8%D0%B6%D0%B0%D0%B9%D1%88%D0%B5%D0%B3%D0%BE-%D1%81%D0%BE%D1%81%D0%B5%D0%B4%D0%B0"&gt;Классификатор ближайшего соседа&lt;/a&gt;&lt;br&gt;
  - &lt;a href="https://mldl.ru/posts/image-classification/#%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%82%D0%BE%D1%80-k---%D0%B1%D0%BB%D0%B8%D0%B6%D0%B0%D0%B9%D1%88%D0%B8%D1%85-%D1%81%D0%BE%D1%81%D0%B5%D0%B4%D0%B5%D0%B9"&gt;Классификатор k - ближайших соседей&lt;/a&gt; &lt;br&gt;
  - &lt;a href="https://mldl.ru/posts/image-classification/#%D0%BD%D0%B0%D0%B1%D0%BE%D1%80%D1%8B-%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85-%D0%B8-%D0%BD%D0%B0%D1%81%D1%82%D1%80%D0%BE%D0%B9%D0%BA%D0%B8-%D0%B3%D0%B8%D0%BF%D0%B5%D1%80%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%BE%D0%B2"&gt;Наборы данных для настройки гиперпараметров&lt;/a&gt;&lt;br&gt;
  - &lt;a href="https://mldl.ru/posts/image-classification/#%D0%BF%D1%80%D0%B8%D0%BC%D0%B5%D0%BD%D0%B5%D0%BD%D0%B8%D0%B5-knn-%D0%BD%D0%B0-%D0%BF%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B5"&gt;Применение kNN на практике&lt;/a&gt;&lt;br&gt;
    - &lt;a href="https://mldl.ru/posts/image-classification/#%D0%B4%D0%BE%D0%BF%D0%BE%D0%BB%D0%BD%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5-%D0%BC%D0%B0%D1%82%D0%B5%D1%80%D0%B8%D0%B0%D0%BB%D1%8B"&gt;Дополнительные материалы&lt;/a&gt; &lt;/p&gt;
&lt;h3&gt;Введение в классификацию изображений&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Мотивация&lt;/strong&gt;. В этом разделе мы рассмотрим задачу классификации изображений. Задача заключается в присвоении входному изображению одной метки из фиксированного набора категорий. Это одна из основных задач компьютерного зрения, которая, несмотря на свою простоту, имеет множество практических применений. Более того, многие другие задачи компьютерного зрения (детекция объектов, сегментация) могут быть сведены к классификации изображений.   &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Пример&lt;/strong&gt;. Например, на изображении ниже модель классификации изображений принимает одно изображение и присваивает вероятности четырём меткам: &lt;em&gt;{«кошка», «собака», «шляпа», «кружка»}&lt;/em&gt;. Как показано на изображении, для компьютера изображение представляет собой один большой трёхмерный массив чисел. В этом примере изображение кошки имеет ширину &lt;strong&gt;248&lt;/strong&gt; пикселей, высоту &lt;strong&gt;400&lt;/strong&gt; пикселей и три цветовых канала: красный, зелёный, синий (или сокращённо &lt;em&gt;RGB&lt;/em&gt;). Таким образом, изображение состоит из &lt;strong&gt;248 x 400 x 3&lt;/strong&gt; чисел, или в общей сложности 297 600 чисел. Каждое число представляет собой целое число от 0 (чёрный) до 255 (белый). Наша задача — превратить эти четверть миллиона чисел в одну метку, например &lt;em&gt;«кошка»&lt;/em&gt;.  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/classify.png"&gt;  &lt;/p&gt;
&lt;p&gt;Задача классификации изображений состоит в том, чтобы предсказать одну метку для заданного изображения. Так же мы можем предсказать распределение вероятностей для всех меток, что отражает степень нашей уверенности в результате классификации.   Изображения представляют собой трёхмерные массивы целых чисел от 0 до 255 размером «ширина x высота x 3». Число 3 обозначает три цветовых канала: красный, зелёный и синий.  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Проблемы&lt;/strong&gt;.  Поскольку задача распознавания визуального образа (например, кошки) относительно проста для человека, стоит рассмотреть связанные с ней проблемы с точки зрения алгоритма компьютерного зрения.&lt;br&gt;
Ниже мы приводим (неполный) список проблем, не забывая о том, что изображения представлены в виде трёхмерного массива значений яркости:&lt;br&gt;
- &lt;strong&gt;Изменение точки обзора&lt;/strong&gt;. Один экземпляр объекта может быть ориентирован по-разному относительно камеры.&lt;br&gt;
- &lt;strong&gt;Изменение масштаба&lt;/strong&gt;. Визуальные классы часто различаются по размеру (размеру в реальном мире, а не только по размеру на изображении).&lt;br&gt;
- &lt;strong&gt;Деформация&lt;/strong&gt;. Многие интересующие нас объекты не являются твёрдыми телами и могут сильно деформироваться.&lt;br&gt;
- &lt;strong&gt;Окклюзия&lt;/strong&gt;. Интересующие нас объекты могут быть частично скрыты. Иногда видна лишь небольшая часть объекта (всего несколько пикселей).&lt;br&gt;
- &lt;strong&gt;Условия освещения&lt;/strong&gt;. Влияние освещения на пиксели очень велико.&lt;br&gt;
- &lt;strong&gt;Фоновый шум&lt;/strong&gt;. Интересующие нас объекты могут сливаться с окружающей средой, что затрудняет их идентификацию.&lt;br&gt;
- &lt;strong&gt;Внутриклассовые различия&lt;/strong&gt;. Классы, представляющие интерес, часто могут быть относительно обширными, например, &lt;em&gt;стулья&lt;/em&gt;. 
Существует множество различных типов этих предметов, каждый из которых имеет отличный от других элементов класса внешний вид.    &lt;/p&gt;
&lt;p&gt;Хорошая модель классификации изображений должна быть инвариантна к перекрёстному произведению всех этих вариаций, сохраняя при этом чувствительность к межклассовым вариациям.   &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/challenges.jpeg"&gt;   &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Подход, основанный на данных&lt;/strong&gt;. Как бы мы могли написать алгоритм, который сможет классифицировать изображения по отдельным категориям? В отличие от написания алгоритма, например, для сортировки списка чисел, не очевидно, как можно написать алгоритм для распознавания кошек на изображениях. Поэтому вместо того, чтобы пытаться описать каждую из интересующих нас категорий непосредственно в коде, мы воспользуемся подходом, похожим на обучение ребёнка. Мы предоставим компьютеру множество примеров, а затем используем алгоритм обучения, который связывает визуальное представление с меткой каждого класса. Этот подход предполагает, что у нас есть обучающий набор с размеченными изображениями. Вот пример того, как может выглядеть такой набор данных:   &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/trainset.jpg"&gt;   &lt;/p&gt;
&lt;p&gt;Пример обучающего набора для четырёх визуальных категорий. 
На практике у нас могут быть тысячи категорий и сотни тысяч изображений для каждой категории.  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Конвейер классификации изображений&lt;/strong&gt;.  Мы увидели, что задача классификации изображений состоит в том, чтобы взять массив пикселей изображения и присвоить ему метку. 
Наш полный конвейер можно формализовать следующим образом:&lt;br&gt;
- &lt;strong&gt;Входные данные&lt;/strong&gt;: состоят из набора &lt;strong&gt;&lt;em&gt;N&lt;/em&gt;&lt;/strong&gt; изображений, каждое из которых помечено одним из &lt;strong&gt;&lt;em&gt;K&lt;/em&gt;&lt;/strong&gt; различных классов. 
Эти данные называются &lt;em&gt;обучающей выборкой&lt;/em&gt;.&lt;br&gt;
- &lt;strong&gt;Обучение&lt;/strong&gt;: наша задача использовать обучающую выборку, чтобы узнать, как выглядит каждый из классов. 
Мы называем этот этап &lt;em&gt;обучением классификатора&lt;/em&gt; или &lt;em&gt;обучением модели&lt;/em&gt;.&lt;br&gt;
- &lt;strong&gt;Оценка&lt;/strong&gt;: в конце мы оцениваем качество классификатора. 
Для этого нужно задать вопрос о том, какие метки предскажет классификатор для нового набора изображений, которые он никогда раньше не видел. 
Затем мы сравниваем истинные метки этих изображений с теми, которые предсказал классификатор. 
Интуитивно мы надеемся, что многие прогнозы совпадут с истинными ответами. 
Данные, которые используются для оценки точности классификатора называются &lt;em&gt;тестовой выборкой&lt;/em&gt;. &lt;/p&gt;
&lt;h4&gt;Классификатор ближайшего соседа&lt;/h4&gt;
&lt;p&gt;В качестве первого подхода мы используем так называемый &lt;strong&gt;классификатор ближайшего соседа&lt;/strong&gt;. 
Этот классификатор не имеет ничего общего со свёрточными нейронными сетями и очень редко используется на практике. 
Однако он позволит нам получить представление о том, как решается задача классификации изображений.   &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Пример набора данных для классификации изображений: CIFAR-10&lt;/strong&gt;.&lt;br&gt;
Одним из популярных наборов данных для классификации изображений является &lt;a href="https://www.cs.toronto.edu/~kriz/cifar.html"&gt;набор данных CIFAR-10&lt;/a&gt;. Этот набор данных состоит из 60 000 крошечных изображений высотой и шириной 32 пикселя. Каждое изображение относится к одному из 10 классов: самолет, автомобиль, птица и т. д. Эти 60 000 изображений разделены на обучающую выборку из 50 000 изображений и тестовую выборку из 10 000 изображений. 
На изображении ниже вы можете увидеть 10 случайных примеров изображений для каждого класса.    &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/nn.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;Слева: примеры изображений из набора данных CIFAR-10.&lt;br&gt;
Справа: в первом столбце показаны несколько тестовых изображений.&lt;br&gt;
Рядом с каждым изображением мы видим 10 наиболее похожих "картинок" из обучающей выборки. &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Изначально, у нас есть обучающая выборка CIFAR-10 из 50 000 изображений (по 5000 изображений для каждой из 10 категорий). 
Мы хотим классифицировать оставшиеся 10 000. Классификатор ближайших соседей работает следующим образом. Берется тестовое изображение и сравается с каждым изображением из обучающей выборки. Будем считать, что метка тестового изображения будет такой же, как и у самого похожего на него изображения.  &lt;/p&gt;
&lt;p&gt;На изображении выше и справа вы можете увидеть пример результата такой процедуры для 10 тестовых изображений. Обратите внимание, что только в 3 из 10 изображений являются элементами того же класса, в то время как в остальных 7 примерах возникает ошибка определения класса. Например, в 8-м ряду ближайшим обучающим изображением к голове лошади является красный автомобиль, предположительно из-за сильного чёрного фона. В результате этого, изображение лошади в данном случае будет ошибочно помечено как автомобиль. &lt;/p&gt;
&lt;p&gt;Мы не уточнили, как именно мы сравниваем два изображения. 
Технически изображения представляют собой просто два блока (тензора) размером 32 x 32 x 3. 
Один из самых простых способов — сравнивать изображения попиксельно и суммировать все разности. 
Другими словами, если у вас есть два изображения, представленные в виде векторов $I_1$, $I_2$, разумным выбором для их сравнения может быть &lt;strong&gt;расстояние L1&lt;/strong&gt;:   &lt;/p&gt;
&lt;p&gt;$$
d_1 (I_1, I_2) = \sum_{p} \left| I^p_1 - I^p_2 \right|
$$   &lt;/p&gt;
&lt;p&gt;Сумма берется по всем пикселям. 
Вот как выглядит эта процедура:   &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/nneg.jpeg"&gt;  &lt;/p&gt;
&lt;p&gt;Пример использования попиксельных различий для сравнения двух изображений с помощью расстояния $L_1$ (в данном примере для одного цветового канала). 
Два изображения вычитаются поэлементно, а затем все различия суммируются до получения одного числа. 
Если два изображения идентичны, результат будет равен нулю. 
Но если изображения сильно отличаются, результат будет большим.   &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Давайте также посмотрим, как можно реализовать классификатор в коде. Сначала загрузим данные CIFAR-10 в память в виде четырех массивов: обучающие данные/метки и тестовые данные/метки. В приведенном ниже коде &lt;code&gt;Xtr&lt;/code&gt; хранятся все изображения из обучающей выборки  (объем 50 000 x 32 x 32 x 3), а соответствующий одномерный массив &lt;code&gt;Ytr&lt;/code&gt; (длиной 50 000) содержит обучающие метки (от 0 до 9):   &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;Xtr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Ytr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Xte&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Yte&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;load_CIFAR10&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'data/cifar10/'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# a magic function we provide&lt;/span&gt;
&lt;span class="c1"&gt;# flatten out all images to be one-dimensional &lt;/span&gt;
&lt;span class="n"&gt;Xtr_rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Xtr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Xtr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# Xtr_rows becomes 50000 x 3072&lt;/span&gt;
&lt;span class="n"&gt;Xte_rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Xte&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Xte&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;32&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# Xte_rows becomes 10000 x 3072 &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Теперь, когда все изображения вытянуты в ряд, мы можем обучить и оценить классификатор:   &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;nn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;NearestNeighbor&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="c1"&gt;# create a Nearest Neighbor classifier class&lt;/span&gt;
&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Xtr_rows&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Ytr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# train the classifier on the training images and labels&lt;/span&gt;
&lt;span class="n"&gt;Yte_predict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Xte_rows&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# predict labels on the test images&lt;/span&gt;
&lt;span class="c1"&gt;# and now print the classification accuracy, which is the average number&lt;/span&gt;
&lt;span class="c1"&gt;# of examples that are correctly predicted (i.e. label matches)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;'accuracy: &lt;/span&gt;&lt;span class="si"&gt;%f&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Yte_predict&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;Yte&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Обратите внимание, что в качестве критерия оценки обычно используется метрика &lt;strong&gt;accuracy&lt;/strong&gt;, 
Эта метрика измеряет долю правильных прогнозов в тестовой выборке. 
Обратите внимание, что все классификаторы, которые мы создадим, имеют общий интерфейс (API). 
У них есть метод &lt;code&gt;train(X,y)&lt;/code&gt;, который принимает на вход данные и метки для обучения. 
Внутри класса должна быть построена своего рода модель, которая предсказывает метки на основе данных. 
Метод &lt;code&gt;predict(X)&lt;/code&gt; принимает новые данные и предсказывает метки. &lt;/p&gt;
&lt;p&gt;Пример реализации простого классификатора ближайшего соседа с расстоянием $L_1$, который реализует интерфейс классификатора:   &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="kn"&gt;import&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;numpy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;as&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="k"&gt;class&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nc"&gt;NearestNeighbor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;pass&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;""" X is N x D where each row is an example. Y is 1-dimension of size N&lt;/span&gt;
&lt;span class="sd"&gt;        The nearest neighbor classifier simply remembers all the training data """&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Xtr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ytr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nf"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="sd"&gt;""" X is N x D where each row is an example we wish to predict label for """&lt;/span&gt;
        &lt;span class="n"&gt;num_test&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="c1"&gt;# lets make sure that the output type matches the input type&lt;/span&gt;
        &lt;span class="n"&gt;Ypred&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_test&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ytr&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="c1"&gt;# loop over all test rows&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_test&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="c1"&gt;# find the nearest training image to the i'th test image&lt;/span&gt;
        &lt;span class="c1"&gt;# using the L1 distance (sum of absolute value differences)&lt;/span&gt;
        &lt;span class="n"&gt;distances&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;abs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Xtr&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,:]),&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;min_index&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argmin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;distances&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# get the index with smallest distance&lt;/span&gt;
        &lt;span class="n"&gt;Ypred&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ytr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;min_index&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="c1"&gt;# predict the label of the nearest example&lt;/span&gt;

        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;Ypred&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Если вы запустите этот код, то увидите, что классификатор достигает точности &lt;strong&gt;38,6%&lt;/strong&gt; на тестовой выборке CIFAR-10. 
Это более впечатляющий результат, чем случайное угадывание (которое дало бы &lt;strong&gt;10%&lt;/strong&gt; точности для 10 классов). 
Но он далёк от результатов человека, которые &lt;a href="https://karpathy.github.io/2011/04/27/manually-classifying-cifar10/"&gt;оцениваются примерно в 94%&lt;/a&gt;.  Еще лучший результат можно получить с помощью свёрточных нейронных сетей, которые достигают примерно 95% (см. таблицу соревнования &lt;a href="https://www.kaggle.com/c/cifar-10/leaderboard"&gt;Kaggle&lt;/a&gt; по CIFAR-10).  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Выбор расстояния&lt;/strong&gt;.  Существует множество других способов вычисления расстояний между векторами. Одним из распространённых вариантов может быть использование &lt;strong&gt;расстояния $L_2$&lt;/strong&gt;, которое имеет геометрическую интерпретацию вычисления евклидова расстояния между двумя векторами. 
Формула для вычисления этого расстояния имеет вид:  &lt;/p&gt;
&lt;p&gt;$$
d_2 (I_1, I_2) = \sqrt{\sum_{p} \left( I^p_1 - I^p_2 \right)^2}
$$  &lt;/p&gt;
&lt;p&gt;Другими словами, мы вычисляем разницу по пикселям, как и раньше, но на этот раз возводим их в квадрат, складываем и, наконец, извлекаем квадратный корень. 
Используя приведенный выше код с numpy, нам нужно заменить только одну строку:   &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;distances&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sqrt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;square&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Xtr&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,:]),&lt;/span&gt; &lt;span class="n"&gt;axis&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Обратите внимание на вычисление корня в функции &lt;code&gt;np.sqrt&lt;/code&gt;. 
В практической реализации метода ближайшего соседа мы могли бы не использовать операцию извлечения квадратного корня, потому что он является &lt;em&gt;монотонной функцией&lt;/em&gt;. 
То есть он масштабирует абсолютные значения расстояний, но сохраняет порядок. 
Поэтому с ним или без него, ближайшие соседи будут идентичны. 
Однако если применить классификатор ближайшего соседа к CIFAR-10 с $L_2$ расстоянием, получится всего &lt;strong&gt;35,4%&lt;/strong&gt; точности. 
Это немного ниже, чем результат с расстоянием &lt;strong&gt;$L_1$&lt;/strong&gt;.   &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Расстояние $L_1$ против $L_2$ .&lt;/strong&gt;  Различие между этими двумя метриками в том, что расстояние &lt;strong&gt;$L_2$&lt;/strong&gt; более строгое, чем расстояние &lt;strong&gt;$L_1$&lt;/strong&gt;. Это значит, что если имеется множество небольших расхождений и всего одно большое, расстояние $L_2$ будет больше, чем $L_1$. Понятия расстояний &lt;strong&gt;$L_1$&lt;/strong&gt; и  &lt;strong&gt;$L_2$&lt;/strong&gt;  эквивалентно нормам, которые являются частными случаями &lt;a href="https://planetmath.org/vectorpnorm"&gt;p-нормы&lt;/a&gt;.   &lt;/p&gt;
&lt;h4&gt;Классификатор k - ближайших соседей&lt;/h4&gt;
&lt;p&gt;Когда мы хотим сделать более точный прогноз, нам не обязательно использовать только одну метку ближайшего изображения. Действительно, почти всегда можно добиться лучшего результата, используя так называемый &lt;strong&gt;классификатор k-ближайших соседей&lt;/strong&gt;. 
Идея очень проста: вместо того, чтобы искать одно ближайшее изображение в обучающем наборе, мы найдём &lt;strong&gt;k&lt;/strong&gt; ближайших изображений. 
Дальше мы сравним их и устроим "голосование" за метку тестового изображения. 
В частности, когда &lt;em&gt;k = 1&lt;/em&gt;, мы получаем классификатор ближайшего соседа. 
Интуитивно понятно, что чем больше значений &lt;strong&gt;k&lt;/strong&gt; мы возьмем, тем больше будет сглаживающий эффект. 
Это первый пример гиперпараметра, который делает классификатор более устойчивым к ошибкам:   &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/knn.jpeg"&gt;  &lt;/p&gt;
&lt;p&gt;Пример разницы между классификатором «один ближайший сосед» и классификатором «ближайшие 5 соседей» с использованием двумерных точек и 3 классов (красный, синий, зелёный). 
Цветные области показывают &lt;strong&gt;границы решений&lt;/strong&gt;, создаваемые классификатором с использованием расстояния  $L_2$. 
Белые области показывают точки, которые классифицируются неоднозначно - голоса за классы равны как минимум для двух классов. 
Обратите внимание, что в случае классификатора 1-соседа ошибки создают небольшие островки вероятных неверных прогнозов. 
Например, зелёная точка в середине облака синих точек. 
В это же время классификатор 5-соседей сглаживает эти неровности, что, приводит к лучшему &lt;strong&gt;обобщению&lt;/strong&gt; на тестовых данных. 
Также обратите внимание, что серые области на изображении 5-соседей вызваны равенством голосов ближайших соседей. 
Например, 2 соседа красные, следующие два соседа синие, последний сосед зелёный. &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;На практике почти всегда используется метод k-ближайших соседей. 
Но какое значение k следует использовать? 
Давайте рассмотрим этот вопрос поподробнее.   &lt;/p&gt;
&lt;h4&gt;Наборы данных и настройки гиперпараметров&lt;/h4&gt;
&lt;p&gt;Классификатор k-ближайших соседей требует настройки параметра &lt;em&gt;k&lt;/em&gt;. 
Интуитивно можно предположить, что существует число, которое подходит лучше всего. 
Кроме того, мы увидели, что существует множество различных функций расстояния, которые мы могли бы использовать: норма  &lt;strong&gt;$L_1$&lt;/strong&gt;, норма &lt;strong&gt;$L_2$&lt;/strong&gt;, а также множество других вариантов, которые мы даже не рассматривали (например, скалярные произведения). 
Эти варианты называются &lt;strong&gt;гиперпараметрами&lt;/strong&gt;, и они очень часто используются при разработке многих алгоритмов машинного обучения, которые обучаются на данных. 
Часто не очевидно, какие значения/настройки следует выбрать.   &lt;/p&gt;
&lt;p&gt;У вас может возникнуть соблазн предложить попробовать множество различных значений и посмотреть, что работает лучше всего. 
Это хорошая идея, и именно это мы и сделаем, но делать это нужно очень осторожно. 
В частности, &lt;strong&gt;мы не можем использовать тестовый набор данных для настройки гиперпараметров&lt;/strong&gt;. 
Всякий раз, когда вы разрабатываете алгоритмы машинного обучения, вы должны относиться к тестовому набору данных как к очень ценному ресурсу, к которому, в идеале, не следует прикасаться до самого конца. 
В противном случае существует реальная опасность того, что вы настроите гиперпараметры так, чтобы они хорошо работали на тестовом наборе данных, но при развёртывании модели показывали значительное снижение производительности. 
На практике можно сказать, что произошло &lt;strong&gt;переобучение&lt;/strong&gt; на тестовом наборе данных. 
С другой стороны, если вы настраиваете гиперпараметры на тестовом наборе данных, вы фактически используете тестовый набор данных в качестве обучающего. 
По этой причине точность, которую вы достигаете на нём, будет слишком оптимистичной по сравнению с тем, что будет наблюдаться на реальных данных при развёртывании модели. 
Но если вы используете тестовый набор данных только один раз в конце, он остаётся хорошим показателем для того, чтобы измерить степень &lt;strong&gt;обобщения&lt;/strong&gt; вашего классификатора.   &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Итого: Оценивайте модель на тестовой выборке только один раз, в самом конце!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Существует правильный способ настройки гиперпараметров, который никак не затрагивает тестовый набор данных. 
Идея состоит в том, чтобы разделить обучающую выборку на две части: немного меньший обучающий набор и то, что называется &lt;strong&gt;выборкой для валидации&lt;/strong&gt;. 
Используя в качестве примера CIFAR-10, мы могли бы использовать 49 000 обучающих изображений для обучения и оставить 1000 для валидации. 
Этот набор данных по сути используется для настройки гиперпараметров.   &lt;/p&gt;
&lt;p&gt;Вот как это может выглядеть в случае CIFAR-10:   &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="c1"&gt;# assume we have Xtr_rows, Ytr, Xte_rows, Yte as before&lt;/span&gt;
&lt;span class="c1"&gt;# recall Xtr_rows is 50,000 x 3072 matrix&lt;/span&gt;
&lt;span class="n"&gt;Xval_rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Xtr_rows&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="c1"&gt;# take first 1000 for validation&lt;/span&gt;
&lt;span class="n"&gt;Yval&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Ytr&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;Xtr_rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Xtr_rows&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;:,&lt;/span&gt; &lt;span class="p"&gt;:]&lt;/span&gt; &lt;span class="c1"&gt;# keep last 49,000 for train&lt;/span&gt;
&lt;span class="n"&gt;Ytr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Ytr&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1000&lt;/span&gt;&lt;span class="p"&gt;:]&lt;/span&gt;

&lt;span class="c1"&gt;# find hyperparameters that work best on the validation set&lt;/span&gt;
&lt;span class="n"&gt;validation_accuracies&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;

&lt;span class="c1"&gt;# use a particular value of k and evaluation on validation data&lt;/span&gt;
&lt;span class="n"&gt;nn&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;NearestNeighbor&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;train&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Xtr_rows&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Ytr&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# here we assume a modified NearestNeighbor class that can take a k as input&lt;/span&gt;
&lt;span class="n"&gt;Yval_predict&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;predict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Xval_rows&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;acc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mean&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;Yval_predict&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;Yval&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="nb"&gt;print&lt;/span&gt; &lt;span class="s1"&gt;'accuracy: &lt;/span&gt;&lt;span class="si"&gt;%f&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;acc&lt;/span&gt;&lt;span class="p"&gt;,)&lt;/span&gt;

&lt;span class="c1"&gt;# keep track of what works on the validation set&lt;/span&gt;
&lt;span class="n"&gt;validation_accuracies&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;k&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;acc&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;По завершении этой процедуры построим график, который показывает, какие значения k работают лучше всего. 
Затем мы остановимся на этом значении и проведем оценку на реальном тестовом наборе данных.   &lt;/p&gt;
&lt;p&gt;Разделите обучающую выборку на обучающую и валидационную. 
Используйте проверочную выборку для настройки всех гиперпараметров. 
В конце выполните один запуск на тестовой выборке и оцените производительность.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Кросс-валидация&lt;/strong&gt;. В случаях, когда размер обучающих данных (и, следовательно, проверочных данных) может быть небольшим, люди иногда используют более сложный метод настройки гиперпараметров, называемый &lt;strong&gt;кросс-валидацией&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Если вернуться к нашему предыдущему примеру, то идея заключается в том, что вместо произвольного выбора первых 1000 точек данных в качестве проверочного набора, а остальных — в качестве обучающего, можно получить более точную и менее зашумлённую оценку того, насколько хорошо работает определённое значение &lt;strong&gt;k&lt;/strong&gt;, перебирая различные проверочные наборы и усредняя результаты по ним. Например, при 5-кратной перекрёстной проверке мы разделили бы обучающие данные на 5 равных частей, использовали 4 из них для обучения, а 1 — для проверки. Затем мы бы определили, какая из выборок является контрольной, оценили бы производительность и, наконец, усреднили бы производительность по разным выборкам.   &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/cvplot.png"&gt;&lt;br&gt;
Пример 5-кратного выполнения перекрестной проверки для параметра &lt;strong&gt;k&lt;/strong&gt;. Для каждого значения &lt;strong&gt;k&lt;/strong&gt; мы тренируемся на 4 сгибах и оцениваем на 5-м. Следовательно, для каждого k мы получаем 5 значений точности для проверочного сгиба (точность отражается на оси y, и каждый результат равен точке). Линия тренда проводится через среднее значение результатов для каждого &lt;strong&gt;k&lt;/strong&gt;, а столбики ошибок указывают на стандартное отклонение. Обратите внимание, что в данном конкретном случае перекрёстная проверка показывает, что значение около &lt;strong&gt;k = 7&lt;/strong&gt; лучше всего подходит для этого конкретного набора данных (соответствует пику на графике). Если бы мы использовали более 5 циклов, то могли бы ожидать более плавную (то есть менее шумную) кривую.   &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;На практике люди предпочитают избегать перекрёстной проверки в пользу одного проверочного набора данных, поскольку перекрёстная проверка может быть ресурсозатратной. Обычно люди используют от &lt;strong&gt;50%&lt;/strong&gt; до &lt;strong&gt;90%&lt;/strong&gt; обучающих данных для обучения и остальную часть для проверки. Однако это зависит от множества факторов: например, если количество гиперпараметров велико, вы можете предпочесть использовать более крупные проверочные наборы данных. Если количество примеров в проверочном наборе невелико (возможно, всего несколько сотен или около того), безопаснее использовать перекрёстную проверку. На практике обычно используется 3-кратная, 5-кратная или 10-кратная перекрёстная проверка.     &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/crossval.jpeg"&gt;  &lt;/p&gt;
&lt;p&gt;Обычное разделение данных. Выделяются обучающий и тестовый наборы данных. Обучающий набор данных делится на части (например, здесь их 5). Части 1-4 становятся обучающим набором данных. Одна часть (например, часть 5, выделенная здесь жёлтым цветом) называется проверочной частью и используется для настройки гиперпараметров. Перекрёстная проверка идёт дальше и позволяет выбрать, какая часть будет проверочной, отдельно от частей 1-5. Это называется 5-кратной перекрёстной проверкой. В самом конце, когда модель обучена и определены все наилучшие гиперпараметры, модель один раз оценивается на тестовых данных (красный цвет). &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Плюсы и минусы классификатора ближайших соседей.&lt;/strong&gt;   &lt;/p&gt;
&lt;p&gt;Стоит рассмотреть некоторые преимущества и недостатки классификатора «ближайший сосед». 
Очевидно, что одним из преимуществ является простота реализации и понимания. 
Кроме того, обучение классификатора не занимает много времени, поскольку всё, что требуется, — это хранить и, возможно, индексировать обучающие данные. 
Однако мы платим за это вычислительными затратами во время тестирования, поскольку для классификации тестового примера требуется сравнение с каждым обучающим примером. 
Это неправильно, поскольку на практике мы часто уделяем больше внимания эффективности во время тестирования, чем во время обучения. 
На самом деле, объемные нейронные сети, которые мы будем разрабатывать в этом классе, смещают этот компромисс в другую крайность: их обучение обходится очень дорого, но после завершения обучения классифицировать новый тестовый пример очень дёшево. 
Такой режим работы гораздо более желателен на практике.   &lt;/p&gt;
&lt;p&gt;Кроме того, вычислительная сложность классификатора «ближайший сосед» является активной областью исследований, и существует несколько алгоритмов и библиотек &lt;strong&gt;приблизительного поиска ближайшего соседа&lt;/strong&gt; (&lt;em&gt;ANN&lt;/em&gt;), которые могут ускорить поиск ближайшего соседа в наборе данных (например, &lt;a href="https://github.com/mariusmuja/flann"&gt;FLANN&lt;/a&gt; ). 
Эти алгоритмы позволяют найти компромисс между точностью поиска ближайшего соседа и его пространственной/временной сложностью во время поиска и обычно полагаются на этап предварительной обработки/индексирования, который включает в себя построение KD-дерева или запуск алгоритма k-средних.  &lt;/p&gt;
&lt;p&gt;В некоторых случаях классификатор ближайших соседей может быть хорошим выбором (особенно если данные имеют низкую размерность), но он редко подходит для использования в практических задачах классификации изображений. 
Одна из проблем заключается в том, что изображения — это объекты с высокой размерностью (то есть они часто содержат много пикселей), а расстояния в многомерных пространствах могут быть очень нелогичными. 
На изображении ниже показано, что сходство на основе пикселей, которое мы описали выше, сильно отличается от сходства с точки зрения восприятия:   &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/samenorm.png"&gt;   &lt;/p&gt;
&lt;p&gt;Расстояния на основе пикселей в многомерных данных (и особенно в изображениях) могут быть очень неинтуитивными. 
Исходное изображение (слева) и три других изображения рядом с ним, которые находятся на одинаковом расстоянии от него на основе пиксельного расстояния &lt;strong&gt;$L_2$&lt;/strong&gt;. 
Очевидно, что пиксельное расстояние никак не соответствует перцептивному или семантическому сходству. &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Вот ещё одна визуализация, которая убедит вас в том, что использование разницы в пикселях для сравнения изображений недостаточно. Мы можем использовать метод визуализации под названием &lt;a href="https://lvdmaaten.github.io/tsne/"&gt;t-SNE&lt;/a&gt;, чтобы взять изображения CIFAR-10 и разместить их в двух измерениях так, чтобы их  парные (локальные) расстояния сохранялись наилучшим образом. В этой визуализации изображения, которые показаны рядом, считаются очень близкими в соответствии с расстоянием &lt;strong&gt;$L_2$&lt;/strong&gt; по пикселям, которое мы разработали выше:    &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/pixels_embed_cifar10.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;Изображения CIFAR-10, размещённые в двух измерениях с помощью &lt;em&gt;t-SNE&lt;/em&gt;. Изображения, расположенные рядом на этом изображении, считаются близкими на основе пиксельного расстояния &lt;strong&gt;$L_2$&lt;/strong&gt;. 
Обратите внимание на сильное влияние фона, а не семантических различий между классами. 
Нажмите &lt;a href="https://cs231n.github.io/assets/pixels_embed_cifar10_big.jpg"&gt;здесь&lt;/a&gt;, чтобы увидеть увеличенную версию этой визуализации. &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;В частности, обратите внимание, что изображения, расположенные друг рядом с другом, в большей степени зависят от общего цветового распределения изображений или типа фона, а не от их семантической идентичности. Например, собаку можно увидеть рядом с лягушкой, потому что они обе находятся на белом фоне. В идеале мы хотели бы, чтобы изображения всех 10 классов образовывали собственные кластеры, чтобы изображения одного класса находились рядом друг с другом независимо от нерелевантных характеристик и вариаций (например, фона). Однако, чтобы добиться этого, нам придётся выйти за рамки необработанных пикселей.   &lt;/p&gt;
&lt;h4&gt;Применение kNN на практике&lt;/h4&gt;
&lt;p&gt;Подводя итог: 
- Мы рассмотрели задачу &lt;strong&gt;классификации изображений&lt;/strong&gt;, в которой нам даётся набор изображений, каждое из которых помечено одной категорией. Затем нас просят предсказать эти категории для нового набора тестовых изображений и оценить точность прогнозов.
- Мы представили простой классификатор под названием &lt;em&gt;«классификатор ближайших соседей»&lt;/em&gt;.  Мы увидели, что существует множество гиперпараметров (например, значение k или тип расстояния, используемого для сравнения примеров), связанных с этим классификатором, и что не существует очевидного способа их выбора.
- Мы увидели, что правильный способ задать эти гиперпараметры — разделить обучающие данные на две части: &lt;em&gt;обучающий набор&lt;/em&gt; и &lt;em&gt;поддельный тестовый набор&lt;/em&gt;, который мы называем &lt;strong&gt;набором для проверки&lt;/strong&gt;. Мы пробуем разные значения гиперпараметров и оставляем те, которые обеспечивают наилучшую производительность на наборе для проверки.
- Если вас беспокоит нехватка обучающих данных, мы обсудили процедуру под названием &lt;strong&gt;перекрёстная проверка&lt;/strong&gt;, которая может помочь уменьшить погрешность при оценке наиболее эффективных гиперпараметров.
- Как только мы находим оптимальные гиперпараметры, мы фиксируем их и проводим одну &lt;strong&gt;оценку&lt;/strong&gt; на реальном тестовом наборе данных.
- Мы увидели, что метод ближайшего соседа может обеспечить нам точность около &lt;strong&gt;40%&lt;/strong&gt; на CIFAR-10. Он прост в реализации, но требует хранения всего обучающего набора данных, и его сложно оценивать на тестовых изображениях.
- В итоге мы увидели, что использование расстояний &lt;strong&gt;$L_1$&lt;/strong&gt; или &lt;strong&gt;$L_2$&lt;/strong&gt; по необработанным значениям пикселей нецелесообразно, поскольку эти расстояния сильнее коррелируют с фоном и цветовыми распределениями изображений, чем с их семантическим содержанием.   &lt;/p&gt;
&lt;p&gt;На следующих лекциях мы приступим к решению этих задач и в конечном итоге придём к решениям, которые обеспечат точность &lt;strong&gt;90%&lt;/strong&gt;, 
позволят полностью отказаться от обучающего набора данных после завершения обучения и позволят оценивать тестовые изображения менее чем за миллисекунду.   &lt;/p&gt;
&lt;p&gt;Если вы хотите применить &lt;em&gt;kNN&lt;/em&gt; на практике (не на изображениях), действуйте следующим образом:  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Предварительная обработка данных.&lt;/strong&gt; 
Нормализуйте признаки в ваших данных (например, один пиксель на изображениях), чтобы среднее значение было равно нулю, а дисперсия — единице. 
Мы рассмотрим этот прием более подробно в следующих разделах. 
Сейчас нормализация данных не используется, потому что распределение яркости пикселей на изображениях достаточно однородны.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Рассмотрите возможность снижения размерности данных&lt;/strong&gt;. 
На практике для снижения размерности используются следующие методы: &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;метод главных компонент &lt;a href="https://en.wikipedia.org/wiki/Principal_component_analysis"&gt;ссылка на вики-страницу&lt;/a&gt;, &lt;a href="http://cs229.stanford.edu/notes/cs229-notes10.pdf"&gt;ссылка на CS229&lt;/a&gt;, &lt;a href="https://web.archive.org/web/20150503165118/http://www.bigdataexaminer.com:80/understanding-dimensionality-reduction-principal-component-analysis-and-singular-value-decomposition/"&gt;ссылка на блог&lt;/a&gt;, &lt;/li&gt;
&lt;li&gt;метод независимых компонент &lt;a href="https://en.wikipedia.org/wiki/Neighbourhood_components_analysis"&gt;ссылка на вики-страницу&lt;/a&gt;, &lt;a href="https://kevinzakka.github.io/2020/02/10/nca/"&gt;ссылка на блог&lt;/a&gt; &lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://scikit-learn.org/stable/modules/random_projection.html"&gt;случайные проекции&lt;/a&gt;.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Разделите обучающие данные случайным образом на обучающую и проверочную (валидационную) выборки.&lt;/strong&gt; 
Как правило, в обучающую выборку попадает от &lt;strong&gt;70&lt;/strong&gt; до &lt;strong&gt;90%&lt;/strong&gt; данных. 
Этот параметр зависит от того, сколько у вас гиперпараметров и насколько сильно они влияют на результат. 
Если нужно оценить множество гиперпараметров, лучше использовать более крупную проверочную выборку для их эффективной оценки. 
Если вас беспокоит размер проверочной выборки, лучше разделить обучающие данные на части и выполнить кросс-валидацию. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Обучите и оцените классификатор kNN на кросс-валидации.&lt;/strong&gt; 
По возможности выполняйте кросс-валидацию для множества вариантов k и для разных типов расстояний (&lt;strong&gt;$L_1$ и $L_2$&lt;/strong&gt; — хорошие кандидаты).&lt;br&gt;
Если вы можете позволить себе потратить больше времени на вычисления, всегда безопаснее использовать кросс-валидацию. 
Чем больше циклов обучения пройдет, тем лучше, но тем дороже с точки зрения вычислений.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Оцените задержку классификатора.&lt;/strong&gt; 
Если ваш классификатор kNN работает слишком долгo, рассмотрите возможность использования библиотеки приближённых ближайших соседей. 
Например, библиотека &lt;a href="https://github.com/mariusmuja/flann"&gt;FLANN&lt;/a&gt; позволяет ускорить поиск за счёт некоторой потери точности.  &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Обратите внимание на гиперпараметры, которые дали наилучшие результаты.&lt;/strong&gt; 
Возникает вопрос, следует ли использовать валидационный набор для финального обучения с наилучшими гиперпараметрами. 
Дело в том, что добавить данные для валидации в набор обучающих данных, оптимальные гиперпараметры могут измениться, поскольку размер данных увеличится. 
На практике лучше не использовать данные валидации в итоговом классификаторе и считать их потерянными при оценке гиперпараметров. &lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Оцените наилучшую модель на тестовом наборе данных.&lt;/strong&gt; 
Вычислите точность на тестовой выборке и объявите результат производительностью классификатора &lt;em&gt;kNN&lt;/em&gt; на ваших данных.  &lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h5&gt;Дополнительные материалы&lt;/h5&gt;
&lt;p&gt;Вот несколько дополнительных ссылок, которые могут быть интересными для дальнейшего чтения:&lt;br&gt;
- &lt;a href="https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf"&gt;Несколько полезных фактов о машинном обучении&lt;/a&gt;, особенно раздел 6, но рекомендуется к прочтению вся статья.&lt;br&gt;
- &lt;a href="https://people.csail.mit.edu/torralba/shortCourseRLOC/index.html"&gt;Распознавание и изучение категорий объектов&lt;/a&gt;, краткий курс по категоризации объектов на ICCV 2005.  &lt;/p&gt;</description><category>CV</category><guid>https://mldl.ru/posts/image-classification/</guid><pubDate>Fri, 14 Mar 2025 05:00:00 GMT</pubDate></item><item><title>Понимание и визуализация</title><link>https://mldl.ru/posts/visualisation/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;h2&gt;Понимание и визуализация&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;(эта страница в настоящее время находится в черновом варианте)&lt;/em&gt;&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;В литературе было разработано несколько подходов к пониманию и визуализации сверточных сетей, отчасти в ответ на распространенную критику о том, что изученные признаки в нейронной сети не поддаются интерпретации. В этом разделе мы кратко рассмотрим некоторые из этих подходов и связанную с ними работу.&lt;/p&gt;
&lt;h3&gt;Визуализация активаций и веса первого слоя&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Активации слоев&lt;/strong&gt;. Наиболее простой метод визуализации заключается в том, чтобы показать активации сети во время прямого прохода. В сетях &lt;em&gt;ReLU&lt;/em&gt; активации обычно выглядят относительно неровными и плотными, но по мере обучения активации обычно становятся более редкими и локализованными. Одна из опасных ловушек, которую можно легко заметить с помощью этой визуализации, заключается в том, что некоторые карты активации могут быть равны нулю для множества различных входных данных, что может указывать на &lt;em&gt;мертвые фильтры&lt;/em&gt; и может быть симптомом высокой скорости обучения.    &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/cnnvis/act1.jpeg"&gt;&lt;br&gt;
&lt;img alt="" src="https://cs231n.github.io/assets/cnnvis/act2.jpeg"&gt;&lt;br&gt;
Типичные активации на первом слое &lt;em&gt;CONV&lt;/em&gt; (&lt;strong&gt;сверху&lt;/strong&gt;) и на 5-м слое &lt;em&gt;CONV&lt;/em&gt; (снизу) обученного &lt;em&gt;AlexNet&lt;/em&gt; смотрят на изображение кошки. В каждом боксе отображается карта активации, соответствующая какому-либо фильтру. Обратите внимание, что активации редкие (большинство значений равны нулю, на этой визуализации показаны черным цветом) и в основном локальные.  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Фильтры Conv/FC&lt;/strong&gt;. Вторая распространенная стратегия заключается в визуализации весов. Обычно они наиболее интерпретируемы на первом слое &lt;em&gt;CONV&lt;/em&gt;, который смотрит непосредственно на необработанные пиксельные данные, но также можно показать веса фильтров в более глубоких слоях сети. Весовые коэффициенты полезны для визуализации, потому что хорошо обученные сети обычно отображают красивые и плавные фильтры без каких-либо зашумленных узоров. Зашумленные паттерны могут быть индикатором сети, которая не обучалась достаточно долго, или, возможно, очень низкой интенсивности регуляризации, которая могла привести к переобучению.  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/cnnvis/filt1.jpeg"&gt;&lt;br&gt;
&lt;img alt="" src="https://cs231n.github.io/assets/cnnvis/filt2.jpeg"&gt;&lt;br&gt;
Типичные фильтры на первом слое &lt;em&gt;CONV&lt;/em&gt; (&lt;strong&gt;сверху&lt;/strong&gt;) и на 2-м слое &lt;em&gt;CONV&lt;/em&gt; (&lt;strong&gt;снизу&lt;/strong&gt;) обученного &lt;em&gt;AlexNet&lt;/em&gt;. Обратите внимание, что веса первого слоя очень красивые и гладкие, что указывает на хорошо сходящуюся сеть. Функции цвета/оттенков серого сгруппированы, потому что &lt;em&gt;AlexNet&lt;/em&gt; содержит два отдельных потока обработки, и очевидным следствием такой архитектуры является то, что один поток развивает высокочастотные элементы оттенков серого, а другой — низкочастотные цветовые функции. Веса 2-го слоя &lt;em&gt;CONV&lt;/em&gt; не так легко интерпретируемы, но очевидно, что они все еще гладкие, хорошо сформированные и лишены зашумленных узоров.  &lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;Получение изображений, которые максимально активируют нейрон&lt;/h3&gt;
&lt;p&gt;Еще один метод визуализации заключается в том, чтобы взять большой набор изображений, пропустить их через сеть и отслеживать, какие изображения максимально активируют тот или иной нейрон. Затем мы можем визуализировать изображения, чтобы понять, что нейрон ищет в своем рецептивном поле. Одна из таких визуализаций (среди прочих) показана в &lt;a href="http://arxiv.org/abs/1311.2524"&gt;статье Богатые иерархии функций для точного обнаружения объектов и семантической сегментации&lt;/a&gt; Росса Гиршика и др.:&lt;br&gt;
&lt;img alt="" src="https://cs231n.github.io/assets/cnnvis/pool5max.jpeg"&gt;&lt;br&gt;
Максимально активизирующие изображения для некоторых нейронов &lt;em&gt;POOL5&lt;/em&gt; (5-й слой пула) AlexNet. Значения активации и рецептивное поле конкретного нейрона показаны белым цветом. (В частности, обратите внимание, что нейроны &lt;em&gt;POOL5&lt;/em&gt; являются функцией относительно большой части входного изображения!) Можно видеть, что некоторые нейроны реагируют на верхнюю часть тела, текст или зеркальные блики.  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Одна из проблем с этим подходом заключается в том, что нейроны &lt;em&gt;ReLU&lt;/em&gt; не обязательно имеют какое-либо семантическое значение сами по себе. Скорее, более уместно думать о множественных нейронах &lt;em&gt;ReLU&lt;/em&gt; как о базисных векторах некоторого пространства, представленного в виде участков изображения. Другими словами, визуализация показывает участки на краю облака представлений, вдоль (произвольных) осей, которые соответствуют весам фильтра. Это также можно увидеть по тому факту, что нейроны в ConvNet работают линейно над входным пространством, поэтому любое произвольное вращение этого пространства является запретным. Этот момент был далее аргументирован в книге Сегеди и др. &lt;a href="http://arxiv.org/abs/1312.6199"&gt;«Интригующие свойства нейронных сетей»&lt;/a&gt;, где они выполняют аналогичную визуализацию вдоль произвольных направлений в пространстве представления.&lt;/p&gt;
&lt;h3&gt;Встраивание кодов с помощью t-SNE&lt;/h3&gt;
&lt;p&gt;ConvNet можно интерпретировать как постепенное преобразование изображений в представление, в котором классы разделяются линейным классификатором. Мы можем получить приблизительное представление о топологии этого пространства, встроив изображения в два измерения таким образом, чтобы их низкоразмерное представление имело примерно равные расстояния, чем их высокомерное представление. Существует множество методов вложения, которые были разработаны с помощью интуиции вложения векторов высокой размерности в пространство низкой размерности с сохранением парных расстояний точек. Среди них &lt;a href="http://lvdmaaten.github.io/tsne/"&gt;t-SNE&lt;/a&gt; является одним из самых известных методов, который неизменно дает визуально приятные результаты.  &lt;/p&gt;
&lt;p&gt;Чтобы произвести встраивание, мы можем взять набор изображений и использовать ConvNet для извлечения кодов &lt;em&gt;CNN&lt;/em&gt; (например, в &lt;em&gt;AlexNet&lt;/em&gt; 4096-мерный вектор прямо перед классификатором, и, что особенно важно, включая нелинейность &lt;em&gt;ReLU&lt;/em&gt;). Затем мы можем подключить их к &lt;em&gt;t-SNE&lt;/em&gt; и получить двумерный вектор для каждого изображения. Соответствующие изображения могут быть визуализированы в виде сетки:  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/cnnvis/tsne.jpeg"&gt;&lt;br&gt;
Встраивание набора изображений в &lt;em&gt;t-SNE&lt;/em&gt; на основе их кодов &lt;em&gt;CNN&lt;/em&gt;. Изображения, которые находятся рядом друг с другом, также близки в пространстве репрезентации &lt;em&gt;CNN&lt;/em&gt;, что подразумевает, что &lt;em&gt;CNN&lt;/em&gt; «видит» их как очень похожие. Обратите внимание, что сходства чаще всего основаны на классах и семантике, а не на пикселях и цветах. Для получения более подробной информации о том, как была создана эта визуализация, связанный код, а также другие связанные визуализации в разных масштабах см. &lt;a href="http://cs.stanford.edu/people/karpathy/cnnembed/"&gt;Визуализация кодов CNN в t-SNE&lt;/a&gt;.  &lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;Окклюзия частей изображения&lt;/h3&gt;
&lt;p&gt;Предположим, что &lt;em&gt;ConvNet&lt;/em&gt; классифицирует изображение как собаку. Как мы можем быть уверены, что он на самом деле улавливает собаку на изображении, а не какие-то контекстуальные подсказки на фоне или какой-то другой объект? Одним из способов исследования того, из какой части изображения исходит предсказание классификации, является построение графика вероятности интересующего класса (например, класса собаки) в зависимости от положения объекта-окклюдера. То есть, мы перебираем области изображения, устанавливаем участок изображения равным нулю и смотрим на вероятность класса. Мы можем визуализировать вероятность в виде двумерной тепловой карты. Этот подход был использован в книге Мэтью Цайлера &lt;a href="http://arxiv.org/abs/1311.2901"&gt;«Визуализация и понимание сверточных сетей»&lt;/a&gt;:  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/cnnvis/occlude.jpeg"&gt;&lt;br&gt;
Три входных изображения (&lt;strong&gt;вверху&lt;/strong&gt;). Обратите внимание, что окклюдерная область показана серым цветом. Когда мы проводим окклюдером по изображению, мы записываем вероятность правильного класса, а затем визуализируем его в виде тепловой карты (&lt;em&gt;показанной под каждым изображением&lt;/em&gt;). Например, на крайнем левом изображении мы видим, что вероятность померанского шпица резко падает, когда окклюдер закрывает морду собаки, что дает нам некоторую степень уверенности в том, что морда собаки в первую очередь ответственна за высокий балл классификации. И наоборот, обнуление других частей изображения имеет относительно незначительное влияние.  &lt;/p&gt;
&lt;hr&gt;
&lt;h3&gt;Визуализация градиента данных и его друзей&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Градиент данных.|&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/abs/1312.6034"&gt;Глубоко внутри сверточных сетей: визуализация моделей классификации изображений и карт заметности&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DeconvNet.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/abs/1311.2901"&gt;Визуализация и понимание сверточных сетей&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Управляемое обратное распространение.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/abs/1412.6806"&gt;Стремление к простоте: Всесвёрточная сеть&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Восстановление оригинальных изображений на основе кодов CNN&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/abs/1412.0035"&gt;Понимание глубоких представлений изображений путем их инвертирования&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Какой объем пространственной информации сохраняется?&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://papers.nips.cc/paper/5420-do-convnets-learn-correspondence.pdf"&gt;Учатся ли ConvNet переписываться?&lt;/a&gt; (Вкратце: да)&lt;/p&gt;
&lt;h3&gt;Производительность построения графиков в зависимости от атрибутов изображения&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/abs/1409.0575"&gt;ImageNet Wide Scale Visual Recognition Challenge&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Обман ConvNet&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://arxiv.org/abs/1412.6572"&gt;Объяснение и использование состязательных примеров&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Сравнение ConvNet с людьми-маркировщиками&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/"&gt;Что я узнал, соревнуясь с ConvNet на ImageNet&lt;/a&gt;&lt;/p&gt;</description><guid>https://mldl.ru/posts/visualisation/</guid><pubDate>Thu, 13 Mar 2025 16:42:16 GMT</pubDate></item><item><title>Архитектура нейросетей </title><link>https://mldl.ru/posts/architecture/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;h2&gt;Архитектура нейросетей&lt;/h2&gt;
&lt;p&gt;Содержание:
- &lt;a href="https://mldl.ru/posts/architecture/"&gt;Обзор архитектуры&lt;/a&gt;
- &lt;a href="https://mldl.ru/posts/architecture/"&gt;Слои ConvNet&lt;/a&gt;
    - &lt;a href="https://mldl.ru/posts/architecture/"&gt;Сверточный слой&lt;/a&gt;
    - &lt;a href="https://mldl.ru/posts/architecture/"&gt;Слой пула&lt;/a&gt;
    - &lt;a href="https://mldl.ru/posts/architecture/"&gt;Слой нормализации&lt;/a&gt;
    - &lt;a href="https://mldl.ru/posts/architecture/"&gt;Полностью подключенный слой&lt;/a&gt;
    - &lt;a href="https://mldl.ru/posts/architecture/"&gt;Преобразование полносвязных слоев в сверточные слои&lt;/a&gt;
- &lt;a href="https://mldl.ru/posts/architecture/"&gt;Архитектуры ConvNet&lt;/a&gt;
     - &lt;a href="https://mldl.ru/posts/architecture/"&gt;Узоры слоев&lt;/a&gt;
     - &lt;a href="https://mldl.ru/posts/architecture/"&gt;Шаблоны для определения размеров слоев&lt;/a&gt;
     - &lt;a href="https://mldl.ru/posts/architecture/"&gt;Тематические исследования &lt;/a&gt; (LeNet / AlexNet / ZFNet / GoogLeNet / VGGNet)
     - &lt;a href="https://mldl.ru/posts/architecture/"&gt;Вычислительные соображения&lt;/a&gt;
- &lt;a href="https://mldl.ru/posts/architecture/"&gt;Дополнительные материалы&lt;/a&gt;  &lt;/p&gt;
&lt;h3&gt;Сверточные нейронные сети (CNNs / ConvNets)&lt;/h3&gt;
&lt;p&gt;Сверточные нейронные сети очень похожи на обычные нейронные сети из предыдущей главы: они состоят из нейронов, которые имеют обучаемые веса и смещения. Каждый нейрон получает некоторые входные данные, выполняет скалярное произведение и опционально следует за ним с нелинейностью. Вся сеть по-прежнему выражает одну дифференцируемую функцию оценки: от пикселей необработанного изображения на одном конце до оценок классов на другом. И у них по-прежнему есть функция потерь (например, &lt;em&gt;SVM/Softmax&lt;/em&gt;) на последнем (полностью подключенном) слое, и все советы/рекомендации, которые мы разработали для обучения обычным нейронным сетям, по-прежнему применимы.  &lt;/p&gt;
&lt;p&gt;Так что же меняется? Архитектуры &lt;em&gt;ConvNet&lt;/em&gt; явно предполагают, что входные данные являются изображениями, что позволяет нам закодировать определенные свойства в архитектуре. Это делает функцию &lt;strong&gt;forward&lt;/strong&gt; более эффективной для реализации и значительно сокращает количество параметров в сети.  &lt;/p&gt;
&lt;h4&gt;Обзор архитектуры&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Напомним: обычные нейронные сети&lt;/em&gt;. Как мы видели в предыдущей главе, нейронные сети получают входные данные (один вектор) и преобразуют их через серию &lt;em&gt;скрытых слоев&lt;/em&gt;. Каждый скрытый слой состоит из набора нейронов, где каждый нейрон полностью связан со всеми нейронами предыдущего слоя, и где нейроны в одном слое функционируют совершенно независимо и не имеют общих связей. Последний полносвязный слой называется «выходным слоем» и в настройках классификации представляет собой баллы класса.  &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Обычные нейронные сети плохо масштабируются до полных изображений&lt;/em&gt;. В CIFAR-10 изображения имеют размер всего &lt;strong&gt;32x32x3&lt;/strong&gt; (&lt;strong&gt;32&lt;/strong&gt; в ширину, &lt;strong&gt;32&lt;/strong&gt; в высоту, &lt;strong&gt;3&lt;/strong&gt; цветных канала), поэтому один полностью связанный нейрон в первом скрытом слое обычной нейронной сети будет иметь &lt;strong&gt;32 * 32 * 3 = 3072&lt;/strong&gt; веса. Это количество все еще кажется управляемым, но очевидно, что эта полностью связанная структура не масштабируется до более крупных изображений. Например, изображение более приличного размера, например, &lt;strong&gt;200x200x3&lt;/strong&gt;, приведет к нейронам с весом &lt;strong&gt;200&lt;em&gt;200&lt;/em&gt;3 = 120 000&lt;/strong&gt;. Более того, мы почти наверняка хотели бы иметь несколько таких нейронов, чтобы параметры быстро складывались! Очевидно, что такая полная связность является расточительной, а огромное количество параметров быстро приведет к переобучению.  &lt;/p&gt;
&lt;p&gt;&lt;em&gt;3D объемы нейронов&lt;/em&gt;. Сверточные нейронные сети используют тот факт, что входные данные состоят из изображений, и они ограничивают архитектуру более разумным образом. В частности, в отличие от обычной нейронной сети, слои ConvNet имеют нейроны, расположенные в трех измерениях: &lt;strong&gt;ширина, высота, глубина&lt;/strong&gt;. (Обратите внимание, что слово &lt;em&gt;«глубина»&lt;/em&gt; здесь относится к третьему измерению объема активации, а не к глубине полной нейронной сети, которая может относиться к общему количеству слоев в сети.) Например, входные изображения в CIFAR-10 представляют собой входной объем активаций, а объем имеет размеры &lt;strong&gt;32х32х3&lt;/strong&gt; (ширина, высота, глубина соответственно). Как мы вскоре увидим, нейроны в слое будут соединены только с небольшой областью слоя перед ним, а не со всеми нейронами в полном объеме. Более того, итоговый выходной слой для CIFAR-10 будет иметь размеры &lt;strong&gt;1x1x10&lt;/strong&gt;, так как к концу архитектуры &lt;em&gt;ConvNet&lt;/em&gt; мы сведем полное изображение к единому вектору оценок классов, расположенных по размерности глубины. Вот визуализация:  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/nn1/neural_net2.jpeg"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/cnn/cnn.jpeg"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Сверху&lt;/strong&gt;: обычная 3-слойная нейронная сеть. &lt;br&gt;
&lt;strong&gt;Снизу&lt;/strong&gt;: &lt;em&gt;ConvNet&lt;/em&gt; располагает свои нейроны в трех измерениях (ширина, высота, глубина), как это визуализировано в одном из слоев. Каждый слой ConvNet преобразует входной объем &lt;strong&gt;3D&lt;/strong&gt; в объем активации нейронов на выходе &lt;strong&gt;3D&lt;/strong&gt;. В этом примере красный входной слой содержит изображение, поэтому его ширина и высота будут соответствовать размерам изображения, а глубина будет равна &lt;strong&gt;3&lt;/strong&gt; (красный, зеленый, синий каналы).  &lt;/p&gt;
&lt;hr&gt;
&lt;blockquote&gt;
&lt;p&gt;ConvNet состоит из слоев. У каждого слоя есть простой API: он преобразует &lt;em&gt;входной 3D-объем&lt;/em&gt; в &lt;em&gt;выходной 3D-объем&lt;/em&gt; с помощью некоторой дифференцируемой функции, которая может иметь или не иметь параметры.  &lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;Слои, используемые для построения ConvNet&lt;/h3&gt;
&lt;p&gt;Как мы уже описывали выше, простая &lt;em&gt;ConvNet&lt;/em&gt; представляет собой последовательность слоев, и каждый слой &lt;em&gt;ConvNet&lt;/em&gt; преобразует один объем активаций в другой с помощью дифференцируемой функции. Мы используем три основных типа слоев для построения архитектур &lt;em&gt;ConvNet&lt;/em&gt;: &lt;strong&gt;сверточный слой, слой пула&lt;/strong&gt; и &lt;strong&gt;полносвязный слой&lt;/strong&gt; (точно так же, как это видно в обычных нейронных сетях). Мы сложим эти слои, чтобы сформировать полноценную &lt;strong&gt;архитектуру&lt;/strong&gt; &lt;em&gt;ConvNet&lt;/em&gt;.  &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Пример архитектуры&lt;/em&gt;: обзор. Мы рассмотрим это более подробно ниже, но простой &lt;em&gt;ConvNet&lt;/em&gt; для классификации CIFAR-10 может иметь архитектуру &lt;strong&gt;[INPUT - CONV - RELU - POOL - FC]&lt;/strong&gt;. Более подробно:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;INPUT &lt;strong&gt;[32x32x3]&lt;/strong&gt; будет содержать исходные значения пикселей изображения, в данном случае изображение шириной &lt;strong&gt;32&lt;/strong&gt;, высотой &lt;strong&gt;32&lt;/strong&gt; и с тремя цветовыми каналами &lt;strong&gt;R,G,B&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Слой &lt;strong&gt;CONV&lt;/strong&gt; будет вычислять выходные данные нейронов, которые соединены с локальными областями на входных данных, каждый из которых вычисляет скалярное произведение между их весами и небольшой областью, к которой они подключены во входном объеме. Это может привести к объему &lt;strong&gt;[32x32x12]&lt;/strong&gt;, если мы решили использовать &lt;strong&gt;12&lt;/strong&gt; фильтров.&lt;/li&gt;
&lt;li&gt;Слой &lt;strong&gt;RELU&lt;/strong&gt; будет применять функцию поэлементной активации, такую как &lt;strong&gt;max(0,х)&lt;/strong&gt; с пороговым значением на нуле. При этом размер тома остается неизменным (&lt;strong&gt;[32x32x12]&lt;/strong&gt;).&lt;/li&gt;
&lt;li&gt;Слой &lt;strong&gt;POOL&lt;/strong&gt; выполнит операцию понижения дискретизации вдоль пространственных измерений (ширина, высота), в результате чего будет получен объем, такой как &lt;strong&gt;[16x16x12]&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Уровень &lt;strong&gt;FC&lt;/strong&gt; (т.е. полностью подключенный) будет вычислять баллы класса, в результате чего будет получен объем размера &lt;strong&gt;[1x1x10]&lt;/strong&gt;, где каждое из &lt;strong&gt;10&lt;/strong&gt; чисел соответствует баллу класса, например, среди &lt;strong&gt;10&lt;/strong&gt; категорий CIFAR-10. Как и в случае с обычными нейронными сетями и как следует из названия, каждый нейрон в этом слое будет связан со всеми числами в предыдущем объеме.  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Таким образом, &lt;em&gt;ConvNet&lt;/em&gt; слой за слоем преобразуют исходное изображение от исходных значений пикселей до итоговых оценок класса. Обратите внимание, что некоторые слои содержат параметры, а другие нет. В частности, слои &lt;em&gt;CONV/FC&lt;/em&gt; выполняют преобразования, которые являются функцией не только активации входного объема, но и параметров (весов и смещений нейронов). С другой стороны, слои &lt;em&gt;RELU/POOL&lt;/em&gt; будут реализовывать фиксированную функцию. Параметры в слоях &lt;em&gt;CONV/FC&lt;/em&gt; будут обучаться с помощью градиентного спуска, чтобы оценки классов, вычисляемые &lt;em&gt;ConvNet&lt;/em&gt;, соответствовали меткам в обучающем наборе для каждого изображения.  &lt;/p&gt;
&lt;p&gt;Вкратце:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Архитектура &lt;em&gt;ConvNet&lt;/em&gt; в простейшем случае представляет собой список слоев, которые преобразуют объем изображения в выходной объем (например, содержат оценки классов)&lt;/li&gt;
&lt;li&gt;Существует несколько различных типов слоев (например, &lt;em&gt;CONV/FC/RELU/POOL&lt;/em&gt; на сегодняшний день являются наиболее популярными)&lt;/li&gt;
&lt;li&gt;Каждый слой принимает входной &lt;strong&gt;3D-объем&lt;/strong&gt; и преобразует его в выходной 3D-объем с помощью дифференцируемой функции&lt;/li&gt;
&lt;li&gt;Каждый слой может иметь или не иметь параметры (например, у &lt;em&gt;CONV/FC&lt;/em&gt; есть, у &lt;em&gt;RELU/POOL&lt;/em&gt; нет)&lt;/li&gt;
&lt;li&gt;Каждый слой может иметь или не иметь дополнительные гиперпараметры (например, у &lt;em&gt;CONV/FC/POOL&lt;/em&gt; есть, у &lt;em&gt;RELU&lt;/em&gt; нет)  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/cnn/convnet.jpeg"&gt;&lt;br&gt;
Активация примера архитектуры &lt;em&gt;ConvNet&lt;/em&gt;. Начальный том хранит необработанные пиксели изображения (&lt;strong&gt;слева&lt;/strong&gt;), а последний том хранит оценки класса (&lt;strong&gt;справа&lt;/strong&gt;). Каждый объем активаций на пути обработки отображается в виде столбца. Так как визуализировать &lt;strong&gt;3D&lt;/strong&gt;-объемы сложно, мы выкладываем срезы каждого тома в ряды. Последний объем слоя содержит баллы для каждого класса, но здесь мы визуализируем только отсортированные &lt;strong&gt;5&lt;/strong&gt; лучших баллов и печатаем этикетки каждого из них. Полный &lt;a href="http://cs231n.stanford.edu/"&gt;прототип веб-версии&lt;/a&gt; приведен в шапке нашего веб-сайта. Архитектура, показанная здесь, представляет собой крошечную сеть &lt;em&gt;VGG&lt;/em&gt;, о которой мы поговорим позже.  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Теперь мы опишем отдельные слои и детали их гиперпараметров и связуемости&lt;/em&gt;.    &lt;/p&gt;
&lt;h4&gt;Сверточный слой&lt;/h4&gt;
&lt;p&gt;Уровень &lt;em&gt;Conv&lt;/em&gt; является основным строительным блоком сверточной сети, который выполняет большую часть тяжелой вычислительной работы.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Обзор и интуиция без мозгов&lt;/strong&gt;. Давайте сначала обсудим, что вычисляет слой &lt;em&gt;CONV&lt;/em&gt; без аналогий между мозгом и нейронами. Параметры слоя &lt;em&gt;CONV&lt;/em&gt; состоят из набора обучаемых фильтров. Каждый фильтр имеет небольшие пространственные размеры (по ширине и высоте), но простирается на всю глубину входного объема. Например, типичный фильтр на первом слое ConvNet может иметь размер &lt;strong&gt;5x5x3&lt;/strong&gt; (&lt;em&gt;т. е. 5 пикселей в ширину и высоту, и 3, поскольку изображения имеют глубину 3, цветовые каналы&lt;/em&gt;). Во время прямого прохода мы скользим (точнее, свертываем) каждый фильтр по ширине и высоте входного объема и вычисляем точечные произведения между входами фильтра и входом в любом положении. Когда мы перемещаем фильтр по ширине и высоте входного объема, мы создадим двумерную карту активации, которая дает ответы этого фильтра в каждом пространственном положении. Интуитивно сеть будет изучать фильтры, которые активируются, когда они видят какой-либо визуальный признак, такой как край определенной ориентации или пятно определенного цвета на первом слое, или, в конечном итоге, целые соты или узоры, похожие на колеса, на более высоких слоях сети. Теперь у нас будет целый набор фильтров в каждом слое &lt;em&gt;CONV&lt;/em&gt; (например, &lt;strong&gt;12&lt;/strong&gt; фильтров), и каждый из них создаст отдельную двухмерную карту активации. Мы наложим эти карты активации вдоль измерения глубины и получим выходной объем.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Взгляд на мозг&lt;/strong&gt;. Если вы являетесь поклонником аналогий между мозгом и нейронами, то каждая запись в &lt;em&gt;3D&lt;/em&gt;-объеме вывода также может быть интерпретирована как выход нейрона, который смотрит только на небольшую область на входе и разделяет параметры со всеми нейронами слева и справа в пространстве (поскольку все эти числа являются результатом применения одного и того же фильтра).  &lt;/p&gt;
&lt;p&gt;Теперь мы обсудим детали соединений нейронов, их расположение в пространстве и схему совместного использования параметров.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Местная связность&lt;/strong&gt;. Когда речь идет о многомерных входных данных, таких как изображения, как мы видели выше, нецелесообразно соединять нейроны со всеми нейронами в предыдущем томе. Вместо этого мы будем подключать каждый нейрон только к локальной области входного объема. Пространственная протяженность этой связности является гиперпараметром, называемым &lt;strong&gt;рецептивным полем&lt;/strong&gt; нейрона (эквивалентно размеру фильтра). Степень связности вдоль оси глубины всегда равна глубине входного объема. Важно еще раз подчеркнуть эту асимметрию в том, как мы трактуем пространственные размеры (ширину и высоту) и размеры глубины: соединения локальны в &lt;em&gt;2D&lt;/em&gt;-пространстве (по ширине и высоте), но всегда полны по всей глубине входного объема.  &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Пример 1&lt;/em&gt;. Например, предположим, что входной объем имеет размер &lt;strong&gt;[32x32x3]&lt;/strong&gt; (например, изображение &lt;em&gt;RGB&lt;/em&gt; CIFAR-10). Если рецептивное поле (или размер фильтра) равно &lt;em&gt;5x5&lt;/em&gt;, то каждый нейрон в слое Conv будет иметь веса в области &lt;strong&gt;[5x5x3]&lt;/strong&gt; во входном объеме, что в сумме составляет &lt;strong&gt;5x5x3 = 75&lt;/strong&gt; весов (и параметр смещения &lt;strong&gt;+1&lt;/strong&gt;). Обратите внимание, что степень связности вдоль оси глубины должна быть равна &lt;strong&gt;3&lt;/strong&gt;, так как это глубина входного объема.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Пример 2&lt;/em&gt;. Предположим, что входной объем имеет размер &lt;strong&gt;[16x16x20]&lt;/strong&gt;. Затем, используя пример с размером рецептивного поля &lt;strong&gt;3x3&lt;/strong&gt;, каждый нейрон в слое Conv теперь будет иметь в общей сложности &lt;strong&gt;3x3x20 = 180&lt;/strong&gt; соединений с входным объемом. Обратите внимание, что, опять же, связность является локальной в &lt;strong&gt;2D&lt;/strong&gt;-пространстве (например, &lt;strong&gt;3x3&lt;/strong&gt;), но полной по глубине ввода (&lt;strong&gt;20&lt;/strong&gt;).  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/cnn/depthcol.jpeg"&gt;&lt;br&gt;
&lt;img alt="" src="https://cs231n.github.io/assets/nn1/neuron_model.jpeg"&gt;&lt;br&gt;
&lt;strong&gt;Сверху&lt;/strong&gt;: Пример входного объема красным цветом (например, изображение CIFAR-10 размером &lt;strong&gt;32x32x3&lt;/strong&gt;) и пример объема нейронов в первом сверточном слое. Каждый нейрон в сверточном слое пространственно связан только с локальной областью во входном объеме, но на всю глубину (&lt;em&gt;т.е. со всеми цветовыми каналами&lt;/em&gt;). Обратите внимание, что в глубине есть несколько нейронов (&lt;strong&gt;5&lt;/strong&gt; в этом примере), все они смотрят на одну и ту же область на входе: линии, которые соединяют этот столбец из &lt;strong&gt;5&lt;/strong&gt; нейронов, не представляют веса (т.е. эти &lt;strong&gt;5&lt;/strong&gt; нейронов не имеют одинаковых весов, но они связаны с &lt;strong&gt;5&lt;/strong&gt; разными фильтрами), они просто указывают на то, что эти нейроны связаны или смотрят на одно и то же рецептивное поле или область входного объема. &lt;em&gt;т.е. они имеют одно и то же рецептивное поле, но не одинаковые веса.&lt;/em&gt; &lt;strong&gt;Снизу&lt;/strong&gt;: Нейроны из главы «Нейронные сети» остаются неизменными: они по-прежнему вычисляют скалярное произведение своих весов с последующим нелинейным значением, но их связность теперь ограничена локальными пространственными данными.  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Пространственное расположение&lt;/strong&gt;. Мы объяснили связь каждого нейрона в слое Conv с входным объемом, но мы еще не обсуждали, сколько нейронов находится в выходном объеме или как они организованы. Три гиперпараметра контролируют размер выходного объема: &lt;strong&gt;глубина, шаг&lt;/strong&gt; и &lt;strong&gt;нулевое отступление&lt;/strong&gt;. Мы обсудим их далее:&lt;br&gt;
- &lt;em&gt;Во-первых&lt;/em&gt;, &lt;strong&gt;глубина&lt;/strong&gt; выходного объема — это гиперпараметр: он соответствует количеству фильтров, которые мы хотели бы использовать, каждый из которых учится искать что-то свое во входных данных. Например, если первый сверточный слой принимает в качестве входных данных исходное изображение, то различные нейроны в измерении глубины могут активироваться в присутствии различных ориентированных краев или цветовых пятен. Мы будем называть набор нейронов, которые смотрят на одну и ту же область входных данных, &lt;strong&gt;столбцом глубины&lt;/strong&gt; (некоторые люди также предпочитают термин &lt;em&gt;«волокно»&lt;/em&gt;).
-&lt;em&gt; Во-вторых&lt;/em&gt;, мы должны указать &lt;em&gt;шаг&lt;/em&gt;, с которым мы перемещаем фильтр. Когда шаг равен 1, мы перемещаем фильтры по одному пикселю за раз. Когда шаг равен 2 (или редко 3 или более, хотя на практике это редкость), фильтры прыгают на 2 пикселя за раз, когда мы их перемещаем. Это позволит производить меньшие объемы выпуска в пространственном отношении.
-&lt;em&gt; Как мы скоро увидим&lt;/em&gt;, иногда будет удобно заполнять входной объем нулями по границе. Размер этого &lt;strong&gt;нулевого отступа&lt;/strong&gt; является гиперпараметром. Приятная особенность нулевого заполнения заключается в том, что он позволяет нам контролировать пространственный размер выходных объемов (чаще всего, как мы скоро увидим, мы будем использовать его для точного сохранения пространственного размера входного объема, чтобы ширина и высота входного и выходного объема были одинаковыми).  &lt;/p&gt;
&lt;p&gt;Мы можем вычислить пространственный размер выходного объема как функцию от размера входного объема (&lt;strong&gt;W&lt;/strong&gt;), размер рецептивного поля нейронов Conv слоя (&lt;strong&gt;F&lt;/strong&gt;), шаг, с которым они наносятся (&lt;strong&gt;S&lt;/strong&gt;) и количество использованного нулевого заполнения (&lt;strong&gt;P&lt;/strong&gt;) на границе. Вы можете убедиться в том, что правильная формула для расчета количества нейронов «поместится» по формуле &lt;strong&gt;(W−F+2P)/S+1&lt;/strong&gt;. Например, для входа &lt;strong&gt;7x7&lt;/strong&gt; и фильтра &lt;strong&gt;3x3&lt;/strong&gt; со stride 1 и pad 0 мы получим выход &lt;strong&gt;5x5&lt;/strong&gt;. С помощью шага &lt;strong&gt;2&lt;/strong&gt; мы получим выход &lt;strong&gt;3x3&lt;/strong&gt;. Давайте также посмотрим еще на один графический пример:  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/cnn/stride.jpeg"&gt;  &lt;/p&gt;
&lt;p&gt;Иллюстрация пространственного расположения. В этом примере есть только одно пространственное измерение (&lt;strong&gt;ось x&lt;/strong&gt;), один нейрон с размером рецептивного поля &lt;strong&gt;F = 3&lt;/strong&gt;, входной размер &lt;strong&gt;W = 5&lt;/strong&gt; и нулевое заполнение &lt;strong&gt;P = 1&lt;/strong&gt;. &lt;strong&gt;Сверху&lt;/strong&gt;: Нейрон шагал по входу с шагом S = 1, давая на выходе размер &lt;strong&gt;(5 - 3 + 2)/1 + 1 = 5&lt;/strong&gt;. &lt;strong&gt;Снизу&lt;/strong&gt;: Нейрон использует шаг &lt;strong&gt;S = 2&lt;/strong&gt;, давая выход размера &lt;strong&gt;(5 - 3 + 2)/2 + 1 = 3&lt;/strong&gt;. Обратите внимание, что шаг &lt;strong&gt;S = 3&lt;/strong&gt; не может быть использован, так как он не будет аккуратно помещаться по объему. С точки зрения уравнения, это можно определить, так как &lt;strong&gt;(5 - 3 + 2) = 4&lt;/strong&gt; не делится на &lt;strong&gt;3&lt;/strong&gt;.
Веса нейронов в этом примере &lt;strong&gt;[1,0,-1]&lt;/strong&gt; (&lt;em&gt;показаны справа&lt;/em&gt;), и их смещение равно нулю. Эти веса являются общими для всех желтых нейронов (см. общие параметры ниже).  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Использование нулевой набивки&lt;/em&gt;. В приведенном выше примере слева обратите внимание, что входной размер был равен &lt;strong&gt;5&lt;/strong&gt;, а выходной размер был равен: также &lt;strong&gt;5&lt;/strong&gt;. Это сработало так, потому что наши рецептивные поля были равны &lt;strong&gt;3&lt;/strong&gt;, и мы использовали нулевую набивку &lt;strong&gt;1&lt;/strong&gt;. Если бы не использовалось заполнение нуля, то выходной объем имел бы пространственную размерность только &lt;strong&gt;3&lt;/strong&gt;, потому что именно столько нейронов «поместилось» бы на исходном входе. Как правило, установка нулевого заполнения равным &lt;strong&gt;P=(F−1)/2&lt;/strong&gt;. Когда шаг &lt;strong&gt;S=1&lt;/strong&gt; гарантирует, что входной и выходной объем будут иметь одинаковый пространственный размер. Очень часто используется нулевое заполнение таким образом, и мы обсудим все причины, когда будем говорить больше об архитектурах ConvNet.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Ограничения на шаг&lt;/em&gt;. Обратите внимание, что гиперпараметры пространственного расположения имеют взаимные ограничения. Например, когда входные данные имеют размер &lt;strong&gt;W=10&lt;/strong&gt;, нулевой отступ не используется &lt;strong&gt;P=0&lt;/strong&gt;, а размер фильтра равен &lt;strong&gt;F=3&lt;/strong&gt;, то использовать stride было бы невозможно &lt;strong&gt;S=2__с &lt;/strong&gt;(W−F+2P)/S+1=(10−3+0)/2+1=4.5__, т.е. не целое число, указывающее на то, что нейроны не «помещаются» аккуратно и симметрично на входе. Таким образом, эта настройка гиперпараметров считается недопустимой, и библиотека ConvNet может выдать исключение или обнулить заполнение оставшейся части, чтобы она поместилась, или обрезать входные данные, чтобы она поместилась, или что-то еще. Как мы увидим в разделе Архитектуры &lt;em&gt;ConvNet&lt;/em&gt;, правильный выбор размеров ConvNet, чтобы все размеры «отрабатывались», может стать настоящей головной болью, которую использование нулевого заполнения и некоторые рекомендации по проектированию значительно облегчат.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Пример из жизни&lt;/strong&gt;.  &lt;a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks"&gt;Архитектура Крижевского и др.&lt;/a&gt;, которая выиграла конкурс ImageNet в 2012 году, принимала изображения размером [227x227x3]. На первом сверточном слое использовались нейроны с размером рецептивного поля &lt;strong&gt;F=11__шаг __S=4&lt;/strong&gt; и без нулевой набивки &lt;strong&gt;P=0&lt;/strong&gt;. Так как &lt;strong&gt;(227 - 11)/4 + 1 = 55&lt;/strong&gt;, и так как слой Conv имел глубину &lt;strong&gt;K=96&lt;/strong&gt;
, выходной объем слоя Conv имел размер &lt;strong&gt;[55x55x96]&lt;/strong&gt;. Каждый из &lt;strong&gt;55x55x96&lt;/strong&gt; нейронов в этом объеме был соединен с областью размера &lt;strong&gt;[11x11x3]&lt;/strong&gt; во входном объеме. Более того, все 96 нейронов в каждой глубинной колонке подключены к одной и той же области входного канала &lt;strong&gt;[11x11x3]&lt;/strong&gt;, но, конечно, с разными весами. В качестве забавного отступления, если вы прочитаете реальную статью, она утверждает, что входные изображения были &lt;strong&gt;224x224&lt;/strong&gt;, что, безусловно, неверно, потому что &lt;strong&gt;(224 - 11)/4 + 1&lt;/strong&gt; совершенно очевидно не является целым числом. Это сбило с толку многих людей в истории &lt;em&gt;ConvNets&lt;/em&gt;, и мало что известно о том, что произошло. Мое собственное предположение заключается в том, что Алекс использовал нулевое заполнение из &lt;strong&gt;3&lt;/strong&gt; дополнительных пикселей, о которых он не упоминает в статье.    &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Совместное использование параметров&lt;/strong&gt;. Схема совместного использования параметров используется в сверточных слоях для управления количеством параметров. Используя приведенный выше пример из реальной жизни, мы видим, что в первом слое &lt;em&gt;Conv&lt;/em&gt; &lt;strong&gt;55 * 55 * 96 = 290 400&lt;/strong&gt; нейронов, и каждый из них имеет &lt;strong&gt;11 * 11 * 3 = 363&lt;/strong&gt; веса и 1 смещение. В совокупности это дает &lt;strong&gt;290400 * 364 = 105 705 600 параметров&lt;/strong&gt; только на первом уровне &lt;em&gt;ConvNet&lt;/em&gt;. Понятно, что это очень большое число.  &lt;/p&gt;
&lt;p&gt;Оказывается, что мы можем значительно сократить число параметров, если сделать одно разумное допущение: если один признак полезен для вычисления в некотором пространственном положении (&lt;strong&gt;x,y&lt;/strong&gt;), то он также должен быть полезен для вычисления в другом положении (&lt;strong&gt;\(x_2, y_2\)&lt;/strong&gt;). Другими словами, обозначив один двумерный срез глубины как &lt;strong&gt;срез глубины&lt;/strong&gt; (например, объем размером &lt;strong&gt;[55x55x96]&lt;/strong&gt; имеет &lt;strong&gt;96&lt;/strong&gt; срезов глубины, каждый размером &lt;strong&gt;[55x55]&lt;/strong&gt;), мы собираемся ограничить нейроны в каждом срезе глубины, чтобы они использовали одни и те же веса и смещение. При такой схеме распределения параметров первый слой Conv в нашем примере теперь будет иметь только 96 уникальных наборов весов (по одному для каждого среза глубины), что в сумме составит &lt;strong&gt;96 * 11 * 11 * 3 = 34 848 уникальных весов&lt;/strong&gt;, или &lt;strong&gt;34 944&lt;/strong&gt; параметра (&lt;em&gt;+96 смещений&lt;/em&gt;). В качестве альтернативы, все &lt;strong&gt;55*55&lt;/strong&gt; нейронов в каждом срезе глубины теперь будут использовать одни и те же параметры. На практике во время обратного распространения каждый нейрон в объеме будет вычислять градиент для своих весов, но эти градиенты будут суммироваться для каждого среза глубины и обновлять только один набор весов для каждого среза.  &lt;/p&gt;
&lt;p&gt;Обратите внимание, что если все нейроны в одном срезе глубины используют один и тот же вектор весов, то прямой проход слоя &lt;em&gt;CONV&lt;/em&gt; в каждом глубинном срезе может быть вычислен как &lt;strong&gt;свертка&lt;/strong&gt; весов нейрона с входным объемом (отсюда и название: сверточный слой). Вот почему принято называть наборы весов &lt;strong&gt;фильтром&lt;/strong&gt; (или &lt;strong&gt;ядром&lt;/strong&gt;), который свертывается с входными данными.  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/cnn/weights.jpeg"&gt;&lt;br&gt;
Примеры фильтров, изученных Крижским и др. Каждый из &lt;strong&gt;96&lt;/strong&gt; показанных здесь фильтров имеет размер &lt;strong&gt;[11x11x3]&lt;/strong&gt;, и каждый из них является общим для нейронов &lt;strong&gt;55 * 55&lt;/strong&gt; в одном глубинном срезе. Обратите внимание, что предположение о совместном использовании параметров относительно разумно: если обнаружение горизонтального края важно в каком-то месте изображения, оно должно быть интуитивно полезным и в каком-то другом месте из-за трансляционно-инвариантной структуры изображений. Таким образом, нет необходимости заново учиться обнаруживать горизонтальный ребро в каждом из &lt;strong&gt;55 * 55&lt;/strong&gt; различных мест в выходном объеме слоя &lt;em&gt;Conv&lt;/em&gt;.  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Обратите внимание, что иногда предположение о совместном использовании параметров может не иметь смысла. Это особенно верно в том случае, когда входные изображения в &lt;em&gt;ConvNet&lt;/em&gt; имеют некоторую специфическую центрированную структуру, где мы должны ожидать, например, что на одной стороне изображения должны быть изучены совершенно разные функции, чем на другой. Одним из практических примеров является ситуация, когда входными данными являются лица, которые были центрированы на изображении. Можно ожидать, что различные особенности, специфичные для глаз или волос, могут (и должны) быть изучены в разных пространственных местах. В этом случае обычно ослабляют схему совместного использования параметров и вместо этого просто называют слой &lt;strong&gt;локально подключенным слоем&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Нумерные примеры&lt;/strong&gt;. Чтобы сделать обсуждение выше более конкретным, давайте выразим те же идеи, но в коде и на конкретном примере. Предположим, что входной объем представляет собой массив &lt;strong&gt;numpy&lt;/strong&gt;. Тогда:&lt;code&gt;X&lt;/code&gt;
- Колонка глубины (или волокно) в позиции будет активацией.&lt;code&gt;(x,y)&lt;/code&gt; &lt;code&gt;X[x,y,:]&lt;/code&gt;
- Глубинным срезом или, что эквивалентно&lt;code&gt;d&lt;/code&gt;, картой активации на глубине были бы активации &lt;code&gt;X[:,:,d]&lt;/code&gt; .  &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Пример слоя conv&lt;/em&gt;. Предположим, что входной объем имеет форму . Предположим далее, что мы не используем нулевое заполнение (&lt;code&gt;X&lt;/code&gt; &lt;code&gt;X.shape: (11,11,4)&lt;/code&gt;&lt;strong&gt;P=0&lt;/strong&gt;), что размер фильтра равен &lt;strong&gt;F=5&lt;/strong&gt;, и что шаг является &lt;strong&gt;S=2&lt;/strong&gt;. Таким образом, выходной объем будет иметь пространственный размер &lt;strong&gt;(11-5)/2+1 = 4&lt;/strong&gt;, что дает объем с шириной и высотой 4. Карта активации в выходном объеме (назовем его ) будет выглядеть следующим образом (в этом примере вычисляются только некоторые элементы):&lt;code&gt;V&lt;/code&gt;
- &lt;code&gt;V[0,0,0] = np.sum(X[:5,:5,:] * W0) + b0&lt;/code&gt;
- &lt;code&gt;V[1,0,0] = np.sum(X[2:7,:5,:] * W0) + b0&lt;/code&gt;
- &lt;code&gt;V[2,0,0] = np.sum(X[4:9,:5,:] * W0) + b0&lt;/code&gt; 
- &lt;code&gt;V[3,0,0] = np.sum(X[6:11,:5,:] * W0) + b0&lt;/code&gt;  &lt;/p&gt;
&lt;p&gt;Помните, что в numpy приведенная выше операция обозначает поэлементное умножение между массивами. Заметьте также, что вектор веса — это вектор веса этого нейрона и смещение. Здесь предполагается, что он имеет форму , так как размер фильтра равен &lt;strong&gt;5&lt;/strong&gt;, а глубина входного объема равна &lt;strong&gt;4&lt;/strong&gt;. Обратите внимание, что в каждой точке мы вычисляем скалярное произведение, как это было показано ранее в обычных нейронных сетях. Кроме того, мы видим, что мы используем тот же вес и смещение (из-за совместного использования параметров), и где размеры по ширине увеличиваются с шагом &lt;strong&gt;2&lt;/strong&gt; (&lt;em&gt;т.е. шаг&lt;/em&gt;). Чтобы построить вторую карту активации в выходном объеме, у нас есть:&lt;code&gt;*&lt;/code&gt; &lt;code&gt;W0&lt;/code&gt; &lt;code&gt;b0&lt;/code&gt; &lt;code&gt;W0&lt;/code&gt; &lt;code&gt;W0.shape: (5,5,4)&lt;/code&gt;&lt;br&gt;
- &lt;code&gt;V[0,0,1] = np.sum(X[:5,:5,:] * W1) + b1&lt;/code&gt;
- &lt;code&gt;V[1,0,1] = np.sum(X[2:7,:5,:] * W1) + b1&lt;/code&gt;
- &lt;code&gt;V[2,0,1] = np.sum(X[4:9,:5,:] * W1) + b1&lt;/code&gt;
- &lt;code&gt;V[3,0,1] = np.sum(X[6:11,:5,:] * W1) + b1&lt;/code&gt;
- &lt;code&gt;V[0,1,1] = np.sum(X[:5,2:7,:] * W1) + b1&lt;/code&gt; (пример перехода по y)
- &lt;code&gt;V[2,3,1] = np.sum(X[4:9,6:11,:] * W1) + b1&lt;/code&gt; (&lt;em&gt;или по обоим&lt;/em&gt;)  &lt;/p&gt;
&lt;p&gt;где мы видим, что мы индексируем второе измерение глубины в &lt;code&gt;V&lt;/code&gt; (по индексу &lt;em&gt;1&lt;/em&gt;), потому что мы вычисляем вторую карту активации, и что теперь используется другой набор параметров (&lt;code&gt;W1&lt;/code&gt;). В приведенном выше примере мы для краткости опускаем некоторые другие операции, которые &lt;em&gt;Conv Layer&lt;/em&gt; выполнил бы для заполнения других частей выходного массива &lt;code&gt;V&lt;/code&gt;. Кроме того, вспомните, что эти карты активации часто отслеживаются по элементам с помощью функции активации, такой как &lt;strong&gt;ReLU&lt;/strong&gt;, но здесь это не показано.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Резюме&lt;/strong&gt;. Подводя итог, можно сказать, что слой Conv:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Принимает объем любого размера &lt;strong&gt;\(W_1 \times H_1 \times D_1\)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Требуется четыре гиперпараметра:&lt;ul&gt;
&lt;li&gt;Количество фильтров &lt;strong&gt;K&lt;/strong&gt;,&lt;/li&gt;
&lt;li&gt;их пространственная протяженность &lt;strong&gt;F&lt;/strong&gt;,&lt;/li&gt;
&lt;li&gt;Шаг вперед &lt;strong&gt;S&lt;/strong&gt;,&lt;/li&gt;
&lt;li&gt;Величина нулевого отступа &lt;strong&gt;P&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Производит объем большого размера &lt;strong&gt;\(W_2 \times H_2 \times D_2\)&lt;/strong&gt; где:&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;W2=(W1−F+2P)/S+1&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;H2=(H1−F+2P)/S+1&lt;/strong&gt; (т.е. ширина и высота вычисляются поровну по симметрии)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;D2=K&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Благодаря совместному использованию параметров он вводит &lt;strong&gt;\(F \cdot F \cdot D_1\)&lt;/strong&gt; веса на фильтр, итого &lt;strong&gt;\((F \cdot F \cdot D_1) \cdot K\)&lt;/strong&gt; веса и &lt;strong&gt;K&lt;/strong&gt; cмещений.&lt;/li&gt;
&lt;li&gt;В выходном объеме метод &lt;strong&gt;d&lt;/strong&gt;-я глубина среза (размера &lt;strong&gt;\(W_2 \times H_2\)&lt;/strong&gt; ) является результатом выполнения валидной свертки &lt;strong&gt;d&lt;/strong&gt;-й фильтр по входной громкости с шагом &lt;strong&gt;S&lt;/strong&gt;, а затем сместить на &lt;strong&gt;d&lt;/strong&gt;-ое смещение.  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Общая настройка гиперпараметров выглядит следующим образом: &lt;strong&gt;F=3,S=1,P=1&lt;/strong&gt;. Тем не менее, существуют общие условности и эмпирические правила, которые мотивируют эти гиперпараметры. Смотрите раздел &lt;a href="https://cs231n.github.io/convolutional-networks/#architectures"&gt;Архитектуры ConvNet&lt;/a&gt; ниже.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Демо свертки&lt;/strong&gt;. Ниже приведена бегущая демонстрация слоя CONV. Поскольку &lt;strong&gt;3D&lt;/strong&gt;-объемы трудно визуализировать, все объемы (входной объем (синий), весовой объем (красный), выходной объем (зеленый)) визуализируются с каждым срезом глубины, уложенным в ряды. Входной объем имеет размер  &lt;strong&gt;\(W_1 = 5, H_1 = 5, D_1 = 3\)&lt;/strong&gt;, а параметры слоя &lt;em&gt;CONV&lt;/em&gt; равны &lt;strong&gt;\(K = 2, F = 3, S = 2, P = 1\)&lt;/strong&gt;. То есть у нас есть два фильтра размера &lt;strong&gt;3×3&lt;/strong&gt;, и наносятся они с шагом &lt;strong&gt;2&lt;/strong&gt;. Следовательно, размер выходного объема имеет пространственный размер &lt;strong&gt;(5 - 3 + 2)/2 + 1 = 3&lt;/strong&gt;. Кроме того, обратите внимание, что отступ &lt;strong&gt;P=1&lt;/strong&gt; применяется к входному объему, при этом внешняя граница входного объема обнуляется. На приведенной ниже визуализации перебираются выходные активации (&lt;em&gt;зеленый&lt;/em&gt;) и показано, что каждый элемент вычисляется путем поэлементного умножения выделенных входных данных (&lt;em&gt;синий&lt;/em&gt;) на фильтр (&lt;em&gt;красный&lt;/em&gt;), суммирования его и последующего смещения результата.  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://mldl.ru/posts/architecture/"&gt;
- !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
- &lt;/p&gt;
&lt;div class="fig figcenter fighighlight"&gt;
  &lt;iframe src="https://mldl.ru/assets/conv-demo/index.html" width="100%" height="700px;" style="border:none;"&gt;&lt;/iframe&gt;
  &lt;div class="figcaption"&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!  &lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Реализация в виде умножения матриц&lt;/strong&gt;. Обратите внимание, что операция свертки по сути выполняет скалярное произведение между фильтрами и локальными областями входных данных. Общий шаблон реализации слоя &lt;em&gt;CONV&lt;/em&gt; заключается в том, чтобы воспользоваться этим фактом и сформулировать прямой проход сверточного слоя в виде умножения одной большой матрицы следующим образом:
_ Локальные регионы на входном изображении растягиваются в столбцы с помощью операции, обычно называемой &lt;strong&gt;im2col&lt;/strong&gt;. Например, если входной параметр имеет размер &lt;strong&gt;[227x227x3]&lt;/strong&gt; и он должен быть свернут с помощью фильтров &lt;strong&gt;11x11x3&lt;/strong&gt; на шаге &lt;strong&gt;4&lt;/strong&gt;, то мы возьмем &lt;strong&gt;[11x11x3]&lt;/strong&gt; блоков пикселей на входе и растянем каждый блок в вектор-столбец размером &lt;strong&gt;11&lt;em&gt;11&lt;/em&gt;3 = 363&lt;/strong&gt;. Повторение этого процесса на входе с шагом &lt;strong&gt;4&lt;/strong&gt; дает &lt;strong&gt;(227-11)/4+1 = 55&lt;/strong&gt; позиций как по ширине, так и по высоте, что приводит к выходной матрице &lt;em&gt;im2col&lt;/em&gt; размера &lt;strong&gt;[363 x 3025&lt;/strong&gt;], где каждый столбец представляет собой растянутое восприимчивое поле, и всего их &lt;strong&gt;55 x 55 = 3025&lt;/strong&gt;. Обратите внимание, что поскольку рецептивные поля перекрываются, каждое число во входном объеме может дублироваться в нескольких отдельных столбцах.&lt;code&gt;X_col&lt;/code&gt;
- Грузы слоя &lt;em&gt;CONV&lt;/em&gt; аналогичным образом растягиваются в ряды. Например, если имеется &lt;strong&gt;96&lt;/strong&gt; фильтров размера &lt;strong&gt;[11x11x3]&lt;/strong&gt;, то получится матрица размера &lt;strong&gt;[96 x 363]&lt;/strong&gt;. &lt;code&gt;W_row&lt;/code&gt;
- Результат свертки теперь эквивалентен выполнению одного умножения большой матрицы , которое вычисляет скалярное произведение между каждым фильтром и каждым местоположением восприимчивого поля. В нашем примере результатом этой операции будет &lt;strong&gt;[96 x 3025]&lt;/strong&gt;, что дает выходные данные скалярного произведения каждого фильтра в каждом месте.&lt;code&gt;np.dot(W_row, X_col)&lt;/code&gt;
- В конечном итоге результат должен быть возвращен к его надлежащему выходному размеру &lt;strong&gt;[55x55x96]&lt;/strong&gt;.  &lt;/p&gt;
&lt;p&gt;У этого подхода есть недостаток, заключающийся в том, что он может использовать много памяти, так как некоторые значения во входном объеме многократно реплицируются в . Тем не менее, преимущество заключается в том, что существует множество очень эффективных реализаций матричного умножения, которыми мы можем воспользоваться (например, в широко используемом &lt;a href="http://www.netlib.org/blas/"&gt;BLAS&lt;/a&gt; &lt;em&gt;API&lt;/em&gt;). Более того, та же идея &lt;em&gt;im2col&lt;/em&gt; может быть повторно использована для выполнения операции объединения, о которой мы поговорим далее.&lt;code&gt;X_col&lt;/code&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Обратное распространение&lt;/strong&gt;. Обратный проход для операции свертки (как для данных, так и для весов) также является сверткой (но с пространственно перевернутыми фильтрами). Это легко вывести в одномерном случае с помощью примера с игрушкой (пока не раскрывается).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Свертка 1х1&lt;/strong&gt;. В качестве отступления, в нескольких работах используются свертки &lt;strong&gt;1x1&lt;/strong&gt;, впервые исследованные &lt;a href="http://arxiv.org/abs/1312.4400"&gt;Network in Network&lt;/a&gt;. Некоторые люди поначалу путаются, видя свертки &lt;strong&gt;1x1&lt;/strong&gt;, особенно когда они исходят из фона обработки сигналов. Обычно сигналы двумерны, поэтому свертки 1x1 не имеют смысла (это просто поточечное масштабирование). Однако в &lt;em&gt;ConvNet&lt;/em&gt; это не так, потому что необходимо помнить, что мы работаем с трехмерными объемами и что фильтры всегда распространяются на всю глубину входного объема. Например, если входные данные равны &lt;strong&gt;[32x32x3]&lt;/strong&gt;, то выполнение сверток &lt;em&gt;1x1&lt;/em&gt; фактически будет выполнением трехмерных скалярных произведений (поскольку глубина входных данных равна &lt;strong&gt;3&lt;/strong&gt; каналам).  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Расширенные извилины&lt;/strong&gt;. Недавняя разработка (&lt;a href="https://arxiv.org/abs/1511.07122"&gt;см., например, статью Фишера Ю. и Владлена Колтуна&lt;/a&gt;) заключается в введении еще одного гиперпараметра в слой &lt;em&gt;CONV&lt;/em&gt;, называемого &lt;em&gt;дилатацией&lt;/em&gt;. До сих пор мы обсуждали только непрерывные фильтры &lt;em&gt;CONV&lt;/em&gt;. Тем не менее, можно иметь фильтры, которые имеют промежутки между каждой клеткой, называемые расширением. Например, в одном измерении фильтр размера &lt;strong&gt;3&lt;/strong&gt; будет вычислять на входных данных следующее: . Это расширение до &lt;strong&gt;0&lt;/strong&gt;. Для расширения &lt;strong&gt;1&lt;/strong&gt; фильтр вместо этого будет вычислять ; Другими словами, между заявками есть разрыв в &lt;strong&gt;1&lt;/strong&gt;. Это может быть очень полезно в некоторых настройках для использования в сочетании с фильтрами &lt;strong&gt;0-расширения&lt;/strong&gt;, поскольку это позволяет объединять пространственную информацию по входным данным гораздо более агрессивно с меньшим количеством слоев. Например, если вы наложите два слоя &lt;em&gt;CONV&lt;/em&gt; &lt;strong&gt;3x3&lt;/strong&gt; друг на друга, то вы можете убедить себя, что нейроны на втором слое являются функцией участка входного сигнала &lt;strong&gt;5x5&lt;/strong&gt; (мы бы сказали, что &lt;em&gt;эффективное рецептивное поле&lt;/em&gt; этих нейронов равно &lt;strong&gt;5x5&lt;/strong&gt;). Если мы будем использовать расширенные извилины, то это эффективное рецептивное поле будет расти гораздо быстрее.&lt;code&gt;w&lt;/code&gt; &lt;code&gt;x&lt;/code&gt; &lt;code&gt;w[0]*x[0] + w[1]*x[1] + w[2]*x[2]w[0]*x[0] + w[1]*x[2] + w[2]*x[4]&lt;/code&gt;  &lt;/p&gt;
&lt;h4&gt;Слой пула&lt;/h4&gt;
&lt;p&gt;В архитектуре &lt;em&gt;ConvNet&lt;/em&gt; обычно периодически вставляется слой Pooling между последовательными слоями &lt;em&gt;Conv&lt;/em&gt;. Его функция состоит в том, чтобы постепенно уменьшать пространственный размер представления для уменьшения количества параметров и вычислений в сети и, следовательно, также контролировать переобучение. Слой пулинга работает независимо на каждом срезе глубины входных данных и изменяет его пространственный размер с помощью операции &lt;strong&gt;MAX&lt;/strong&gt;. Наиболее распространенной формой является пулинговый слой с фильтрами размером &lt;strong&gt;2x2&lt;/strong&gt;, применяемыми с шагом &lt;strong&gt;2&lt;/strong&gt; вниздискретизации каждого глубинного среза на входе на &lt;strong&gt;2&lt;/strong&gt; по ширине и высоте, отбрасывая &lt;strong&gt;75%&lt;/strong&gt; активаций. Каждая операция &lt;strong&gt;MAX&lt;/strong&gt; в этом случае будет принимать максимум более 4 чисел (маленькая область &lt;strong&gt;2x2&lt;/strong&gt; в некотором глубинном срезе). Размер глубины остается неизменным. В более общем смысле, пуловый слой:
- Принимает объем любого размера &lt;strong&gt;W1×H1×D1&lt;/strong&gt;
- Требуется два гиперпараметра:
    - их пространственная протяженность &lt;strong&gt;F&lt;/strong&gt;,
    - Шаг вперед &lt;strong&gt;S&lt;/strong&gt;,
- Производит объем большого размера &lt;strong&gt;\(W_2 \times H_2 \times D_2\)&lt;/strong&gt; где:
    - &lt;strong&gt;\(W_2 = (W_1 - F)/S + 1\)&lt;/strong&gt;
    - &lt;strong&gt;\(H_2 = (H_1 - F)/S + 1\)&lt;/strong&gt;
    - &lt;strong&gt;\(D_2 = D_1\)&lt;/strong&gt;
- Вводит нулевые параметры, так как вычисляет фиксированную функцию входных данных
- Для слоев &lt;em&gt;Pooling&lt;/em&gt; заполнение входных данных не является обычным способом с использованием нулевого отступа.  &lt;/p&gt;
&lt;p&gt;Стоит отметить, что на практике встречаются только два распространенных варианта максимального слоя пула: Слой пулинга с &lt;strong&gt;F=3,S=2&lt;/strong&gt; (также называемое перекрывающимся пулом) и чаще &lt;strong&gt;F=2,S=2&lt;/strong&gt;. Объединение размеров с большими рецептивными полями слишком разрушительно.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Общий пул&lt;/strong&gt;. В дополнение к максимальному объединению, единицы объединения могут выполнять и другие функции, такие как &lt;em&gt;усредненное объединение&lt;/em&gt; или даже &lt;em&gt;объединение по L2-норме&lt;/em&gt;. Исторически часто использовалось среднее объединение, но в последнее время оно вышло из моды по сравнению с операцией максимального объединения, которая, как было показано, работает лучше на практике.  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/cnn/pool.jpeg"&gt;&lt;br&gt;
&lt;img alt="" src="https://cs231n.github.io/assets/cnn/maxpool.jpeg"&gt;&lt;br&gt;
Пулинг слоя понижает дискретизацию объема пространственно, независимо в каждом глубинном срезе входного объема. &lt;strong&gt;Сверху&lt;/strong&gt;: В этом примере входной объем размера &lt;strong&gt;[224x224x64]&lt;/strong&gt; объединяется с фильтром размера 2, шаг 2 в выходной объем размера &lt;strong&gt;[112x112x64]&lt;/strong&gt;. Обратите внимание, что глубина объема сохраняется. &lt;strong&gt;Снизу&lt;/strong&gt;: Наиболее распространенной операцией понижения дискретизации является max, что приводит к &lt;strong&gt;максимальному объединению&lt;/strong&gt;, показанному здесь с шагом &lt;strong&gt;2&lt;/strong&gt;. То есть, каждый макс берется над 4 числами (маленький квадратик &lt;strong&gt;2х2&lt;/strong&gt;).  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Обратное распространение&lt;/strong&gt;. Вспомните из главы об обратном распространении, что обратный проход для операции &lt;strong&gt;max(x, y)&lt;/strong&gt; имеет простую интерпретацию как только маршрутизацию градиента на вход, который имел наибольшее значение в прямом проходе. Следовательно, во время прямого прохождения пулового слоя обычно отслеживают индекс максимальной активации (иногда также называемый &lt;em&gt;переключателями&lt;/em&gt;), чтобы градиентная маршрутизация была эффективной во время обратного распространения.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Избавление от пулов&lt;/strong&gt;. Многим людям не нравится операция по объединению, и они думают, что мы можем обойтись без нее. Например, &lt;a href="http://arxiv.org/abs/1412.6806"&gt;Pursuit for Simplicity: The All Convolutional Net&lt;/a&gt; предлагает отказаться от пулового слоя в пользу архитектуры, состоящей только из повторяющихся слоев &lt;em&gt;CONV&lt;/em&gt;. Чтобы уменьшить размер представления, они предлагают время от времени использовать больший шаг в слое &lt;em&gt;CONV&lt;/em&gt;. Также было обнаружено, что отказ от слоев пула важен для обучения хороших генеративных моделей, таких как вариационные автоэнкодеры (&lt;em&gt;VAE&lt;/em&gt;) или генеративно-состязательные сети (&lt;em&gt;GAN&lt;/em&gt;). Вполне вероятно, что в будущих архитектурах будет очень мало или вообще не будет слоев пула.  &lt;/p&gt;
&lt;h4&gt;Слой нормализации&lt;/h4&gt;
&lt;p&gt;Многие типы уровней нормализации были предложены для использования в архитектурах &lt;em&gt;ConvNet&lt;/em&gt;, иногда с намерением реализовать схемы торможения, наблюдаемые в биологическом мозге. Однако с тех пор эти слои вышли из моды, потому что на практике их вклад был минимальным, если вообще был. О различных типах нормализации см. обсуждение в &lt;a href="http://code.google.com/p/cuda-convnet/wiki/LayerParams#Local_response_normalization_layer_(same_map)"&gt;API библиотеки cuda-convnet&lt;/a&gt; Алекса Крижевского.  &lt;/p&gt;
&lt;h4&gt;Полносвязный слой&lt;/h4&gt;
&lt;p&gt;Нейроны в полностью связном слое имеют полные связи со всеми активациями в предыдущем слое, как это видно в обычных нейронных сетях. Таким образом, их активации могут быть вычислены с помощью умножения матриц с последующим смещением смещения. Дополнительные сведения см. в разделе &lt;em&gt;«Нейронные сети»&lt;/em&gt; примечаний.  &lt;/p&gt;
&lt;h4&gt;Преобразование слоев FC в слои CONV&lt;/h4&gt;
&lt;p&gt;Стоит отметить, что единственное различие между слоями &lt;em&gt;FC&lt;/em&gt; и &lt;em&gt;CONV&lt;/em&gt; заключается в том, что нейроны в слое &lt;em&gt;CONV&lt;/em&gt; связаны только с локальной областью на входе, и что многие нейроны в объеме &lt;em&gt;CONV&lt;/em&gt; имеют общие параметры. Тем не менее, нейроны в обоих слоях по-прежнему вычисляют точечные произведения, поэтому их функциональная форма идентична. Таким образом, оказывается, что можно преобразовывать между слоями &lt;em&gt;FC&lt;/em&gt; и &lt;em&gt;CONV&lt;/em&gt;:
- Для любого слоя &lt;em&gt;CONV&lt;/em&gt; существует слой &lt;em&gt;FC&lt;/em&gt;, реализующий ту же прямую функцию. Матрица весов будет большой матрицей, которая в основном равна нулю, за исключением некоторых блоков (из-за локальной связности), где веса во многих блоках равны (из-за совместного использования параметров).
- И наоборот, любой слой &lt;em&gt;FC&lt;/em&gt; может быть преобразован в слой &lt;em&gt;CONV&lt;/em&gt;. Например, слой &lt;em&gt;FC&lt;/em&gt; с &lt;strong&gt;K=4096&lt;/strong&gt;, то есть с учетом некоторого входного объема размера &lt;strong&gt;7×7×512&lt;/strong&gt; может быть эквивалентно выражен в виде слоя CONV с помощью &lt;strong&gt;F=7,P=0,S=1,K=4096&lt;/strong&gt;. Другими словами, мы устанавливаем размер фильтра точно равным размеру входного объема, и, следовательно, на выходе будет просто &lt;strong&gt;1×1×4096&lt;/strong&gt; так как только один столбец глубины «помещается» поперек входного объема, давая тот же результат, что и исходный слой FC.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Конверсия FC-&amp;gt;CONV&lt;/strong&gt;. Из этих двух преобразований возможность преобразования слоя FC в слой CONV особенно полезна на практике. Рассмотрим архитектуру ConvNet, которая берет изображение размером &lt;strong&gt;224x224x3&lt;/strong&gt;, а затем использует ряд слоев &lt;em&gt;CONV&lt;/em&gt; и слоев &lt;em&gt;POOL&lt;/em&gt; для уменьшения объема активации до размера &lt;strong&gt;7x7x512&lt;/strong&gt; (в архитектуре &lt;em&gt;AlexNet&lt;/em&gt;, которую мы увидим позже, это делается с помощью &lt;strong&gt;5&lt;/strong&gt; слоев пула, которые каждый раз уменьшают пространственную дискретизацию входных данных в два раза). Получаем итоговый пространственный размер &lt;strong&gt;224/2/2/2/2/2 = 7&lt;/strong&gt;). После этого &lt;em&gt;AlexNet&lt;/em&gt; использует два слоя &lt;em&gt;FC&lt;/em&gt; размера &lt;strong&gt;4096&lt;/strong&gt; и, наконец, последний слой &lt;em&gt;FC&lt;/em&gt; с &lt;strong&gt;1000&lt;/strong&gt; нейронами, которые вычисляют баллы класса. Мы можем преобразовать каждый из этих трех слоев &lt;em&gt;FC&lt;/em&gt; в слои &lt;em&gt;CONV&lt;/em&gt;, как описано выше:
- Замените первый слой &lt;em&gt;FC&lt;/em&gt;, который смотрит на объем &lt;strong&gt;[7x7x512]&lt;/strong&gt;, на слой &lt;em&gt;CONV&lt;/em&gt;, использующий размер фильтра &lt;strong&gt;F=7&lt;/strong&gt;, дающий выходной объем &lt;strong&gt;[1x1x4096]&lt;/strong&gt;.
- Замените второй слой FC на слой &lt;em&gt;CONV&lt;/em&gt;, использующий размер фильтра &lt;strong&gt;F=1&lt;/strong&gt;, дающий выходной объем &lt;strong&gt;[1x1x4096]&lt;/strong&gt;
- Замените последний слой &lt;em&gt;FC&lt;/em&gt; аналогичным образом, на &lt;strong&gt;F=1&lt;/strong&gt;, выдающий итоговый вывод &lt;strong&gt;[1x1x1000]&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;Каждое из этих преобразований на практике может включать в себя манипуляции (например, изменение формы) матрицей весов &lt;strong&gt;W&lt;/strong&gt; в каждом слое &lt;em&gt;FC&lt;/em&gt; в фильтры слоя &lt;em&gt;CONV&lt;/em&gt;. Оказывается, что это преобразование позволяет нам очень эффективно «скользить» по исходной &lt;em&gt;ConvNet&lt;/em&gt; через множество пространственных положений в более крупном изображении за один проход вперед.  &lt;/p&gt;
&lt;p&gt;Например, если образ &lt;strong&gt;224x224&lt;/strong&gt; дает объем размера &lt;strong&gt;[7x7x512]&lt;/strong&gt; - т.е. уменьшение на &lt;strong&gt;32&lt;/strong&gt;, то пересылка образа размера &lt;strong&gt;384x384&lt;/strong&gt; через преобразованную архитектуру даст эквивалентный объем в размере &lt;strong&gt;[12x12x512]&lt;/strong&gt;, так как &lt;em&gt;384/32 = 12&lt;/em&gt;. Последующие &lt;strong&gt;3&lt;/strong&gt; слоя &lt;em&gt;CONV&lt;/em&gt;, которые мы только что преобразовали из слоев FC, теперь дадут окончательный объем размера &lt;strong&gt;[6x6x1000]&lt;/strong&gt;, поскольку &lt;strong&gt;(12 - 7)/1 + 1 = 6&lt;/strong&gt;. Обратите внимание, что вместо одного вектора оценок классов размера &lt;strong&gt;[1x1x1000]&lt;/strong&gt; мы теперь получаем целый массив оценок классов &lt;strong&gt;6x6&lt;/strong&gt; на изображении &lt;strong&gt;384x384&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Независимая оценка исходной ConvNet (со слоями FC) по кадрам 224x224 изображения 384x384 с шагом 32 пикселя дает результат, идентичный однократной пересылке преобразованной ConvNet.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Естественно, пересылка преобразованной &lt;em&gt;ConvNet&lt;/em&gt; за один раз гораздо эффективнее, чем итерация исходной ConvNet по всем этим &lt;strong&gt;36&lt;/strong&gt; местоположениям, поскольку &lt;strong&gt;36&lt;/strong&gt; оценок используют общие вычисления. Этот трюк часто используется на практике для повышения производительности, когда, например, обычно изменяют размер изображения, чтобы сделать его больше, используют преобразованный &lt;em&gt;ConvNet&lt;/em&gt; для оценки оценок класса во многих пространственных положениях, а затем усредняют баллы класса.  &lt;/p&gt;
&lt;p&gt;Наконец, что, если мы хотим эффективно применить исходную &lt;em&gt;ConvNet&lt;/em&gt; поверх изображения, но с шагом меньше &lt;strong&gt;32&lt;/strong&gt; пикселей? Мы могли бы добиться этого с помощью нескольких передач вперед. Например, обратите внимание, что если бы мы хотели использовать шаг в &lt;strong&gt;16&lt;/strong&gt; пикселей, мы могли бы сделать это, объединив объемы, полученные при пересылке преобразованной &lt;em&gt;ConvNet&lt;/em&gt; дважды: сначала над исходным изображением, а затем над изображением, но с пространственным сдвигом изображения на &lt;strong&gt;16&lt;/strong&gt; пикселей как по ширине, так и по высоте.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Блокнот IPython по &lt;a href="https://github.com/BVLC/caffe/blob/master/examples/net_surgery.ipynb"&gt;сетевой хирургии&lt;/a&gt; показывает, как выполнить преобразование на практике, в коде (с использованием &lt;em&gt;Caffe&lt;/em&gt;)  &lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Архитектуры ConvNet&lt;/h2&gt;
&lt;p&gt;Мы видели, что сверточные сети обычно состоят только из трех типов слоев: &lt;em&gt;CONV&lt;/em&gt;, &lt;em&gt;POOL&lt;/em&gt; (мы предполагаем &lt;em&gt;Max&lt;/em&gt; &lt;em&gt;pool&lt;/em&gt;, если не указано иное) и &lt;em&gt;FC&lt;/em&gt; (сокращение от &lt;em&gt;fully&lt;/em&gt; &lt;em&gt;connected&lt;/em&gt;). Мы также явно напишем функцию активации &lt;em&gt;RELU&lt;/em&gt; в виде слоя, который применяет элементную нелинейность. В этом разделе мы обсудим, как они обычно складываются в целые &lt;em&gt;ConvNet&lt;/em&gt;.  &lt;/p&gt;
&lt;h3&gt;Узоры слоев&lt;/h3&gt;
&lt;p&gt;Наиболее распространенная форма архитектуры &lt;em&gt;ConvNet&lt;/em&gt; состоит из нескольких слоев &lt;em&gt;CONV&lt;/em&gt;-&lt;em&gt;RELU&lt;/em&gt;, затем за ними следуют слои &lt;em&gt;POOL&lt;/em&gt; и повторяет этот шаблон до тех пор, пока изображение не будет объединено в пространстве до небольшого размера. В какой-то момент часто происходит переход к полносвязным слоям. Последний полносвязный слой содержит выходные данные, такие как баллы класса. Другими словами, наиболее распространенная архитектура &lt;em&gt;ConvNet&lt;/em&gt; следует шаблону:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;INPUT -&amp;gt; [[CONV -&amp;gt; RELU]*N -&amp;gt; POOL?]*M -&amp;gt; [FC -&amp;gt; RELU]*K -&amp;gt; FC&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;где &lt;code&gt;*&lt;/code&gt; указывает на повторение, а &lt;code&gt;POOL?&lt;/code&gt; указывает на необязательный слой пула. Более того, &lt;code&gt;N &amp;gt;= 0&lt;/code&gt; (и обычно  &lt;code&gt;N &amp;lt;= 3&lt;/code&gt; &lt;code&gt;M &amp;gt;= 0&lt;/code&gt; &lt;code&gt;K &amp;gt;= 0&lt;/code&gt;), , (и обычно &lt;code&gt;K &amp;lt; 3&lt;/code&gt; ). Например, вот некоторые распространенные архитектуры ConvNet, которые следуют этому шаблону:&lt;br&gt;
- &lt;code&gt;INPUT -&amp;gt; FC&lt;/code&gt; реализует линейный классификатор. Здесь &lt;code&gt;N = M = K = 0&lt;/code&gt;
- &lt;code&gt;INPUT -&amp;gt; CONV -&amp;gt; RELU -&amp;gt; FC&lt;/code&gt;
- &lt;code&gt;INPUT -&amp;gt; [CONV -&amp;gt; RELU -&amp;gt; POOL]*2 -&amp;gt; FC -&amp;gt; RELU -&amp;gt; FC&lt;/code&gt;. Здесь мы видим, что между каждым слоем POOL есть один слой CONV.
 -&lt;code&gt;INPUT -&amp;gt; [CONV -&amp;gt; RELU -&amp;gt; CONV -&amp;gt; RELU -&amp;gt; POOL]*3 -&amp;gt; [FC -&amp;gt; RELU]*2 -&amp;gt; FC&lt;/code&gt;. Здесь мы видим два слоя &lt;em&gt;CONV&lt;/em&gt;, расположенных перед каждым слоем &lt;em&gt;POOL&lt;/em&gt;. Как правило, это хорошая идея для более крупных и глубоких сетей, поскольку несколько слоев &lt;em&gt;CONV&lt;/em&gt; могут привести к более сложным характеристикам входного объема перед деструктивной операцией объединения.  &lt;/p&gt;
&lt;p&gt;&lt;em&gt;Отдайте предпочтение стеку небольших фильтров CONV одному большому слою рецептивного поля CONV&lt;/em&gt;. Предположим, что вы накладываете три слоя &lt;em&gt;CONV&lt;/em&gt; &lt;strong&gt;3x3&lt;/strong&gt; друг на друга (конечно, с нелинейностями между ними). При таком расположении каждый нейрон на первом слое &lt;em&gt;CONV&lt;/em&gt; имеет представление входного объема &lt;strong&gt;3x3&lt;/strong&gt;. Нейрон на втором слое &lt;em&gt;CONV&lt;/em&gt; имеет представление &lt;strong&gt;3x3&lt;/strong&gt; первого слоя &lt;em&gt;CONV&lt;/em&gt; и, следовательно, представление входного объема &lt;strong&gt;5x5&lt;/strong&gt;. Аналогично, нейрон на третьем слое &lt;em&gt;CONV&lt;/em&gt; имеет представление &lt;strong&gt;3x3&lt;/strong&gt; на 2-й слой &lt;em&gt;CONV&lt;/em&gt; и, следовательно, на входной объем &lt;strong&gt;7x7&lt;/strong&gt;. Предположим, что вместо этих трех слоев &lt;strong&gt;3x3&lt;/strong&gt; &lt;em&gt;CONV&lt;/em&gt; мы хотим использовать только один слой &lt;em&gt;CONV&lt;/em&gt; с рецептивными полями &lt;strong&gt;7x7&lt;/strong&gt;. Эти нейроны будут иметь размер рецептивного поля входного объема, идентичный в пространственном масштабе (&lt;strong&gt;7x7&lt;/strong&gt;), но с некоторыми недостатками.
- Во-первых, нейроны будут вычислять линейную функцию над входными данными, в то время как три стека слоев &lt;em&gt;CONV&lt;/em&gt; содержат нелинейности, которые делают их особенности более выразительными. 
- Во-вторых, если мы предположим, что все тома имеют &lt;strong&gt;C&lt;/strong&gt; каналов, то можно видеть, что один слой &lt;strong&gt;7x7&lt;/strong&gt; &lt;em&gt;CONV&lt;/em&gt; будет содержать &lt;strong&gt;\(C \times (7 \times 7 \times C) = 49 C^2\)&lt;/strong&gt; параметры, в то время как три слоя &lt;strong&gt;3x3&lt;/strong&gt; &lt;em&gt;CONV&lt;/em&gt; будут содержать только &lt;strong&gt;\(3 \times (C \times (3 \times 3 \times C)) = 27 C^2\)&lt;/strong&gt; параметры. Интуитивно понятно, что наложение слоев &lt;em&gt;CONV&lt;/em&gt; с маленькими фильтрами в отличие от одного слоя &lt;em&gt;CONV&lt;/em&gt; с большими фильтрами позволяет нам выразить более мощные функции входных данных с меньшим количеством параметров. В качестве практического недостатка нам может потребоваться больше памяти для хранения всех результатов промежуточного слоя &lt;em&gt;CONV&lt;/em&gt;, если мы планируем использовать обратное распространение.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Недавние уходы&lt;/strong&gt;. Следует отметить, что традиционная парадигма линейного списка слоев в последнее время была поставлена под сомнение в архитектурах &lt;em&gt;Google Inception&lt;/em&gt;, а также в современных (современных) &lt;em&gt;Residual Networks&lt;/em&gt; от &lt;em&gt;Microsoft Research Asia&lt;/em&gt;. Оба они (см. подробности ниже в разделе тематических исследований) имеют более сложные и разные структуры подключения.&lt;/p&gt;
&lt;p&gt;__На практике: используйте то, что лучше всего работает на &lt;em&gt;ImageNet__&lt;/em&gt;. Если вы чувствуете некоторую усталость, думая об архитектурных решениях, вам будет приятно узнать, что в &lt;strong&gt;90%&lt;/strong&gt; или более приложений вам не нужно беспокоиться об этом. Я предпочитаю резюмировать этот момент как &lt;em&gt;«не будьте героем»&lt;/em&gt; : вместо того, чтобы создавать свою собственную архитектуру для решения проблемы, вы должны посмотреть, какая архитектура в настоящее время лучше всего работает на &lt;em&gt;ImageNet&lt;/em&gt;, загрузить предварительно обученную модель и настроить ее на основе ваших данных. В редких случаях приходится обучать &lt;em&gt;ConvNet&lt;/em&gt; с нуля или проектировать его с нуля. Я также говорил об этом в &lt;a href="https://www.youtube.com/watch?v=u6aEYuemt0M"&gt;школе Deep Learning&lt;/a&gt;.  &lt;/p&gt;
&lt;h3&gt;Шаблоны для определения размеров слоев&lt;/h3&gt;
&lt;p&gt;До сих пор мы опускали упоминания об общих гиперпараметрах, используемых на каждом из уровней ConvNet. Сначала мы изложим общие эмпирические правила для определения размеров архитектур, а затем будем следовать правилам, обсуждая нотацию:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Входной слой&lt;/strong&gt; (содержащий изображение) должен быть кратен &lt;strong&gt;2&lt;/strong&gt; много раз. К распространенным номерам относятся 32 (например, CIFAR-10), &lt;strong&gt;64&lt;/strong&gt;, &lt;strong&gt;96&lt;/strong&gt; (например, &lt;strong&gt;STL-10&lt;/strong&gt;) или &lt;strong&gt;224&lt;/strong&gt; (например, общие &lt;em&gt;ImageNet&lt;/em&gt; &lt;em&gt;ConvNet&lt;/em&gt;), &lt;strong&gt;384&lt;/strong&gt; и &lt;strong&gt;512&lt;/strong&gt;.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Для конвальных слоев&lt;/strong&gt; следует использовать небольшие фильтры (например, &lt;strong&gt;3x3&lt;/strong&gt; или максимум &lt;strong&gt;5x5&lt;/strong&gt;), с шагом &lt;strong&gt;S=1&lt;/strong&gt; и, что особенно важно, заполнение входного объема нулями таким образом, чтобы слой conv не изменял пространственные размеры входных данных. То есть, когда &lt;strong&gt;F=3&lt;/strong&gt;, то с помощью &lt;strong&gt;P=1&lt;/strong&gt; сохранит исходный размер входных данных. Когда &lt;strong&gt;F=5&lt;/strong&gt;, &lt;strong&gt;P=2&lt;/strong&gt;. Для генерала &lt;strong&gt;F&lt;/strong&gt;, видно, что &lt;strong&gt;P=(F−1)/2&lt;/strong&gt; cохраняет размер ввода. Если вам нужно использовать фильтры большего размера (например, &lt;strong&gt;7x7&lt;/strong&gt; или около того), это обычно можно увидеть только на самом первом выпуклом слое, который смотрит на входное изображение.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Слои пула&lt;/strong&gt; отвечают за понижение дискретизации пространственных размеров входных данных. Наиболее распространенной настройкой является использование max-pooling с рецептивными полями &lt;strong&gt;2x2&lt;/strong&gt; (т.е. &lt;strong&gt;F=2&lt;/strong&gt;), и с шагом &lt;strong&gt;2&lt;/strong&gt; (т.е. &lt;strong&gt;S=2&lt;/strong&gt;). Обратите внимание, что при этом отбрасывается ровно &lt;strong&gt;75%&lt;/strong&gt; активаций входного объема (из-за уменьшения дискретизации на &lt;strong&gt;2&lt;/strong&gt; раза как по ширине, так и по высоте). Другой, чуть менее распространенный вариант — использование рецептивных полей &lt;strong&gt;3x3&lt;/strong&gt; с шагом &lt;strong&gt;2&lt;/strong&gt;, но это делает «подгонку» более сложной (например, слой &lt;strong&gt;32x32x3&lt;/strong&gt; потребует нулевого заполнения для использования с максимальным объединением полей с рецептивным полем &lt;strong&gt;3x3&lt;/strong&gt; и шагом &lt;strong&gt;2&lt;/strong&gt;). Очень редко можно увидеть, что размеры рецептивных полей для максимального пула больше &lt;strong&gt;3&lt;/strong&gt;, потому что в этом случае пулинг слишком потерян и агрессивен. Обычно это приводит к ухудшению производительности.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Уменьшение головной боли при уменьшении размера&lt;/strong&gt;. Представленная выше схема радует тем, что все слои &lt;em&gt;CONV&lt;/em&gt; сохраняют пространственный размер входных данных, в то время как только слои &lt;em&gt;POOL&lt;/em&gt; отвечают за пространственное понижение объемов. В альтернативной схеме, где мы используем шаги больше &lt;strong&gt;1&lt;/strong&gt; или не обнуляем входные данные в слоях &lt;em&gt;CONV&lt;/em&gt;, нам пришлось бы очень тщательно отслеживать входные объемы по всей архитектуре &lt;em&gt;CNN&lt;/em&gt; и убедиться, что все шаги и фильтры  &lt;em&gt;«работают»&lt;/em&gt; , и что архитектура &lt;em&gt;ConvNet&lt;/em&gt; хорошо и симметрично связана.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Зачем использовать strace of 1 в CONV?&lt;/strong&gt; Меньшие шаги лучше работают на практике. Кроме того, как уже упоминалось, шаг &lt;strong&gt;1&lt;/strong&gt; позволяет нам оставить всю пространственную понижение дискретизации слоям &lt;em&gt;POOL&lt;/em&gt;, при этом слои &lt;em&gt;CONV&lt;/em&gt; преобразуют только входной объем по глубине.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Зачем использовать набивку?&lt;/strong&gt; В дополнение к вышеупомянутому преимуществу сохранения постоянных пространственных размеров после &lt;em&gt;CONV&lt;/em&gt;, это фактически повышает производительность. Если бы слои &lt;em&gt;CONV&lt;/em&gt; не обнуляли входные данные, а выполняли только корректные свертки, то размер объемов уменьшался бы на небольшую величину после каждого &lt;em&gt;CONV&lt;/em&gt;, а информация на границах &lt;em&gt;«смывалась»&lt;/em&gt; бы слишком быстро.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Компрометация из-за ограничений памяти&lt;/strong&gt;. В некоторых случаях (особенно на ранних этапах архитектуры ConvNet) объем памяти может очень быстро увеличиваться с помощью эмпирических правил, представленных выше. Например, фильтрация изображения размером &lt;strong&gt;224x224x3&lt;/strong&gt; с тремя слоями &lt;em&gt;CONV&lt;/em&gt; &lt;strong&gt;3x3&lt;/strong&gt; с &lt;strong&gt;64&lt;/strong&gt; фильтрами каждый и отступом &lt;strong&gt;1&lt;/strong&gt; создаст три объема активации размером &lt;strong&gt;[224x224x64]&lt;/strong&gt;. Это составляет в общей сложности около &lt;strong&gt;10&lt;/strong&gt; миллионов активаций, или 72 МБ памяти (на изображение, как для активаций, так и для градиентов). Поскольку графические процессоры часто имеют узкие места из-за памяти, может потребоваться пойти на компромисс. На практике люди предпочитают идти на компромисс только на первом уровне &lt;em&gt;CONV&lt;/em&gt; сети. Например, одним из компромиссов может быть использование первого слоя &lt;em&gt;CONV&lt;/em&gt; с размерами фильтра &lt;strong&gt;7x7&lt;/strong&gt; и шагом &lt;strong&gt;2&lt;/strong&gt; (как в сети ZF). В качестве другого примера, &lt;em&gt;AlexNet&lt;/em&gt; использует размеры фильтров &lt;strong&gt;11x11&lt;/strong&gt; и &lt;em&gt;stride 4&lt;/em&gt;.&lt;/p&gt;
&lt;h3&gt;Тематические исследования&lt;/h3&gt;
&lt;p&gt;В области сверточных сетей существует несколько архитектур, которые имеют название. Наиболее распространенными являются:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;LeNet&lt;/strong&gt;. Первые успешные приложения сверточных сетей были разработаны Яном Лекуном в 1990-х годах. Из них наиболее известной является архитектура &lt;a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf"&gt;LeNet&lt;/a&gt;, которая использовалась для чтения почтовых индексов, цифр и т. д.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;AlexNet&lt;/strong&gt;. Первой работой, которая популяризировала сверточные сети в компьютерном зрении, стала &lt;a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks"&gt;сеть AlexNet&lt;/a&gt;, разработанная Алексом Крижевским, Ильей Суцкевером и Джеффом Хинтоном. В 2012 году AlexNet был представлен на &lt;a href="http://www.image-net.org/challenges/LSVRC/2014/"&gt;конкурс ImageNet ILSVRC&lt;/a&gt; и значительно превзошел занявшего второе место (ошибка в топ-5 &lt;strong&gt;16%&lt;/strong&gt; по сравнению с ошибкой в &lt;strong&gt;26%&lt;/strong&gt;, занявшей второе место). Сеть имела очень похожую архитектуру на &lt;em&gt;LeNet&lt;/em&gt;, но была глубже, больше и включала сверточные слои, наложенные друг на друга (ранее было обычным делом иметь только один слой &lt;em&gt;CONV&lt;/em&gt;, за которым всегда следовал слой &lt;em&gt;POOL&lt;/em&gt;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ZF Net&lt;/strong&gt;. Победителем &lt;em&gt;ILSVRC 2013&lt;/em&gt; стала сверточная сеть от Мэтью Зейлера и Роба Фергуса. Она стала известна как &lt;a href="http://arxiv.org/abs/1311.2901"&gt;ZFNet&lt;/a&gt; (сокращение от Zeiler &amp;amp; Fergus Net). Это было усовершенствование AlexNet за счет настройки гиперпараметров архитектуры, в частности, за счет увеличения размера средних сверточных слоев и уменьшения размера шага и фильтра на первом слое.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GoogLeNet&lt;/strong&gt;. Победителем &lt;em&gt;ILSVRC 2014&lt;/em&gt; стала сверточная сеть от &lt;a href="http://arxiv.org/abs/1409.4842"&gt;Сегеди и др.&lt;/a&gt; от Google. Ее основным вкладом стала разработка модуля Inception, который значительно сократил количество параметров в сети (&lt;strong&gt;4M&lt;/strong&gt;, по сравнению с &lt;em&gt;AlexNet&lt;/em&gt; с &lt;strong&gt;60M&lt;/strong&gt;). Кроме того, в этой статье используется &lt;em&gt;Average Pooling&lt;/em&gt; вместо &lt;em&gt;Fully Connected layers&lt;/em&gt; в верхней части &lt;em&gt;ConvNet&lt;/em&gt;, что устраняет большое количество параметров, которые не имеют большого значения. Существует также несколько последующих версий &lt;em&gt;GoogLeNet&lt;/em&gt;, последняя из которых &lt;a href="http://arxiv.org/abs/1602.07261"&gt;Inception-v4&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;VGGNet&lt;/strong&gt;. Второе место на &lt;em&gt;ILSVRC 2014&lt;/em&gt; заняла сеть Карена Симоняна и Эндрю Зиссермана, которая стала известна как &lt;a href="http://www.robots.ox.ac.uk/~vgg/research/very_deep/"&gt;VGGNet&lt;/a&gt;. Его основной вклад заключался в том, что он показал, что глубина сети является критически важным компонентом для хорошей производительности. Их окончательная лучшая сеть содержит 16 слоев &lt;em&gt;CONV&lt;/em&gt;/&lt;em&gt;FC&lt;/em&gt; и, что привлекательно, отличается чрезвычайно однородной архитектурой, которая выполняет только свертки 3x3 и пул &lt;strong&gt;2x2&lt;/strong&gt; от начала до конца. Их &lt;a href="http://www.robots.ox.ac.uk/~vgg/research/very_deep/"&gt;предварительно обученная модель&lt;/a&gt; доступна для использования в &lt;em&gt;Caffe&lt;/em&gt; по принципу «подключи и работай». Недостатком &lt;em&gt;VGGNet&lt;/em&gt; является то, что он дороже в оценке и использует гораздо больше памяти и параметров (&lt;em&gt;140M&lt;/em&gt;). Большинство этих параметров находятся в первом полностью связанном слое, и с тех пор было обнаружено, что эти слои &lt;em&gt;FC&lt;/em&gt; могут быть удалены без снижения производительности, что значительно сокращает количество необходимых параметров.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ResNet&lt;/strong&gt;.. &lt;a href="http://arxiv.org/abs/1512.03385"&gt;Остаточная сеть&lt;/a&gt;, разработанная Каим Хе и др., стала победителем &lt;em&gt;ILSVRC 2015&lt;/em&gt;. Она оснащена &lt;em&gt;специальными соединениями для пропуска&lt;/em&gt; и интенсивным использованием &lt;a href="http://arxiv.org/abs/1502.03167"&gt;пакетной нормализации&lt;/a&gt;. В архитектуре также отсутствуют полностью связанные слои в конце сети. Читателю также предлагается ознакомиться с презентацией Кайминга (&lt;a href="https://www.youtube.com/watch?v=1PGLj-uKT1w"&gt;видео&lt;/a&gt;, &lt;a href="http://research.microsoft.com/en-us/um/people/kahe/ilsvrc15/ilsvrc2015_deep_residual_learning_kaiminghe.pdf"&gt;слайды&lt;/a&gt;) и некоторыми &lt;a href="https://github.com/gcr/torch-residual-networks"&gt;недавними экспериментами&lt;/a&gt;, которые воспроизводят эти сети в Torch. В настоящее время ResNet являются самыми современными моделями сверточных нейронных сетей и являются выбором по умолчанию для использования &lt;em&gt;ConvNet&lt;/em&gt; на практике (по состоянию на &lt;em&gt;10 мая 2016 года&lt;/em&gt;). В частности, см. более поздние разработки, которые корректируют исходную архитектуру, из &lt;a href="https://arxiv.org/abs/1603.05027"&gt;книги Каим Хе и др. IСопоставления идентификационных данных в глубоких остаточных сетях&lt;/a&gt; (опубликована &lt;em&gt;в марте 2016 г.&lt;/em&gt;).  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;VGGNet в деталях&lt;/strong&gt;. Давайте разберем &lt;a href="http://www.robots.ox.ac.uk/~vgg/research/very_deep/"&gt;VGGNet&lt;/a&gt; более подробно в качестве тематического исследования. Вся сеть &lt;em&gt;VGGNet&lt;/em&gt; состоит из слоев &lt;em&gt;CONV&lt;/em&gt;, которые выполняют свертки &lt;strong&gt;3x3&lt;/strong&gt; со &lt;em&gt;stride 1 и pad 1&lt;/em&gt;, и из слоев &lt;em&gt;POOL&lt;/em&gt;, которые выполняют &lt;strong&gt;2x2&lt;/strong&gt; &lt;em&gt;max&lt;/em&gt; &lt;em&gt;pooling&lt;/em&gt; с &lt;em&gt;stride&lt;/em&gt; &lt;em&gt;2&lt;/em&gt; (и без отступа). Мы можем записывать размер представления на каждом шаге обработки и отслеживать как размер представления, так и общее количество весов:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;INPUT: [224x224x3]        memory:  224*224*3=150K   weights: 0
CONV3-64: [224x224x64]  memory:  224*224*64=3.2M   weights: (3*3*3)*64 = 1,728
CONV3-64: [224x224x64]  memory:  224*224*64=3.2M   weights: (3*3*64)*64 = 36,864
POOL2: [112x112x64]  memory:  112*112*64=800K   weights: 0
CONV3-128: [112x112x128]  memory:  112*112*128=1.6M   weights: (3*3*64)*128 = 73,728
CONV3-128: [112x112x128]  memory:  112*112*128=1.6M   weights: (3*3*128)*128 = 147,456
POOL2: [56x56x128]  memory:  56*56*128=400K   weights: 0
CONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*128)*256 = 294,912
CONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*256)*256 = 589,824
CONV3-256: [56x56x256]  memory:  56*56*256=800K   weights: (3*3*256)*256 = 589,824
POOL2: [28x28x256]  memory:  28*28*256=200K   weights: 0
CONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*256)*512 = 1,179,648
CONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*512)*512 = 2,359,296
CONV3-512: [28x28x512]  memory:  28*28*512=400K   weights: (3*3*512)*512 = 2,359,296
POOL2: [14x14x512]  memory:  14*14*512=100K   weights: 0
CONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296
CONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296
CONV3-512: [14x14x512]  memory:  14*14*512=100K   weights: (3*3*512)*512 = 2,359,296
POOL2: [7x7x512]  memory:  7*7*512=25K  weights: 0
FC: [1x1x4096]  memory:  4096  weights: 7*7*512*4096 = 102,760,448
FC: [1x1x4096]  memory:  4096  weights: 4096*4096 = 16,777,216
FC: [1x1x1000]  memory:  1000 weights: 4096*1000 = 4,096,000

TOTAL memory: 24M * 4 bytes ~= 93MB / image (only forward! ~*2 for bwd)
TOTAL params: 138M parameters  
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Как и в случае со сверточными сетями, обратите внимание, что большая часть памяти (а также вычислительного времени) используется в ранних слоях &lt;em&gt;CONV&lt;/em&gt;, а большинство параметров — в последних слоях &lt;em&gt;FC&lt;/em&gt;. В данном конкретном случае первый слой &lt;em&gt;FC&lt;/em&gt; содержит 100 м грузов из общего числа 140 м.&lt;/p&gt;
&lt;h3&gt;Вычислительные соображения&lt;/h3&gt;
&lt;p&gt;Самым большим узким местом, о котором следует знать при создании архитектур ConvNet, является узкое место памяти. Многие современные графические процессоры имеют ограничение в &lt;strong&gt;3/4/6 ГБ&lt;/strong&gt; памяти, а лучшие графические процессоры имеют около &lt;strong&gt;12 ГБ&lt;/strong&gt; памяти. Существует три основных источника памяти, которые необходимо отслеживать:  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Из промежуточных размеров объемов: Это исходное количество &lt;strong&gt;активаций&lt;/strong&gt; на каждом уровне ConvNet, а также их градиенты (одинакового размера). Как правило, большая часть активаций происходит на более ранних уровнях &lt;em&gt;ConvNet&lt;/em&gt; (т.е. на первых уровнях &lt;em&gt;Conv&lt;/em&gt;). Они сохраняются, потому что они нужны для обратного распространения, но умная реализация, которая запускает &lt;em&gt;ConvNet&lt;/em&gt; только во время тестирования, в принципе могла бы значительно сократить это, сохраняя только текущие активации на любом уровне и отбрасывая предыдущие активации на уровнях ниже.&lt;/li&gt;
&lt;li&gt;Из размеров параметров: Это числа, которые содержат &lt;strong&gt;параметры&lt;/strong&gt; сети, их градиенты во время обратного распространения и, как правило, также кэш шагов, если оптимизация выполняется с использованием momentum, &lt;em&gt;Adagrad&lt;/em&gt; или &lt;em&gt;RMSProp&lt;/em&gt;. Следовательно, память для хранения только вектора параметров обычно должна быть умножена по крайней мере на &lt;strong&gt;3&lt;/strong&gt; или около того.&lt;/li&gt;
&lt;li&gt;Каждая реализация &lt;em&gt;ConvNet&lt;/em&gt; должна поддерживать &lt;strong&gt;различную&lt;/strong&gt; память, такую как пакеты данных изображений, возможно, их дополненные версии и т.д.  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;После того, как вы получили приблизительную оценку общего количества значений (для активаций, градиентов и разного), это число следует преобразовать в размер в ГБ. Возьмите количество значений, умножьте на 4, чтобы получить исходное количество байтов (поскольку каждая плавающая точка равна 4 байтам, или, возможно, на 8 для двойной точности), а затем разделите на 1024 несколько раз, чтобы получить объем памяти в КБ, МБ и, наконец, в ГБ. Если ваша сеть не подходит, обычной эвристикой для «подгонки» является уменьшение размера пакета, поскольку большая часть памяти обычно потребляется активациями.  &lt;/p&gt;
&lt;h2&gt;Дополнительные материалы&lt;/h2&gt;
&lt;p&gt;Дополнительные ресурсы, связанные с реализацией:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/soumith/convnet-benchmarks"&gt;Бенчмарки Soumith для производительности CONV&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html"&gt;Демонстрация ConvNetJS CIFAR-10&lt;/a&gt; позволяет экспериментировать с архитектурами ConvNet и видеть результаты и вычисления в режиме реального времени, в браузере.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://caffe.berkeleyvision.org/"&gt;Caffe&lt;/a&gt;, одна из популярных библиотек ConvNet.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://torch.ch/blog/2016/02/04/resnets.html"&gt;Современные ResNet в Torch7&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description><guid>https://mldl.ru/posts/architecture/</guid><pubDate>Wed, 12 Mar 2025 16:42:16 GMT</pubDate></item><item><title>Обучение нейронных сетей 2</title><link>https://mldl.ru/posts/convnets-4/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;h2&gt;Обучение нейронных сетей&lt;/h2&gt;
&lt;p&gt;Содержание:
- &lt;a href="https://mldl.ru/posts/convnets-4/"&gt;Генерация некоторых данных&lt;/a&gt;
- &lt;a href="https://mldl.ru/posts/convnets-4/"&gt;Обучение линейного классификатора Softmax&lt;/a&gt;
    - &lt;a href="https://mldl.ru/posts/convnets-4/"&gt;Инициализируйте параметры&lt;/a&gt;
    - &lt;a href="https://mldl.ru/posts/convnets-4/"&gt;Подсчитайте баллы за класс&lt;/a&gt;
    - &lt;a href="https://mldl.ru/posts/convnets-4/"&gt;Вычислите потери&lt;/a&gt;
    - &lt;a href="https://mldl.ru/posts/convnets-4/"&gt;Вычисление аналитического градиента с обратным распространением&lt;/a&gt;
    - &lt;a href="https://mldl.ru/posts/convnets-4/"&gt;Выполнение обновления параметров&lt;/a&gt;
    - &lt;a href="https://mldl.ru/posts/convnets-4/"&gt;Сведение всего этого воедино: обучение классификатора Softmax&lt;/a&gt;
- &lt;a href="https://mldl.ru/posts/convnets-4/"&gt;Обучение нейронной сети&lt;/a&gt;
- &lt;a href="https://mldl.ru/posts/convnets-4/"&gt;Краткая сводка&lt;/a&gt;
- &lt;a href="https://mldl.ru/posts/convnets-4/"&gt;Дополнительные материалы&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;В этом разделе мы рассмотрим полную реализацию игрушечной нейронной сети в двух измерениях. Сначала мы реализуем простой линейный классификатор, а затем расширим код до двухслойной нейронной сети. Как мы увидим, это расширение на удивление простое, и требуется внести совсем немного изменений.  &lt;/p&gt;
&lt;h2&gt;Генерация некоторых данных&lt;/h2&gt;
&lt;p&gt;Давайте создадим набор данных для классификации, который нелегко разделить на линейные классы. Наш любимый пример — набор данных «спираль», который можно создать следующим образом:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;of&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;points&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;per&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt;
&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dimensionality&lt;/span&gt;
&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;number&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;of&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;classes&lt;/span&gt;
&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;data&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;matrix&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;each&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;row&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;single&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;example&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;'uint8'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;labels&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="ow"&gt;in&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;ix&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mf"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;radius&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;linspace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,(&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="mf"&gt;0.2&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;theta&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ix&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;c_&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;r*np.sin(t), r*np.cos(t)&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;ix&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;
&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;lets&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;visualize&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;data&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scatter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;:, 0&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="o"&gt;[&lt;/span&gt;&lt;span class="n"&gt;:, 1&lt;/span&gt;&lt;span class="o"&gt;]&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;40&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cmap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cm&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Spectral&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;show&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/eg/spiral_raw.png"&gt;  &lt;/p&gt;
&lt;p&gt;Данные игрушечной спирали состоят из трёх классов (синий, красный, жёлтый), которые нельзя разделить линейно.  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Обычно мы хотим предварительно обработать набор данных, чтобы среднее значение каждого признака было равно нулю, а стандартное отклонение — единице, но в данном случае признаки уже находятся в диапазоне от &lt;strong&gt;-1 до 1&lt;/strong&gt;, поэтому мы пропускаем этот шаг.  &lt;/p&gt;
&lt;h2&gt;Обучение линейного классификатора Softmax&lt;/h2&gt;
&lt;h3&gt;Инициализируйте параметры&lt;/h3&gt;
&lt;p&gt;Давайте сначала обучим классификатор &lt;strong&gt;Softmax&lt;/strong&gt; на этом наборе данных для классификации. Как мы видели в предыдущих разделах, классификатор &lt;strong&gt;Softmax&lt;/strong&gt; имеет линейную функцию оценки и использует функцию потерь кросс-энтропии. Параметры линейного классификатора состоят из весовой матрицы &lt;code&gt;W&lt;/code&gt; и вектора смещения &lt;code&gt;b&lt;/code&gt; для каждого класса. Давайте сначала инициализируем эти параметры случайными числами:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="gh"&gt;#&lt;/span&gt; initialize parameters randomly
W = 0.01 * np.random.randn(D,K)
b = np.zeros((1,K))
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Напомним, что &lt;code&gt;D = 2&lt;/code&gt; — это размерность, а &lt;code&gt;K = 3&lt;/code&gt; — количество классов.  &lt;/p&gt;
&lt;h3&gt;Подсчитайте баллы за класс&lt;/h3&gt;
&lt;p&gt;Поскольку это линейный классификатор, мы можем очень просто вычислить оценки для всех классов параллельно с помощью одного умножения матриц:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;#&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;compute&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;class&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;scores&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;linear&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;classifier&lt;/span&gt;
&lt;span class="nv"&gt;scores&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;np&lt;/span&gt;.&lt;span class="nv"&gt;dot&lt;/span&gt;&lt;span class="ss"&gt;(&lt;/span&gt;&lt;span class="nv"&gt;X&lt;/span&gt;,&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;W&lt;/span&gt;&lt;span class="ss"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nv"&gt;b&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;В этом примере у нас есть &lt;strong&gt;300 двумерных точек&lt;/strong&gt;, поэтому после этого умножения массив &lt;code&gt;scores&lt;/code&gt; будет иметь размер &lt;strong&gt;[300 x 3]&lt;/strong&gt;, где каждая строка содержит баллы за классы, соответствующие трём классам (синий, красный, жёлтый).&lt;/p&gt;
&lt;h3&gt;Вычислите потери&lt;/h3&gt;
&lt;p&gt;Второй ключевой компонент, который нам нужен, — это функция потерь, представляющая собой дифференцируемую целевую функцию, которая количественно оценивает наше недовольство вычисленными оценками классов. Интуитивно понятно, что мы хотим, чтобы правильный класс имел более высокую оценку, чем другие классы. В этом случае потери должны быть низкими, а в противном случае — высокими. Существует множество способов количественно оценить эту интуитивную догадку, но в этом примере мы будем использовать потери перекрёстной энтропии, которые связаны с классификатором Softmax. Напомним, что если &lt;strong&gt;f&lt;/strong&gt; — это массив оценок классов для одного примера (например, массив из трёх чисел), тогда классификатор &lt;strong&gt;Softmax&lt;/strong&gt; вычисляет потерю для этого примера следующим образом:  &lt;/p&gt;
&lt;p&gt;$$
L_i = -\log\left(\frac{e^{f_{y_i}}}{ \sum_j e^{f_j} }\right)
$$  &lt;/p&gt;
&lt;p&gt;Мы можем видеть, что классификатор &lt;strong&gt;Softmax&lt;/strong&gt; интерпретирует каждый элемент &lt;strong&gt;f&lt;/strong&gt;. В качестве входных данных используются (ненормализованные) логарифмические вероятности трёх классов. Мы возводим их в степень, чтобы получить (&lt;em&gt;ненормализованные&lt;/em&gt;) вероятности, а затем нормализуем их, чтобы получить вероятности. Таким образом, выражение внутри логарифма — это нормализованная вероятность правильного класса. Обратите внимание на то, как работает это выражение: эта величина всегда находится в диапазоне от &lt;strong&gt;0 до 1&lt;/strong&gt;. Когда вероятность правильного класса очень мала (&lt;strong&gt;близка к 0&lt;/strong&gt;), потери будут стремиться к (положительной) бесконечности. И наоборот, когда вероятность правильного класса приближается к &lt;strong&gt;1&lt;/strong&gt;, потери приближаются к нулю, потому что &lt;strong&gt;log(1)=0&lt;/strong&gt;. Следовательно, выражение для &lt;strong&gt;\(L_i\)&lt;/strong&gt;. Вероятность правильного класса низкая, когда она высока, и очень высокая, когда она низка.   &lt;/p&gt;
&lt;p&gt;Напомним также, что полная потеря классификатора &lt;strong&gt;Softmax&lt;/strong&gt; определяется как средняя потеря кросс-энтропии по обучающим примерам и регуляризация:  &lt;/p&gt;
&lt;p&gt;$$
L =  \underbrace{ \frac{1}{N} \sum_i L_i }&lt;em k_l="k,l"&gt;\text{потеря данных} + \underbrace{ \frac{1}{2} \lambda \sum_k\sum_l W&lt;/em&gt; \\
$$  }^2 }_\text{потеря регуляризации&lt;/p&gt;
&lt;p&gt;Учитывая массив &lt;code&gt;scores&lt;/code&gt; значений, которые мы вычислили выше, мы можем вычислить потери. Во-первых, способ получения вероятностей прост:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;num_examples = X.shape[0]
&lt;span class="gh"&gt;#&lt;/span&gt; get unnormalized probabilities
exp_scores = np.exp(scores)
&lt;span class="gh"&gt;#&lt;/span&gt; normalize them for each example
probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Теперь у нас есть массив &lt;code&gt;probs&lt;/code&gt; размером [300 x 3], где каждая строка содержит вероятности классов. В частности, поскольку мы их нормализовали, сумма значений в каждой строке равна единице. Теперь мы можем запросить логарифмические вероятности, присвоенные правильным классам в каждом примере:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;orrect_logprobs = -np.log(probs[range(num_examples),y])
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Массив &lt;code&gt;correct_logprobs&lt;/code&gt; — это одномерный массив, содержащий только вероятности, присвоенные правильным классам для каждого примера. &lt;strong&gt;Полная потеря&lt;/strong&gt; — это среднее значение этих логарифмических вероятностей и потери от регуляризации:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="p"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;compute&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;loss:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;average&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cross&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;entropy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;and&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;regularization&lt;/span&gt;
&lt;span class="n"&gt;data_loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;correct_logprobs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;num_examples&lt;/span&gt;
&lt;span class="n"&gt;reg_loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="kt"&gt;reg&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;W&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;data_loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;reg_loss&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;В этом коде сила регуляризации &lt;strong&gt;λ&lt;/strong&gt; хранится внутри &lt;code&gt;reg&lt;/code&gt;. Коэффициент удобства &lt;code&gt;0.5&lt;/code&gt; умножения регуляризации станет ясен через секунду. Оценка этого вначале (со случайными параметрами) может дать нам &lt;code&gt;loss = 1.1&lt;/code&gt;, что и есть &lt;code&gt;-np.log(1.0/3)&lt;/code&gt;, поскольку при небольших начальных случайных весах все вероятности, присвоенные всем классам, составляют около одной трети. Теперь мы хотим сделать потери как можно более низкими, используя &lt;code&gt;loss = 0&lt;/code&gt; в качестве абсолютной нижней границы. Но чем меньше потери, тем выше вероятности, присвоенные правильным классам для всех примеров.  &lt;/p&gt;
&lt;h3&gt;Вычисление аналитического градиента с обратным распространением&lt;/h3&gt;
&lt;p&gt;У нас есть способ оценки потерь, и теперь нам нужно их минимизировать. Мы сделаем это с помощью градиентного спуска. То есть мы начнём со случайных параметров (как показано выше) и вычислим градиент функции потерь по отношению к параметрам, чтобы знать, как изменить параметры для уменьшения потерь. Давайте введём промежуточную переменную &lt;strong&gt;p&lt;/strong&gt;, который представляет собой вектор (&lt;em&gt;нормализованных&lt;/em&gt;) вероятностей. Потери для одного примера составляют:  &lt;/p&gt;
&lt;p&gt;$$
p_k = \frac{e^{f_k}}{ \sum_j e^{f_j} } \hspace{1in} L_i =-\log\left(p_{y_i}\right)
$$  &lt;/p&gt;
&lt;p&gt;Теперь мы хотим понять, как вычисляются баллы внутри &lt;strong&gt;f&lt;/strong&gt; следует изменить, чтобы уменьшить потери &lt;strong&gt;\(L_i\)&lt;/strong&gt;, что этот пример соответствует общей цели. Другими словами, мы хотим вычислить градиент &lt;strong&gt;\( \partial L_i / \partial f_k \)&lt;/strong&gt;. Потеря __\(L_i\)__вычисляется из &lt;strong&gt;p&lt;/strong&gt;, что , в свою очередь , зависит от &lt;strong&gt;f&lt;/strong&gt;. Читателю будет интересно использовать правило дифференцирования сложной функции для вычисления градиента, но в итоге всё оказывается очень простым и понятным, после того как многое сокращается:  &lt;/p&gt;
&lt;p&gt;$$
\frac{\partial L_i }{ \partial f_k } = p_k - \mathbb{1}(y_i = k)
$$  &lt;/p&gt;
&lt;p&gt;Обратите внимание, насколько элегантно и просто выглядит это выражение. Предположим, что вычисленные нами вероятности были &lt;code&gt;p = [0.2, 0.3, 0.5]&lt;/code&gt; и что правильным классом был средний (&lt;strong&gt;с вероятностью 0,3&lt;/strong&gt;). Согласно этому выводу, градиент оценок будет равен &lt;code&gt;df = [0.2, -0.7, 0.5]&lt;/code&gt;. Вспомнив, что означает интерпретация градиента, мы видим, что этот результат вполне интуитивен: увеличение первого или последнего элемента вектора оценок &lt;strong&gt;f&lt;/strong&gt; (оценок неверных классов) приводит к &lt;em&gt;увеличению&lt;/em&gt; потерь (из-за положительных значений &lt;strong&gt;+0,2 и +0,5&lt;/strong&gt;) — а увеличение потерь плохо, как и ожидалось. Однако увеличение оценки правильного класса отрицательно влияет на потери. Градиент &lt;strong&gt;-0,7&lt;/strong&gt; говорит нам о том, что увеличение оценки правильного класса приведёт к уменьшению потерь &lt;strong&gt;\(L_i\)&lt;/strong&gt;, что имеет смысл.  &lt;/p&gt;
&lt;p&gt;Всё это сводится к следующему коду. Напомним, что &lt;code&gt;probs&lt;/code&gt; хранит вероятности всех классов (в виде строк) для каждого примера. Чтобы получить градиент оценок, который мы называем &lt;code&gt;dscores&lt;/code&gt;, мы поступаем следующим образом:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;dscores = probs
dscores[range(num_examples),y] -= 1
dscores /= num_examples
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Наконец, у нас есть &lt;code&gt;scores = np.dot(X, W) + b&lt;/code&gt; и, вооружившись градиентом &lt;code&gt;scores&lt;/code&gt; (хранящимся в &lt;em&gt;dscores&lt;/em&gt;), мы можем выполнить обратное распространение ошибки в &lt;code&gt;W&lt;/code&gt; и &lt;code&gt;b&lt;/code&gt;:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;dW&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dscores&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dscores&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mh"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;keepdims&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;dW&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;reg&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;W&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;don&lt;/span&gt;&lt;span class="p"&gt;'&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;forget&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;regularization&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Здесь мы видим, что мы выполнили обратное преобразование с помощью операции умножения матриц, а также добавили вклад от регуляризации. Обратите внимание, что градиент регуляризации имеет очень простую форму &lt;code&gt;reg*W&lt;/code&gt;, поскольку мы использовали константу &lt;code&gt;0.5&lt;/code&gt; для вклада в потери (т. е. &lt;strong&gt;\(\frac{d}{dw} ( \frac{1}{2} \lambda w^2) = \lambda w\)&lt;/strong&gt; ). Это распространенный удобный прием, который упрощает выражение градиента.  &lt;/p&gt;
&lt;h3&gt;Выполнение обновления параметров&lt;/h3&gt;
&lt;p&gt;Теперь, когда мы вычислили градиент, мы знаем, как каждый параметр влияет на функцию потерь. Теперь мы обновим параметры в направлении &lt;em&gt;отрицательного&lt;/em&gt; градиента, чтобы &lt;em&gt;уменьшить&lt;/em&gt; потери:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="gh"&gt;#&lt;/span&gt; perform a parameter update
W += -step_size &lt;span class="gs"&gt;* dW&lt;/span&gt;
&lt;span class="gs"&gt;b += -step_size *&lt;/span&gt; db
&lt;/pre&gt;&lt;/div&gt;

&lt;h3&gt;Сведение всего этого воедино: обучение классификатора Softmax&lt;/h3&gt;
&lt;p&gt;Если собрать всё это воедино, получится полный код для обучения классификатора &lt;strong&gt;Softmax&lt;/strong&gt; с помощью градиентного спуска:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="p"&gt;#&lt;/span&gt;&lt;span class="n"&gt;Train&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Linear&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Classifier&lt;/span&gt;

&lt;span class="p"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;initialize&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;parameters&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;randomly&lt;/span&gt;
&lt;span class="n"&gt;W&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.01&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;random&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;randn&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="mh"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="p"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;some&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;hyperparameters&lt;/span&gt;
&lt;span class="n"&gt;step_size&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1e-0&lt;/span&gt;
&lt;span class="kt"&gt;reg&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1e-3&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;regularization&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;strength&lt;/span&gt;

&lt;span class="p"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;descent&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loop&lt;/span&gt;
&lt;span class="n"&gt;num_examples&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;shape&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mh"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;in&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mh"&gt;200&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;evaluate&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;scores&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;scores&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;W&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;compute&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;class&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;probabilities&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;exp_scores&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scores&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;probs&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;exp_scores&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;exp_scores&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mh"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;keepdims&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;K&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;compute&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nl"&gt;loss:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;average&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;cross&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;entropy&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;and&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;regularization&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;correct_logprobs&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;probs&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_examples&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;data_loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;correct_logprobs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;num_examples&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;reg_loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.5&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="kt"&gt;reg&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;W&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;data_loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;reg_loss&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;10&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="w"&gt;    &lt;/span&gt;&lt;span class="n"&gt;print&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s"&gt;"iteration %d: loss %f"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;%&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;compute&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;on&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;scores&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;dscores&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;probs&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;dscores&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_examples&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;1&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;dscores&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;/=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;num_examples&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;backpropate&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;to&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;the&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;parameters&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;W&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;dW&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;dot&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;X&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dscores&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;np&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sum&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dscores&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;axis&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mh"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;keepdims&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;dW&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="kt"&gt;reg&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;W&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;regularization&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;gradient&lt;/span&gt;

&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="p"&gt;#&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;perform&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="k"&gt;parameter&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;W&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;step_size&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;dW&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;+=&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;step_size&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;
&lt;span class="w"&gt;  &lt;/span&gt;&lt;span class="err"&gt;```&lt;/span&gt;


&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;При&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;выполнении&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;этой&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;операции&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;выводятся&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;выходные&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;данные&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;

&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="err"&gt;```&lt;/span&gt;
&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;0&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;1.096956&lt;/span&gt;
&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;10&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.917265&lt;/span&gt;
&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;20&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.851503&lt;/span&gt;
&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;30&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.822336&lt;/span&gt;
&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;40&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.807586&lt;/span&gt;
&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;50&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.799448&lt;/span&gt;
&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;60&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.794681&lt;/span&gt;
&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;70&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.791764&lt;/span&gt;
&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;80&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.789920&lt;/span&gt;
&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;90&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.788726&lt;/span&gt;
&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;100&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.787938&lt;/span&gt;
&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;110&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.787409&lt;/span&gt;
&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;120&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.787049&lt;/span&gt;
&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;130&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.786803&lt;/span&gt;
&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;140&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.786633&lt;/span&gt;
&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;150&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.786514&lt;/span&gt;
&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;160&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.786431&lt;/span&gt;
&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;170&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.786373&lt;/span&gt;
&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;180&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.786331&lt;/span&gt;
&lt;span class="n"&gt;iteration&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mh"&gt;190&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;loss&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.786302&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Мы видим, что после примерно &lt;strong&gt;190&lt;/strong&gt; итераций мы приблизились к чему-то. Мы можем оценить точность обучающего набора данных:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="gh"&gt;#&lt;/span&gt; evaluate training set accuracy
scores = np.dot(X, W) + b
predicted_class = np.argmax(scores, axis=1)
print 'training accuracy: %.2f' % (np.mean(predicted_class == y))
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Это выводит &lt;strong&gt;49%&lt;/strong&gt;. Не очень хорошо, но и неудивительно, учитывая, что набор данных составлен таким образом, что он не является линейно разделимым. Мы также можем построить границы принятых решений:  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/eg/spiral_linear.png"&gt;&lt;br&gt;
Линейный классификатор не может изучить набор данных &lt;em&gt;toy spiral&lt;/em&gt;.  &lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Обучение нейронной сети&lt;/h2&gt;
&lt;p&gt;Очевидно, что линейный классификатор не подходит для этого набора данных, и мы хотели бы использовать нейронную сеть. Для этих игрушечных данных будет достаточно одного дополнительного скрытого слоя. Теперь нам понадобятся два набора весовых коэффициентов и смещений (&lt;em&gt;для первого и второго слоев&lt;/em&gt;):  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="gh"&gt;#&lt;/span&gt; initialize parameters randomly
h = 100 # size of hidden layer
W = 0.01 &lt;span class="gs"&gt;* np.random.randn(D,h)&lt;/span&gt;
&lt;span class="gs"&gt;b = np.zeros((1,h))&lt;/span&gt;
&lt;span class="gs"&gt;W2 = 0.01 *&lt;/span&gt; np.random.randn(h,K)
b2 = np.zeros((1,K))
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Прямой проход для подсчета очков теперь меняет форму:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="gh"&gt;#&lt;/span&gt; evaluate class scores with a 2-layer Neural Network
hidden_layer = np.maximum(0, np.dot(X, W) + b) # note, ReLU activation
scores = np.dot(hidden_layer, W2) + b2
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Обратите внимание, что единственное отличие от предыдущего варианта — это одна дополнительная строка кода, в которой мы сначала вычисляем представление скрытого слоя, а затем баллы на основе этого скрытого слоя. Важно отметить, что мы также добавили нелинейность, которая в данном случае представляет собой простую функцию &lt;strong&gt;ReLU&lt;/strong&gt;, устанавливающую пороговое значение активации скрытого слоя на нуле.  &lt;/p&gt;
&lt;p&gt;Всё остальное остаётся прежним. Мы вычисляем потери на основе оценок точно так же, как и раньше, и получаем градиент для оценок &lt;code&gt;dscores&lt;/code&gt; точно так же, как и раньше. Однако способ обратного распространения этого градиента на параметры модели, конечно, меняется. Сначала давайте выполним обратное распространение для второго слоя нейронной сети. Это выглядит так же, как и код для классификатора &lt;strong&gt;Softmax&lt;/strong&gt;, за исключением того, что мы заменяем &lt;code&gt;X&lt;/code&gt; (исходные данные) на переменную &lt;code&gt;hidden_layer&lt;/code&gt;):  &lt;/p&gt;
&lt;p&gt;```# backpropate the gradient to the parameters&lt;/p&gt;
&lt;h2&gt;first backprop into parameters W2 and b2&lt;/h2&gt;
&lt;p&gt;dW2 = np.dot(hidden_layer.T, dscores)
db2 = np.sum(dscores, axis=0, keepdims=True)&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="n"&gt;Однако&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;в&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;отличие&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;от&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;предыдущего&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;случая&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;мы&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ещё&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;не&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;закончили&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;потому&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;что&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n n-Quoted"&gt;`hidden_layer`&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;сама&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;является&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;функцией&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;других&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;параметров&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;и&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;данных&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Нам&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;нужно&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;продолжить&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;обратное&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;распространение&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;ошибки&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;через&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;эту&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;переменную&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;Её&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;градиент&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;можно&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;вычислить&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;следующим&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="n"&gt;образом&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="w"&gt;  &lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;dhidden = np.dot(dscores, W2.T)&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;Теперь у нас есть градиент на выходе скрытого слоя. Далее нам нужно выполнить обратное распространение ошибки для нелинейности **ReLU**. Это оказывается простым, потому что **ReLU** при обратном распространении ошибки фактически является переключателем. Поскольку **r=max(0,x)**, у нас есть это **dr/dx=1(x&amp;gt;0)**. В сочетании с правилом дифференцирования по частям мы видим, что блок **ReLU** пропускает градиент без изменений, если его входные данные больше 0, но &lt;span class="ge"&gt;_отменяет_&lt;/span&gt; его, если входные данные меньше нуля во время прямого прохода. Следовательно, мы можем выполнить обратное распространение ошибки для **ReLU** следующим образом:  
&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;backprop the ReLU non-linearity&lt;/h2&gt;
&lt;p&gt;dhidden[hidden_layer &amp;lt;= 0] = 0&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;И теперь мы, наконец, переходим к первому слою весов и смещений:  
&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;finally into W,b&lt;/h2&gt;
&lt;p&gt;dW = np.dot(X.T, dhidden)
db = np.sum(dhidden, axis=0, keepdims=True)&lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;**Готово!** У нас есть градиенты &lt;span class="sb"&gt;`dW,db,dW2,db2`&lt;/span&gt; и мы можем выполнить обновление параметров. Всё остальное остаётся без изменений. Полный код выглядит очень похоже:  
&lt;/pre&gt;&lt;/div&gt;

&lt;h2&gt;initialize parameters randomly&lt;/h2&gt;
&lt;p&gt;h = 100 # size of hidden layer
W = 0.01 * np.random.randn(D,h)
b = np.zeros((1,h))
W2 = 0.01 * np.random.randn(h,K)
b2 = np.zeros((1,K))&lt;/p&gt;
&lt;h2&gt;some hyperparameters&lt;/h2&gt;
&lt;p&gt;step_size = 1e-0
reg = 1e-3 # regularization strength&lt;/p&gt;
&lt;h2&gt;gradient descent loop&lt;/h2&gt;
&lt;p&gt;num_examples = X.shape[0]
for i in range(10000):&lt;/p&gt;
&lt;p&gt;# evaluate class scores, [N x K]
  hidden_layer = np.maximum(0, np.dot(X, W) + b) # note, ReLU activation
  scores = np.dot(hidden_layer, W2) + b2&lt;/p&gt;
&lt;p&gt;# compute the class probabilities
  exp_scores = np.exp(scores)
  probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True) # [N x K]&lt;/p&gt;
&lt;p&gt;# compute the loss: average cross-entropy loss and regularization
  correct_logprobs = -np.log(probs[range(num_examples),y])
  data_loss = np.sum(correct_logprobs)/num_examples
  reg_loss = 0.5&lt;em&gt;reg&lt;/em&gt;np.sum(W&lt;em&gt;W) + 0.5&lt;/em&gt;reg&lt;em&gt;np.sum(W2&lt;/em&gt;W2)
  loss = data_loss + reg_loss
  if i % 1000 == 0:
    print "iteration %d: loss %f" % (i, loss)&lt;/p&gt;
&lt;p&gt;# compute the gradient on scores
  dscores = probs
  dscores[range(num_examples),y] -= 1
  dscores /= num_examples&lt;/p&gt;
&lt;p&gt;# backpropate the gradient to the parameters
  # first backprop into parameters W2 and b2
  dW2 = np.dot(hidden_layer.T, dscores)
  db2 = np.sum(dscores, axis=0, keepdims=True)
  # next backprop into hidden layer
  dhidden = np.dot(dscores, W2.T)
  # backprop the ReLU non-linearity
  dhidden[hidden_layer &amp;lt;= 0] = 0
  # finally into W,b
  dW = np.dot(X.T, dhidden)
  db = np.sum(dhidden, axis=0, keepdims=True)&lt;/p&gt;
&lt;p&gt;# add regularization gradient contribution
  dW2 += reg * W2
  dW += reg * W&lt;/p&gt;
&lt;p&gt;# perform a parameter update
  W += -step_size * dW
  b += -step_size * db
  W2 += -step_size * dW2
  b2 += -step_size * db2
  ```&lt;/p&gt;
&lt;p&gt;Это печатает:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;iteration 0: loss 1.098744
iteration 1000: loss 0.294946
iteration 2000: loss 0.259301
iteration 3000: loss 0.248310
iteration 4000: loss 0.246170
iteration 5000: loss 0.245649
iteration 6000: loss 0.245491
iteration 7000: loss 0.245400
iteration 8000: loss 0.245335
iteration 9000: loss 0.245292
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Точность обучения теперь равна:  &lt;/p&gt;
&lt;div class="code"&gt;&lt;pre class="code literal-block"&gt;&lt;span class="gh"&gt;#&lt;/span&gt; evaluate training set accuracy
hidden_layer = np.maximum(0, np.dot(X, W) + b)
scores = np.dot(hidden_layer, W2) + b2
predicted_class = np.argmax(scores, axis=1)
print 'training accuracy: %.2f' % (np.mean(predicted_class == y))
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Что выводит &lt;strong&gt;98%&lt;/strong&gt;!. Мы также можем визуализировать границы решений:  &lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;img alt="" src="https://cs231n.github.io/assets/eg/spiral_net.png"&gt;&lt;br&gt;
Классификатор нейронной сети сжимает набор данных &lt;em&gt;spiral&lt;/em&gt;.  &lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;Краткие сведения&lt;/h2&gt;
&lt;p&gt;Мы работали с игрушечным 2D-набором данных и обучали как линейную сеть, так и двухслойную нейронную сеть. Мы увидели, что переход от линейного классификатора к нейронной сети требует очень мало изменений в коде. Функция оценки меняет свою форму (разница в 1 строке кода), а обратное распространение ошибки меняет свою форму (нам нужно выполнить ещё один цикл обратного распространения ошибки через скрытый слой к первому слою сети).  &lt;/p&gt;
&lt;h2&gt;Дополнительные материалы&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Возможно, вам захочется взглянуть на этот код &lt;strong&gt;IPython Notebook&lt;/strong&gt; &lt;a href="http://cs.stanford.edu/people/karpathy/cs231nfiles/minimal_net.html"&gt;отображаемый в формате HTML&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Или загрузите &lt;a href="http://cs.stanford.edu/people/karpathy/cs231nfiles/minimal_net.ipynb"&gt;файл ipynb&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description><guid>https://mldl.ru/posts/convnets-4/</guid><pubDate>Tue, 11 Mar 2025 16:42:16 GMT</pubDate></item></channel></rss>