<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Заметки по ML, DL (Записи о cs231a)</title><link>https://mldl.ru/</link><description></description><atom:link href="https://mldl.ru/categories/cs231a.xml" rel="self" type="application/rss+xml"></atom:link><language>ru</language><copyright>Contents © 2025 &lt;a href="mailto:andrej.labintsev@yandex.ru"&gt;Андрей Лабинцев&lt;/a&gt; </copyright><lastBuildDate>Sat, 04 Oct 2025 23:49:43 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Активное стерео и объёмное стереовидение</title><link>https://mldl.ru/posts/active-volumetric/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;h4&gt;Введение&lt;/h4&gt;
&lt;p&gt;В классическом стереовидении мы пытаемся определить положение трёхмерной точки в пространстве, используя &lt;strong&gt;соответствующие точки&lt;/strong&gt; на двух изображениях. Главная сложность здесь — решить &lt;strong&gt;проблему соответствия&lt;/strong&gt;: как понять, что точка на одном изображении соответствует точке на другом?&lt;/p&gt;
&lt;p&gt;Эта проблема усложняется тем, что в сцене присутствует множество трёхмерных точек, и нам нужно обработать их все. Сегодня мы рассмотрим альтернативный подход к реконструкции трехмерной сцены. &lt;/p&gt;
&lt;h4&gt;1. Активное стерео&lt;/h4&gt;
&lt;p&gt;Чтобы решить проблему поиска соответствующих точек, была разработана концепция &lt;strong&gt;активного стерео&lt;/strong&gt;. Её суть состоит в том, что вместо одной из камер используется специальный проектор, который взаимодействует с трёхмерной сценой.
Проектор создаёт на объекте специальный узор или проецирует определённую точку, а вторая камера наблюдает за тем, как этот узор отображается на объекте. 
Поскольку мы точно знаем, что и куда проецируем (положение точки, цвет, яркость), нам легко найти соответствующую точку на изображении второй камеры&lt;/p&gt;
&lt;p&gt;Главное преимущество активного стерео состоит в том, что оно значительно упрощает решение проблему поиска соответствующих точек. Проектор и камера работают как единая система, создавая особую геометрию, похожую на обычную стереосистему, но с виртуальной проекционной плоскостью вместо второй камеры.&lt;/p&gt;
&lt;p&gt;Этот метод особенно эффективен, когда нужно точно определить положение объектов в пространстве, так как мы контролируем проецируемый узор и можем легко отследить его отображение на второй камере.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 1: Система активного стерео" src="https://storage.yandexcloud.net/yahosting/active/1.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 1: Система активного стерео&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;На рисунке 1 показано, как проектор используется для проецирования точки $p$ из виртуальной плоскости на объект в трёхмерном пространстве, создавая точку в трёхмерном пространстве $P$. Эта трёхмерная точка $P$ должна наблюдаться второй камерой как точка $p'$.&lt;/p&gt;
&lt;p&gt;Поскольку мы знаем, что именно проецируем (например, положение точки $p$ в виртуальной плоскости, цвет и интенсивность проекции и так далее), мы можем легко обнаружить соответствующее наблюдение во второй камере $p'$.&lt;/p&gt;
&lt;p&gt;Распространённый прием в активном стерео — проецировать из виртуальной плоскости вертикальную полосу $s$ вместо одиночной точки. Этот случай очень похож на случай с точкой, когда линия $s$ проецируется в виде полосы в трёхмерное пространство $S$ и наблюдается камерой как линия $s'$.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 2: Проецирование отрезка" src="https://storage.yandexcloud.net/yahosting/active/2.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 2: Проецирование отрезка&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Если проектор и камера расположены параллельно или откалиброваны, мы можем легко обнаружить соответствующие точки, просто пересекая $s'$ с горизонтальными эпиполярными линиями. На основе этих соответствий мы можем использовать методы триангуляции, рассмотренных в предыдущих материалах курса, чтобы восстановить все трёхмерные точки на полосе $S$.&lt;/p&gt;
&lt;p&gt;Перемещая линию по сцене и повторяя процесс, мы можем восстановить полную форму всех видимых объектов в сцене.&lt;/p&gt;
&lt;p&gt;Обратите внимание, что одно из требований для работы этого алгоритма заключается в том, что проектор и камера должны быть откалиброваны. Активная стереосистема может быть откалибрована с использованием аналогичных техник, как описано в предыдущих заметках.&lt;/p&gt;
&lt;p&gt;Сначала мы калибруем камеру с помощью калибровочного устройства. Затем, проецируя известные полосы на калибровочное устройство и используя соответствующие наблюдения в недавно откалиброванной камере, мы можем установить ограничения для оценки внутренних и внешних параметров проектора.&lt;/p&gt;
&lt;p&gt;После калибровки эта активная стереоустановка может давать очень точные результаты. В 2000 году Марк Левой и его студенты из Стэнфорда продемонстрировали, что, используя точно настроенный лазерный сканер, они могли восстановить форму скульптуры «Пьета» Микеланджело с субмиллиметровой точностью.&lt;/p&gt;
&lt;p&gt;Однако в некоторых случаях наличие точно настроенного проектора может быть слишком дорогим или неудобным. Альтернативный подход, который использует гораздо более дешёвую установку, использует тени для создания активных паттернов на объекте, который мы хотим восстановить.&lt;/p&gt;
&lt;p&gt;Размещая палочку между объектом и источником света в известном положении, мы можем эффективно проецировать полосу на объект, как и раньше. Перемещение палочки позволяет нам проецировать различные теневые полосы на объект и восстанавливать объект аналогичным образом, как и раньше.&lt;/p&gt;
&lt;p&gt;Этот метод, хотя и намного дешевле, имеет тенденцию давать менее точные результаты, поскольку требует очень хорошей калибровки между палочкой, камерой и источником света, при этом необходимо поддерживать компромисс между длиной и тонкостью тени палочки.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 3: Активное стерео с цветными отрезками" src="https://storage.yandexcloud.net/yahosting/active/3.jpg"&gt; &lt;/p&gt;
&lt;p&gt;Одно из ограничений проецирования единственной полосы на объекты заключается в том, что этот метод довольно медленный, поскольку проектору необходимо охватить весь объект с разных ракурсов. Более того, это означает, что данный метод не может фиксировать деформации в режиме реального времени.&lt;/p&gt;
&lt;p&gt;Естественное развитие этой идеи — попытка восстановить объект путём проецирования одного кадра или изображения вместо последовательного сканирования. Суть заключается в проецировании известного узора из различных полос на весь видимый участок объекта, а не одной полосы.&lt;/p&gt;
&lt;p&gt;Цвета этих полос разработаны таким образом, чтобы их можно было однозначно идентифицировать на изображении. Рисунок 3 иллюстрирует этот метод с использованием множества цветных полос. Эта концепция легла в основу многих современных датчиков глубины, например, оригинальной версии Microsoft Kinect.&lt;/p&gt;
&lt;p&gt;На практике такие датчики используют инфракрасные лазерные проекторы, которые позволяют захватывать трёхмерные видеоданные при любых условиях внешней освещённости.&lt;/p&gt;
&lt;p&gt;### 2. Методы объёмного стереовидения &lt;/p&gt;
&lt;p&gt;Альтернативой как традиционному стереовидению, так и активному стерео является объёмное стереовидение, которое переворачивает проблему использования соответствующих точек для восстановления трёхмерной структуры.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 4: Основная идея объемного стереовидения - поиск точки в известном объеме" src="https://storage.yandexcloud.net/yahosting/active/4.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 4: Основная идея объемного стереовидения - поиск точки в известном объеме&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;В объёмном стереовидении мы предполагаем, что трёхмерная точка, которую мы пытаемся оценить, находится в некотором ограниченном, известном объёме. Затем мы проецируем гипотетическую трёхмерную точку обратно в откалиброванные камеры и проверяем, согласуются ли эти проекции в нескольких видах. Рисунок 4 иллюстрирует общую схему задачи объёмного стереовидения.&lt;/p&gt;
&lt;p&gt;Поскольку мы предполагаем, что точки, которые мы хотим восстановить, содержатся в ограниченном объёме, этот метод пригоден для восстановления трёхмерных моделей конкретных объектов. Это главное отличие от более общей задачи восстановления моделей сцены, в которой расположение объектов может быть неограниченным.&lt;/p&gt;
&lt;p&gt;Основной принцип любого метода объёмного стереовидения заключается в том, чтобы сначала определить способ для определения согласованности точки, которая проецируется на несколько ракурсов изображений. Известно множество различных методов определения того, что мы будем считать согласованными наблюдениями. Мы кратко опишем три основных метода:&lt;br&gt;
- пространственное вырезание (Space carving),&lt;br&gt;
- теневое вырезание (shadow carving),&lt;br&gt;
- раскраска вокселей (voxel coloring). &lt;/p&gt;
&lt;h5&gt;2.1 Space carving&lt;/h5&gt;
&lt;p&gt;Идея пространственного вырезания (space carving) в основном основана на наблюдении, что контуры объекта предоставляют богатый источник геометрической информации об этом объекте.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 5: Силуэт объекта и визуальный конус" src="https://storage.yandexcloud.net/yahosting/active/5.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 5: Силуэт объекта и визуальный конус&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;В контексте множественных видов сначала рассмотрим задачу, проиллюстрированную на рисунке 5. Каждая камера наблюдает некоторую видимую часть объекта, по которой можно определить контур. При проецировании в плоскость изображения этот контур охватывает набор пикселей, известный как &lt;strong&gt;силуэт объекта&lt;/strong&gt; в плоскости изображения. Пространственное вырезание в конечном итоге использует силуэты объектов с разных видов для обеспечения согласованности.&lt;/p&gt;
&lt;p&gt;Однако если у нас нет информации о трёхмерной сцене, а есть только её изображения, то как мы можем получить информацию о силуэтах? К счастью, одно из практических преимуществ работы с силуэтами заключается в том, что их можно легко обнаружить на изображениях, если мы контролируем фон за объектом, который хотим восстановить. Например, мы можем использовать «зелёный экран» за объектом или использовать специальные алгоритмы отделения объекта от фона.&lt;/p&gt;
&lt;p&gt;Теперь, когда у нас есть силуэты, как мы можем их использовать? Напомним, что в объёмном стереовидении у нас есть оценка некоторого объёма, в котором, как мы гарантируем, может находиться объект. Теперь введём понятие &lt;strong&gt;визуального конуса&lt;/strong&gt; — это охватывающая поверхность, определяемая центром камеры и контуром объекта в плоскости изображения. По построению сцены гарантируется, что объект будет полностью находиться как в начальном объёме, так и в визуальном конусе.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 6: Построение визуальной оболочки" src="https://storage.yandexcloud.net/yahosting/active/6.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 6: Построение визуальной оболочки&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Если у нас есть множество видов с разных ракурсов, мы можем вычислить визуальные конусы для каждого вида. Поскольку, по определению, объект находится в каждом из этих визуальных конусов, он должен лежать в их пересечении, как показано на рисунке 6. Такое пересечение часто называют визуальной оболочкой (visual hull).&lt;/p&gt;
&lt;p&gt;На практике мы сначала начинаем с определения рабочего объёма, в котором, как мы знаем, находится объект. Например, если наши камеры окружают объект, мы можем просто сказать, что рабочий объём — это всё внутреннее пространство, ограниченное камерами. Мы разделяем этот объём на маленькие единицы, известные как воксели, создавая то, что называется воксельной сеткой. Мы берём каждый воксель из воксельной сетки и проецируем его на каждый из видов. Если воксель не содержится в силуэте на каком-либо виде, он отбрасывается. Следовательно, в конце алгоритма пространственного вырезания у нас остаются воксели, содержащиеся внутри визуальной оболочки.&lt;/p&gt;
&lt;p&gt;Хотя метод пространственного вырезания позволяет избежать проблемы соответствий и является относительно простым, у него всё ещё есть множество ограничений. Одно из ограничений пространственного вырезания заключается в том, что он масштабируется линейно с количеством вокселей в сетке. По мере уменьшения размера каждого вокселя, количество вокселей в сетке увеличивается кубически. Поэтому получение более точных результатов реконструкции приводит к значительному увеличению времени обработки. Однако некоторые методы, такие как использование октетных деревьев (octrees), могут помочь решить эту проблему. Продвинутые методы включают выполнение итеративной адаптации для уменьшения размера начальной воксельной сетки в тех областях изображений, где это необходимо.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 7: Воксельная сетка объекта" src="https://storage.yandexcloud.net/yahosting/active/7.jpg"&gt; &lt;/p&gt;
&lt;p&gt;На рисунке 7 показан результат пространственного вырезания при работе с воксельной сеткой. Область представляет собой реконструированный объект после вырезания с использованием двух видов, в то время как затенённая часть внутри — это фактический объект. &lt;/p&gt;
&lt;p&gt;Ограничение метода заключается в том, что эффективность пространственного вырезания зависит от количества видов, точности силуэта и даже формы объекта, который мы пытаемся восстановить. Если количество видов слишком мало, мы получаем очень приблизительную оценку визуальной оболочки объекта. По мере увеличения количества видов можно удалить больше лишних вокселей с помощью проверки согласованности.&lt;/p&gt;
&lt;p&gt;Кроме того, достоверность проверки согласованности поддерживается только тем фактом, что мы считаем силуэты правильными и гладкими. Если силуэт слишком сложен и содержит больше пикселей, чем мы имеем в распоряжении, наша реконструкция может оказаться неточной. В потенциально ещё худшем случае силуэт пропускает части фактического объекта, что приводит к чрезмерному вырезанию при реконструкции.&lt;/p&gt;
&lt;p&gt;Наконец, основным недостатком пространственного вырезания является то, что оно не способно моделировать определённые вогнутости объекта, как показано на рисунке 8.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 8: Недостаток пространственного вырезания при наличии вогнутостей на объекте" src="https://storage.yandexcloud.net/yahosting/active/8.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 8: Недостаток пространственного вырезания при наличии вогнутостей на объекте&lt;/strong&gt;&lt;/p&gt;
&lt;h5&gt;2.2 Shadow carving&lt;/h5&gt;
&lt;p&gt;Чтобы обойти проблему вогнутостей, возникающую при пространственном вырезании, нам нужно обратиться к другим формам проверок согласованности.&lt;/p&gt;
&lt;p&gt;Одним из важных признаков для определения трёхмерной формы объекта является наличие самотеней — теней, которые объект отбрасывает на себя. Для вогнутых объектов характерно то, что они часто отбрасывают самотени в вогнутых областях.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 9: Вырезание с учетом теней" src="https://storage.yandexcloud.net/yahosting/active/9.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 9: Вырезание с учетом теней&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;По своей сути теневое вырезание дополняет пространственное вырезание идеей использования самотеней для более точной оценки вогнутостей. Как показано на рисунке 9, общая установка теневого вырезания очень похожа на пространственное вырезание. Объект помещается на поворотный стол, который просматривается откалиброванной камерой. Однако вокруг камеры располагается массив источников света в известных позициях, состояние которых можно соответствующим образом включать и выключать. Эти источники света будут использоваться для того, чтобы заставить объект отбрасывать самотени.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 10: Источник света как дополнительный инструмент для построения визуальной оболочки" src="https://storage.yandexcloud.net/yahosting/active/10.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 10: Источник света как дополнительный инструмент для построения визуальной оболочки&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Как показано на рисунке 10, процесс теневого вырезания начинается с начальной воксельной сетки, которая обрезается с помощью того же подхода, что и при пространственном вырезании. Однако в каждом виде мы можем включать и выключать каждый источник света в массиве, окружающем камеру. Каждый источник света будет создавать различную самотень на объекте. После определения тени в плоскости изображения мы можем найти воксели на поверхности нашей обрезанной воксельной сетки, которые находятся в визуальном конусе тени. Эти поверхностные воксели позволяют нам затем создать новый визуальный конус с источником изображения. Затем мы используем полезный факт, что воксель, являющийся частью обоих визуальных конусов, не может быть частью объекта, чтобы исключить воксели в вогнутости.&lt;/p&gt;
&lt;p&gt;Как и в случае с пространственным вырезанием, время работы теневого вырезания зависит от разрешения воксельной сетки. Время работы масштабируется кубически с разрешением воксельной сетки. Однако если имеется N источников света, то теневое вырезание занимает примерно в N + 1 раз больше времени, чем пространственное вырезание, поскольку каждый воксель необходимо проецировать в камеру и на каждый из N источников света.&lt;/p&gt;
&lt;p&gt;Подводя итог, теневое вырезание всегда даёт консервативную оценку объёма, которая лучше восстанавливает трёхмерные формы с вогнутостями. Качество результатов зависит как от количества видов, так и от количества источников света. Некоторые недостатки этого подхода заключаются в том, что он не может обрабатывать случаи, когда объект содержит отражающие области или области с низким альбедо. Это связано с тем, что в таких условиях невозможно точно определить тени.&lt;/p&gt;
&lt;h5&gt;2.3 Раскраска вокселей (Voxel coloring)&lt;/h5&gt;
&lt;p&gt;И напоследок рассмотрим еще одну технику объёмного стереовидения — раскраска вокселей. 
Эта техника основана на пространственном вырезании, но для согласованности контуров дополнительно использует согласованность цветов.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 11: Раскраска вокселей" src="https://storage.yandexcloud.net/yahosting/active/11.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 11: Раскраска вокселей&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Предположим, что нам даны изображения объекта с нескольких точек зрения, который мы хотим восстановить (рисунок 11). Для каждого вокселя мы смотрим на его соответствующие проекции на каждом из изображений и сравниваем цвет каждой из этих проекций. Если цвета этих проекций достаточно совпадают, мы отмечаем воксель как часть объекта.&lt;/p&gt;
&lt;p&gt;Одно из преимуществ раскраски вокселей, которого нет в пространственном вырезании, заключается в том, что цвет, связанный с проекциями, может быть перенесён на воксель, что даёт цветную реконструкцию.&lt;/p&gt;
&lt;p&gt;В целом существует множество методов, которые можно использовать для проверки согласованности цветов. Один из примеров — установка порога между сходством цветов проекций. Однако существует критическое предположение для любой используемой проверки согласованности цветов: реконструируемый объект должен быть ламбертовским. Это означает, что воспринимаемая яркость любой части объекта не должна меняться с изменением положения точки обзора или позы.&lt;/p&gt;
&lt;p&gt;Для неламбертовских объектов, например, сделанных из высокоотражающих материалов, легко представить, что проверка согласованности цветов может дать сбой на вокселях, которые фактически являются частью объекта.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 12: Частный случай неоднозначности раскраски вокселей" src="https://storage.yandexcloud.net/yahosting/active/12.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 12: Частный случай неоднозначности раскраски вокселей&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Одним из недостатков простой раскраски вокселей является то, что она даёт решение, которое не обязательно является уникальным (рисунок 12). Поиск истинного, уникального решения усложняет задачу реконструкции с помощью раскраски вокселей.&lt;/p&gt;
&lt;p&gt;Можно устранить неоднозначность в реконструкции, введя ограничение видимости на воксель, которое требует, чтобы воксели проходили в определённом порядке. В частности, мы хотим проходить воксели слой за слоем, начиная с вокселей, расположенных ближе к камерам, а затем переходить к более удалённым вокселям.&lt;/p&gt;
&lt;p&gt;При использовании такого порядка мы выполняем проверку согласованности цветов. Затем проверяем, виден ли воксель как минимум двум камерам, что создаёт наше ограничение видимости. Если воксель не виден как минимум двум камерам, он должен быть закрыт и, следовательно, не является частью объекта.&lt;/p&gt;
&lt;p&gt;Обратите внимание, что наш порядок обработки ближайших вокселей позволяет нам убедиться, что мы сохраняем воксели, которые могут закрывать более поздние обработанные воксели, чтобы обеспечить это ограничение видимости.&lt;/p&gt;
&lt;p&gt;В заключение отметим, что раскраска вокселей имеет преимущество одновременного захвата формы и текстуры объекта. Некоторые из недостатков включают предположение о том, что объект является ламбертовским, и то, что камеры не могут находиться в определённых местах, поскольку воксели должны обрабатываться в определённом порядке из-за ограничения видимости.&lt;/p&gt;
&lt;h4&gt;Резюме&lt;/h4&gt;
&lt;p&gt;Мы рассмотрели современные подходы к решению задачи трёхмерной реконструкции объектов, которые позволяют обойти сложности классического стереовидения, связанные с поиском соответствующих точек на разных изображениях.&lt;/p&gt;
&lt;p&gt;Основное внимание уделяется двум ключевым направлениям. Первое — активное стерео, где вместо второй камеры применяется специальный проектор, создающий определённые узоры на объекте. Этот метод значительно упрощает определение соответствий между точками. В рамках активного стерео описаны различные техники: от проецирования отдельных точек и полос до создания сложных цветных узоров, подобных тем, что используются в датчиках глубины типа Microsoft Kinect. Также рассматривается вариант с применением теневых проекций, который является более экономичным, хотя и менее точным решением.&lt;/p&gt;
&lt;p&gt;Второе направление — объёмное стереовидение, основанное на проверке согласованности проекций точек в ограниченном объёме. Этот подход включает несколько методов реконструкции: пространственное вырезание (space carving), использующее силуэты объекта и воксельные сетки; теневое вырезание (shadow carving), улучшающее реконструкцию вогнутых поверхностей за счёт анализа самотеней; и раскраска вокселей (voxel coloring), позволяющая получать цветные трёхмерные модели благодаря анализу цветовой согласованности.&lt;/p&gt;
&lt;p&gt;Описанные методы обладают рядом преимуществ: они существенно упрощают поиск соответствий между точками, обеспечивают возможность создания детальных трёхмерных моделей и могут применяться в различных условиях съёмки. Однако существуют и определённые ограничения: необходимость тщательной калибровки оборудования, требование ламбертовского характера объектов, значительные временные затраты на обработку данных, а также проблемы при работе с отражающими поверхностями.&lt;/p&gt;</description><category>cs231a</category><guid>https://mldl.ru/posts/active-volumetric/</guid><pubDate>Sat, 04 Oct 2025 11:00:00 GMT</pubDate></item><item><title>Извлечение структуры сцены из движения камеры </title><link>https://mldl.ru/posts/structure-from-motion/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;h3&gt;1. Аффинная структура из движения&lt;/h3&gt;
&lt;p&gt;В конце предыдущего раздела мы затронули интересную тему, как можно использовать более двух проекций сцены, чтобы получить информацию о трёхмерной сцене. Теперь давайте более подробно рассмотрим расширение геометрии двух камер на более общий случай множества камер. Комбинируя наблюдения точек из нескольких видов, мы сможем одновременно определить как трёхмерную структуру сцены, так и параметры камеры — эта задача известна как &lt;strong&gt;структура из движения&lt;/strong&gt; (structure from motion).&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 1: Общая схема структуры из движения" src="https://storage.yandexcloud.net/yahosting/stereo/3.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 1: Общая схема структуры из движения&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Схема для формальной постановки задачи приведена на рисунке 1. Предположим, что у нас есть $m$ камер с матрицами камер $M_i$, которые кодируют как внутренние, так и внешние параметры камер. Пусть $X_j$ — одна из $n$ трёхмерных точек в сцене. Каждая трёхмерная точка может быть видна в нескольких камерах в позиции $x_{ij}$, которая является проекцией $X_j$ на изображение камеры $i$ с помощью проективного преобразования $M_i$.&lt;/p&gt;
&lt;p&gt;Цель оценки &lt;strong&gt;структуры из движения&lt;/strong&gt; - восстановление как структуры сцены (то есть $n$ трёхмерных точек $X_j$), так и движения камер (то есть $m$ проективных матриц $M_i$) из всех наблюдений $x_{ij}$.&lt;/p&gt;
&lt;p&gt;Основные данные этой системы включают в себя:&lt;br&gt;
- &lt;strong&gt;Структура сцены&lt;/strong&gt;: набор трёхмерных точек $X_j$, которые составляют геометрию сцены.&lt;br&gt;
- &lt;strong&gt;Движение камер&lt;/strong&gt;: параметры проективных матриц $M_i$, описывающие положение и ориентацию каждой камеры.&lt;br&gt;
- &lt;strong&gt;Наблюдения&lt;/strong&gt;: множество проекций $x_{ij}$, показывающих, где трёхмерные точки видны на изображениях разных камер.  &lt;/p&gt;
&lt;p&gt;Таким образом, задача структуры из движения заключается в одновременном восстановлении трёхмерной геометрии сцены и параметров движения камер на основе множества двумерных наблюдений. Это фундаментальная задача в компьютерном зрении и трёхмерной реконструкции.&lt;/p&gt;
&lt;p&gt;Прежде чем решать общую задачу структуры из движения, мы начнем с более простой задачи, которая предполагает, что камеры являются аффинными или слабоперспективными. В конечном итоге отсутствие операции перспективного масштабирования упрощает математическое выведение для этой задачи.&lt;/p&gt;
&lt;p&gt;Ранее мы вывели приведенные уравнения для случаев перспективы и слабой перспективы. 
Вспомним, что в полной перспективной модели матрица камеры определяется как:&lt;/p&gt;
&lt;p&gt;$M = \begin{bmatrix} A &amp;amp; b \\ v &amp;amp; 1 \end{bmatrix}$ (1)&lt;/p&gt;
&lt;p&gt;где $v$ — некоторый ненулевой вектор размером $1 \times 3$. 
С другой стороны, для модели слабой перспективы $v = 0$. Мы обнаруживаем, что это свойство делает однородную координату $MX$ равной 1:&lt;/p&gt;
&lt;p&gt;$x = MX = \begin{bmatrix} m_1 \\ m_2 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix} \begin{bmatrix} X_1 \\ X_2 \\ X_3 \\ 1 \end{bmatrix} = \begin{bmatrix} m_1X \\ m_2X \\ 1 \end{bmatrix}$ (2)&lt;/p&gt;
&lt;p&gt;Следовательно, при переходе от однородных к евклидовым координатам нелинейность проективного преобразования исчезает, и преобразование слабой перспективы действует как простой увеличитель. Мы можем представить проекцию в более компактной форме:&lt;/p&gt;
&lt;p&gt;$ M_{affine} = \begin{bmatrix} m_1X \\ m_2X \end{bmatrix} = [A \ b]X = AX + b$ (3)&lt;/p&gt;
&lt;p&gt;Таким образом, теперь мы используем аффинную модель камеры для выражения связи между точкой $X_j$ в 3D и соответствующими наблюдениями в каждой аффинной камере (например, $x_{ij}$ в камере $i$).&lt;/p&gt;
&lt;p&gt;Возвращаясь к задаче структуры из движения, нам нужно оценить $m$ матриц $M_i$ и $n$ векторов мировых координат $X_j$. 
Такая система содержит всего $8m + 3n$ неизвестных, на основе $mn$ наблюдений. Каждое наблюдение создает 2 ограничения на камеру, поэтому имеется $2mn$ уравнений с $8m + 3n$ неизвестными.&lt;/p&gt;
&lt;p&gt;Мы можем использовать это уравнение, чтобы определить нижнюю границу количества соответствующих наблюдений в каждом из изображений, которые нам необходимы. Например, если у нас есть $m = 2$ камеры, то нам нужно иметь как минимум $n = 16$ точек в 3D. Однако как решить эту задачу, когда у нас достаточно соответствующих точек, помеченных на каждом изображении? &lt;/p&gt;
&lt;h3&gt;2 Метод факторизации Томаси и Канеде&lt;/h3&gt;
&lt;p&gt;В этой части мы рассмотрим метод факторизации Томаси и Канеде для решения задачи аффинной структуры из движения. Этот метод состоит из двух основных этапов:  центрирования данных и собственно факторизации.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 2: Центроид наблюдаемых точек" src="https://storage.yandexcloud.net/yahosting/stereo/4.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 2: Центроид наблюдаемых точек&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;На рисунке 2 приведен пример центрирования - все точки изображения размещаются таким образом, чтобы их центроид находился в начале координат в плоскости изображения. Аналогично мы размещаем систему мировых координат так, чтобы начало координат находилось в центроиде 3D точек.
Основная идея этого этапа — центрирование данных в начале координат. Для этого для каждого изображения $i$ мы переопределяем новые координаты $\hat{x}&lt;em ij&gt;{ij}$ для каждой точки изображения $x&lt;/em&gt;_i$:}$, вычитая их центроид $\bar{x&lt;/p&gt;
&lt;p&gt;$\hat{x}&lt;em ij&gt;{ij} = x&lt;/em&gt;} - \bar{x&lt;em ij&gt;i = x&lt;/em&gt;$ (4)} - \frac{1}{n} \sum_{j=1}^{n} x_{ij&lt;/p&gt;
&lt;p&gt;Напомним, что задача аффинной структуры из движения позволяет нам определить взаимосвязь между точками изображения $x_{ij}$, переменными матрицы камеры $A_i$ и $b_i$, и 3D точками $X_j$ как:&lt;/p&gt;
&lt;p&gt;$x_{ij} = A_i X_j + b_i$ (5)&lt;/p&gt;
&lt;p&gt;После этапа центрирования мы можем объединить определение центрированных точек изображения $\hat{x}_{ij}$ из уравнения (4) и аффинное выражение из уравнения (5):&lt;/p&gt;
&lt;p&gt;$\hat{x}&lt;em ij&gt;{ij} = x&lt;/em&gt; = $} - \frac{1}{n} \sum_{k=1}^{n} x_{ik&lt;br&gt;
$= A_i X_j - \frac{1}{n} \sum_{k=1}^{n} A_i X_k = A_i(X_j - \frac{1}{n} \sum_{k=1}^{n} X_k) = $&lt;br&gt;
$ = A_i(X_j - \bar{X}) = A_i \hat{X}_j$ (6)&lt;/p&gt;
&lt;p&gt;Как видно из уравнения (6), если мы переместим начало системы мировых координат в центроид $\bar{X}$, то центрированные координаты точек изображения $\hat{x}_{ij}$ и центрированные координаты 3D точек $\hat{X}_j$ связаны только одной матрицей $2 \times 3$ $A_i$. В конечном итоге этап центрирования метода факторизации позволяет нам создать компактное матричное произведение для связи 3D структуры с наблюдаемыми точками на множестве изображений.&lt;/p&gt;
&lt;p&gt;Однако заметим, что в матричном произведении $\hat{x}&lt;em ij&gt;{ij} = A_i \hat{X}_j$ у нас есть доступ только к значениям в левой части уравнения. Таким образом, нам нужно каким-то образом выделить матрицы движения $A_i$ и структуру $X_j$. Используя все наблюдения для всех камер, мы можем построить матрицу измерений $D$, состоящую из $n$ наблюдений в $m$ камерах (помните, что каждая запись $\hat{x}&lt;/em&gt;$ — это вектор $2 \times 1$):&lt;/p&gt;
&lt;p&gt;$D = \begin{bmatrix} \hat{x}&lt;em 12&gt;{11} &amp;amp; \hat{x}&lt;/em&gt;} &amp;amp; \dots &amp;amp; \hat{x&lt;em 21&gt;{1n} \\ \hat{x}&lt;/em&gt;} &amp;amp; \hat{x&lt;em 2n&gt;{22} &amp;amp; \dots &amp;amp; \hat{x}&lt;/em&gt;} \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ \hat{x&lt;em m2&gt;{m1} &amp;amp; \hat{x}&lt;/em&gt;$ (7)} &amp;amp; \dots &amp;amp; \hat{x}_{mn} \end{bmatrix&lt;/p&gt;
&lt;p&gt;Теперь вспомним, что из-за нашего аффинного предположения, $D$ может быть выражена как произведение матрицы движения $2m \times 3$ $M$ (которая включает матрицы камер $A_1, \dots, A_m$) и матрицы структуры $3 \times n$ $S$ (которая включает 3D точки $X_1, \dots, X_n$). Важный факт, который мы будем использовать, заключается в том, что $rank(D) = 3$, поскольку $D$ — это произведение двух матриц, максимальное измерение которых равно 3.&lt;/p&gt;
&lt;p&gt;Чтобы разложить $D$ на $M$ и $S$, мы будем использовать сингулярное разложение:&lt;/p&gt;
&lt;p&gt;$D = U\Sigma V^T = \begin{bmatrix} u_1 &amp;amp; \dots &amp;amp; u_n \end{bmatrix} \begin{bmatrix} \sigma_1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \dots &amp;amp; 0 \\ 0 &amp;amp; \sigma_2 &amp;amp; 0 &amp;amp; 0 &amp;amp; \dots &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \sigma_3 &amp;amp; 0 &amp;amp; \dots &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \dots &amp;amp; 0 \\ \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \dots &amp;amp; 0 \end{bmatrix} \begin{bmatrix} v_1^T \\ \vdots \\ v_n^T \end{bmatrix} = $  &lt;/p&gt;
&lt;p&gt;$ = \begin{bmatrix} u_1 &amp;amp; u_2 &amp;amp; u_3 \end{bmatrix} \begin{bmatrix} \sigma_1 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \sigma_2 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \sigma_3 \end{bmatrix} \begin{bmatrix} v_1^T \\ v_2^T \\ v_3^T \end{bmatrix} = U_3\Sigma_3V_3^T$ (8)&lt;/p&gt;
&lt;p&gt;В этом разложении $\Sigma_3$ определяется как диагональная матрица, образованная ненулевыми сингулярными значениями, в то время как $U_3$ и $V_3^T$ получаются путем взятия соответствующих трех столбцов матрицы $U$ и строк матрицы $V^T$ соответственно.&lt;/p&gt;
&lt;p&gt;К сожалению, на практике $rank(D) &amp;gt; 3$ из-за шума измерений и аффинного приближения камеры. Однако мы помним замечательное свойство сингулярного разложения, что когда $rank(D) &amp;gt; 3$, $U_3W_3V_3^T$ все еще остается наилучшим возможным приближением ранга 3 для $MS$ в смысле нормы Фробениуса.&lt;/p&gt;
&lt;p&gt;При внимательном рассмотрении мы видим, что матричное произведение $\Sigma_3V_3^T$ образует матрицу размером $3 \times n$, что точно соответствует размеру матрицы структуры $S$. Аналогично, $U_3$ — это матрица размером $2m \times 3$, что соответствует размеру матрицы движения $M$.&lt;/p&gt;
&lt;p&gt;Хотя такой способ сопоставления компонентов SVD-разложения с $M$ и $S$ приводит к физически и геометрически правдоподобному решению задачи аффинной структуры из движения, этот выбор не является единственным решением. 
Например, мы также могли бы установить матрицу движения как $M = U_3\Sigma_3$, а матрицу структуры как $S = V_3^T$, поскольку в обоих случаях матрица наблюдений $D$ остается той же.&lt;/p&gt;
&lt;p&gt;Так какое разложение выбрать? В своей работе Томаси и Канеде пришли к выводу, что наиболее надежным выбором факторизации является $M = U_3\sqrt{\Sigma_3}$ и $S = \sqrt{\Sigma_3}V_3^T$. &lt;/p&gt;
&lt;p&gt;Тем не менее, мы обнаруживаем внутреннюю неоднозначность в любом выборе факторизации $D = MS$, поскольку в разложение можно вставить любую произвольную обратимую матрицу $3 \times 3$ $A$:&lt;/p&gt;
&lt;p&gt;$D = MA A^{-1}S = (MA)(A^{-1}S)$ (9)&lt;/p&gt;
&lt;p&gt;Это означает, что матрицы камер, полученные из движения $M$, и 3D точки, полученные из структуры $S$, определяются с точностью до умножения на общую матрицу $A$. Следовательно, наше решение недоопределено и требует дополнительных ограничений для разрешения этой аффинной неоднозначности. Несмотря на то, что параллельность линий сохраняется, метрический масштаб элементов матрицы и координат точек остаются неизвестными. &lt;/p&gt;
&lt;p&gt;Другой важный класс неоднозначностей для реконструкции — это неоднозначность подобия, которая возникает, когда реконструкция верна с точностью до преобразования подобия (вращение, перенос и масштабирование). Реконструкция только с неоднозначностью подобия известна как метрическая реконструкция. Эта неоднозначность существует даже при внутренней калибровке камер. Хорошая новость заключается в том, что для откалиброванных камер неоднозначность подобия является единственной возможной неоднозначностью.&lt;/p&gt;
&lt;p&gt;Тот факт, что невозможно восстановить абсолютный масштаб сцены по изображениям, довольно интуитивен. 
Масштаб объекта, абсолютное положение и каноническая ориентация всегда будут неизвестны, если мы не сделаем дополнительные предположения (например, знаем высоту дома на рисунке) или не включим дополнительные данные о матрице переноса. 
Это происходит потому, что одни атрибуты могут компенсировать другие. Например, чтобы получить то же изображение, мы можем просто отодвинуть объект назад и соответствующим образом масштабировать его.&lt;/p&gt;
&lt;p&gt;Один из примеров устранения неоднозначности подобия возник во время процедуры калибровки камеры, когда мы сделали предположение, что знаем расположение калибровочных точек относительно мировой системы координат. Это позволило нам узнать размер квадратов шахматной доски для определения метрического масштаба 3D структуры. &lt;/p&gt;
&lt;h3&gt;3. Структура из движения с перспективными преобразованиями камер (метод разложения)&lt;/h3&gt;
&lt;p&gt;После изучения упрощённой задачи аффинной структуры из движения давайте рассмотрим общий случай для проективных камер $M_i$.&lt;/p&gt;
&lt;p&gt;В общем случае с проективными камерами каждая матрица камеры $M_i$ содержит 11 степеней свободы, поскольку она определена с точностью до масштабного множителя:&lt;/p&gt;
&lt;p&gt;$M_i = \begin{bmatrix} a_{11} &amp;amp; a_{12} &amp;amp; a_{13} &amp;amp; b_1 \\ a_{21} &amp;amp; a_{22} &amp;amp; a_{23} &amp;amp; b_2 \\ a_{31} &amp;amp; a_{32} &amp;amp; a_{33} &amp;amp; 1 \end{bmatrix}$ (10)&lt;/p&gt;
&lt;p&gt;Более того, в общем случае решения определение матриц структуры из движения могут быть определены с точностью до проективного преобразования, как и при афинной неоднозначности. Мы всегда можем произвольно применить проективное преобразование $4 \times 4$ $H$ к матрице движения, при условии, что мы также преобразуем матрицу структуры с помощью обратного преобразования $H^{-1}$. Результирующие наблюдения в плоскости изображения останутся прежними.&lt;/p&gt;
&lt;p&gt;Аналогично аффинному случаю, мы можем сформулировать общую задачу структуры из движения как оценку как $m$ матриц движения $M_i$, так и $n$ 3D точек $X_j$ на основе $mn$ наблюдений $x_{ij}$. Поскольку камеры и точки могут быть восстановлены только с точностью до проективного преобразования $4 \times 4$ с учётом масштаба (15 параметров), у нас есть $11m + 3n - 15$ неизвестных в $2mn$ уравнениях.&lt;/p&gt;
&lt;p&gt;Из этих фактов мы можем определить необходимое количество видов и наблюдений, требуемых для решения неизвестных. &lt;/p&gt;
&lt;h3&gt;4. Алгебраический подход к SFM с перспективой&lt;/h3&gt;
&lt;p&gt;Теперь рассмотрим алгебраический подход, который использует концепцию фундаментальной матрицы $F$ для решения задачи оценки структуры из движения для двух камер.
В отличии от метода разложения, в алгебраическом подходе мы рассматриваем последовательные пары камер для определения матриц камер $M_1$ и $M_2$ с точностью до перспективного преобразования. Затем мы находим перспективное преобразование $H$ такое, что $M_1H = [I \ 0]$ и $M_2H = [A \ B]$.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 3: Алгебраический подход к оценке структуры из движения" src="https://storage.yandexcloud.net/yahosting/stereo/5.jpg"&gt; &lt;/p&gt;
&lt;p&gt;Как показано на рисунке 3, основная идея алгебраического подхода заключается в вычислении двух матриц камер $M_1$ и $M_2$, которые могут быть вычислены только с точностью до перспективного преобразования $H$.&lt;/p&gt;
&lt;p&gt;Поскольку каждая $M_i$ может быть вычислена только с точностью до перспективного преобразования $H$, мы всегда можем рассмотреть такое $H$, при котором матрица проекции первой камеры $M_1H^{-1}$ будет канонической. Разумеется, то же преобразование должно быть применено и ко второй камере, что приводит к следующей форме:&lt;/p&gt;
&lt;p&gt;$M_1H^{-1} = [I \ 0]$&lt;br&gt;
$M_2H^{-1} = [A \ b]$ (11)&lt;/p&gt;
&lt;p&gt;Для выполнения этой задачи сначала необходимо вычислить фундаментальную матрицу $F$ с помощью алгоритма восьми точек. 
Далее матрица $F$ используется для оценки проективных матриц камер $M_1$ и $M_2$.&lt;/p&gt;
&lt;p&gt;Для этой оценки определим 3D точку $P$ и соответствующие наблюдения на изображениях $p$ и $p'$. 
Поскольку мы применили $H^{-1}$ к обеим матрицам проекции камер, мы также должны применить $H$ к структуре, получая $P_e = HP$.&lt;br&gt;
Таким образом, мы можем связать координаты пикселей $p$ и $p'$ с преобразованной структурой следующим образом:  &lt;/p&gt;
&lt;p&gt;$p = M_1P = M_1H^{-1}HP = [I \ 0]P_e$&lt;br&gt;
$p' = M_2P = M_2H^{-1}HP = [A \ b]P_e$ (12)&lt;/p&gt;
&lt;p&gt;Интересное свойство между двумя соответствиями изображений $p$ и $p'$ возникает при подстановках:&lt;/p&gt;
&lt;p&gt;$p' = [A \ b] P_e =$&lt;br&gt;
$= A[I \ 0] P_e + b =$  &lt;br&gt;
$= Ap + b$ (13)&lt;/p&gt;
&lt;p&gt;Используя уравнение (13), мы можем записать векторное произведение между $p'$ и $b$ как:&lt;/p&gt;
&lt;p&gt;$p' \times b = (Ap + b) \times b = Ap \times b$ (14)&lt;/p&gt;
&lt;p&gt;По определению векторного произведения, $p' \times b$ перпендикулярен $p'$. Поэтому мы можем записать:&lt;/p&gt;
&lt;p&gt;$0 = p'^T(p' \times b) = p'^T(Ap \times b) = p'^T \cdot (b \times Ap) = p'^T[b\times] Ap$ (15)&lt;/p&gt;
&lt;p&gt;Рассматрев это ограничение более внимательно, можно увидеть, что оно напоминает общее определение фундаментальной матрицы&lt;br&gt;
$p'^TFp = 0$  &lt;/p&gt;
&lt;p&gt;Если мы установим $F = [b\times] A$, то извлечение $A$ и $b$ снова сводится к задаче разложения.&lt;/p&gt;
&lt;p&gt;Давайте начнем с определения $b$. Снова используя определение векторного произведения, мы можем записать:&lt;/p&gt;
&lt;p&gt;$F^\top b = [[b\times] A]^\top b = 0$ (16) &lt;/p&gt;
&lt;p&gt;Поскольку матрица $F$ является сингулярной, вектор $b$ можно вычислить как решение методом наименьших квадратов уравнения $F^\top b = 0$ при условии $|b| = 1$ с помощью сингулярного разложения (SVD).&lt;/p&gt;
&lt;p&gt;Как только вектор $b$ становится известным, мы можем вычислить матрицу $A$. Если мы положим $A = −[b\times] F$, то можем проверить, что это определение удовлетворяет условию $F = [b\times] A$:&lt;/p&gt;
&lt;p&gt;$[b\times] A' = −[b\times][b\times] F$
$= (bb^\top − |b|^2I)F$
$= bb^\top F + |b|^2F$
$= 0 + 1 · F$
$= F$ (17)&lt;/p&gt;
&lt;p&gt;Следовательно, мы определяем два выражения для матриц наших камер $M_1H^{−1}$ и $M_2H^{−1}$:&lt;/p&gt;
&lt;p&gt;$\tilde{M}_1 = [I \ 0]$
$\tilde{M}_2 = [−[b\times] F \ b]$ (18)&lt;/p&gt;
&lt;p&gt;Прежде чем завершить этот раздел, мы хотим дать геометрическую интерпретацию для вектора $b$. Мы знаем, что $b$ удовлетворяет условию $Fb = 0$. Вспомним эпиполярные ограничения, которые мы вывели в предыдущих конспектах, где было показано, что эпиполы на изображении — это точки, которые отображаются в ноль при преобразовании фундаментальной матрицей (то есть $Fe_2 = 0$ и $F^\top e_1 = 0$). Таким образом, мы видим, что $b$ является эпиполом. Это даёт нам новый набор уравнений для матриц проекции камер (формулы 4.10):&lt;/p&gt;
&lt;p&gt;$\tilde{M}_1 = [I \ 0]$
$\tilde{M}_2 = [−[e\times] F \ e]$ (19) &lt;/p&gt;</description><category>cs231a</category><guid>https://mldl.ru/posts/structure-from-motion/</guid><pubDate>Sat, 04 Oct 2025 07:00:00 GMT</pubDate></item><item><title>Стерео системы </title><link>https://mldl.ru/posts/stereo-systems/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;p&gt;В предыдущих заметках мы рассмотрели, как с помощью ключевых точек можно значительно улучшить наше понимание -сцены. Мы сосредоточились на настройке &lt;strong&gt;эполярной геометрии&lt;/strong&gt;, чтобы связать точки одной плоскости изображения с точками другой без извлечения какой-либо информации о трёхмерной сцене. В этой заметке мы обсудим, как восстановить информацию о трёхмерной сцене из нескольких двумерных изображений.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 1: Триангуляция точки Р по двум изображениям" src="https://storage.yandexcloud.net/yahosting/stereo/1.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 1: Триангуляция точки Р по двум изображениям&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Одной из фундаментальных задач в геометрии множественных видов является задача &lt;strong&gt;триангуляции&lt;/strong&gt; — процесс определения местоположения трёхмерной точки по её проекциям на два или более изображений. В задаче триангуляции с двумя видами у нас есть две камеры с известными внутренними параметрами камеры $K$ и $K'$ соответственно. Нам также известны относительные ориентации и смещения $R$, $T$ этих камер относительно друг друга.&lt;/p&gt;
&lt;p&gt;Предположим, что у нас есть точка $P$ в трёхмерном пространстве, которая может быть найдена на изображениях двух камер в точках $p$ и $p'$ соответственно. Хотя местоположение $P$ в данный момент неизвестно, мы можем измерить точные местоположения $p$ и $p'$ на изображении. Поскольку $K$, $K'$, $R$, $T$ известны, мы можем вычислить две линии визирования $ℓ$ и $ℓ'$, которые определяются центрами камер $O_1$, $O_2$ и местоположениями изображений $p$, $p'$. Следовательно, $P$ может быть вычислена как точка пересечения $ℓ$ и $ℓ'$.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 2: Ошибки в проекции точки" src="https://storage.yandexcloud.net/yahosting/stereo/2.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 2: Ошибки в проекции точки&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Хотя этот процесс кажется простым и математически обоснованным, на практике он работает не очень хорошо. В реальном мире из-за того, что наблюдения $p$ и $p'$ зашумлены, а параметры калибровки камеры не являются точными, поиск точки пересечения прямых $ℓ$ и $ℓ'$ может быть проблематичным. В большинстве случаев она вообще не существует, поскольку эти две прямые могут не пересекаться.&lt;/p&gt;
&lt;h4&gt;1. Линейный метод триангуляции&lt;/h4&gt;
&lt;p&gt;В этом разделе мы описываем простой линейный метод триангуляции, который решает проблему отсутствия точки пересечения между лучами. Нам даны две точки на изображениях, которые соответствуют друг другу:&lt;br&gt;
$p = MP = (x, y, 1)$&lt;br&gt;
$p' = M'P = (x', y', 1)$   &lt;/p&gt;
&lt;p&gt;Вспомним, что векторное произведение двух векторов в трехмерном пространстве дает вектор, перпендикулярный обоим исходным векторам.&lt;/p&gt;
&lt;p&gt;В нашем случае:
* $p = (x, y, 1)$ — это точка на плоскости изображения
* $MP$ — это результат умножения матрицы камеры $M$ на координаты 3D точки $P$&lt;/p&gt;
&lt;p&gt;Векторы $p$ и $MP$ коллинеарны (лежат на одной прямой или параллельны), а значит  $p \times (MP) = 0$&lt;/p&gt;
&lt;p&gt;Развернем это векторное произведение в координатной форме:&lt;/p&gt;
&lt;p&gt;$p \times (MP) = \begin{vmatrix}
i &amp;amp; j &amp;amp; k \\
x &amp;amp; y &amp;amp; 1 \\
M_1P &amp;amp; M_2P &amp;amp; M_3P
\end{vmatrix} = 0$&lt;/p&gt;
&lt;p&gt;Раскрывая определитель, получаем:&lt;/p&gt;
&lt;p&gt;$p \times (MP) = i(yM_3P - M_2P) - j(xM_3P - M_1P) + k(xM_2P - yM_1P) = 0$&lt;/p&gt;
&lt;p&gt;Это векторное равенство равно нулю тогда и только тогда, когда каждая его компонента равна нулю:&lt;/p&gt;
&lt;p&gt;$x(M_3P) − (M_1P) = 0$&lt;br&gt;
$y(M_3P) − (M_2P) = 0$&lt;br&gt;
$x(M_2P) − y(M_1P) = 0$ (1)  &lt;/p&gt;
&lt;p&gt;где $M_i$ — это $i$-я строка матрицы $M$.  &lt;/p&gt;
&lt;p&gt;Подобные ограничения можно сформулировать для $p'$ и $M'$. Используя ограничения обоих изображений, мы можем сформулировать линейное уравнение вида&lt;br&gt;
$AP = 0$, где  &lt;/p&gt;
&lt;p&gt;$A = \begin{bmatrix}
xM_3 − M_1 \\
yM_3 − M_2 \\
x'M'_3 − M'_1 \\
y'M'_3 − M'_2
\end{bmatrix}$ (2)&lt;/p&gt;
&lt;p&gt;Это уравнение можно решить с помощью сингулярного разложения (SVD), чтобы найти наилучшую линейную оценку точки $P$. &lt;/p&gt;
&lt;p&gt;Другой интересный аспект этого метода заключается в том, что он фактически может обрабатывать триангуляцию из нескольких видов. Для этого нужно просто добавить дополнительные строки к матрице $A$, соответствующие новым ограничениям от дополнительных видов.&lt;/p&gt;
&lt;p&gt;Однако этот метод не подходит для проективной реконструкции.&lt;br&gt;
Основная причина - особенность разложения методом SVD, которое решается при ограничении $∥P∥ = 1$. 
Ограничение $|P| = 1$ означает, что вектор $P$ нормирован, то есть его длина равна единице. Однако при проективных преобразованиях это свойство не сохраняется, так как такие преобразования изменяют длины векторов. 
Другими словами, сингулярное разложение не является инвариантным относительно проективного преобразования $H$.
Например, предположим, что мы заменяем матрицы камер $M$ и $M'$ на матрицы, подвергнутые проективному преобразованию $MH^{-1}$ и $M'H^{-1}$. Тогда матрица линейных уравнений $A$ становится равной $AH^{-1}$. Следовательно, решение $P$ для предыдущей оценки $AP = 0$ будет соответствовать решению $HP$ для преобразованной задачи $(AH^{-1})(HP) = 0$.&lt;/p&gt;
&lt;p&gt;Поэтому линейный метод триангуляции вычислительно простой, но часто не является оптимальным решением задачи триангуляции.&lt;/p&gt;
&lt;h4&gt;2. Нелинейный метод триангуляции&lt;/h4&gt;
&lt;p&gt;Вместо этого задача триангуляции для реальных сценариев часто математически характеризуется как решение задачи минимизации:&lt;/p&gt;
&lt;p&gt;$\min_{\hat{P}} |M\hat{P} - p|^2 + |M'\hat{P} - p'|^2$ (3)&lt;/p&gt;
&lt;p&gt;В приведенном уравнении мы стремимся найти точку $\hat{P}$ в 3D пространстве, которая наилучшим образом аппроксимирует $P$, путем нахождения наилучшей оценки методом наименьших квадратов для ошибки репроекции $\hat{P}$ на обоих изображениях.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ошибка репроекции&lt;/strong&gt; для 3D точки на изображении — это расстояние между проекцией этой точки на изображении и соответствующей наблюдаемой точкой в плоскости изображения. В случае нашего примера на рисунке 2, поскольку $M$ — это проективное преобразование из 3D пространства в изображение 1, проецируемая точка $\hat{P}$ на изображении 1 равна $M\hat{P}$. Соответствующее наблюдение точки $\hat{P}$ на изображении 1 — это $p$. Таким образом, ошибка репроекции для точки $P$ на изображении 1 равна расстоянию $|M\hat{P} - p|$.&lt;/p&gt;
&lt;p&gt;Общая ошибка репроекции, найденная в уравнении (3), представляет собой сумму ошибок репроекции для всех точек на изображении. В случае более чем двух изображений мы просто добавим дополнительные члены расстояния в целевую функцию:&lt;/p&gt;
&lt;p&gt;$\min_{\hat{P}} \sum_i |M\hat{P}_i - p_i|^2$ (4)&lt;/p&gt;
&lt;p&gt;На практике существует множество очень сложных методов оптимизации, которые дают хорошие приближения к решению задачи. Однако в рамках курса мы сосредоточимся только на одном из этих методов — алгоритме Гаусса-Ньютона для нелинейных наименьших квадратов.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Общая задача нелинейных наименьших квадратов&lt;/strong&gt; заключается в нахождении $x \in \mathbb{R}^n$, который минимизирует:&lt;/p&gt;
&lt;p&gt;$|r(x)|^2 = \sum_{i=1}^m r_i(x)^2$ (5)&lt;/p&gt;
&lt;p&gt;где $r$ — любая остаточная функция $r: \mathbb{R}^n \rightarrow \mathbb{R}^m$ такая, что $r(x) = f(x) - y$ для некоторой функции $f$, входных данных $x$ и наблюдения $y$. Задача нелинейных наименьших квадратов сводится к обычной линейной задаче наименьших квадратов, когда функция $f$ линейна. Однако помните, что в общем случае наши матрицы камер не являются аффинными.&lt;/p&gt;
&lt;p&gt;Если мы обозначим $e_i$ как вектор $2 \times 1$, $e_i = M\hat{P}_i - p_i$, то мы можем переформулировать нашу задачу оптимизации следующим образом:&lt;/p&gt;
&lt;p&gt;$\min_{\hat{P}} \sum_i e_i(\hat{P})^2$ (6)&lt;/p&gt;
&lt;p&gt;что может быть идеально представлено как задача нелинейных наименьших квадратов.&lt;/p&gt;
&lt;p&gt;В этих заметках мы рассмотрим, как можно использовать популярный алгоритм Гаусса-Ньютона для нахождения приближенного решения этой задачи нелинейных наименьших квадратов. Сначала предположим, что у нас есть достаточно разумная оценка 3D точки $\hat{P}$, которую мы можем вычислить с помощью предыдущего линейного метода.&lt;/p&gt;
&lt;p&gt;Ключевая идея алгоритма Гаусса-Ньютона заключается в обновлении нашей оценки путем корректировки её в направлении еще лучшей оценки, которая минимизирует ошибку репроекции. На каждом шаге мы хотим обновить нашу оценку $\hat{P}$ на некоторую величину $\delta P$: $\hat{P} = \hat{P} + \delta P$. &lt;/p&gt;
&lt;p&gt;Как выбрать параметр обновления δP?
Ключевая идея алгоритма Гаусса-Ньютона заключается в линеаризации остаточной функции вблизи текущей оценки $\hat{P}$. В нашем случае это означает, что остаточная ошибка $e$ точки $P$ может быть представлена как:&lt;/p&gt;
&lt;p&gt;$e(\hat{P} + \delta P) \approx e(\hat{P}) + \frac{\partial e}{\partial P} \delta P$ (7)&lt;/p&gt;
&lt;p&gt;После этого задача минимизации преобразуется в:&lt;/p&gt;
&lt;p&gt;$\min_{\delta P} \left| \frac{\partial e}{\partial P} \delta P - (-e(\hat{P})) \right|^2$ (8)&lt;/p&gt;
&lt;p&gt;Когда мы формулируем остаточную функцию таким образом, становится видно, что она принимает формат стандартной задачи линейных наименьших квадратов. Для задачи триангуляции с $N$ изображениями решение линейных наименьших квадратов имеет вид:&lt;/p&gt;
&lt;p&gt;$\delta P = -(J^TJ)^{-1}J^Te$ (9)&lt;/p&gt;
&lt;p&gt;где:&lt;/p&gt;
&lt;p&gt;$e = \begin{bmatrix} e_1 \\ \vdots \\ e_N \end{bmatrix} = \begin{bmatrix} p_1 - M_1\hat{P} \\ \vdots \\ p_n - M_n\hat{P} \end{bmatrix}$ (10)&lt;/p&gt;
&lt;p&gt;и&lt;/p&gt;
&lt;p&gt;$J = \begin{bmatrix} \frac{\partial e_1}{\partial \hat{P}_1} &amp;amp; \frac{\partial e_1}{\partial \hat{P}_2} &amp;amp; \frac{\partial e_1}{\partial \hat{P}_3} \\ \vdots &amp;amp; \vdots &amp;amp; \vdots \\ \frac{\partial e_N}{\partial \hat{P}_1} &amp;amp; \frac{\partial e_N}{\partial \hat{P}_2} &amp;amp; \frac{\partial e_N}{\partial \hat{P}_3} \end{bmatrix}$ (11)&lt;/p&gt;
&lt;p&gt;Важно отметить, что вектор остаточной ошибки для конкретного изображения $e_i$ является вектором размера $2 \times 1$, поскольку в плоскости изображения есть два измерения. Следовательно, в простейшем случае с двумя камерами ($N = 2$) вектор остаточной ошибки $e$ будет иметь размер $2N \times 1 = 4 \times 1$, а матрица Якоби $J$ — размер $2N \times 3 = 4 \times 3$.&lt;/p&gt;
&lt;p&gt;Этот метод легко обрабатывает множественные виды, так как дополнительные изображения учитываются путем добавления соответствующих строк к вектору $e$ и матрице $J$. После вычисления обновления $\delta P$ мы можем просто повторить процесс фиксированное количество шагов или до численной сходимости.&lt;/p&gt;
&lt;p&gt;Важное свойство алгоритма Гаусса-Ньютона заключается в том, что наше предположение о линейности остаточной функции вблизи оценки не гарантирует сходимость. Поэтому на практике всегда полезно установить верхнюю границу количества обновлений оценки.&lt;/p&gt;
&lt;h4&gt;Резюме&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Триангуляция&lt;/strong&gt; представляет собой фундаментальный процесс определения местоположения трёхмерной точки по её проекциям на два или более изображений. В основе этого метода лежит работа с двумя камерами, для которых известны внутренние параметры $K$ и $K'$, а также их относительные ориентации и смещения $R$ и $T$.&lt;/p&gt;
&lt;p&gt;При наличии трёхмерной точки $P$, которая проецируется на изображения в точках $p$ и $p'$, задача сводится к вычислению линий визирования $\ell$ и $\ell'$, определяемых центрами камер $O_1$ и $O_2$. В идеальном случае точка $P$ находится в точке пересечения этих линий. Однако на практике из-за шума в измерениях и неточностей калибровки камер точное пересечение линий может отсутствовать.&lt;/p&gt;
&lt;p&gt;Существует два основных подхода к решению задачи триангуляции.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Линейный метод&lt;/strong&gt; основан на использовании векторного произведения для формирования системы линейных уравнений вида $AP = 0$, которая решается с помощью сингулярного разложения (SVD). Несмотря на вычислительную простоту, этот метод имеет существенные ограничения, главным из которых является невозможность корректной работы с проективными преобразованиями.&lt;/p&gt;
&lt;p&gt;Более эффективным является &lt;strong&gt;нелинейный метод триангуляции&lt;/strong&gt;, который формулирует задачу как минимизацию ошибки репроекции. Основная идея заключается в поиске такой трёхмерной точки $\hat{P}$, которая обеспечивает минимальное расстояние между её проекциями на изображения и наблюдаемыми точками.&lt;/p&gt;
&lt;p&gt;Для решения этой оптимизационной задачи широко применяется &lt;strong&gt;алгоритм Гаусса-Ньютона&lt;/strong&gt;. Метод работает путём итеративного обновления оценки точки через вычисление остаточной ошибки $e$ и матрицы Якоби $J$. На каждом шаге происходит корректировка оценки по формуле:&lt;/p&gt;
&lt;p&gt;$\delta P = -(J^TJ)^{-1}J^Te$&lt;/p&gt;
&lt;p&gt;Важным преимуществом нелинейного подхода является его способность работать с множественными видами — дополнительные изображения просто добавляются в систему уравнений. При этом алгоритм обеспечивает более точную оценку положения точки за счёт минимизации суммарной ошибки репроекции на всех изображениях.&lt;/p&gt;
&lt;p&gt;Несмотря на эффективность, метод требует разумной начальной оценки и контроля количества итераций для обеспечения сходимости. Тем не менее, нелинейная триангуляция остаётся предпочтительным выбором для практических приложений, где требуется высокая точность реконструкции трёхмерных сцен.&lt;/p&gt;</description><category>cs231a</category><guid>https://mldl.ru/posts/stereo-systems/</guid><pubDate>Fri, 03 Oct 2025 11:00:00 GMT</pubDate></item><item><title>Эпиполярная геометрия </title><link>https://mldl.ru/posts/epipolar-geometry/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;h4&gt;Введение&lt;/h4&gt;
&lt;p&gt;В предыдущих разделах мы изучали методы расчёта внутренних и внешних параметров камеры. Это можно сделать с помощью стандартной процедуры калибровки камеры или используя знания о перпендикулярных плоскостях по одному изображению. В результате этих вычислений мы смогли получить определённые характеристики трёхмерного пространства.&lt;/p&gt;
&lt;p&gt;Однако в общем случае невозможно восстановить полную структуру трёхмерного мира, опираясь только на одно изображение. Причина этого кроется во внутренней неоднозначности процесса отображения трёхмерного пространства на двумерную плоскость — часть информации неизбежно теряется при таком преобразовании.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 1: Проблема неоднозначности" src="https://storage.yandexcloud.net/yahosting/epipolar/1.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 1: Проблема неоднозначности&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Рассмотрим характерный пример, показанный на рисунке 1. На первый взгляд может показаться, что человек действительно удерживает Пизанскую башню. Только при внимательном изучении изображения становится понятно, что это всего лишь оптическая иллюзия, возникшая из-за проецирования объектов с разной глубиной на плоскость изображения.&lt;/p&gt;
&lt;p&gt;Если же рассмотреть эту сцену с совершенно другой точки зрения, иллюзия исчезает, и мы можем определить правильное расположение объектов в пространстве. Именно поэтому использование нескольких точек обзора является ключевым для точного понимания структуры сцены.&lt;/p&gt;
&lt;h4&gt;1. Эпиполярная геометрия&lt;/h4&gt;
&lt;p&gt;Эпиполярная геометрия представляет собой раздел компьютерной геометрии, который изучает взаимосвязь между точками на разных изображениях, ограничения на их расположение при проецировании и геометрические соотношения между камерами.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 2: Основные элементы эпиполярной геометрии" src="https://storage.yandexcloud.net/yahosting/epipolar/2.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 2: Основные элементы эпиполярной геометрии&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Рассмотрим основные элементы эпиполярной геометрии, изображённые на рисунке 2:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Две камеры наблюдают одну и ту же трёхмерную точку $P$  &lt;/li&gt;
&lt;li&gt;Проекции точки $P$ на плоскости изображений находятся в точках $p$ и $p'$  &lt;/li&gt;
&lt;li&gt;Центры камер расположены в точках $O_1$ и $O_2$  &lt;/li&gt;
&lt;li&gt;Линия, соединяющая центры камер, называется &lt;strong&gt;базисом&lt;/strong&gt; (оранжевая линия)  &lt;/li&gt;
&lt;li&gt;Плоскость, образованная двумя центрами камер и точкой $P$, называется &lt;strong&gt;эпиполярной плоскостью&lt;/strong&gt; (изображена серым цветом)  &lt;/li&gt;
&lt;li&gt;Эпиполы — точки пересечения базиса с плоскостями изображений ($e$ и $e'$)   &lt;/li&gt;
&lt;li&gt;Эпиполярные линии — прямые, образованные пересечением эпиполярной плоскости с плоскостями изображений (голубые отрезки)  &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="Рисунок 3: Пример расположения эпиполярных линий и ключевых точек" src="https://storage.yandexcloud.net/yahosting/epipolar/3.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 3: Пример расположения эпиполярных линий и ключевых точек&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;На рисунке 3 показан пример эпиполярных линий и соответствующих ключевых точек, нанесённых на пару изображений. Эта визуализация демонстрирует, как эпиполярная геометрия помогает установить связь между точками на разных снимках.&lt;/p&gt;
&lt;p&gt;Таким образом, эпиполярная геометрия помогает установить связи между изображениями одной и той же сцены, снятыми с разных точек зрения, и восстанавливать трёхмерную структуру.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 4: Частный случай эпиполярной геометрии" src="https://storage.yandexcloud.net/yahosting/epipolar/4.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 4: Частный случай эпиполярной геометрии&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;Рассмотрим интересную ситуацию, когда плоскости изображений расположены параллельны друг другу (см. рисунок 4). 
В этом случае эпиполы $e$ и $e'$ располагаются в бесконечности. 
Это происходит потому, что &lt;strong&gt;базис&lt;/strong&gt;, соединяющий центры камер $O_1$ и $O_2$, параллелен плоскостям изображений. 
Эпиполярные линии становятся параллельными оси $u$ на плоскости изображения. &lt;/p&gt;
&lt;p&gt;Этот частный случай имеет важное практическое значение, особенно при работе с выравниванием изображений, о чём будет подробно рассказано в следующем разделе.&lt;/p&gt;
&lt;p&gt;В практических ситуациях точное расположение трёхмерной точки $P$ неизвестно. 
Но мы можем определить её проекции $p, p'$ на плоскости изображений, местоположение, ориентацию и внутренние параметры камер. &lt;/p&gt;
&lt;p&gt;Кроме того, зная положения камер $O_1$, $O_2$ и положение проекции точки $p$ на одном изображении, можно определить эпиполярную плоскость и найти эпиполярные линии на основе этой плоскости. Это существенно упрощает поиск соответствующей ключевой точки на других изображениях. Это свойство делает эпиполярную геометрию мощным инструментом в задачах компьютерного зрения и трёхмерной реконструкции сцены.&lt;/p&gt;
&lt;h4&gt;2. Эссенциальная матрица&lt;/h4&gt;
&lt;p&gt;Для создания эффективного способа отображения точек и эпиполярных линий между разными видами сцены мы используем базовую структуру эпиполярной геометрии. 
В этой системе матрицы проекции $M$ и $M'$ отвечают за преобразование трёхмерных точек в двумерные координаты на плоскостях изображений.
Мировая система координат связывается с первой камерой, при этом вторая камера смещается относительно первой через последовательное применение поворота $R$ и переноса $T$.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 5: Расположение второй камеры относительно первой" src="https://storage.yandexcloud.net/yahosting/epipolar/5.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 5: Расположение второй камеры относительно первой&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;В результате того, что за точку отсчета мировых координат мы принимаем центр камеры $O_1$, матрицы проекции принимают следующий вид:&lt;/p&gt;
&lt;p&gt;$M = K \begin{bmatrix} I &amp;amp; 0 \end{bmatrix}$ (2)&lt;/p&gt;
&lt;p&gt;$M' = K' \begin{bmatrix} R &amp;amp; -RT \end{bmatrix}$&lt;/p&gt;
&lt;p&gt;где $K$ и $K'$ представляют внутренние параметры камер, $I$ — единичная матрица, $R$ отвечает за поворот, а $T$ — за перенос (вектор $O_1 O_2$).&lt;/p&gt;
&lt;p&gt;Рассмотрим частный случай с каноническими камерами:  &lt;/p&gt;
&lt;p&gt;$K = K' = I$  &lt;/p&gt;
&lt;p&gt;$p'$ - это координаты проекции точки в системе координат второй камеры. 
Координаты точки $p'$ в системе координат первой камеры определяются как $Rp' + T$.  &lt;/p&gt;
&lt;p&gt;Поскольку векторы $Rp' + T$ и $T$ лежат в эпиполярной плоскости, их векторное произведение даёт вектор, перпендикулярный этой плоскости.&lt;br&gt;
Благодаря свойствам дистрибутивности векторного произведения получаем результат: &lt;/p&gt;
&lt;p&gt;$T \times (Rp' + T) = T \times (Rp')$ &lt;/p&gt;
&lt;p&gt;Точка $p$, лежащая в эпиполярной плоскости, ортогональна вектору $T \times (Rp')$, что даёт ограничение:&lt;/p&gt;
&lt;p&gt;$p^T \cdot [T \times (Rp')] = 0$ (3)&lt;/p&gt;
&lt;p&gt;Напомним, &lt;strong&gt;векторное произведение&lt;/strong&gt; — это операция над двумя векторами в трёхмерном пространстве, результатом которой является новый вектор.
Результат — вектор, перпендикулярный обоим исходным векторам, его длина равна площади параллелограмма, построенного на исходных векторах, а направление определяется правилом правой руки&lt;/p&gt;
&lt;p&gt;Пусть даны два вектора:&lt;/p&gt;
&lt;p&gt;$\vec{a} = (a_1, a_2, a_3)$&lt;/p&gt;
&lt;p&gt;$\vec{b} = (b_1, b_2, b_3)$&lt;/p&gt;
&lt;p&gt;Их векторное произведение:&lt;/p&gt;
&lt;p&gt;$\vec{a} \times \vec{b} = \begin{vmatrix}
\vec{i} &amp;amp; \vec{j} &amp;amp; \vec{k} \\
a_1 &amp;amp; a_2 &amp;amp; a_3 \\
b_1 &amp;amp; b_2 &amp;amp; b_3
\end{vmatrix}$&lt;/p&gt;
&lt;p&gt;где $\vec{i}, \vec{j}, \vec{k}$ — единичные векторы по осям координат.&lt;/p&gt;
&lt;p&gt;Формула для вычисления имеет вид: &lt;/p&gt;
&lt;p&gt;$\vec{a} \times \vec{b} = (a_2b_3 - a_3b_2, a_3b_1 - a_1b_3, a_1b_2 - a_2b_1)$&lt;/p&gt;
&lt;p&gt;Вернемся к эпиполярной геометрии. &lt;/p&gt;
&lt;p&gt;Используя аппарат линейной алгебры, векторное произведение можно представить в виде матрично-векторного умножения:&lt;/p&gt;
&lt;p&gt;$a \times b = \begin{bmatrix} 0 &amp;amp; -a_z &amp;amp; a_y \\ a_z &amp;amp; 0 &amp;amp; -a_x \\ -a_y &amp;amp; a_x &amp;amp; 0 \end{bmatrix} \begin{bmatrix} b_x \\ b_y \\ b_z \end{bmatrix} = [a\times]b$ (4)&lt;/p&gt;
&lt;p&gt;Преобразуя выражение с учётом этого представления, получаем:&lt;/p&gt;
&lt;p&gt;$p^T[T\times]Rp' = 0$ (5)&lt;/p&gt;
&lt;p&gt;Матрица $E = [T\times]R$ называется &lt;strong&gt;эссенциальной матрицей&lt;/strong&gt; и даёт компактную форму эпиполярного ограничения:&lt;/p&gt;
&lt;p&gt;$p^TEp' = 0$ (6)&lt;/p&gt;
&lt;p&gt;Эссенциальная матрица — это матрица размером $3 \times 3$, содержащая 5 степеней свободы. Она имеет ранг 2 и является сингулярной.&lt;/p&gt;
&lt;p&gt;Эта матрица полезна для вычисления эпиполярных линий. Например, $l' = E^Tp$ даёт эпиполярную линию в плоскости изображения второй камеры, а $l = Ep'$ — в плоскости первой камеры.&lt;/p&gt;
&lt;p&gt;Важные свойства эссенциальной матрицы:
* Её скалярное произведение с эпиполями равно нулю: $E^Te = Ee' = 0$
* Для любой точки $x$ (кроме $e$) в изображении первой камеры соответствующая эпиполярная линия во второй камере содержит эпиполь $e'$&lt;/p&gt;
&lt;p&gt;Таким образом, эссенциальная матрица является фундаментальным инструментом для работы с эпиполярной геометрией и установления связей между точками на разных изображениях. &lt;/p&gt;
&lt;h4&gt;3. Фундаментальная матрица&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Фундаментальная матрица&lt;/strong&gt; — это важный инструмент в эпиполярной геометрии, который обобщает концепцию эссенциальной матрицы на случай камер с нетривиальными внутренними параметрами.&lt;/p&gt;
&lt;p&gt;Рассмотрим матрицы проекции для двух камер:&lt;/p&gt;
&lt;p&gt;$M = K \begin{bmatrix} I &amp;amp; 0 \end{bmatrix}$&lt;/p&gt;
&lt;p&gt;$M' = K' \begin{bmatrix} R &amp;amp; -RT \end{bmatrix}$ (7)&lt;/p&gt;
&lt;p&gt;Для работы с неканоническими камерами введём обозначения:
* $p_c = K^{-1}p$ — проекция точки $p$ для канонической камеры
* $p'_c = K'^{-1}p'$ — проекция точки $p'$ для канонической камеры&lt;/p&gt;
&lt;p&gt;В каноническом случае (единичная матрица $K$) выполняется соотношение:&lt;/p&gt;
&lt;p&gt;$p_c^T [T \times] R p'_c = 0$ (8)&lt;/p&gt;
&lt;p&gt;Однако, с учетом преобразований внутренних параметров камеры, получаем:&lt;/p&gt;
&lt;p&gt;$p^T K^{-T} [T \times] R K'^{-1} p' = 0$ (9)&lt;/p&gt;
&lt;p&gt;Матрица $F = K'^{-T} [T \times] R K^{-1}$ называется &lt;strong&gt;фундаментальной матрицей&lt;/strong&gt;.&lt;br&gt;
Она обобщает свойства эссенциальной матрицы, учитывает параметры камер $K$ и $K'$ и содержит информацию о взаимном положении камер. (вращение $R$ и перенос $T$).
очками на разных изображениях
Фундаментальная матрица имеет 7 степеней свободы (против 5 у эссенциальной матрицы), позволяет находить эпиполярные линии без знания 3D-координат точек и работает даже при неизвестных параметрах камер. &lt;/p&gt;
&lt;p&gt;Таким образом, фундаментальная матрица даёт мощный инструмент для установления связей между точками на разных изображениях, не требуя полной информации о параметрах камер или трёхмерных координатах точек.&lt;/p&gt;
&lt;h4&gt;4. Алгоритм восьми точек для вычисления фундаментальной матрицы&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Алгоритм восьми точек&lt;/strong&gt; — это метод оценки фундаментальной матрицы по двум изображениям сцены без знания параметров камер. Метод был предложен Лонге-Хиггинсом в 1981 году и расширен Хартли в 1995 году.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 6: Ключевые точки и их соответствие на двух изображениях" src="https://storage.yandexcloud.net/yahosting/epipolar/6.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 6: Ключевые точки и их соответствие на двух изображениях&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Для работы алгоритма требуется минимум 8 пар соответствующих точек между двумя изображениями. 
Каждая пара точек $p_i = (u_i, v_i, 1)$ и $p'_i = (u'_i, v'_i, 1)$ даёт ограничение $p_i^TFp'_i = 0$. &lt;/p&gt;
&lt;p&gt;Математически ограничение можно представить в виде:&lt;/p&gt;
&lt;p&gt;$\begin{bmatrix}
u_iu'&lt;em 11&gt;i &amp;amp; v'_iu_i &amp;amp; u_iu'_i &amp;amp; v_iu'_i &amp;amp; v_iv'_i &amp;amp; v_iu'_i &amp;amp; v'_i &amp;amp; 1
\end{bmatrix}
\begin{bmatrix}
F&lt;/em&gt;
\end{bmatrix} = 0$} \\ F_{12} \\ F_{13} \\ F_{21} \\ F_{22} \\ F_{23} \\ F_{31} \\ F_{32} \\ F_{33&lt;/p&gt;
&lt;p&gt;Практическая реализация для $N ≥ 8$ соответствий формируется система уравнений:&lt;/p&gt;
&lt;p&gt;$Wf = 0$,&lt;/p&gt;
&lt;p&gt;где:
* $W$ — матрица размером $N × 9$
* $f$ — вектор элементов фундаментальной матрицы&lt;/p&gt;
&lt;p&gt;На практике эффективнее использовать больше восьми соответствий и создавать более крупную матрицу W, поскольку это снижает влияние зашумлённых измерений. &lt;/p&gt;
&lt;p&gt;Решение этой системы однородных уравнений можно найти методом наименьших квадратов с помощью сингулярного разложения (SVD), так как матрица W является дефектной по рангу. &lt;/p&gt;
&lt;p&gt;SVD даёт оценку фундаментальной матрицы $\hat{F}$, которая может иметь полный ранг. Однако истинная фундаментальная матрица имеет ранг 2, поэтому нужно искать решение, которое является наилучшим приближением ранга 2 для $\hat{F}$.&lt;/p&gt;
&lt;p&gt;Математически это формулируется как задача оптимизации:&lt;/p&gt;
&lt;p&gt;$\min_F ||F - \hat{F}||_F$ при условии $\det(F) = 0$&lt;/p&gt;
&lt;p&gt;где:
* $||\cdot||_F$ — норма Фробениуса
* $\det(F) = 0$ — условие, обеспечивающее ранг матрицы равный 2&lt;/p&gt;
&lt;p&gt;Напомним, сингулярное разложение (SVD) для приблизительной оценки матрицы имеет вид:&lt;/p&gt;
&lt;p&gt;$\hat{F} = U\Sigma V^T$&lt;/p&gt;
&lt;p&gt;Искомая матрица $F$ будет иметь наилучшее приближение 2 ранга:&lt;/p&gt;
&lt;p&gt;$F = U
   \begin{bmatrix}
   \sigma_1 &amp;amp; 0 &amp;amp; 0 \\
   0 &amp;amp; \sigma_2 &amp;amp; 0 \\
   0 &amp;amp; 0 &amp;amp; 0
   \end{bmatrix}
   V^T$&lt;/p&gt;
&lt;p&gt;где $\sigma_1$ и $\sigma_2$ — первые два сингулярных числа матрицы $\hat{F}$.&lt;/p&gt;
&lt;p&gt;Такой подход гарантирует схранение геометрических свойств фундаментальной матрицы, минимизацию отклонения от исходной оценки и сохранение ранга 2. &lt;/p&gt;
&lt;p&gt;Таким образом, алгоритм позволяет оценить фундаментальную матрицу без знания параметров камер и является основой для многих задач стереовидения и трёхмерной реконструкции. &lt;/p&gt;
&lt;h4&gt;5. Нормализованный алгоритм восьми точек&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Стандартная реализация&lt;/strong&gt; алгоритма восьми точек часто даёт неточные результаты. Обычное расстояние между точкой $p_i$ и соответствующей эпиполярной линией $l_i = Fp'_i$ может достигать 10 и более пикселей.&lt;/p&gt;
&lt;p&gt;Основная проблема заключается в том, что матрица $W$ плохо обусловлена, это создает проблемы для алгоритма SVD. 
Основная причина - большие абсолютные значения координат точек (например, $p_i = (1832, 1023, 1)$)
Проблема усугубляется, если  точки $p_i$ и $p'_i$ находятся в небольшой области изображения, при наличии одного большого сингулярного значения при малых остальных. &lt;/p&gt;
&lt;p&gt;Для решения этой проблемы и улучшения точности используется &lt;strong&gt;нормализация координат&lt;/strong&gt;. 
1. Сдвиг координат так, чтобы начало новой системы находилось в центре масс точек
2. Масштабирование координат так, чтобы среднеквадратичное расстояние от начала координат равнялось 2 пикселям&lt;/p&gt;
&lt;p&gt;Для реализации используются матрицы преобразования $T$ и $T'$, которые выполняют сдвиг на центроид и применяют масштабирующий коэффициент $\left(\frac{2N}{\sum_{i=1}^N||x_i - \bar{x}||^2}\right)^{1/2}$&lt;/p&gt;
&lt;p&gt;Нормализованные координаты вычисляются как:&lt;br&gt;
$q_i = Tp_i$&lt;br&gt;
$q'_i = T'p'_i$  &lt;/p&gt;
&lt;p&gt;Далее, используя нормализованные координаты, вычисляется матрица $F_q$ стандартным методом и производится денормализация:  &lt;/p&gt;
&lt;p&gt;$F = T'^TF_qT$&lt;/p&gt;
&lt;p&gt;Нормализованный алгоритм обеспечивает:&lt;br&gt;
- Более точные результаты в реальных приложениях&lt;br&gt;
- Улучшенную обусловленность матрицы $W$&lt;br&gt;
- Снижение влияния больших значений координат&lt;br&gt;
- Повышение точности оценки фундаментальной матрицы  &lt;/p&gt;
&lt;p&gt;Такой подход значительно улучшает качество оценки фундаментальной матрицы и является предпочтительным методом для практического применения. &lt;/p&gt;
&lt;h4&gt;6. Выравнивание изображений (Image Rectification)&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Особое свойство эпиполярной геометрии&lt;/strong&gt; проявляется, когда два изображения параллельны друг другу. 
Рассмотрим частный случай параллельных плоскостей изображений.&lt;/p&gt;
&lt;p&gt;Камеры имеют одинаковую матрицу $K$, отсутствует относительное вращение ($R = I$) и есть только перенос вдоль оси $x$ ($T = (T_x, 0, 0)$)&lt;/p&gt;
&lt;p&gt;В этом случае эссенциальная матрица принимает вид:&lt;/p&gt;
&lt;p&gt;$E = [T×]R = \begin{bmatrix} 
0 &amp;amp; 0 &amp;amp; 0 \\ 
0 &amp;amp; 0 &amp;amp; -T_x \\ 
0 &amp;amp; T_x &amp;amp; 0 
\end{bmatrix}$ (17)&lt;/p&gt;
&lt;p&gt;Направление эпиполярной линии для точки $p' = (u', v', 1)$ вычисляется как:&lt;/p&gt;
&lt;p&gt;$l = Ep' = \begin{bmatrix} 
0 &amp;amp; 0 &amp;amp; 0 \\ 
0 &amp;amp; 0 &amp;amp; -T_x \\ 
0 &amp;amp; T_x &amp;amp; 0 
\end{bmatrix}
\begin{bmatrix} 
u' \\ 
v' \\ 
1 
\end{bmatrix} = 
\begin{bmatrix} 
0 \\ 
-T_x \\ 
T_xv' 
\end{bmatrix}$ (18)&lt;/p&gt;
&lt;p&gt;В этом случае направление эпиполярной линии $l$ горизонтально. 
Аналогично, направление $l'$ также горизонтально, а все эпиполярные линии параллельны друг другу.&lt;br&gt;
Такое выравнивание изображений позволяет значительно упростить поиск соответствий между точками и упрощает стереообработку и трёхмерную реконструкцию сцены.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 7: Ректификация (выравнивание) изображений" src="https://storage.yandexcloud.net/yahosting/epipolar/7.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 7: Ректификация (выравнивание) изображений&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Если мы используем &lt;strong&gt;эпиполярное ограничение&lt;/strong&gt; $p^T E p' = 0$, то приходим к тому, что $v = v'$. Это показывает, что точки $p$ и $p'$ имеют одинаковую координату $v$.&lt;/p&gt;
&lt;p&gt;Следовательно, между соответствующими точками существует очень простая взаимосвязь. Поэтому &lt;strong&gt;выравнивание&lt;/strong&gt; (процесс приведения любых двух заданных изображений к параллельному виду) становится полезным при определении взаимосвязей между соответствующими точками на изображениях.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 8: Вычисление гомографий ректификации" src="https://storage.yandexcloud.net/yahosting/epipolar/8.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 8: Вычисление гомографий ректификации&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Выравнивание пары изображений не требует знания матриц камер $K$ и $K'$ или относительного преобразования $R$, $T$ между ними. Вместо этого можно использовать &lt;strong&gt;фундаментальную матрицу&lt;/strong&gt;, оценённую с помощью &lt;strong&gt;нормализованного алгоритма восьми точек&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;После получения фундаментальной матрицы можно вычислить &lt;strong&gt;эпиполярные линии&lt;/strong&gt; $l_i$ и $l'_i$ для каждой пары соответствующих точек $p_i$ и $p'_i$.&lt;/p&gt;
&lt;p&gt;На основе набора эпиполярных линий можно оценить &lt;strong&gt;эпиполи&lt;/strong&gt; $e$ и $e'$ для каждого изображения. Это возможно потому, что эпиполь лежит в точке пересечения всех эпиполярных линий.&lt;/p&gt;
&lt;p&gt;В реальных условиях из-за зашумлённых измерений все эпиполярные линии не пересекаются в одной точке. Поэтому вычисление эпиполя можно найти путём минимизации среднеквадратичной ошибки подгонки точки ко всем эпиполярным линиям.&lt;/p&gt;
&lt;p&gt;Каждая эпиполярная линия может быть представлена в виде вектора $l$ так, что все точки на линии (в однородных координатах) принадлежат множеству ${x | l^T x = 0}$. 
Если определить каждую эпиполярную линию как $l_i = [l_{i,1}, l_{i,2}, l_{i,3}]^T$, то можно сформулировать линейную систему уравнений и решить её с помощью &lt;strong&gt;сингулярного разложения&lt;/strong&gt; (SVD) для нахождения эпиполя $e$.&lt;/p&gt;
&lt;p&gt;$\begin{bmatrix}
l^T_1 \\
\vdots \\
l^T_n
\end{bmatrix} e = 0$&lt;/p&gt;
&lt;p&gt;После нахождения эпиполей $e$ и $e'$, мы, скорее всего, обнаружим, что они не являются точками на бесконечности вдоль горизонтальной оси. Если бы это было так, то изображения уже были бы параллельными по определению.&lt;/p&gt;
&lt;p&gt;Это наводит на мысль: можно ли найти &lt;strong&gt;гомографию&lt;/strong&gt;, которая отобразит эпиполь $e$ в бесконечность вдоль горизонтальной оси?&lt;/p&gt;
&lt;p&gt;Все что нам нужно - это найти пару гомографий $H_1$ и $H_2$, применить их к изображениям и отобразить эпиполи в бесконечность. &lt;/p&gt;
&lt;p&gt;Начнём с поиска гомографии $H_2$, которая отображает второй эпиполь $e'$ в точку на горизонтальной оси в бесконечности $(f, 0, 0)$.&lt;/p&gt;
&lt;p&gt;Хотя существует множество вариантов такой гомографии, на практике хорошо работает условие, при котором гомография действует как преобразование и применяет перенос и поворот к точкам около центра изображения. &lt;/p&gt;
&lt;p&gt;Первый шаг — сдвиг второго изображения так, чтобы его центр оказался в точке $(0, 0, 1)$ в однородных координатах. Это достигается применением матрицы переноса.&lt;/p&gt;
&lt;p&gt;$T = \begin{bmatrix}
1 &amp;amp; 0 &amp;amp; -\frac{width}{2} \\
0 &amp;amp; 1 &amp;amp; -\frac{height}{2} \\
0 &amp;amp; 0 &amp;amp; 1
\end{bmatrix}$ (20)&lt;/p&gt;
&lt;p&gt;После применения переноса мы выполняем поворот, чтобы разместить эпиполь на горизонтальной оси в некоторой точке $(f, 0, 1)$.&lt;/p&gt;
&lt;p&gt;Если перенесённый эпиполь $T e'$ находится в однородных координатах $(e'_1, e'_2, 1)$, то применяемый поворот определяется следующим образом:&lt;/p&gt;
&lt;p&gt;$R = \begin{bmatrix}
\alpha\frac{e'_1}{\sqrt{e'^2_1 + e'^2_2}} &amp;amp; \alpha\frac{e'_2}{\sqrt{e'^2_1 + e'^2_2}} &amp;amp; 0 \\
-\alpha\frac{e'_2}{\sqrt{e'^2_1 + e'^2_2}} &amp;amp; \alpha\frac{e'_1}{\sqrt{e'^2_1 + e'^2_2}} &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 1
\end{bmatrix}$ (21) &lt;/p&gt;
&lt;p&gt;где параметр $\alpha$ определяется следующим образом:&lt;br&gt;
$\alpha = 1$, если $e'_1 \geq 0$&lt;br&gt;
$\alpha = -1$ в противном случае. &lt;/p&gt;
&lt;p&gt;После применения этого поворота заметим, что для любой точки $(f, 0, 1)$ перевод её в точку на бесконечности по горизонтальной оси $(f, 0, 0)$ требует применения преобразования:&lt;/p&gt;
&lt;p&gt;$G = \begin{bmatrix} 
1 &amp;amp; 0 &amp;amp; 0 \\ 
0 &amp;amp; 1 &amp;amp; 0 \\ 
-\frac{1}{f} &amp;amp; 0 &amp;amp; 1 
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;После применения этого преобразования мы наконец получаем эпиполь в бесконечности, поэтому можем вернуться к обычному пространству изображения.&lt;/p&gt;
&lt;p&gt;Таким образом, гомография $H_2$, которую мы применяем ко второму изображению для его выравнивания, имеет вид:&lt;/p&gt;
&lt;p&gt;$H_2 = T^{-1}GRT$ (23)&lt;/p&gt;
&lt;p&gt;Теперь, когда мы нашли допустимую $H_2$, нам нужно найти подходящую гомографию $H_1$ для первого изображения. Мы делаем это путём поиска такого преобразования $H_1$, которое минимизирует сумму квадратов расстояний между соответствующими точками изображений:&lt;/p&gt;
&lt;p&gt;$\arg\min_{H_1} \sum_{i} ||H_1p_i - H_2p'_i||^2$&lt;/p&gt;
&lt;p&gt;В результате мы получаем пару гомографий ($H_1$, $H_2$), которые позволяют выровнять изображения, сделать эпиполярные линии горизонтальными и упростить поиск соответствий между точками. &lt;/p&gt;
&lt;p&gt;Можно доказать, что подходящая гомография $H_1$ имеет следующий вид:&lt;/p&gt;
&lt;p&gt;$H_1 = H_A H_2 M$ (25)&lt;/p&gt;
&lt;p&gt;где:
* $F = [e]\times M$
* $H_A$ — специальная матрица вида:&lt;/p&gt;
&lt;p&gt;$H_A = \begin{bmatrix} 
a_1 &amp;amp; a_2 &amp;amp; a_3 \\ 
0 &amp;amp; 1 &amp;amp; 0 \\ 
0 &amp;amp; 0 &amp;amp; 1 
\end{bmatrix}$ (26)&lt;/p&gt;
&lt;p&gt;Здесь $(a_1, a_2, a_3)$ — компоненты определённого вектора $a$, который будет вычислен позже.&lt;/p&gt;
&lt;p&gt;Разберём структуру этого выражения:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Матрица $H_A$&lt;/strong&gt; представляет собой линейное преобразование вдоль оси $x$, координаты $y$ и $z$ остаются неизменными. 
$H_2$ — уже известная гомография для второго изображения&lt;br&gt;
$M$ — вспомогательная матрица, связанная с фундаментальной матрицей $F$&lt;br&gt;
$[e]\times$ — кососимметричная матрица, построенная на векторе $e$  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Кососимметричная матрица&lt;/strong&gt; обладает свойством $A = A^3$ с точностью до масштаба.&lt;/p&gt;
&lt;p&gt;Поскольку:
* Матрица векторного произведения $[e]\times$ — кососимметричная
* Фундаментальная матрица $F$ известна только с точностью до масштаба&lt;/p&gt;
&lt;p&gt;Получаем:&lt;/p&gt;
&lt;p&gt;$F = [e]\times M = [e]\times[e]\times[e]\times M = [e]\times[e]\times F$ (27)&lt;/p&gt;
&lt;p&gt;Отсюда следует:&lt;/p&gt;
&lt;p&gt;$M = [e]\times F$ (28)&lt;/p&gt;
&lt;p&gt;Важно заметить: если к столбцам $M$ добавить любое скалярное кратное вектора $e$, равенство $F = [e]\times M$ сохраняется.&lt;/p&gt;
&lt;p&gt;Поэтому более общий вид $M$:&lt;/p&gt;
&lt;p&gt;$M = [e]\times F + ev^T$ (29)&lt;/p&gt;
&lt;p&gt;На практике хорошо работает выбор $v^T = [1, 1, 1]$.&lt;/p&gt;
&lt;p&gt;Для нахождения $H_1$ нужно вычислить значения вектора $a$ в матрице $H_A$.&lt;/p&gt;
&lt;p&gt;Задача сводится к минимизации:&lt;/p&gt;
&lt;p&gt;$\arg\min_{H_A} \sum_{i} ||H_A\hat{p}_i - \hat{p}'_i||^2$ (30)&lt;/p&gt;
&lt;p&gt;где:
* $\hat{p}_i = H_2Mp_i$
* $\hat{p}'_i = H_2p'_i$&lt;/p&gt;
&lt;p&gt;При этом $H_2$ и $M$ уже известны. &lt;/p&gt;</description><category>cs231a</category><guid>https://mldl.ru/posts/epipolar-geometry/</guid><pubDate>Thu, 02 Oct 2025 11:00:00 GMT</pubDate></item><item><title>Измерение углов </title><link>https://mldl.ru/posts/single-view-metrology/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;h4&gt;Введение&lt;/h4&gt;
&lt;p&gt;На предыдущих лекциях мы обсуждали, как можно преобразовывать точки из реального трёхмерного мира в цифровые изображения, используя внешние и внутренние характеристики камер. Мы рассмотрели, как можно использовать известную структуру калибровочной установки и соответствующие изображения для определения характеристик камеры. &lt;/p&gt;
&lt;p&gt;Теперь мы обратимся к смежной проблеме: можно ли восстановить известную структуру трёхмерного мира, если у нас есть единственное изображение и известны свойства камеры, которой это изображение было сделано? И наконец мы рассмотрим алгоритм калибровки камеры и измерения углов между плоскостями на одиночном изображении. &lt;/p&gt;
&lt;h4&gt;1. Преобразования в 2D пространстве&lt;/h4&gt;
&lt;p&gt;Чтобы лучше понять, как мы можем извлекать информацию из изображений, сначала необходимо разобраться с различными преобразованиями в двумерном пространстве.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Изометрические преобразования&lt;/strong&gt; — это преобразования, сохраняющие расстояния. В своей базовой форме изометрия может быть описана как вращение $R$ и перенос $t$. Математически они определяются следующим образом:&lt;/p&gt;
&lt;p&gt;$\begin{bmatrix}
x' \\
y' \\
1
\end{bmatrix} = 
\begin{bmatrix}
R &amp;amp; t \\
0 &amp;amp; 1
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
1
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;где $(x', y', 1)^T$ — точка, полученная после изометрического преобразования.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Преобразования подобия&lt;/strong&gt; — это преобразования, сохраняющие форму. Интуитивно они могут выполнять всё то же, что и изометрические преобразования, плюс масштабирование. Математически они обозначаются так:&lt;/p&gt;
&lt;p&gt;$\begin{bmatrix}
x' \\
y' \\
1
\end{bmatrix} = 
\begin{bmatrix}
SR &amp;amp; t \\
0 &amp;amp; 1
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
1
\end{bmatrix} $  &lt;/p&gt;
&lt;p&gt;$ S = 
\begin{bmatrix}
s &amp;amp; 0 \\
0 &amp;amp; s
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Преобразования подобия&lt;/strong&gt; сохраняют форму объектов, а значит, сохраняют:&lt;br&gt;
&lt;em&gt; Отношения длин отрезков&lt;br&gt;
&lt;/em&gt; Величины углов  &lt;/p&gt;
&lt;p&gt;Важно отметить, что любое &lt;strong&gt;изометрическое преобразование&lt;/strong&gt; является частным случаем преобразования подобия при $s = 1$. Однако обратное утверждение неверно.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Аффинные преобразования&lt;/strong&gt; сохраняют:&lt;br&gt;
&lt;em&gt; Точки&lt;br&gt;
&lt;/em&gt; Прямые линии&lt;br&gt;
* Параллельность прямых  &lt;/p&gt;
&lt;p&gt;Для вектора $v$ аффинное преобразование $T$ определяется как:
$T(v) = Av + t$, где $A$ — линейное преобразование пространства $R^n$&lt;/p&gt;
&lt;p&gt;В однородных координатах аффинные преобразования записываются так:  &lt;/p&gt;
&lt;p&gt;$\begin{bmatrix}
x' \\
y' \\
1
\end{bmatrix} = 
\begin{bmatrix}
A &amp;amp; t \\
0 &amp;amp; 1
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
1
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;Из этого уравнения видно, что все преобразования подобия (и, следовательно, изометрии) являются частным случаем аффинных преобразований.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Проективные преобразования&lt;/strong&gt; (или гомографии) — это преобразования, которые переводят прямые в прямые, но не обязательно сохраняют параллельность.&lt;/p&gt;
&lt;p&gt;В однородных координатах проективные преобразования представляются как: &lt;/p&gt;
&lt;p&gt;$\begin{bmatrix}
x' \\
y' \\
1
\end{bmatrix} = 
\begin{bmatrix}
A &amp;amp; t \\
v &amp;amp; b
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
1
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;Это представление является обобщением аффинных преобразований за счёт добавления вектора $v$, который вводит дополнительные степени свободы.&lt;/p&gt;
&lt;p&gt;Несмотря на то, что проективные преобразования не сохраняют параллельность, они сохраняют:&lt;br&gt;
&lt;em&gt; Коллинеарность точек (прямые переходят в прямые)&lt;br&gt;
&lt;/em&gt; Перекрестное отношение четырёх коллинеарных точек.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Перекрестное отношение&lt;/strong&gt; четырёх точек $P_1, P_2, P_3, P_4$, лежащих на одной прямой, вычисляется по формуле:  &lt;/p&gt;
&lt;p&gt;$cross\ ratio = \frac{||P_3 - P_1||\ ||P_4 - P_2||}{||P_3 - P_2||\ ||P_4 - P_1||}$ (1)&lt;/p&gt;
&lt;p&gt;Доказательство инвариантности перекрестного отношения при проективных преобразованиях предлагается выполнить в качестве учебного упражнения. &lt;/p&gt;
&lt;h4&gt;2. Точки и прямые в бесконечности&lt;/h4&gt;
&lt;p&gt;Прямые играют важную роль в определении структуры изображений, поэтому важно понимать их представление как в 2D, так и в 3D пространстве.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Прямая на плоскости&lt;/strong&gt; может быть представлена однородным вектором $\ell = \begin{bmatrix} a &amp;amp; b &amp;amp; c \end{bmatrix}^T$.  &lt;/p&gt;
&lt;p&gt;Отношение $-\frac{a}{b}$ определяет наклон прямой, а отношение $-\frac{c}{b}$ — точку пересечения с осью $y$.  &lt;/p&gt;
&lt;p&gt;Для любой точки, лежащей на прямой, справедливо уравнение:&lt;/p&gt;
&lt;p&gt;$\forall p = \begin{bmatrix} x \\ y \end{bmatrix} \in \ell, \quad \begin{bmatrix} a &amp;amp; b &amp;amp; c \end{bmatrix} \begin{bmatrix} x \\ y \\ 1 \end{bmatrix} = 0$ (2)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Пересечение прямых&lt;/strong&gt;&lt;br&gt;
В общем случае две прямые $\ell$ и $\ell'$ пересекаются в точке $x$, которая определяется как векторное произведение этих прямых.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Доказательство: если две прямые пересекаются, точка пересечения $x$ должна лежать на обеих прямых. Следовательно, $x^T\ell = 0$ и $x^T\ell' = 0$. Если мы положим $x = \ell \times \ell'$, то по определению векторного произведения вектор $x$ будет ортогонален обоим векторам $\ell$ и $\ell'$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Параллельные прямые&lt;/strong&gt;&lt;br&gt;
В школьной геометрии считается, что параллельные прямые не пересекаются. Однако в однородных координатах можно сказать, что они пересекаются в бесконечности.  &lt;/p&gt;
&lt;p&gt;Рассмотрим две параллельные прямые $\ell$ и $\ell'$. Когда прямые параллельны, их наклоны равны: $\frac{a}{b} = \frac{a'}{b'}$. Если вычислить точку пересечения в однородных координатах, получим:&lt;/p&gt;
&lt;p&gt;$\ell \times \ell' \propto \begin{bmatrix} b \\ -a \\ 0 \end{bmatrix} = x_\infty$ (3)&lt;/p&gt;
&lt;p&gt;Это подтверждает, что параллельные прямые пересекаются в бесконечности. Точка пересечения параллельных прямых в бесконечности называется &lt;strong&gt;идеальной точкой&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;В однородных координатах идеальная точка в бесконечности представляется как:&lt;/p&gt;
&lt;p&gt;$\begin{bmatrix} x \ y \ 0 \end{bmatrix}^T$ &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Свойство идеальных точек&lt;/strong&gt;
Все параллельные прямые с одинаковым наклоном $-\frac{a}{b}$ проходят через идеальную точку:&lt;/p&gt;
&lt;p&gt;$\ell^T x_\infty = \begin{bmatrix} a &amp;amp; b &amp;amp; c \end{bmatrix} \begin{bmatrix} b \\ -a \\ 0 \end{bmatrix} = 0$ (4)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Бесконечно удалённые точки&lt;/strong&gt; позволяют определить прямую в бесконечности. Рассмотрим несколько пар параллельных прямых. Каждая пара пересекается в своей точке бесконечности $x_{\infty,i}$. Прямая $\ell_\infty$, проходящая через все эти точки, должна удовлетворять условию:&lt;/p&gt;
&lt;p&gt;$\forall i, \ell_\infty^T x_{\infty,i} = 0$&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 1: Точки в бесконечности образуют прямые в бесконечности" src="https://storage.yandexcloud.net/yahosting/photo_metro/1.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 1: Точки в бесконечности образуют прямые в бесконечности&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;Такая прямая имеет вид $\ell_\infty = \begin{bmatrix} 0 &amp;amp; 0 &amp;amp; c \end{bmatrix}^T$. Поскольку $c$ — произвольное значение, можно принять:&lt;/p&gt;
&lt;p&gt;$\ell_\infty = \begin{bmatrix} 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix}^T$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Проективное преобразование&lt;/strong&gt; точки в бесконечности:&lt;/p&gt;
&lt;p&gt;При применении проективного преобразования $H$ к точке в бесконечности $p_\infty$ получаем:&lt;/p&gt;
&lt;p&gt;$p' = Hp_\infty = \begin{bmatrix} A &amp;amp; t \\ v &amp;amp; b \end{bmatrix} \begin{bmatrix} 1 \\ 1 \\ 0 \end{bmatrix} = \begin{bmatrix} p'_x \\ p'_y \\ p'_z \end{bmatrix}$ (5)&lt;/p&gt;
&lt;p&gt;Заметим, что последний элемент $p'$ может стать ненулевым. Это означает, что проективное преобразование обычно переводит точки в бесконечности в точки, которые уже не находятся в бесконечности. Т.е. имеют конечные евклидовы координаты, пусть и за пределами изображения. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Аффинные преобразования&lt;/strong&gt; ведут себя иначе и всегда переводят точку из бесконечности в бесконечность:&lt;/p&gt;
&lt;p&gt;$p' = Hp_\infty = \begin{bmatrix} A &amp;amp; t \\ 0 &amp;amp; 1 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \\ 0 \end{bmatrix} = \begin{bmatrix} p'_x \\ p'_y \\ 0 \end{bmatrix}$ (6)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Преобразование прямых&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;При применении проективного преобразования $H$ к прямой $\ell$ получаем новую прямую $\ell'$. Все точки $x$, лежащие на прямой, должны удовлетворять условию $x^T\ell = 0$. В преобразованном пространстве прямые переходят в прямые, то есть $x'^T\ell' = 0$. Используя свойство тождественного преобразования, получаем:&lt;/p&gt;
&lt;p&gt;$x^TI\ell = x^TH^TH^{-T}\ell = 0$&lt;/p&gt;
&lt;p&gt;При применении &lt;strong&gt;проективного преобразования&lt;/strong&gt; к прямой происходит преобразование всех точек, лежащих на ней. Если $x$ — точка исходной прямой, то после преобразования получаем:&lt;/p&gt;
&lt;p&gt;$x' = Hx$&lt;/p&gt;
&lt;p&gt;Используя это преобразование, можно записать:&lt;/p&gt;
&lt;p&gt;$x^TH^TH^{-T}\ell = x'^T\ell'$,&lt;/p&gt;
&lt;p&gt;откуда следует, что проективное преобразование прямой имеет вид:&lt;/p&gt;
&lt;p&gt;$\ell' = H^{-T}\ell$&lt;/p&gt;
&lt;p&gt;Важные выводы:&lt;br&gt;
&lt;em&gt; При проективном преобразовании прямая в бесконечности не обязательно переходит в другую прямую в бесконечности&lt;br&gt;
&lt;/em&gt; В отличие от этого, &lt;strong&gt;аффинные преобразования&lt;/strong&gt; сохраняют прямые в бесконечности, переводя их в прямые в бесконечности.  &lt;/p&gt;
&lt;p&gt;Эти свойства имеют важное значение для понимания того, как различные типы преобразований влияют на структуру изображения и геометрию сцены. Особенно это касается работы с бесконечно удалёнными точками и прямыми, которые играют ключевую роль в проективной геометрии и компьютерном зрении.&lt;/p&gt;
&lt;p&gt;Таким образом, при работе с проективными преобразованиями необходимо учитывать, что они могут существенно изменять геометрию сцены, в том числе расположение прямых и точек в бесконечности, в то время как аффинные преобразования сохраняют некоторые геометрические свойства. &lt;/p&gt;
&lt;h4&gt;3. Точки и линии схода&lt;/h4&gt;
&lt;p&gt;В трёхмерном пространстве вводится понятие &lt;strong&gt;плоскости&lt;/strong&gt;, которая представляется вектором $\begin{bmatrix} a &amp;amp; b &amp;amp; c &amp;amp; d \end{bmatrix}^T$. 
Здесь $(a, b, c)$ образуют вектор нормали, а $d$ — расстояние от начала координат до плоскости в направлении этого вектора. Формально плоскость определяется как множество точек $x$, удовлетворяющих уравнению:&lt;/p&gt;
&lt;p&gt;$x^T \begin{bmatrix} a \\ b \\ c \\ d \end{bmatrix} = ax_1 + bx_2 + cx_3 + d = 0$ (7)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Прямые в 3D&lt;/strong&gt; определяются как пересечение двух плоскостей. Они имеют четыре степени свободы (точка пересечения и наклоны в трёх измерениях).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Точки в бесконечности&lt;/strong&gt; в 3D определяются как точки пересечения параллельных прямых. При проективном преобразовании таких точек получается &lt;strong&gt;точка схода&lt;/strong&gt; $p_\infty$ на плоскости изображения.&lt;/p&gt;
&lt;p&gt;Существует полезное соотношение между параллельными прямыми в 3D, их точкой схода на изображении и параметрами камеры $K$, $R$, $T$.&lt;/p&gt;
&lt;p&gt;Пусть $d = (a, b, c)$ — направление набора параллельных прямых в системе координат камеры. Тогда точка схода $v$ определяется как:&lt;/p&gt;
&lt;p&gt;$v = Kd$ (8)&lt;/p&gt;
&lt;p&gt;Отсюда можно выразить направление $d$:&lt;/p&gt;
&lt;p&gt;$d = \frac{K^{-1}v}{|K^{-1}v|}$ (9)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Линия горизонта&lt;/strong&gt; (или линия схода) $l_{horiz}$ — это проекция линии в бесконечности на плоскость изображения. Она проходит через соответствующие точки схода на изображении и вычисляется по формуле:&lt;/p&gt;
&lt;p&gt;$l_{horiz} = H^{-T}P l_\infty$ (10)&lt;/p&gt;
&lt;p&gt;Точки и линии схода являются важными инструментами для анализа структуры сцены и определения параметров камеры по изображению, т.к. они позволяют восстанавливать трёхмерную геометрию по двумерной проекции. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 2: Линия горизонта как множество точек схода" src="https://storage.yandexcloud.net/yahosting/photo_metro/2.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Линия горизонта&lt;/strong&gt; позволяет нам интуитивно определять свойства изображения, которые могут быть неочевидны с математической точки зрения. Например,  линии на земле не выглядят параллельными на изображении (как показано на рисунке 2), но интуитивно мы все же понимаем, что в трёхмерном пространстве они параллельны.&lt;/p&gt;
&lt;p&gt;Линия горизонта позволяет &lt;strong&gt;вычислять&lt;/strong&gt; важные характеристики сцены. Существует интересное соотношение между нормалью $n$ плоскости в 3D и соответствующей линией горизонта $l_{horiz}$ на изображении:&lt;/p&gt;
&lt;p&gt;$n = K^Tl_{horiz}$ (11)&lt;/p&gt;
&lt;p&gt;Это означает, что если мы можем определить линию горизонта, связанную с плоскостью, и знаем внутренние характеристики камеры $K$, мы можем оценить ориентацию этой плоскости.&lt;/p&gt;
&lt;p&gt;Теперь давайте рассмотрим понятие &lt;strong&gt;плоскость в бесконечности&lt;/strong&gt;.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 3: Плоскость в бесконечности" src="https://storage.yandexcloud.net/yahosting/photo_metro/3.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 3: Плоскость в бесконечности&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Эта плоскость определяется набором из двух или более линий схода. В однородных координатах плоскость описывается вектором:&lt;/p&gt;
&lt;p&gt;$Π_\infty = \begin{bmatrix} 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix}^T$ &lt;/p&gt;
&lt;p&gt;Плоскость в бесконечности поможет нам понять важное свойство, связывающее линии и плоскости в 3D с соответствующими точками и линиями схода на плоскости изображения.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 4: Определение угла между линиями" src="https://storage.yandexcloud.net/yahosting/photo_metro/4.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 4: Определение угла между линиями&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;Пусть две пары параллельных линий в 3D имеют направления $d_1$ и $d_2$, связанные с точками в бесконечности $x_{1,\infty}$ и $x_{2,\infty}$. 
Пусть $v_1$ и $v_2$ — соответствующие точки схода. 
Тогда угол $θ$ между $d_1$ и $d_2$ определяется по формуле:&lt;/p&gt;
&lt;p&gt;$\cos θ = \frac{d_1 \cdot d_2}{|d_1||d_2|} = \frac{v_1^T \omega v_2}{\sqrt{v_1^T \omega v_1} \sqrt{v_2^T \omega v_2}}$ (12)&lt;/p&gt;
&lt;p&gt;где $\omega = (KK^T)^{-1}$.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Матрица $\omega$&lt;/strong&gt; определяется через матрицу камеры $K$ следующим образом:&lt;/p&gt;
&lt;p&gt;$\omega = (K K^T)^{-1}$&lt;/p&gt;
&lt;p&gt;Эта матрица имеет важные свойства:  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Симметричность: матрица $\omega$ является симметричной, так как $K K^T$ — симметричная матрица, а обратная к симметричной матрице также симметрична&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Связь с параметрами камеры: содержит информацию о внутренних параметрах камеры, зависит от фокусных расстояний, координат главной точки и коэффициента скоса (skew).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;При стандартных предположениях о камере (нулевой скос, квадратные пиксели) матрица $\omega$ имеет вид:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$\omega = \begin{bmatrix}
\omega_1 &amp;amp; 0 &amp;amp; \omega_4 \\
0 &amp;amp; \omega_1 &amp;amp; \omega_5 \\
\omega_4 &amp;amp; \omega_5 &amp;amp; \omega_6
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;Матрица $\omega$ определяется с точностью до масштабного множителя, что влияет на количество независимых переменных при решении системы уравнений. Это свойство учитывается при калибровке камеры и восстановлении 3D-структуры сцены.&lt;/p&gt;
&lt;p&gt;Это соотношение показывает, как можно определить угол между направлениями в пространстве, используя только точки схода на изображении и параметры камеры.&lt;/p&gt;
&lt;p&gt;И наконец, расширим рассмотренную концепцию на случай трёхмерных плоскостей, чтобы установить связь между различными плоскостями в 3D пространстве.&lt;/p&gt;
&lt;p&gt;Для любой плоскости мы можем:&lt;br&gt;
&lt;em&gt; Вычислить соответствующую линию горизонта $l_{horiz}$&lt;br&gt;
&lt;/em&gt; Определить нормаль к плоскости $n = K^\ l_{horiz}$  &lt;/p&gt;
&lt;p&gt;Угол $\theta$ между двумя плоскостями можно определить через угол между их нормалями $n_1$ и $n_2$. 
Рассмотрим две плоскости с линиями горизонта $l_1$ и $l_2$ соответственно. 
Угол между нормалями этих плоскостей определяется формулой:&lt;/p&gt;
&lt;p&gt;$\cos \theta = \frac{n_1 \cdot n_2}{|n_1||n_2|} = \frac{l_1^T \omega^{-1} l_2}{\sqrt{l_1^T \omega^{-1} l_1} \sqrt{l_2^T \omega^{-1} l_2}}$ (13)&lt;/p&gt;
&lt;p&gt;Таким образом, используя линии горизонта и параметры камеры, мы можем восстанавливать пространственные отношения между плоскостями в сцене, что является важным инструментом в компьютерном зрении и трёхмерной реконструкции.&lt;/p&gt;
&lt;h4&gt;4. Алгоритм калибровки камеры и измерения углов&lt;/h4&gt;
&lt;p&gt;Рассмотрим пример решения задачи калибровки камеры по одной фотографии. 
Для этого нам понадобится изображение трёхмерного мира, на котором мы можем выполнить следующие операции:&lt;br&gt;
&lt;em&gt; Определить три плоскости и на каждой из этих плоскостей пару параллельных линий&lt;br&gt;
&lt;/em&gt; Идентифицировать точки схода $v_1$ $v_2$ и $v_3$&lt;br&gt;
* Использовать априорное знание и том, что плоскости перпендикулярны в 3D пространстве.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 5: Точки схода на перпендикулярных плоскостях" src="https://storage.yandexcloud.net/yahosting/photo_metro/6.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 5: Точки схода на перпендикулярных плоскостях&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Из уравнения (12) мы знаем, что для перпендикулярных плоскостей выполняется соотношение $v_1\omega v_2 = 0$. &lt;/p&gt;
&lt;p&gt;Если мы имеем три точки схода для трех взаимно перпендикулярной плоскости, то получаем систему: &lt;/p&gt;
&lt;p&gt;$v_1\omega v_2 = 0$&lt;br&gt;
 $v_1\omega v_3 = 0$&lt;br&gt;
 $v_2\omega v_3 = 0$  &lt;/p&gt;
&lt;p&gt;При предположении об отсутствии скоса камеры и квадратных пикселях, мы можем решить эту систему относительно элементов матрицы $\omega_1, \omega_4, \omega_5, \omega_6$ (с точностью до масштаба).  &lt;/p&gt;
&lt;p&gt;Зная матрицу $\omega$, можно вычислить элементы матрицы камеры $K$ с помощью разложения Холецкого. &lt;/p&gt;
&lt;p&gt;Таким образом, мы выполняем калибровку камеры всего по одному изображению. 
После определения $K$ мы можем восстановить 3D-геометрию сцены, вычислить ориентацию всех идентифицированных плоскостей, а также получить обширную информацию о снимаемой сцене с точностью до масштабного коэффициента. &lt;/p&gt;</description><category>cs231a</category><guid>https://mldl.ru/posts/single-view-metrology/</guid><pubDate>Wed, 01 Oct 2025 11:00:00 GMT</pubDate></item><item><title>Калибровка камеры </title><link>https://mldl.ru/posts/camera-calibration/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;p&gt;&lt;strong&gt;Калибровка камеры&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Чтобы точно знать преобразование из реального трёхмерного мира в цифровые изображения, необходимо заранее знать многие внутренние параметры камеры. Если у нас есть произвольная камера, мы можем как иметь доступ к этим параметрам, так и не иметь его. Однако у нас есть доступ к изображениям, которые делает камера.&lt;/p&gt;
&lt;p&gt;Возникает вопрос: можем ли мы найти способ вывести эти параметры из изображений? Эта задача оценки внешних и внутренних параметров камеры известна как &lt;strong&gt;калибровка камеры&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Калибровка камеры&lt;/strong&gt; — это фундаментальный процесс в компьютерном зрении и обработке изображений, который позволяет нам переходить от наблюдаемых пикселей к реальным координатам в пространстве.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 1: Пример калибровочной установки" src="https://storage.yandexcloud.net/yahosting/calibrate/1.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 1: Пример калибровочной установки&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Процесс калибровки камеры заключается в определении &lt;strong&gt;внутренней матрицы камеры&lt;/strong&gt; $K$ и &lt;strong&gt;внешних параметров&lt;/strong&gt; $R$, $T$ из уравнения (1).  &lt;/p&gt;
&lt;p&gt;$P' = K \begin{bmatrix} R &amp;amp; T \end{bmatrix} P_w = MP_w$     (1)&lt;/p&gt;
&lt;p&gt;Рассмотрим этот процесс в контексте калибровочной установки, подобной показанной на рисунке 1.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Калибровочная установка&lt;/strong&gt; обычно состоит из простого шаблона (например, шахматной доски) с известными размерами. Кроме того, установка определяет нашу мировую систему координат с началом $O_w$ и осями $i_w$, $j_w$, $k_w$.&lt;/p&gt;
&lt;p&gt;Из известного шаблона мы получаем точки в мировой системе координат $P_1, ..., P_n$. Найдя эти точки на изображении, полученном с камеры, мы получаем соответствующие точки изображения $p_1, ..., p_n$.&lt;/p&gt;
&lt;p&gt;Мы составляем линейную систему уравнений из $n$ соответствий, таких что для каждого соответствия $P_i$, $p_i$ и матрицы камеры $M$, строки которой $m_1$, $m_2$, $m_3$:&lt;/p&gt;
&lt;p&gt;$p_i = \begin{pmatrix} u_i \\ v_i \end{pmatrix} = MP_i = \begin{pmatrix} \frac{m_1P_i}{m_3P_i} \\ \frac{m_2P_i}{m_3P_i} \end{pmatrix}$ (2)&lt;/p&gt;
&lt;p&gt;Уравнение (2) даёт нам два ограничения для нахождения неизвестных параметров, содержащихся в $m$.&lt;/p&gt;
&lt;p&gt;Мы знаем, что матрица камеры имеет 11 неизвестных параметров (6 внешних и 5 внутренних). Это означает, что нам нужно как минимум 6 соответствий для решения. Однако в реальном мире мы часто используем больше соответствий, поскольку измерения часто зашумлены.&lt;/p&gt;
&lt;p&gt;Для каждой точки $P_i$ мы можем вывести пару уравнений, связывающих координаты на плоскости $u_i, v_i$ с 3D координатами:&lt;/p&gt;
&lt;p&gt;$u_i(m_3P_i) − m_1P_i = 0$&lt;br&gt;
$v_i(m_3P_i) − m_2P_i = 0$&lt;/p&gt;
&lt;p&gt;При наличии $n$ таких соответствующих точек вся линейная система уравнений принимает вид:&lt;/p&gt;
&lt;p&gt;$u_1(m_3P_1)−m_1P_1 = 0$&lt;br&gt;
$v_1(m_3P_1)−m_2P_1 = 0$&lt;br&gt;
...&lt;br&gt;
$u_n(m_3P_n)−m_1P_n = 0$&lt;br&gt;
$v_n(m_3P_n)−m_2P_n = 0$  &lt;/p&gt;
&lt;p&gt;Мы можем вынести вектора $m_1 , m_2, m_3$ и представить эту систему уравнений в виде матричного произведения:&lt;/p&gt;
&lt;p&gt;$\begin{bmatrix}
P_1^T &amp;amp; 0^T &amp;amp; -u_1P_1^T  \\
0^T &amp;amp; P_1^T &amp;amp; -v_1P_1^T  \\
\vdots &amp;amp; \vdots &amp;amp; \vdots \\
P_n^T &amp;amp; 0^T &amp;amp; -u_nP_n^T  \\
0^T &amp;amp; P_n^T &amp;amp; -v_nP_n^T
\end{bmatrix}
\begin{bmatrix}
m_1^T \\
m_2^T \\
m_3^T
\end{bmatrix} = Pm = 0$ (3)&lt;/p&gt;
&lt;p&gt;Когда $2n &amp;gt; 11$, наша однородная линейная система является переопределённой. Для такой системы $m = 0$ всегда является тривиальным решением. Более того, даже если существует ненулевое решение $m$, то для любого $\rho \in \mathbb{R}$, $km$ также будет решением.&lt;/p&gt;
&lt;p&gt;Поэтому для ограничения решения мы выполняем следующую минимизацию:&lt;/p&gt;
&lt;p&gt;$\min_{m} |Pm|^2 \quad \text{при условии} \quad |m|^2 = 1$ (4)&lt;/p&gt;
&lt;p&gt;Для решения этой задачи минимизации используется сингулярное разложение. Если обозначить $P = UDV^T$, то решение задачи минимизации заключается в том, чтобы установить $m$ равным последнему столбцу матрицы $V$.
Обоснование данного решения выходит за рамки этого курса. Для более подробного изучения вы можете обратиться к разделу 5.3 книги Hartley &amp;amp; Zisserman стр. 592–593. &lt;/p&gt;
&lt;p&gt;В этом разделе вы найдёте:&lt;br&gt;
- Математическое обоснование метода&lt;br&gt;
- Подробное доказательство решения&lt;br&gt;
- Дополнительные технические детали  &lt;/p&gt;
&lt;p&gt;После преобразования вектора $m$ в матрицу $M$ мы хотим явно найти внешние и внутренние параметры камеры.&lt;/p&gt;
&lt;p&gt;C помощью SVD мы вычислили матрицу $M$, с точностью до масштабного множителя $\rho$. &lt;/p&gt;
&lt;p&gt;$\rho M = \begin{bmatrix}
\alpha r_1^T - \alpha \cot \theta r_2^T + c_x r_3^T &amp;amp; \alpha t_x - \alpha \cot \theta t_y + c_x t_z \\
\frac{\beta}{\sin \theta} r_2^T + c_y r_3^T &amp;amp; \frac{\beta}{\sin \theta} t_y + c_y t_z \\
r_3^T &amp;amp; t_z
\end{bmatrix}$ (5)&lt;/p&gt;
&lt;p&gt;где $r_1^T$, $r_2^T$, и $r_3^T$ — это три строки матрицы вращения $R$.&lt;/p&gt;
&lt;p&gt;Разделим на скаляр $\rho$ и обозначим первый столбец как матрицу $A$, а второй столбец как вектор $b$:&lt;/p&gt;
&lt;p&gt;$M = \frac{1}{\rho} \begin{bmatrix}
\alpha r_1^T - \alpha \cot \theta r_2^T + c_x r_3^T &amp;amp; \alpha t_x - \alpha \cot \theta t_y + c_x t_z \\
\frac{\beta}{\sin \theta} r_2^T + c_y r_3^T &amp;amp; \frac{\beta}{\sin \theta} t_y + c_y t_z \\
r_3^T &amp;amp; t_z
\end{bmatrix} =
\begin{bmatrix}
A &amp;amp; b
\end{bmatrix} =
\begin{bmatrix}
a_1^T &amp;amp; b_1 \\
a_2^T &amp;amp; b_2 \\
a_3^T &amp;amp; b_3
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;Теперь мы можем вычислить внутренние параметры камеры через элементы известной матрицы $M$, она же $A$ и $b$: (6)&lt;/p&gt;
&lt;p&gt;Масштабный множитель:&lt;br&gt;
$\rho = \pm \frac{1}{|a_3|}$  &lt;/p&gt;
&lt;p&gt;Координаты главной точки:&lt;br&gt;
$c_x = \rho^2 (a_1 \cdot a_3)$&lt;br&gt;
$c_y = \rho^2 (a_2 \cdot a_3)$  &lt;/p&gt;
&lt;p&gt;Угол скоса:&lt;br&gt;
$\theta = \cos^{-1} \left( -\frac{(a_1 \times a_3) \cdot (a_2 \times a_3)}{|a_1 \times a_3| \cdot |a_2 \times a_3|} \right)$ &lt;/p&gt;
&lt;p&gt;Масштабные коэффициенты:&lt;br&gt;
$\alpha = \rho^2 |a_1 \times a_3| \sin \theta$&lt;br&gt;
$\beta = \rho^2 |a_2 \times a_3| \sin \theta$  &lt;/p&gt;
&lt;p&gt;Формулы для вычисления внешних параметров (7)&lt;/p&gt;
&lt;p&gt;Матрица вращения:&lt;br&gt;
  $r_1 = \frac{a_2 \times a_3}{|a_2 \times a_3|}$&lt;br&gt;
  $r_2 = r_3 \times r_1$&lt;br&gt;
  $r_3 = \rho a_3$  &lt;/p&gt;
&lt;p&gt;Вектор переноса:&lt;br&gt;
  $T = \rho K^{-1} b$&lt;/p&gt;
&lt;p&gt;При подготовке данных для процедуры калибровки важно учитывать особые случаи, при которых процесс может дать некорректные результаты. 
 &lt;strong&gt;Вырожденные конфигурации&lt;/strong&gt; возникают, когда точки $P_i$ располагаются в одной плоскости или лежат на кривой пересечения двух квадрик. В таких случаях система уравнений становится неразрешимой, что приводит к невозможности корректного определения параметров камеры.
Чтобы избежать подобных проблем, следует тщательно подходить к процессу калибровки. Необходимо использовать точки с различной глубиной расположения, обеспечивать разнообразие положений калибровочной мишени в пространстве и внимательно следить за распределением точек. Важно также проверять качество получаемых данных и анализировать корректность результатов на тестовых наборах.
Для более глубокого понимания теоретических аспектов рекомендуется обратиться к разделу 1.3.1 учебника Forsyth &amp;amp; Ponce, где подробно рассматриваются вырожденные конфигурации и методы их предотвращения.&lt;/p&gt;
&lt;h4&gt;2. Компенсация искажений при калибровке камеры&lt;/h4&gt;
&lt;p&gt;До этого момента мы рассматривали идеальные линзы, свободные от любых искажений. Однако в реальности объективы могут отклоняться от прямолинейной проекции, что требует применения более сложных методов обработки. В этом разделе мы кратко рассмотрим подходы к работе с искажениями.&lt;/p&gt;
&lt;p&gt;Благодаря физической симметрии линзы &lt;strong&gt;радиальные искажения&lt;/strong&gt; тоже обладают симметрией. 
 Для моделирования радиальных искажений используется изотропное преобразование $Q$:&lt;/p&gt;
&lt;p&gt;$Q P_i =
\begin{bmatrix}
q_1 \\ q_2 \\ q_3
\end{bmatrix} P_i = 
\begin{bmatrix}
\frac{1}{\lambda} &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; \frac{1}{\lambda} &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 1
\end{bmatrix} M P_i = 
\begin{bmatrix}
u_i \\
v_i
\end{bmatrix} = p_i$ (8)&lt;/p&gt;
&lt;p&gt;Переписав в систему векторных уравнений, получаем:  &lt;/p&gt;
&lt;p&gt;$u_i q_3 P_i = q_1 P_i$ &lt;br&gt;
$v_i q_3 P_i = q_2 P_i$   &lt;/p&gt;
&lt;p&gt;Однако такая система перестаёт быть линейной, и для её решения требуются методы &lt;strong&gt;нелинейной оптимизации&lt;/strong&gt;, которые подробно рассматриваются в разделе 22.2 учебника Forsyth &amp;amp; Ponce.&lt;/p&gt;
&lt;p&gt;Упростить процесс нелинейной оптимизации при калибровке можно, сделав определённые допущения. В случае радиальных искажений важно отметить, что соотношение между координатами $u_i$ и $v_i$ остаётся неизменным. Это соотношение можно вычислить следующим образом:&lt;/p&gt;
&lt;p&gt;$\frac{u_i}{v_i} = \frac{\frac{m_1P_i}{m_3P_i}}{\frac{m_2P_i}{m_3P_i}} = \frac{m_1P_i}{m_2P_i}$ (18)&lt;/p&gt;
&lt;p&gt;При наличии $n$ соответствий мы можем составить систему линейных уравнений следующего вида:&lt;/p&gt;
&lt;p&gt;$v_1(m_1P_1) - u_1(m_2P_1) = 0$&lt;br&gt;
$\vdots$&lt;br&gt;
$v_n(m_1P_n) - u_n(m_2P_n) = 0$  &lt;/p&gt;
&lt;p&gt;Эта система может быть представлена в виде матрично-векторного произведения, решаемого с помощью &lt;strong&gt;сингулярного разложения (SVD)&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;$L n = \begin{bmatrix}
v_1P_1^T &amp;amp; -u_1P_1^T \\
\vdots &amp;amp; \vdots \\
v_nP_n^T &amp;amp; -u_nP_n^T
\end{bmatrix}
\begin{bmatrix}
m_1^T \\
m_2^T
\end{bmatrix}$ (19)&lt;/p&gt;
&lt;p&gt;После оценки векторов $m_1$ и $m_2$ вектор $m_3$ может быть выражен как &lt;strong&gt;нелинейная функция&lt;/strong&gt; от $m_1$, $m_2$ и $\lambda$. Это приводит к необходимости решения задачи &lt;strong&gt;нелинейной оптимизации&lt;/strong&gt;, которая значительно проще исходной задачи оценки элементов матрицы $Q$.&lt;/p&gt;
&lt;p&gt;Процесс решения включает следующие этапы:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Формирование матрицы $L n$ на основе известных соответствий между точками  &lt;/li&gt;
&lt;li&gt;Применение SVD для нахождения $m_1$ и $m_2$  &lt;/li&gt;
&lt;li&gt;Вычисление $m_3$ через нелинейную зависимость  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Используем условие ортогональности:  &lt;/p&gt;
&lt;p&gt;$m_1 \cdot m_3 = 0$ и $m_2 \cdot m_3 = 0$  &lt;/p&gt;
&lt;p&gt;Учитываем нормировку:  &lt;/p&gt;
&lt;p&gt;$|m_3| = 1$&lt;/p&gt;
&lt;p&gt;Вводим зависимость от параметра $\lambda$, итоговая формула для вычисления $m_3$ имеет вид:  &lt;/p&gt;
&lt;p&gt;$m_3 = \frac{m_1 \times m_2}{|m_1 \times m_2|} \cdot g(\lambda)$  &lt;/p&gt;
&lt;p&gt;где $g(\lambda)$ — некоторая функция от параметра $\lambda$, зависящая от конкретной модели искажений.&lt;/p&gt;
&lt;p&gt;Вид функции $g(\lambda)$ зависит от требуемой точности модели. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Полиномиальная модель&lt;/strong&gt; общего вида: &lt;/p&gt;
&lt;p&gt;$g(\lambda) = 1 + k_1\lambda^2 + k_2\lambda^4 + k_3\lambda^6 + ...$  &lt;/p&gt;
&lt;p&gt;где $k_1, k_2, k_3$ — коэффициенты радиальных искажений.&lt;/p&gt;
&lt;p&gt;На практике используют вычислительно несложные модели:  &lt;/p&gt;
&lt;p&gt;$g(\lambda) = 1 + k_1\lambda^2$&lt;/p&gt;
&lt;p&gt;или&lt;/p&gt;
&lt;p&gt;$g(\lambda) = 1 + k_1\lambda^2 + k_2\lambda^4$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Модель Брауна&lt;/strong&gt; включает как радиальные, так и тангенциальные искажения:&lt;/p&gt;
&lt;p&gt;$x_{distorted} = x(1 + k_1r^2 + k_2r^4) + 2p_1xy + p_2(r^2 + 2x^2)$  &lt;/p&gt;
&lt;p&gt;$y_{distorted} = y(1 + k_1r^2 + k_2r^4) + p_1(r^2 + 2y^2) + 2p_2xy$  &lt;/p&gt;
&lt;p&gt;где $r^2 = x^2 + y^2$  &lt;/p&gt;
&lt;h4&gt;Резюме&lt;/h4&gt;
&lt;p&gt;Калибровка камеры — это комплексный процесс определения внутренних и внешних параметров оптической системы для точного преобразования координат между трёхмерным пространством и двумерным изображением. 
В основе калибровки лежит использование калибровочной мишени с известными координатами, что позволяет установить соответствие между мировыми и экранными координатами. Процесс включает определение матрицы камеры, которая содержит информацию о фокусном расстоянии, координатах главной точки и коэффициентах искажения.&lt;/p&gt;
&lt;p&gt;Важным этапом является учёт искажений, которые неизбежно присутствуют в реальных объективах. Для их компенсации применяются специальные математические модели, чаще всего основанные на полиномиальных функциях радиальных искажений. 
При калибровке необходимо избегать вырожденных конфигураций, когда точки располагаются в одной плоскости, что делает невозможным корректное определение параметров. 
Практическая реализация требует достаточного количества калибровочных изображений с разнообразным расположением мишени относительно камеры. После завершения калибровки получается набор параметров, позволяющий компенсировать искажения и восстанавливать пространственные координаты по изображениям с точностью до удаления $z$. &lt;/p&gt;
&lt;p&gt;Качество калибровки напрямую влияет на точность последующих измерений и является критически важным этапом в системах компьютерного зрения и машинного обучения.&lt;/p&gt;</description><category>cs231a</category><guid>https://mldl.ru/posts/camera-calibration/</guid><pubDate>Tue, 30 Sep 2025 11:00:00 GMT</pubDate></item><item><title>Основы трехмерного компьютерного зрения </title><link>https://mldl.ru/posts/base-3d/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;h4&gt;1. Введение&lt;/h4&gt;
&lt;p&gt;Камера является одним из важнейших инструментов в компьютерном зрении. Это механизм, с помощью которого мы можем фиксировать окружающий мир и использовать получаемые результаты — фотографии — для различных приложений. Поэтому один из фундаментальных вопросов трехмерного компьютерного зрения звучит так: как мы можем смоделировать камеру? &lt;/p&gt;
&lt;h4&gt;2. Камера-обскура&lt;/h4&gt;
&lt;p&gt;Камера-обскура — это простейшая система, которая позволяет фиксировать изображение объекта или сцены в трёхмерном мире. Такая система может быть создана путём размещения преграды с небольшим отверстием (апертурой) между трёхмерным объектом и фотоплёнкой или светочувствительным сенсором.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 1: Модель камеры обскуры" src="https://storage.yandexcloud.net/yahosting/3d/1.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 1: Модель камеры обскуры&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Как показано на рисунке 1, каждая точка на трёхмерном объекте испускает множество световых лучей во все стороны. Без преграды каждая точка на плёнке подвергалась бы воздействию световых лучей, исходящих от каждой точки трёхмерного объекта. Благодаря наличию преграды через отверстие проходит только один (или несколько) из этих лучей света и попадает на плёнку.&lt;/p&gt;
&lt;p&gt;Таким образом, мы можем установить взаимно-однозначное соответствие между точками на трёхмерном объекте и точками на плёнке. В результате плёнка получает «изображение» трёхмерного объекта посредством такого отображения. Эта простая модель известна как модель камеры-обскуры.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 2: Формальная модель камеры-обскуры" src="https://storage.yandexcloud.net/yahosting/3d/2.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 2: Формальная модель модели камеры-обскуры&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Более формальное построение камеры-обскуры показано на рисунке 2. В этой конструкции плёнка обычно называется &lt;strong&gt;плоскостью изображения&lt;/strong&gt; или &lt;strong&gt;сетчаткой&lt;/strong&gt;. Отверстие называется &lt;strong&gt;точечным отверстием&lt;/strong&gt; O или центром камеры. Расстояние между плоскостью изображения и точечным отверстием O называется &lt;strong&gt;фокусным расстоянием&lt;/strong&gt; f.&lt;/p&gt;
&lt;p&gt;Иногда плоскость сетчатки размещается между точкой O и трёхмерным объектом на расстоянии f от O. В этом случае она называется &lt;strong&gt;виртуальной плоскостью изображения&lt;/strong&gt; или &lt;strong&gt;виртуальной плоскостью сетчатки&lt;/strong&gt;. Важно отметить, что проекция объекта на плоскость изображения и изображение объекта на виртуальной плоскости изображения идентичны с точностью до масштабного (подобного) преобразования.&lt;/p&gt;
&lt;p&gt;Теперь рассмотрим, как использовать камеры-обскуры. Пусть P = [x y z]ᵀ — точка на некотором трёхмерном объекте, видимом для камеры-обскуры. Точка P будет отображена или спроецирована на плоскость изображения Π', в результате чего получится точка P' = [x' y']ᵀ.&lt;/p&gt;
&lt;p&gt;Аналогично, само точечное отверстие может быть спроецировано на плоскость изображения, что даст новую точку C'. Здесь мы можем определить систему координат [i j k], центрированную в точке отверстия O, так что ось k перпендикулярна плоскости изображения и направлена к ней. Эта система координат часто известна как &lt;strong&gt;система отсчёта камеры&lt;/strong&gt; или &lt;strong&gt;система координат камеры&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Линия, определяемая точками C' и O, называется &lt;strong&gt;оптической осью&lt;/strong&gt; системы камеры. &lt;/p&gt;
&lt;p&gt;Напомним, что точка $P_0$ получается в результате проекции трёхмерной точки $P$ на плоскость изображения $Π'$. 
Следовательно, если мы выведем соотношение между трёхмерной точкой $P$ и точкой $P'$ на плоскости изображения, мы сможем понять, как трёхмерный мир отображается на снимке, сделанном камерой-обскурой.&lt;/p&gt;
&lt;p&gt;Обратите внимание, что треугольник $P' C'O$ подобен треугольнику, образованному точками $P$, $O$ и $(0, 0, z)$. 
Используя теорему о подобных треугольниках, мы получаем:&lt;/p&gt;
&lt;p&gt;$P' = \begin{pmatrix} x' \\ y' \end{pmatrix} = \begin{pmatrix} \frac{fx}{z} \\ \frac{fy}{z} \end{pmatrix}$ (1)&lt;/p&gt;
&lt;p&gt;Важно отметить, что в этой модели камеры-обскуры мы делаем одно существенное допущение: апертура (отверстие) считается одной точкой. Однако в большинстве реальных ситуаций мы не можем предполагать, что апертура может быть бесконечно малой. Возникает вопрос: как влияет изменение размера апертуры на результат?&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 3: Влияние размера апертуры на изображение" src="https://storage.yandexcloud.net/yahosting/3d/3.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 3: Влияние размера апертуры на изображение&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;При уменьшении размера апертуры изображение становится более резким, но более тёмным.&lt;/p&gt;
&lt;p&gt;По мере увеличения размера апертуры количество световых лучей, проходящих через преграду, соответственно возрастает. При большем количестве проходящих лучей каждая точка на плёнке может подвергаться воздействию световых лучей от нескольких точек в трёхмерном пространстве, что приводит к размытию изображения.&lt;/p&gt;
&lt;p&gt;Хотя может показаться заманчивым сделать апертуру как можно меньше, следует помнить, что меньший размер апертуры пропускает меньше световых лучей, в результате чего изображение получается более чётким, но более тёмным.&lt;/p&gt;
&lt;p&gt;Таким образом, мы приходим к фундаментальной проблеме, возникающей при использовании  камеры-обскуры: возможно ли создать камеру, которая делает одновременно чёткие и яркие изображения?&lt;/p&gt;
&lt;h4&gt;3. Камеры и линзы&lt;/h4&gt;
&lt;p&gt;В современных камерах указанное противоречие между резкостью и яркостью изображения решается с помощью &lt;strong&gt;линз&lt;/strong&gt; — устройств, способных фокусировать или рассеивать свет.&lt;/p&gt;
&lt;p&gt;Если заменить отверстие (апертуру) камеры-обскуры на линзу, которая правильно расположена и имеет подходящий размер, то она будет обладать следующим свойством: все световые лучи, испускаемые некоторой точкой $P$, преломляются линзой таким образом, что они сходятся в одной точке $P'$. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 4: Схема простой модели линзы" src="https://storage.yandexcloud.net/yahosting/3d/4.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 4: Схема простой модели линзы&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;На рисунке 4 показано, как лучи от верхней точки дерева хорошо сходятся на плёнке. Однако точка, находящаяся на другом расстоянии от линзы, приводит к тому, что лучи не сходятся идеально на плёнке.&lt;/p&gt;
&lt;p&gt;Благодаря линзе проблема блокировки большинства световых лучей из-за малого отверстия устраняется (см. рисунок 4). Однако важно отметить, что это свойство выполняется не для всех точек трёхмерного пространства, а только для определённой точки $P$.&lt;/p&gt;
&lt;p&gt;Рассмотрим другую точку $Q$, которая находится ближе или дальше от плоскости изображения, чем точка $P$. Соответствующая проекция на изображение будет размытой или не в фокусе. Таким образом, у линз есть определённое расстояние, на котором объекты находятся «в фокусе».
Эффективный диапазон, в пределах которого камеры могут делать чёткие снимки называется &lt;strong&gt;глубина резкости&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 5: Фокусировка световых лучей с помощью линзы" src="https://storage.yandexcloud.net/yahosting/3d/5.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 5: Фокусировка световых лучей с помощью линзы&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;На данном рисунке демонстрируется, как линза фокусирует световые лучи, параллельные оптической оси, в &lt;strong&gt;фокусе&lt;/strong&gt; (фокальной точке). Эта схема также иллюстрирует &lt;strong&gt;модель параксиального преломления&lt;/strong&gt; — упрощённую модель, которая помогает установить взаимосвязь между точками на плоскости изображения и объектами в трёхмерном пространстве для камер с линзами.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Параксиальное преломление&lt;/strong&gt; — это приближение, используемое в оптике, которое позволяет:&lt;br&gt;
- точно рассчитывать траектории световых лучей;&lt;br&gt;
- определять положение точек в пространстве;&lt;br&gt;
- вычислять параметры фокусировки;&lt;br&gt;
- моделировать работу оптических систем.  &lt;/p&gt;
&lt;p&gt;Такая модель является фундаментальной для понимания принципов работы современных камер и систем компьютерного зрения. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Объективы камер&lt;/strong&gt; обладают ещё одним важным свойством: они фокусируют все световые лучи, движущиеся параллельно оптической оси, в одну точку, известную как &lt;strong&gt;фокусная точка&lt;/strong&gt; (см. рисунок 5). Расстояние между фокусной точкой и центром линзы называется &lt;strong&gt;фокусным расстоянием&lt;/strong&gt; $f$.&lt;/p&gt;
&lt;p&gt;Кроме того, световые лучи, проходящие через центр линзы, не отклоняются. Благодаря этому мы можем построить конструкцию, аналогичную модели камеры-обскуры, которая связывает точку $P$ в трёхмерном пространстве с соответствующей точкой $P'$ на плоскости изображения:&lt;/p&gt;
&lt;p&gt;$P' = \begin{pmatrix} x' \\ y' \end{pmatrix} = \begin{pmatrix} z' \frac{x}{z} \\ z' \frac{y}{z} \end{pmatrix}$ (2)&lt;/p&gt;
&lt;p&gt;Важно отметить следующие различия между моделями:&lt;br&gt;
- В модели камеры-обскуры $z' = f$&lt;br&gt;
- В модели с линзой $z' = f + z_0$  &lt;/p&gt;
&lt;p&gt;Данное соотношение основано на &lt;strong&gt;параксиальном приближении&lt;/strong&gt; (или предположении о «тонкой линзе»), а такая модель называется &lt;strong&gt;моделью параксиального преломления&lt;/strong&gt;. Подробное доказательство этой модели выходит за рамки данного курса. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 6: Подушкообразное и бочкообразное искажение изображения" src="https://storage.yandexcloud.net/yahosting/3d/6.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 6: Подушкообразное и бочкообразное искажение изображения&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Поскольку модель параксиального преломления использует приближение тонкой линзы, может возникать ряд аберраций. Наиболее распространённой из них является &lt;strong&gt;радиальное искажение&lt;/strong&gt;, которое приводит к уменьшению или увеличению увеличения изображения в зависимости от расстояния до оптической оси.&lt;/p&gt;
&lt;p&gt;Мы классифицируем радиальное искажение следующим образом:&lt;br&gt;
- &lt;strong&gt;Подушкообразное искажение&lt;/strong&gt; — когда увеличение возрастает&lt;br&gt;
- &lt;strong&gt;Бочкообразное искажение&lt;/strong&gt; — когда увеличение уменьшается.  &lt;/p&gt;
&lt;p&gt;Радиальное искажение возникает из-за того, что различные участки линзы имеют разные фокусные расстояния. Это явление наглядно показано на рисунке 6, где можно увидеть, как эти типы искажений влияют на конечное изображение.&lt;/p&gt;
&lt;p&gt;Такие искажения особенно заметны:
- По краям кадра
- При использовании широкоугольных объективов
- В системах компьютерного зрения, где важна точность геометрических измерений &lt;/p&gt;
&lt;h4&gt;4. Матричная модель камеры&lt;/h4&gt;
&lt;p&gt;В этом разделе мы рассмотрим детали параметров, которые необходимо учитывать при моделировании проекции из трёхмерного пространства на известные нам цифровые изображения. Все полученные результаты будут использовать модель камеры-обскуры, но они также применимы и к модели параксиального преломления.&lt;/p&gt;
&lt;p&gt;Как обсуждалось ранее, точка $P$ в трёхмерном пространстве может быть отображена (или спроецирована) в двумерную точку $P'$ на плоскости изображения $Π'$. Такое отображение $R^3 → R^2$ называется &lt;strong&gt;проективным преобразованием&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Однако такая проекция трёхмерных точек на плоскость изображения не соответствует напрямую тому, что мы видим в реальных цифровых изображениях по нескольким причинам:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Точки в цифровых изображениях, как правило, находятся в другой системе отсчёта, чем точки в плоскости изображения.&lt;/li&gt;
&lt;li&gt;Цифровые изображения разделены на дискретные пиксели, тогда как точки в плоскости изображения являются непрерывными.&lt;/li&gt;
&lt;li&gt;Физические датчики могут вносить нелинейные искажения в отображение.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Чтобы учесть эти различия, мы введём ряд дополнительных преобразований, которые позволят нам отображать любую точку из трёхмерного мира в координаты пикселей.&lt;/p&gt;
&lt;p&gt;Таким образом, нам необходимо: &lt;br&gt;
- Учесть различия в системах координат;&lt;br&gt;
- Преобразовать непрерывные координаты в дискретные пиксельные;&lt;br&gt;
- Компенсировать возможные искажения сенсора.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Матричная модель камеры&lt;/strong&gt; описывает набор важных параметров, влияющих на то, как точка мира $P$ отображается в координаты изображения $P'$. Как следует из названия, эти параметры представлены в матричной форме.&lt;/p&gt;
&lt;p&gt;Рассмотрим основные параметры:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Параметры $c_x$ и $c_y$&lt;/strong&gt; описывают разницу между координатами плоскости изображения и цифровыми координатами изображения через перенос.&lt;br&gt;
   - Координаты плоскости изображения имеют начало координат $C_0$ в центре изображения, где ось $k$ пересекает плоскость изображения.&lt;br&gt;
   - Цифровые координаты изображения обычно имеют начало в левом нижнем углу изображения.&lt;br&gt;
   - Таким образом, 2D точки на плоскости изображения и 2D точки в цифровом изображении смещаются на вектор переноса $\begin{pmatrix} c_x \\ c_y \end{pmatrix}^T$.  &lt;/p&gt;
&lt;p&gt;С учётом этого изменения систем координат отображение теперь выглядит так:&lt;/p&gt;
&lt;p&gt;$P' = \begin{pmatrix} x' \\ y' \end{pmatrix} = \begin{pmatrix} \frac{f}{z}x + c_x \\ \frac{f}{z}y + c_y \end{pmatrix}$ (3)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Второй важный эффект&lt;/strong&gt; — это то, что точки в цифровых изображениях выражаются в пикселях, в то время как точки на плоскости изображения представлены в физических измерениях (например, сантиметрах).&lt;/p&gt;
&lt;p&gt;Для учёта этого изменения единиц измерения необходимо ввести два новых параметра $k$ и $l$. Эти параметры имеют размерность [пиксель на сантиметр], соответствуют изменению единиц измерения по двум осям плоскости изображения. Важно отметить, что $k$ и $l$ могут быть разными, поскольку соотношение сторон пикселя не обязательно равно единице. Если $k = l$, мы говорим, что камера имеет квадратные пиксели. 
Мы модифицируем наше предыдущее отображение следующим образом:&lt;/p&gt;
&lt;p&gt;$P_0 = \begin{pmatrix} x' \\ y' \end{pmatrix} = \begin{pmatrix} f k \frac{x}{z} + c_x \\ f l \frac{y}{z} + c_y \end{pmatrix} = \begin{pmatrix} \alpha\frac{x}{z} + c_x \\ \beta\frac{y}{z} + c_y \end{pmatrix}$ (4)&lt;/p&gt;
&lt;p&gt;где&lt;br&gt;
$\alpha = f \cdot k$&lt;br&gt;
$\beta = f \cdot l$&lt;br&gt;
$f$ — фокусное расстояние в мм,&lt;br&gt;
$k$ — размер пикселя по оси x, пикс/мм. &lt;br&gt;
$l$ — размер пикселя по оси x, пикс/мм.  &lt;/p&gt;
&lt;p&gt;Сокращение размерностей приводит к тому, что параметры $\alpha$ и $\beta$ выражаются в пикселях.&lt;br&gt;
Это логично, так как коэффициенты связывают физические измерения (метры) с дискретными единицами цифрового изображения (пиксели).&lt;/p&gt;
&lt;p&gt;Геометрический смысл состоит в том, сколько в пикселях будет объект, размер которого на плоскости проекции равен фокусному расстоянию камеры. &lt;/p&gt;
&lt;p&gt;Таким образом, измерение $\alpha$ и $\beta$ в пикселях является необходимым для:&lt;br&gt;
- Точного проецирования точек;&lt;br&gt;
- Корректной калибровки камеры;&lt;br&gt;
- Работы алгоритмов обработки изображений;&lt;br&gt;
- Взаимодействия между физическим и цифровым пространством.  &lt;/p&gt;
&lt;h4&gt;5. Однородные координаты&lt;/h4&gt;
&lt;p&gt;Теперь рассмотрим вопрос: существует ли линейный способ представления проецирования $P \rightarrow P'$?&lt;/p&gt;
&lt;p&gt;Линейное преобразование на практике является более удобным, т.к. его можно представить как произведение входного вектора $P$ на некоторую матрицу. 
Из уравнения (4) видно, что  проецирование $P \rightarrow P'$ не является линейным, поскольку операция включает деление на один из входных параметров, а именно на $z$.
Тем не менее, представление этого проецирования в виде произведения вектора на матрицу возможно.
Решение заключается в использовании &lt;strong&gt;однородных координат&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;Рассмотрим этот подход:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Введение новой координаты&lt;/strong&gt;:&lt;br&gt;
Любая точка на плоскости $P' = (x', y')$ преобразуется в $(x', y', 1)$&lt;br&gt;
Любая точка в трехмерном пространстве $P = (x, y, z)$ преобразуется в $(x, y, z, 1)$  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Такое расширенное пространство называется &lt;strong&gt;системой однородных координат&lt;/strong&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Преобразование координат&lt;/strong&gt;:&lt;br&gt;
Для преобразования евклидова вектора $(v_1, ..., v_n)$ в однородные координаты мы просто добавляем 1 в новое измерение, получая $(v_1, ..., v_n, 1)$&lt;br&gt;
Важно отметить: равенство между вектором и его однородными координатами выполняется только когда последняя координата равна единице&lt;br&gt;
При обратном преобразовании из произвольных однородных координат $(v_1, ..., v_n, w)$ мы получаем евклидовы координаты $(\frac{v_1}{w}, ..., \frac{v_n}{w})$  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Используя однородные координаты, мы можем сформулировать преобразование следующим образом:&lt;/p&gt;
&lt;p&gt;$P'_h = \begin{bmatrix} \alpha x + c_x z \\ \beta y + c_y z \\ z \end{bmatrix} = \begin{bmatrix} \alpha &amp;amp; 0 &amp;amp; c_x &amp;amp; 0 \\ 0 &amp;amp; \beta &amp;amp; c_y &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{bmatrix} \begin{bmatrix} x \\ y \\ z \\ 1 \end{bmatrix} = \begin{bmatrix} \alpha &amp;amp; 0 &amp;amp; c_x &amp;amp; 0 \\ 0 &amp;amp; \beta &amp;amp; c_y &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{bmatrix} P_h$ (5)&lt;/p&gt;
&lt;p&gt;Преимущества использования однородных координат:&lt;br&gt;
- Позволяют представить нелинейное преобразование в виде матричного умножения;&lt;br&gt;
- Упрощают дальнейшие математические выкладки;&lt;br&gt;
- Обеспечивают единый способ работы с проективными преобразованиями.  &lt;/p&gt;
&lt;p&gt;С этого момента будем работать преимущественно в &lt;strong&gt;однородных координатах&lt;/strong&gt;, если не указано иное. Индекс $h$ опустим, подразумевая, что любая точка $P$ или $P'$ задана в однородных координатах.&lt;/p&gt;
&lt;p&gt;Как видно из уравнения (5), мы можем представить связь между точкой в трёхмерном пространстве и её координатами изображения в виде матрично-векторного соотношения:&lt;/p&gt;
&lt;p&gt;$P' = \begin{bmatrix} x' \\ y' \\ z \end{bmatrix} = \begin{bmatrix} \alpha &amp;amp; 0 &amp;amp; c_x &amp;amp; 0 \\ 0 &amp;amp; \beta &amp;amp; c_y &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{bmatrix} \begin{bmatrix} x \\ y \\ z \\ 1 \end{bmatrix} = \begin{bmatrix} \alpha &amp;amp; 0 &amp;amp; c_x &amp;amp; 0 \\ 0 &amp;amp; \beta &amp;amp; c_y &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{bmatrix} P = MP$ (6)&lt;/p&gt;
&lt;p&gt;где:
- $M$ — &lt;strong&gt;матрица камеры&lt;/strong&gt;&lt;br&gt;
- $P$ — точка в однородных координатах трёхмерного пространства&lt;br&gt;
- $P'$ — проекция точки на плоскость изображения  &lt;/p&gt;
&lt;h4&gt;6. Внутренние параметры камеры&lt;/h4&gt;
&lt;p&gt;Важные параметры матрицы камеры:&lt;br&gt;
- $\alpha$ и $\beta$ — масштабные коэффициенты в направлениях $x$ и $y$&lt;br&gt;
- $c_x$ и $c_y$ — координаты главной точки (principal point)&lt;br&gt;
- Последний столбец матрицы $M$ содержит нули, что характерно для проективных преобразований.  &lt;/p&gt;
&lt;p&gt;Давайте разберем это матричное разложение более подробно:&lt;/p&gt;
&lt;p&gt;Мы можем представить преобразование в виде:&lt;/p&gt;
&lt;p&gt;$P' = MP = \begin{bmatrix} \alpha &amp;amp; 0 &amp;amp; c_x \\ 0 &amp;amp; \beta &amp;amp; c_y \\ 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix} \begin{bmatrix} I &amp;amp; 0 \end{bmatrix} P = K \begin{bmatrix} I &amp;amp; 0 \end{bmatrix} P$ (7)&lt;/p&gt;
&lt;p&gt;где:
- $P'$ — координаты точки на плоскости изображения&lt;br&gt;
- $M$ — полная матрица преобразования&lt;br&gt;
- $K$ — *&lt;em&gt;матрица камеры&lt;/em&gt;- (внутренняя калибровка)&lt;br&gt;
- $I$ — единичная матрица размером 3×3&lt;br&gt;
- $0$ — нулевой вектор размером 3×1&lt;br&gt;
- $P$ — координаты точки в пространстве в однородных координатах.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 7: Проекция точки с помощью матрицы камеры" src="https://storage.yandexcloud.net/yahosting/3d/7.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 7: Проекция точки с помощью матрицы камеры&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Матрица камеры $K$ имеет следующий вид:&lt;/p&gt;
&lt;p&gt;$K = \begin{bmatrix} \alpha &amp;amp; 0 &amp;amp; c_x \\ 0 &amp;amp; \beta &amp;amp; c_y \\ 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix}$&lt;/p&gt;
&lt;p&gt;где:
- $\alpha$ и $\beta$ — масштабные коэффициенты, связанные с фокусным расстоянием&lt;br&gt;
- $c_x$ и $c_y$ — координаты главной точки (principal point)&lt;br&gt;
- Последняя строка [0 0 1] обеспечивает сохранение однородных координат  &lt;/p&gt;
&lt;p&gt;Такое разложение позволяет:
- Выделить внутренние параметры камеры и работать с ними отдельно от внешних;&lt;br&gt;
- Упрощать вычисления при работе с проективными преобразованиями;&lt;br&gt;
- Более эффективно выполнять калибровку камеры;&lt;br&gt;
- Разделять влияние различных параметров на процесс проецирования.  &lt;/p&gt;
&lt;p&gt;Матрица $K$ содержит всю необходимую информацию об &lt;strong&gt;внутренней калибровке&lt;/strong&gt; камеры, что делает её ключевым элементом в задачах компьютерного зрения и обработки изображений. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 8: Расположение главной точки С'" src="https://storage.yandexcloud.net/yahosting/3d/8.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 8: Расположение главной точки С'&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Полная матричная модель камеры $K$ содержит ключевые параметры, описывающие характеристики камеры и её модель, включая параметры $c_x$, $c_y$, $k$ и $l$, как обсуждалось ранее.&lt;/p&gt;
&lt;p&gt;В текущей формулировке отсутствуют два важных параметра:
* &lt;strong&gt;Скос (skewness)&lt;/strong&gt;
* &lt;strong&gt;Дисторсия (distortion)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Скос изображения&lt;/strong&gt; возникает, когда система координат камеры имеет неточный угол между осями (отличающийся от 90 градусов). Большинство камер имеют нулевой скос, однако некоторое его значение может появиться из-за погрешностей при производстве сенсора.&lt;/p&gt;
&lt;p&gt;Матрица камеры с учётом скоса имеет вид:&lt;/p&gt;
&lt;p&gt;$K = \begin{bmatrix} x' \\ y' \\ z \end{bmatrix} = \begin{bmatrix} \alpha &amp;amp; -\alpha \cot \theta &amp;amp; c_x \\ 0 &amp;amp; \frac{\beta}{\sin \theta} &amp;amp; c_y \\ 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix}$ (8)&lt;/p&gt;
&lt;p&gt;где:&lt;br&gt;
- $\alpha$ и $\beta$ — масштабные коэффициенты&lt;br&gt;
- $\theta$ — угол скоса&lt;br&gt;
- $c_x$ и $c_y$ — координаты главной точки  &lt;/p&gt;
&lt;p&gt;В рамках данного курса мы рассматриваем матрицу камеры $K$ с 5 степенями свободы:&lt;br&gt;
- 2 параметра для фокусного расстояния &lt;br&gt;
- 2 параметра для смещения&lt;br&gt;
- 1 параметр для скоса  &lt;/p&gt;
&lt;p&gt;Эти параметры называются &lt;strong&gt;внутренними параметрами камеры&lt;/strong&gt; (intrinsic parameters), так как они:&lt;br&gt;
- Уникальны для каждой конкретной камеры&lt;br&gt;
- Связаны с её конструктивными особенностями&lt;br&gt;
- Определяются при производстве  &lt;/p&gt;
&lt;p&gt;Важно отметить, что большинство методов компьютерного зрения игнорируют эффекты дисторсии, позволяя состедоточиться на 4 основных параметрах камеры.&lt;/p&gt;
&lt;h4&gt;7. Внешние параметры камеры&lt;/h4&gt;
&lt;p&gt;До сих пор мы описывали отображение точки $P$ из трёхмерной системы координат камеры в точку $P'$ на двумерной плоскости изображения, используя внутренние параметры камеры в матричной форме.&lt;/p&gt;
&lt;p&gt;Однако возникает вопрос: что делать, если информация о трёхмерном мире представлена в другой системе координат? В этом случае необходимо добавить дополнительное преобразование, связывающее точки из мировой системы координат с системой координат камеры.&lt;/p&gt;
&lt;p&gt;Это преобразование описывается:
- &lt;strong&gt;Матрицей вращения&lt;/strong&gt; $R$
- &lt;strong&gt;Вектором переноса&lt;/strong&gt; $T$&lt;/p&gt;
&lt;p&gt;Таким образом, для точки $P_w$ в мировой системе координат её координаты в системе камеры можно вычислить следующим образом:&lt;/p&gt;
&lt;p&gt;$P = \begin{bmatrix} R &amp;amp; T \\ 0 &amp;amp; 1 \end{bmatrix} P_w$ (9)&lt;/p&gt;
&lt;p&gt;где:
- $R$ — матрица вращения размером 3×3&lt;br&gt;
- $T$ — вектор переноса размером 3×1&lt;br&gt;
- $P_w$ — координаты точки в мировой системе&lt;br&gt;
- $P$ — координаты точки в системе камеры  &lt;/p&gt;
&lt;p&gt;Подставляя это в уравнение (7) и упрощая, получаем:&lt;/p&gt;
&lt;p&gt;$P' = K \begin{bmatrix} R &amp;amp; T \end{bmatrix} P_w = MP_w$ (10)&lt;/p&gt;
&lt;p&gt;Параметры $R$ и $T$ называются &lt;strong&gt;внешними параметрами&lt;/strong&gt;, поскольку они:&lt;br&gt;
- Находятся вне камеры&lt;br&gt;
- Не зависят от характеристик камеры  &lt;/p&gt;
&lt;p&gt;Это завершает описание отображения трёхмерной точки $P$ из произвольной мировой системы координат на плоскость изображения.&lt;/p&gt;
&lt;h4&gt;Резюме&lt;/h4&gt;
&lt;p&gt;Полная матрица проекции $M$ состоит из двух типов параметров:
- &lt;strong&gt;Внутренние параметры&lt;/strong&gt; (intrinsic parameters) — содержатся в матрице камеры $K$, меняются при смене типа камеры&lt;br&gt;
- &lt;strong&gt;Внешние параметры&lt;/strong&gt; (extrinsic parameters) — включают вращение и перенос, не зависят от конструкции камеры  &lt;/p&gt;
&lt;p&gt;Полная матрица проекции $M$ размером 3×4 имеет 11 степеней свободы:&lt;br&gt;
- 5 степеней свободы от внутренней матрицы камеры&lt;br&gt;
- 3 степени свободы от внешнего вращения&lt;br&gt;
- 3 степени свободы от внешнего переноса  &lt;/p&gt;
&lt;p&gt;Таким образом, мы получили полное описание процесса проецирования точки из трёхмерного пространства на плоскость изображения, учитывающее как характеристики самой камеры, так и её положение в пространстве относительно наблюдаемой сцены.&lt;/p&gt;</description><category>cs231a</category><guid>https://mldl.ru/posts/base-3d/</guid><pubDate>Mon, 29 Sep 2025 11:00:00 GMT</pubDate></item></channel></rss>