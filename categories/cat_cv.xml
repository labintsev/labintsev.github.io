<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Заметки по ML, DL (Записи о CV)</title><link>https://mldl.ru/</link><description></description><atom:link href="https://mldl.ru/categories/cat_cv.xml" rel="self" type="application/rss+xml"></atom:link><language>ru</language><copyright>Contents © 2025 &lt;a href="mailto:andrej.labintsev@yandex.ru"&gt;Андрей Лабинцев&lt;/a&gt; </copyright><lastBuildDate>Wed, 01 Oct 2025 17:42:24 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Измерение углов </title><link>https://mldl.ru/posts/single-view-metrology/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;h4&gt;Введение&lt;/h4&gt;
&lt;p&gt;На предыдущих лекциях мы обсуждали, как можно преобразовывать точки из реального трёхмерного мира в цифровые изображения, используя внешние и внутренние характеристики камер. Мы рассмотрели, как можно использовать известную структуру калибровочной установки и соответствующие изображения для определения характеристик камеры. &lt;/p&gt;
&lt;p&gt;Теперь мы обратимся к смежной проблеме: можно ли восстановить известную структуру трёхмерного мира, если у нас есть единственное изображение и известны свойства камеры, которой это изображение было сделано? И наконец мы рассмотрим алгоритм калибровки камеры и измерения углов между плоскостями на одиночном изображении. &lt;/p&gt;
&lt;h4&gt;1. Преобразования в 2D пространстве&lt;/h4&gt;
&lt;p&gt;Чтобы лучше понять, как мы можем извлекать информацию из изображений, сначала необходимо разобраться с различными преобразованиями в двумерном пространстве.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Изометрические преобразования&lt;/strong&gt; — это преобразования, сохраняющие расстояния. В своей базовой форме изометрия может быть описана как вращение $R$ и перенос $t$. Математически они определяются следующим образом:&lt;/p&gt;
&lt;p&gt;$\begin{bmatrix}
x' \\
y' \\
1
\end{bmatrix} = 
\begin{bmatrix}
R &amp;amp; t \\
0 &amp;amp; 1
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
1
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;где $(x', y', 1)^T$ — точка, полученная после изометрического преобразования.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Преобразования подобия&lt;/strong&gt; — это преобразования, сохраняющие форму. Интуитивно они могут выполнять всё то же, что и изометрические преобразования, плюс масштабирование. Математически они обозначаются так:&lt;/p&gt;
&lt;p&gt;$\begin{bmatrix}
x' \\
y' \\
1
\end{bmatrix} = 
\begin{bmatrix}
SR &amp;amp; t \\
0 &amp;amp; 1
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
1
\end{bmatrix} $  &lt;/p&gt;
&lt;p&gt;$ S = 
\begin{bmatrix}
s &amp;amp; 0 \\
0 &amp;amp; s
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Преобразования подобия&lt;/strong&gt; сохраняют форму объектов, а значит, сохраняют:&lt;br&gt;
&lt;em&gt; Отношения длин отрезков&lt;br&gt;
&lt;/em&gt; Величины углов  &lt;/p&gt;
&lt;p&gt;Важно отметить, что любое &lt;strong&gt;изометрическое преобразование&lt;/strong&gt; является частным случаем преобразования подобия при $s = 1$. Однако обратное утверждение неверно.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Аффинные преобразования&lt;/strong&gt; сохраняют:&lt;br&gt;
&lt;em&gt; Точки&lt;br&gt;
&lt;/em&gt; Прямые линии&lt;br&gt;
* Параллельность прямых  &lt;/p&gt;
&lt;p&gt;Для вектора $v$ аффинное преобразование $T$ определяется как:
$T(v) = Av + t$, где $A$ — линейное преобразование пространства $R^n$&lt;/p&gt;
&lt;p&gt;В однородных координатах аффинные преобразования записываются так:  &lt;/p&gt;
&lt;p&gt;$\begin{bmatrix}
x' \\
y' \\
1
\end{bmatrix} = 
\begin{bmatrix}
A &amp;amp; t \\
0 &amp;amp; 1
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
1
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;Из этого уравнения видно, что все преобразования подобия (и, следовательно, изометрии) являются частным случаем аффинных преобразований.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Проективные преобразования&lt;/strong&gt; (или гомографии) — это преобразования, которые переводят прямые в прямые, но не обязательно сохраняют параллельность.&lt;/p&gt;
&lt;p&gt;В однородных координатах проективные преобразования представляются как: &lt;/p&gt;
&lt;p&gt;$\begin{bmatrix}
x' \\
y' \\
1
\end{bmatrix} = 
\begin{bmatrix}
A &amp;amp; t \\
v &amp;amp; b
\end{bmatrix}
\begin{bmatrix}
x \\
y \\
1
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;Это представление является обобщением аффинных преобразований за счёт добавления вектора $v$, который вводит дополнительные степени свободы.&lt;/p&gt;
&lt;p&gt;Несмотря на то, что проективные преобразования не сохраняют параллельность, они сохраняют:&lt;br&gt;
&lt;em&gt; Коллинеарность точек (прямые переходят в прямые)&lt;br&gt;
&lt;/em&gt; Перекрестное отношение четырёх коллинеарных точек.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Перекрестное отношение&lt;/strong&gt; четырёх точек $P_1, P_2, P_3, P_4$, лежащих на одной прямой, вычисляется по формуле:  &lt;/p&gt;
&lt;p&gt;$cross\ ratio = \frac{||P_3 - P_1||\ ||P_4 - P_2||}{||P_3 - P_2||\ ||P_4 - P_1||}$ (1)&lt;/p&gt;
&lt;p&gt;Доказательство инвариантности перекрестного отношения при проективных преобразованиях предлагается выполнить в качестве учебного упражнения. &lt;/p&gt;
&lt;h4&gt;2. Точки и прямые в бесконечности&lt;/h4&gt;
&lt;p&gt;Прямые играют важную роль в определении структуры изображений, поэтому важно понимать их представление как в 2D, так и в 3D пространстве.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Прямая на плоскости&lt;/strong&gt; может быть представлена однородным вектором $\ell = \begin{bmatrix} a &amp;amp; b &amp;amp; c \end{bmatrix}^T$.  &lt;/p&gt;
&lt;p&gt;Отношение $-\frac{a}{b}$ определяет наклон прямой, а отношение $-\frac{c}{b}$ — точку пересечения с осью $y$.  &lt;/p&gt;
&lt;p&gt;Для любой точки, лежащей на прямой, справедливо уравнение:&lt;/p&gt;
&lt;p&gt;$\forall p = \begin{bmatrix} x \\ y \end{bmatrix} \in \ell, \quad \begin{bmatrix} a &amp;amp; b &amp;amp; c \end{bmatrix} \begin{bmatrix} x \\ y \\ 1 \end{bmatrix} = 0$ (2)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Пересечение прямых&lt;/strong&gt;&lt;br&gt;
В общем случае две прямые $\ell$ и $\ell'$ пересекаются в точке $x$, которая определяется как векторное произведение этих прямых.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Доказательство: если две прямые пересекаются, точка пересечения $x$ должна лежать на обеих прямых. Следовательно, $x^T\ell = 0$ и $x^T\ell' = 0$. Если мы положим $x = \ell \times \ell'$, то по определению векторного произведения вектор $x$ будет ортогонален обоим векторам $\ell$ и $\ell'$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Параллельные прямые&lt;/strong&gt;&lt;br&gt;
В школьной геометрии считается, что параллельные прямые не пересекаются. Однако в однородных координатах можно сказать, что они пересекаются в бесконечности.  &lt;/p&gt;
&lt;p&gt;Рассмотрим две параллельные прямые $\ell$ и $\ell'$. Когда прямые параллельны, их наклоны равны: $\frac{a}{b} = \frac{a'}{b'}$. Если вычислить точку пересечения в однородных координатах, получим:&lt;/p&gt;
&lt;p&gt;$\ell \times \ell' \propto \begin{bmatrix} b \\ -a \\ 0 \end{bmatrix} = x_\infty$ (3)&lt;/p&gt;
&lt;p&gt;Это подтверждает, что параллельные прямые пересекаются в бесконечности. Точка пересечения параллельных прямых в бесконечности называется &lt;strong&gt;идеальной точкой&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;В однородных координатах идеальная точка в бесконечности представляется как:&lt;/p&gt;
&lt;p&gt;$\begin{bmatrix} x \ y \ 0 \end{bmatrix}^T$ &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Свойство идеальных точек&lt;/strong&gt;
Все параллельные прямые с одинаковым наклоном $-\frac{a}{b}$ проходят через идеальную точку:&lt;/p&gt;
&lt;p&gt;$\ell^T x_\infty = \begin{bmatrix} a &amp;amp; b &amp;amp; c \end{bmatrix} \begin{bmatrix} b \\ -a \\ 0 \end{bmatrix} = 0$ (4)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Бесконечно удалённые точки&lt;/strong&gt; позволяют определить прямую в бесконечности. Рассмотрим несколько пар параллельных прямых. Каждая пара пересекается в своей точке бесконечности $x_{\infty,i}$. Прямая $\ell_\infty$, проходящая через все эти точки, должна удовлетворять условию:&lt;/p&gt;
&lt;p&gt;$\forall i, \ell_\infty^T x_{\infty,i} = 0$&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 1: Точки в бесконечности образуют прямые в бесконечности" src="https://storage.yandexcloud.net/yahosting/photo_metro/1.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 1: Точки в бесконечности образуют прямые в бесконечности&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;Такая прямая имеет вид $\ell_\infty = \begin{bmatrix} 0 &amp;amp; 0 &amp;amp; c \end{bmatrix}^T$. Поскольку $c$ — произвольное значение, можно принять:&lt;/p&gt;
&lt;p&gt;$\ell_\infty = \begin{bmatrix} 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix}^T$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Проективное преобразование&lt;/strong&gt; точки в бесконечности:&lt;/p&gt;
&lt;p&gt;При применении проективного преобразования $H$ к точке в бесконечности $p_\infty$ получаем:&lt;/p&gt;
&lt;p&gt;$p' = Hp_\infty = \begin{bmatrix} A &amp;amp; t \\ v &amp;amp; b \end{bmatrix} \begin{bmatrix} 1 \\ 1 \\ 0 \end{bmatrix} = \begin{bmatrix} p'_x \\ p'_y \\ p'_z \end{bmatrix}$ (5)&lt;/p&gt;
&lt;p&gt;Заметим, что последний элемент $p'$ может стать ненулевым. Это означает, что проективное преобразование обычно переводит точки в бесконечности в точки, которые уже не находятся в бесконечности. Т.е. имеют конечные евклидовы координаты, пусть и за пределами изображения. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Аффинные преобразования&lt;/strong&gt; ведут себя иначе и всегда переводят точку из бесконечности в бесконечность:&lt;/p&gt;
&lt;p&gt;$p' = Hp_\infty = \begin{bmatrix} A &amp;amp; t \\ 0 &amp;amp; 1 \end{bmatrix} \begin{bmatrix} 1 \\ 1 \\ 0 \end{bmatrix} = \begin{bmatrix} p'_x \\ p'_y \\ 0 \end{bmatrix}$ (6)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Преобразование прямых&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;При применении проективного преобразования $H$ к прямой $\ell$ получаем новую прямую $\ell'$. Все точки $x$, лежащие на прямой, должны удовлетворять условию $x^T\ell = 0$. В преобразованном пространстве прямые переходят в прямые, то есть $x'^T\ell' = 0$. Используя свойство тождественного преобразования, получаем:&lt;/p&gt;
&lt;p&gt;$x^TI\ell = x^TH^TH^{-T}\ell = 0$&lt;/p&gt;
&lt;p&gt;При применении &lt;strong&gt;проективного преобразования&lt;/strong&gt; к прямой происходит преобразование всех точек, лежащих на ней. Если $x$ — точка исходной прямой, то после преобразования получаем:&lt;/p&gt;
&lt;p&gt;$x' = Hx$&lt;/p&gt;
&lt;p&gt;Используя это преобразование, можно записать:&lt;/p&gt;
&lt;p&gt;$x^TH^TH^{-T}\ell = x'^T\ell'$,&lt;/p&gt;
&lt;p&gt;откуда следует, что проективное преобразование прямой имеет вид:&lt;/p&gt;
&lt;p&gt;$\ell' = H^{-T}\ell$&lt;/p&gt;
&lt;p&gt;Важные выводы:&lt;br&gt;
&lt;em&gt; При проективном преобразовании прямая в бесконечности не обязательно переходит в другую прямую в бесконечности&lt;br&gt;
&lt;/em&gt; В отличие от этого, &lt;strong&gt;аффинные преобразования&lt;/strong&gt; сохраняют прямые в бесконечности, переводя их в прямые в бесконечности.  &lt;/p&gt;
&lt;p&gt;Эти свойства имеют важное значение для понимания того, как различные типы преобразований влияют на структуру изображения и геометрию сцены. Особенно это касается работы с бесконечно удалёнными точками и прямыми, которые играют ключевую роль в проективной геометрии и компьютерном зрении.&lt;/p&gt;
&lt;p&gt;Таким образом, при работе с проективными преобразованиями необходимо учитывать, что они могут существенно изменять геометрию сцены, в том числе расположение прямых и точек в бесконечности, в то время как аффинные преобразования сохраняют некоторые геометрические свойства. &lt;/p&gt;
&lt;h4&gt;3. Точки и линии схода&lt;/h4&gt;
&lt;p&gt;В трёхмерном пространстве вводится понятие &lt;strong&gt;плоскости&lt;/strong&gt;, которая представляется вектором $\begin{bmatrix} a &amp;amp; b &amp;amp; c &amp;amp; d \end{bmatrix}^T$. 
Здесь $(a, b, c)$ образуют вектор нормали, а $d$ — расстояние от начала координат до плоскости в направлении этого вектора. Формально плоскость определяется как множество точек $x$, удовлетворяющих уравнению:&lt;/p&gt;
&lt;p&gt;$x^T \begin{bmatrix} a \\ b \\ c \\ d \end{bmatrix} = ax_1 + bx_2 + cx_3 + d = 0$ (7)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Прямые в 3D&lt;/strong&gt; определяются как пересечение двух плоскостей. Они имеют четыре степени свободы (точка пересечения и наклоны в трёх измерениях).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Точки в бесконечности&lt;/strong&gt; в 3D определяются как точки пересечения параллельных прямых. При проективном преобразовании таких точек получается &lt;strong&gt;точка схода&lt;/strong&gt; $p_\infty$ на плоскости изображения.&lt;/p&gt;
&lt;p&gt;Существует полезное соотношение между параллельными прямыми в 3D, их точкой схода на изображении и параметрами камеры $K$, $R$, $T$.&lt;/p&gt;
&lt;p&gt;Пусть $d = (a, b, c)$ — направление набора параллельных прямых в системе координат камеры. Тогда точка схода $v$ определяется как:&lt;/p&gt;
&lt;p&gt;$v = Kd$ (8)&lt;/p&gt;
&lt;p&gt;Отсюда можно выразить направление $d$:&lt;/p&gt;
&lt;p&gt;$d = \frac{K^{-1}v}{|K^{-1}v|}$ (9)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Линия горизонта&lt;/strong&gt; (или линия схода) $l_{horiz}$ — это проекция линии в бесконечности на плоскость изображения. Она проходит через соответствующие точки схода на изображении и вычисляется по формуле:&lt;/p&gt;
&lt;p&gt;$l_{horiz} = H^{-T}P l_\infty$ (10)&lt;/p&gt;
&lt;p&gt;Точки и линии схода являются важными инструментами для анализа структуры сцены и определения параметров камеры по изображению, т.к. они позволяют восстанавливать трёхмерную геометрию по двумерной проекции. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 2: Линия горизонта как множество точек схода" src="https://storage.yandexcloud.net/yahosting/photo_metro/2.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Линия горизонта&lt;/strong&gt; позволяет нам интуитивно определять свойства изображения, которые могут быть неочевидны с математической точки зрения. Например,  линии на земле не выглядят параллельными на изображении (как показано на рисунке 2), но интуитивно мы все же понимаем, что в трёхмерном пространстве они параллельны.&lt;/p&gt;
&lt;p&gt;Линия горизонта позволяет &lt;strong&gt;вычислять&lt;/strong&gt; важные характеристики сцены. Существует интересное соотношение между нормалью $n$ плоскости в 3D и соответствующей линией горизонта $l_{horiz}$ на изображении:&lt;/p&gt;
&lt;p&gt;$n = K^Tl_{horiz}$ (11)&lt;/p&gt;
&lt;p&gt;Это означает, что если мы можем определить линию горизонта, связанную с плоскостью, и знаем внутренние характеристики камеры $K$, мы можем оценить ориентацию этой плоскости.&lt;/p&gt;
&lt;p&gt;Теперь давайте рассмотрим понятие &lt;strong&gt;плоскость в бесконечности&lt;/strong&gt;.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 3: Плоскость в бесконечности" src="https://storage.yandexcloud.net/yahosting/photo_metro/3.jpg"&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 3: Плоскость в бесконечности&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Эта плоскость определяется набором из двух или более линий схода. В однородных координатах плоскость описывается вектором:&lt;/p&gt;
&lt;p&gt;$Π_\infty = \begin{bmatrix} 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix}^T$ &lt;/p&gt;
&lt;p&gt;Плоскость в бесконечности поможет нам понять важное свойство, связывающее линии и плоскости в 3D с соответствующими точками и линиями схода на плоскости изображения.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 4: Определение угла между линиями" src="https://storage.yandexcloud.net/yahosting/photo_metro/4.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 4: Определение угла между линиями&lt;/strong&gt;  &lt;/p&gt;
&lt;p&gt;Пусть две пары параллельных линий в 3D имеют направления $d_1$ и $d_2$, связанные с точками в бесконечности $x_{1,\infty}$ и $x_{2,\infty}$. 
Пусть $v_1$ и $v_2$ — соответствующие точки схода. 
Тогда угол $θ$ между $d_1$ и $d_2$ определяется по формуле:&lt;/p&gt;
&lt;p&gt;$\cos θ = \frac{d_1 \cdot d_2}{|d_1||d_2|} = \frac{v_1^T \omega v_2}{\sqrt{v_1^T \omega v_1} \sqrt{v_2^T \omega v_2}}$ (12)&lt;/p&gt;
&lt;p&gt;где $\omega = (KK^T)^{-1}$.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Матрица $\omega$&lt;/strong&gt; определяется через матрицу камеры $K$ следующим образом:&lt;/p&gt;
&lt;p&gt;$\omega = (K K^T)^{-1}$&lt;/p&gt;
&lt;p&gt;Эта матрица имеет важные свойства:  &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Симметричность: матрица $\omega$ является симметричной, так как $K K^T$ — симметричная матрица, а обратная к симметричной матрице также симметрична&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Связь с параметрами камеры: содержит информацию о внутренних параметрах камеры, зависит от фокусных расстояний, координат главной точки и коэффициента скоса (skew).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;При стандартных предположениях о камере (нулевой скос, квадратные пиксели) матрица $\omega$ имеет вид:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;$\omega = \begin{bmatrix}
\omega_1 &amp;amp; 0 &amp;amp; \omega_4 \\
0 &amp;amp; \omega_1 &amp;amp; \omega_5 \\
\omega_4 &amp;amp; \omega_5 &amp;amp; \omega_6
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;Матрица $\omega$ определяется с точностью до масштабного множителя, что влияет на количество независимых переменных при решении системы уравнений. Это свойство учитывается при калибровке камеры и восстановлении 3D-структуры сцены.&lt;/p&gt;
&lt;p&gt;Это соотношение показывает, как можно определить угол между направлениями в пространстве, используя только точки схода на изображении и параметры камеры.&lt;/p&gt;
&lt;p&gt;И наконец, расширим рассмотренную концепцию на случай трёхмерных плоскостей, чтобы установить связь между различными плоскостями в 3D пространстве.&lt;/p&gt;
&lt;p&gt;Для любой плоскости мы можем:&lt;br&gt;
&lt;em&gt; Вычислить соответствующую линию горизонта $l_{horiz}$&lt;br&gt;
&lt;/em&gt; Определить нормаль к плоскости $n = K^\ l_{horiz}$  &lt;/p&gt;
&lt;p&gt;Угол $\theta$ между двумя плоскостями можно определить через угол между их нормалями $n_1$ и $n_2$. 
Рассмотрим две плоскости с линиями горизонта $l_1$ и $l_2$ соответственно. 
Угол между нормалями этих плоскостей определяется формулой:&lt;/p&gt;
&lt;p&gt;$\cos \theta = \frac{n_1 \cdot n_2}{|n_1||n_2|} = \frac{l_1^T \omega^{-1} l_2}{\sqrt{l_1^T \omega^{-1} l_1} \sqrt{l_2^T \omega^{-1} l_2}}$ (13)&lt;/p&gt;
&lt;p&gt;Таким образом, используя линии горизонта и параметры камеры, мы можем восстанавливать пространственные отношения между плоскостями в сцене, что является важным инструментом в компьютерном зрении и трёхмерной реконструкции.&lt;/p&gt;
&lt;h4&gt;4. Алгоритм калибровки камеры и измерения углов&lt;/h4&gt;
&lt;p&gt;Рассмотрим пример решения задачи калибровки камеры по одной фотографии. 
Для этого нам понадобится изображение трёхмерного мира, на котором мы можем выполнить следующие операции:&lt;br&gt;
&lt;em&gt; Определить три плоскости и на каждой из этих плоскостей пару параллельных линий&lt;br&gt;
&lt;/em&gt; Идентифицировать точки схода $v_1$ $v_2$ и $v_3$&lt;br&gt;
* Использовать априорное знание и том, что плоскости перпендикулярны в 3D пространстве.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 5: Точки схода на перпендикулярных плоскостях" src="https://storage.yandexcloud.net/yahosting/photo_metro/6.jpg"&gt;  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 5: Точки схода на перпендикулярных плоскостях&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Из уравнения (12) мы знаем, что для перпендикулярных плоскостей выполняется соотношение $v_1\omega v_2 = 0$. &lt;/p&gt;
&lt;p&gt;Если мы имеем три точки схода для трех взаимно перпендикулярной плоскости, то получаем систему: &lt;/p&gt;
&lt;p&gt;$v_1\omega v_2 = 0$&lt;br&gt;
 $v_1\omega v_3 = 0$&lt;br&gt;
 $v_2\omega v_3 = 0$  &lt;/p&gt;
&lt;p&gt;При предположении об отсутствии скоса камеры и квадратных пикселях, мы можем решить эту систему относительно элементов матрицы $\omega_1, \omega_4, \omega_5, \omega_6$ (с точностью до масштаба).  &lt;/p&gt;
&lt;p&gt;Зная матрицу $\omega$, можно вычислить элементы матрицы камеры $K$ с помощью разложения Холецкого. &lt;/p&gt;
&lt;p&gt;Таким образом, мы выполняем калибровку камеры всего по одному изображению. 
После определения $K$ мы можем восстановить 3D-геометрию сцены, вычислить ориентацию всех идентифицированных плоскостей, а также получить обширную информацию о снимаемой сцене с точностью до масштабного коэффициента. &lt;/p&gt;</description><category>cs231a</category><guid>https://mldl.ru/posts/single-view-metrology/</guid><pubDate>Wed, 01 Oct 2025 11:00:00 GMT</pubDate></item><item><title>Калибровка камеры </title><link>https://mldl.ru/posts/camera-calibration/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;p&gt;&lt;strong&gt;Калибровка камеры&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Чтобы точно знать преобразование из реального трёхмерного мира в цифровые изображения, необходимо заранее знать многие внутренние параметры камеры. Если у нас есть произвольная камера, мы можем как иметь доступ к этим параметрам, так и не иметь его. Однако у нас есть доступ к изображениям, которые делает камера.&lt;/p&gt;
&lt;p&gt;Возникает вопрос: можем ли мы найти способ вывести эти параметры из изображений? Эта задача оценки внешних и внутренних параметров камеры известна как &lt;strong&gt;калибровка камеры&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Калибровка камеры&lt;/strong&gt; — это фундаментальный процесс в компьютерном зрении и обработке изображений, который позволяет нам переходить от наблюдаемых пикселей к реальным координатам в пространстве.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 1: Пример калибровочной установки" src="https://storage.yandexcloud.net/yahosting/calibrate/1.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 1: Пример калибровочной установки&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Процесс калибровки камеры заключается в определении &lt;strong&gt;внутренней матрицы камеры&lt;/strong&gt; $K$ и &lt;strong&gt;внешних параметров&lt;/strong&gt; $R$, $T$ из уравнения (1).  &lt;/p&gt;
&lt;p&gt;$P' = K \begin{bmatrix} R &amp;amp; T \end{bmatrix} P_w = MP_w$     (1)&lt;/p&gt;
&lt;p&gt;Рассмотрим этот процесс в контексте калибровочной установки, подобной показанной на рисунке 1.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Калибровочная установка&lt;/strong&gt; обычно состоит из простого шаблона (например, шахматной доски) с известными размерами. Кроме того, установка определяет нашу мировую систему координат с началом $O_w$ и осями $i_w$, $j_w$, $k_w$.&lt;/p&gt;
&lt;p&gt;Из известного шаблона мы получаем точки в мировой системе координат $P_1, ..., P_n$. Найдя эти точки на изображении, полученном с камеры, мы получаем соответствующие точки изображения $p_1, ..., p_n$.&lt;/p&gt;
&lt;p&gt;Мы составляем линейную систему уравнений из $n$ соответствий, таких что для каждого соответствия $P_i$, $p_i$ и матрицы камеры $M$, строки которой $m_1$, $m_2$, $m_3$:&lt;/p&gt;
&lt;p&gt;$p_i = \begin{pmatrix} u_i \\ v_i \end{pmatrix} = MP_i = \begin{pmatrix} \frac{m_1P_i}{m_3P_i} \\ \frac{m_2P_i}{m_3P_i} \end{pmatrix}$ (2)&lt;/p&gt;
&lt;p&gt;Уравнение (2) даёт нам два ограничения для нахождения неизвестных параметров, содержащихся в $m$.&lt;/p&gt;
&lt;p&gt;Мы знаем, что матрица камеры имеет 11 неизвестных параметров (6 внешних и 5 внутренних). Это означает, что нам нужно как минимум 6 соответствий для решения. Однако в реальном мире мы часто используем больше соответствий, поскольку измерения часто зашумлены.&lt;/p&gt;
&lt;p&gt;Для каждой точки $P_i$ мы можем вывести пару уравнений, связывающих координаты на плоскости $u_i, v_i$ с 3D координатами:&lt;/p&gt;
&lt;p&gt;$u_i(m_3P_i) − m_1P_i = 0$&lt;br&gt;
$v_i(m_3P_i) − m_2P_i = 0$&lt;/p&gt;
&lt;p&gt;При наличии $n$ таких соответствующих точек вся линейная система уравнений принимает вид:&lt;/p&gt;
&lt;p&gt;$u_1(m_3P_1)−m_1P_1 = 0$&lt;br&gt;
$v_1(m_3P_1)−m_2P_1 = 0$&lt;br&gt;
...&lt;br&gt;
$u_n(m_3P_n)−m_1P_n = 0$&lt;br&gt;
$v_n(m_3P_n)−m_2P_n = 0$  &lt;/p&gt;
&lt;p&gt;Мы можем вынести вектора $m_1 , m_2, m_3$ и представить эту систему уравнений в виде матричного произведения:&lt;/p&gt;
&lt;p&gt;$\begin{bmatrix}
P_1^T &amp;amp; 0^T &amp;amp; -u_1P_1^T  \\
0^T &amp;amp; P_1^T &amp;amp; -v_1P_1^T  \\
\vdots &amp;amp; \vdots &amp;amp; \vdots \\
P_n^T &amp;amp; 0^T &amp;amp; -u_nP_n^T  \\
0^T &amp;amp; P_n^T &amp;amp; -v_nP_n^T
\end{bmatrix}
\begin{bmatrix}
m_1^T \\
m_2^T \\
m_3^T
\end{bmatrix} = Pm = 0$ (3)&lt;/p&gt;
&lt;p&gt;Когда $2n &amp;gt; 11$, наша однородная линейная система является переопределённой. Для такой системы $m = 0$ всегда является тривиальным решением. Более того, даже если существует ненулевое решение $m$, то для любого $\rho \in \mathbb{R}$, $km$ также будет решением.&lt;/p&gt;
&lt;p&gt;Поэтому для ограничения решения мы выполняем следующую минимизацию:&lt;/p&gt;
&lt;p&gt;$\min_{m} |Pm|^2 \quad \text{при условии} \quad |m|^2 = 1$ (4)&lt;/p&gt;
&lt;p&gt;Для решения этой задачи минимизации используется сингулярное разложение. Если обозначить $P = UDV^T$, то решение задачи минимизации заключается в том, чтобы установить $m$ равным последнему столбцу матрицы $V$.
Обоснование данного решения выходит за рамки этого курса. Для более подробного изучения вы можете обратиться к разделу 5.3 книги Hartley &amp;amp; Zisserman стр. 592–593. &lt;/p&gt;
&lt;p&gt;В этом разделе вы найдёте:&lt;br&gt;
- Математическое обоснование метода&lt;br&gt;
- Подробное доказательство решения&lt;br&gt;
- Дополнительные технические детали  &lt;/p&gt;
&lt;p&gt;После преобразования вектора $m$ в матрицу $M$ мы хотим явно найти внешние и внутренние параметры камеры.&lt;/p&gt;
&lt;p&gt;C помощью SVD мы вычислили матрицу $M$, с точностью до масштабного множителя $\rho$. &lt;/p&gt;
&lt;p&gt;$\rho M = \begin{bmatrix}
\alpha r_1^T - \alpha \cot \theta r_2^T + c_x r_3^T &amp;amp; \alpha t_x - \alpha \cot \theta t_y + c_x t_z \\
\frac{\beta}{\sin \theta} r_2^T + c_y r_3^T &amp;amp; \frac{\beta}{\sin \theta} t_y + c_y t_z \\
r_3^T &amp;amp; t_z
\end{bmatrix}$ (5)&lt;/p&gt;
&lt;p&gt;где $r_1^T$, $r_2^T$, и $r_3^T$ — это три строки матрицы вращения $R$.&lt;/p&gt;
&lt;p&gt;Разделим на скаляр $\rho$ и обозначим первый столбец как матрицу $A$, а второй столбец как вектор $b$:&lt;/p&gt;
&lt;p&gt;$M = \frac{1}{\rho} \begin{bmatrix}
\alpha r_1^T - \alpha \cot \theta r_2^T + c_x r_3^T &amp;amp; \alpha t_x - \alpha \cot \theta t_y + c_x t_z \\
\frac{\beta}{\sin \theta} r_2^T + c_y r_3^T &amp;amp; \frac{\beta}{\sin \theta} t_y + c_y t_z \\
r_3^T &amp;amp; t_z
\end{bmatrix} =
\begin{bmatrix}
A &amp;amp; b
\end{bmatrix} =
\begin{bmatrix}
a_1^T &amp;amp; b_1 \\
a_2^T &amp;amp; b_2 \\
a_3^T &amp;amp; b_3
\end{bmatrix}$&lt;/p&gt;
&lt;p&gt;Теперь мы можем вычислить внутренние параметры камеры через элементы известной матрицы $M$, она же $A$ и $b$: (6)&lt;/p&gt;
&lt;p&gt;Масштабный множитель:&lt;br&gt;
$\rho = \pm \frac{1}{|a_3|}$  &lt;/p&gt;
&lt;p&gt;Координаты главной точки:&lt;br&gt;
$c_x = \rho^2 (a_1 \cdot a_3)$&lt;br&gt;
$c_y = \rho^2 (a_2 \cdot a_3)$  &lt;/p&gt;
&lt;p&gt;Угол скоса:&lt;br&gt;
$\theta = \cos^{-1} \left( -\frac{(a_1 \times a_3) \cdot (a_2 \times a_3)}{|a_1 \times a_3| \cdot |a_2 \times a_3|} \right)$ &lt;/p&gt;
&lt;p&gt;Масштабные коэффициенты:&lt;br&gt;
$\alpha = \rho^2 |a_1 \times a_3| \sin \theta$&lt;br&gt;
$\beta = \rho^2 |a_2 \times a_3| \sin \theta$  &lt;/p&gt;
&lt;p&gt;Формулы для вычисления внешних параметров (7)&lt;/p&gt;
&lt;p&gt;Матрица вращения:&lt;br&gt;
  $r_1 = \frac{a_2 \times a_3}{|a_2 \times a_3|}$&lt;br&gt;
  $r_2 = r_3 \times r_1$&lt;br&gt;
  $r_3 = \rho a_3$  &lt;/p&gt;
&lt;p&gt;Вектор переноса:&lt;br&gt;
  $T = \rho K^{-1} b$&lt;/p&gt;
&lt;p&gt;При подготовке данных для процедуры калибровки важно учитывать особые случаи, при которых процесс может дать некорректные результаты. 
 &lt;strong&gt;Вырожденные конфигурации&lt;/strong&gt; возникают, когда точки $P_i$ располагаются в одной плоскости или лежат на кривой пересечения двух квадрик. В таких случаях система уравнений становится неразрешимой, что приводит к невозможности корректного определения параметров камеры.
Чтобы избежать подобных проблем, следует тщательно подходить к процессу калибровки. Необходимо использовать точки с различной глубиной расположения, обеспечивать разнообразие положений калибровочной мишени в пространстве и внимательно следить за распределением точек. Важно также проверять качество получаемых данных и анализировать корректность результатов на тестовых наборах.
Для более глубокого понимания теоретических аспектов рекомендуется обратиться к разделу 1.3.1 учебника Forsyth &amp;amp; Ponce, где подробно рассматриваются вырожденные конфигурации и методы их предотвращения.&lt;/p&gt;
&lt;h4&gt;2. Компенсация искажений при калибровке камеры&lt;/h4&gt;
&lt;p&gt;До этого момента мы рассматривали идеальные линзы, свободные от любых искажений. Однако в реальности объективы могут отклоняться от прямолинейной проекции, что требует применения более сложных методов обработки. В этом разделе мы кратко рассмотрим подходы к работе с искажениями.&lt;/p&gt;
&lt;p&gt;Благодаря физической симметрии линзы &lt;strong&gt;радиальные искажения&lt;/strong&gt; тоже обладают симметрией. 
 Для моделирования радиальных искажений используется изотропное преобразование $Q$:&lt;/p&gt;
&lt;p&gt;$Q P_i =
\begin{bmatrix}
q_1 \\ q_2 \\ q_3
\end{bmatrix} P_i = 
\begin{bmatrix}
\frac{1}{\lambda} &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; \frac{1}{\lambda} &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 1
\end{bmatrix} M P_i = 
\begin{bmatrix}
u_i \\
v_i
\end{bmatrix} = p_i$ (8)&lt;/p&gt;
&lt;p&gt;Переписав в систему векторных уравнений, получаем:  &lt;/p&gt;
&lt;p&gt;$u_i q_3 P_i = q_1 P_i$ &lt;br&gt;
$v_i q_3 P_i = q_2 P_i$   &lt;/p&gt;
&lt;p&gt;Однако такая система перестаёт быть линейной, и для её решения требуются методы &lt;strong&gt;нелинейной оптимизации&lt;/strong&gt;, которые подробно рассматриваются в разделе 22.2 учебника Forsyth &amp;amp; Ponce.&lt;/p&gt;
&lt;p&gt;Упростить процесс нелинейной оптимизации при калибровке можно, сделав определённые допущения. В случае радиальных искажений важно отметить, что соотношение между координатами $u_i$ и $v_i$ остаётся неизменным. Это соотношение можно вычислить следующим образом:&lt;/p&gt;
&lt;p&gt;$\frac{u_i}{v_i} = \frac{\frac{m_1P_i}{m_3P_i}}{\frac{m_2P_i}{m_3P_i}} = \frac{m_1P_i}{m_2P_i}$ (18)&lt;/p&gt;
&lt;p&gt;При наличии $n$ соответствий мы можем составить систему линейных уравнений следующего вида:&lt;/p&gt;
&lt;p&gt;$v_1(m_1P_1) - u_1(m_2P_1) = 0$&lt;br&gt;
$\vdots$&lt;br&gt;
$v_n(m_1P_n) - u_n(m_2P_n) = 0$  &lt;/p&gt;
&lt;p&gt;Эта система может быть представлена в виде матрично-векторного произведения, решаемого с помощью &lt;strong&gt;сингулярного разложения (SVD)&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;$L n = \begin{bmatrix}
v_1P_1^T &amp;amp; -u_1P_1^T \\
\vdots &amp;amp; \vdots \\
v_nP_n^T &amp;amp; -u_nP_n^T
\end{bmatrix}
\begin{bmatrix}
m_1^T \\
m_2^T
\end{bmatrix}$ (19)&lt;/p&gt;
&lt;p&gt;После оценки векторов $m_1$ и $m_2$ вектор $m_3$ может быть выражен как &lt;strong&gt;нелинейная функция&lt;/strong&gt; от $m_1$, $m_2$ и $\lambda$. Это приводит к необходимости решения задачи &lt;strong&gt;нелинейной оптимизации&lt;/strong&gt;, которая значительно проще исходной задачи оценки элементов матрицы $Q$.&lt;/p&gt;
&lt;p&gt;Процесс решения включает следующие этапы:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Формирование матрицы $L n$ на основе известных соответствий между точками  &lt;/li&gt;
&lt;li&gt;Применение SVD для нахождения $m_1$ и $m_2$  &lt;/li&gt;
&lt;li&gt;Вычисление $m_3$ через нелинейную зависимость  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Используем условие ортогональности:  &lt;/p&gt;
&lt;p&gt;$m_1 \cdot m_3 = 0$ и $m_2 \cdot m_3 = 0$  &lt;/p&gt;
&lt;p&gt;Учитываем нормировку:  &lt;/p&gt;
&lt;p&gt;$|m_3| = 1$&lt;/p&gt;
&lt;p&gt;Вводим зависимость от параметра $\lambda$, итоговая формула для вычисления $m_3$ имеет вид:  &lt;/p&gt;
&lt;p&gt;$m_3 = \frac{m_1 \times m_2}{|m_1 \times m_2|} \cdot g(\lambda)$  &lt;/p&gt;
&lt;p&gt;где $g(\lambda)$ — некоторая функция от параметра $\lambda$, зависящая от конкретной модели искажений.&lt;/p&gt;
&lt;p&gt;Вид функции $g(\lambda)$ зависит от требуемой точности модели. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Полиномиальная модель&lt;/strong&gt; общего вида: &lt;/p&gt;
&lt;p&gt;$g(\lambda) = 1 + k_1\lambda^2 + k_2\lambda^4 + k_3\lambda^6 + ...$  &lt;/p&gt;
&lt;p&gt;где $k_1, k_2, k_3$ — коэффициенты радиальных искажений.&lt;/p&gt;
&lt;p&gt;На практике используют вычислительно несложные модели:  &lt;/p&gt;
&lt;p&gt;$g(\lambda) = 1 + k_1\lambda^2$&lt;/p&gt;
&lt;p&gt;или&lt;/p&gt;
&lt;p&gt;$g(\lambda) = 1 + k_1\lambda^2 + k_2\lambda^4$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Модель Брауна&lt;/strong&gt; включает как радиальные, так и тангенциальные искажения:&lt;/p&gt;
&lt;p&gt;$x_{distorted} = x(1 + k_1r^2 + k_2r^4) + 2p_1xy + p_2(r^2 + 2x^2)$  &lt;/p&gt;
&lt;p&gt;$y_{distorted} = y(1 + k_1r^2 + k_2r^4) + p_1(r^2 + 2y^2) + 2p_2xy$  &lt;/p&gt;
&lt;p&gt;где $r^2 = x^2 + y^2$  &lt;/p&gt;
&lt;h4&gt;Резюме&lt;/h4&gt;
&lt;p&gt;Калибровка камеры — это комплексный процесс определения внутренних и внешних параметров оптической системы для точного преобразования координат между трёхмерным пространством и двумерным изображением. 
В основе калибровки лежит использование калибровочной мишени с известными координатами, что позволяет установить соответствие между мировыми и экранными координатами. Процесс включает определение матрицы камеры, которая содержит информацию о фокусном расстоянии, координатах главной точки и коэффициентах искажения.&lt;/p&gt;
&lt;p&gt;Важным этапом является учёт искажений, которые неизбежно присутствуют в реальных объективах. Для их компенсации применяются специальные математические модели, чаще всего основанные на полиномиальных функциях радиальных искажений. 
При калибровке необходимо избегать вырожденных конфигураций, когда точки располагаются в одной плоскости, что делает невозможным корректное определение параметров. 
Практическая реализация требует достаточного количества калибровочных изображений с разнообразным расположением мишени относительно камеры. После завершения калибровки получается набор параметров, позволяющий компенсировать искажения и восстанавливать пространственные координаты по изображениям с точностью до удаления $z$. &lt;/p&gt;
&lt;p&gt;Качество калибровки напрямую влияет на точность последующих измерений и является критически важным этапом в системах компьютерного зрения и машинного обучения.&lt;/p&gt;</description><category>cs231a</category><guid>https://mldl.ru/posts/camera-calibration/</guid><pubDate>Tue, 30 Sep 2025 11:00:00 GMT</pubDate></item><item><title>Основы трехмерного компьютерного зрения </title><link>https://mldl.ru/posts/base-3d/</link><dc:creator>Андрей Лабинцев</dc:creator><description>&lt;h4&gt;1. Введение&lt;/h4&gt;
&lt;p&gt;Камера является одним из важнейших инструментов в компьютерном зрении. Это механизм, с помощью которого мы можем фиксировать окружающий мир и использовать получаемые результаты — фотографии — для различных приложений. Поэтому один из фундаментальных вопросов трехмерного компьютерного зрения звучит так: как мы можем смоделировать камеру? &lt;/p&gt;
&lt;h4&gt;2. Камера-обскура&lt;/h4&gt;
&lt;p&gt;Камера-обскура — это простейшая система, которая позволяет фиксировать изображение объекта или сцены в трёхмерном мире. Такая система может быть создана путём размещения преграды с небольшим отверстием (апертурой) между трёхмерным объектом и фотоплёнкой или светочувствительным сенсором.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 1: Модель камеры обскуры" src="https://storage.yandexcloud.net/yahosting/3d/1.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 1: Модель камеры обскуры&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Как показано на рисунке 1, каждая точка на трёхмерном объекте испускает множество световых лучей во все стороны. Без преграды каждая точка на плёнке подвергалась бы воздействию световых лучей, исходящих от каждой точки трёхмерного объекта. Благодаря наличию преграды через отверстие проходит только один (или несколько) из этих лучей света и попадает на плёнку.&lt;/p&gt;
&lt;p&gt;Таким образом, мы можем установить взаимно-однозначное соответствие между точками на трёхмерном объекте и точками на плёнке. В результате плёнка получает «изображение» трёхмерного объекта посредством такого отображения. Эта простая модель известна как модель камеры-обскуры.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 2: Формальная модель камеры-обскуры" src="https://storage.yandexcloud.net/yahosting/3d/2.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 2: Формальная модель модели камеры-обскуры&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Более формальное построение камеры-обскуры показано на рисунке 2. В этой конструкции плёнка обычно называется &lt;strong&gt;плоскостью изображения&lt;/strong&gt; или &lt;strong&gt;сетчаткой&lt;/strong&gt;. Отверстие называется &lt;strong&gt;точечным отверстием&lt;/strong&gt; O или центром камеры. Расстояние между плоскостью изображения и точечным отверстием O называется &lt;strong&gt;фокусным расстоянием&lt;/strong&gt; f.&lt;/p&gt;
&lt;p&gt;Иногда плоскость сетчатки размещается между точкой O и трёхмерным объектом на расстоянии f от O. В этом случае она называется &lt;strong&gt;виртуальной плоскостью изображения&lt;/strong&gt; или &lt;strong&gt;виртуальной плоскостью сетчатки&lt;/strong&gt;. Важно отметить, что проекция объекта на плоскость изображения и изображение объекта на виртуальной плоскости изображения идентичны с точностью до масштабного (подобного) преобразования.&lt;/p&gt;
&lt;p&gt;Теперь рассмотрим, как использовать камеры-обскуры. Пусть P = [x y z]ᵀ — точка на некотором трёхмерном объекте, видимом для камеры-обскуры. Точка P будет отображена или спроецирована на плоскость изображения Π', в результате чего получится точка P' = [x' y']ᵀ.&lt;/p&gt;
&lt;p&gt;Аналогично, само точечное отверстие может быть спроецировано на плоскость изображения, что даст новую точку C'. Здесь мы можем определить систему координат [i j k], центрированную в точке отверстия O, так что ось k перпендикулярна плоскости изображения и направлена к ней. Эта система координат часто известна как &lt;strong&gt;система отсчёта камеры&lt;/strong&gt; или &lt;strong&gt;система координат камеры&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Линия, определяемая точками C' и O, называется &lt;strong&gt;оптической осью&lt;/strong&gt; системы камеры. &lt;/p&gt;
&lt;p&gt;Напомним, что точка $P_0$ получается в результате проекции трёхмерной точки $P$ на плоскость изображения $Π'$. 
Следовательно, если мы выведем соотношение между трёхмерной точкой $P$ и точкой $P'$ на плоскости изображения, мы сможем понять, как трёхмерный мир отображается на снимке, сделанном камерой-обскурой.&lt;/p&gt;
&lt;p&gt;Обратите внимание, что треугольник $P' C'O$ подобен треугольнику, образованному точками $P$, $O$ и $(0, 0, z)$. 
Используя теорему о подобных треугольниках, мы получаем:&lt;/p&gt;
&lt;p&gt;$P' = \begin{pmatrix} x' \\ y' \end{pmatrix} = \begin{pmatrix} \frac{fx}{z} \\ \frac{fy}{z} \end{pmatrix}$ (1)&lt;/p&gt;
&lt;p&gt;Важно отметить, что в этой модели камеры-обскуры мы делаем одно существенное допущение: апертура (отверстие) считается одной точкой. Однако в большинстве реальных ситуаций мы не можем предполагать, что апертура может быть бесконечно малой. Возникает вопрос: как влияет изменение размера апертуры на результат?&lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 3: Влияние размера апертуры на изображение" src="https://storage.yandexcloud.net/yahosting/3d/3.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 3: Влияние размера апертуры на изображение&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;При уменьшении размера апертуры изображение становится более резким, но более тёмным.&lt;/p&gt;
&lt;p&gt;По мере увеличения размера апертуры количество световых лучей, проходящих через преграду, соответственно возрастает. При большем количестве проходящих лучей каждая точка на плёнке может подвергаться воздействию световых лучей от нескольких точек в трёхмерном пространстве, что приводит к размытию изображения.&lt;/p&gt;
&lt;p&gt;Хотя может показаться заманчивым сделать апертуру как можно меньше, следует помнить, что меньший размер апертуры пропускает меньше световых лучей, в результате чего изображение получается более чётким, но более тёмным.&lt;/p&gt;
&lt;p&gt;Таким образом, мы приходим к фундаментальной проблеме, возникающей при использовании  камеры-обскуры: возможно ли создать камеру, которая делает одновременно чёткие и яркие изображения?&lt;/p&gt;
&lt;h4&gt;3. Камеры и линзы&lt;/h4&gt;
&lt;p&gt;В современных камерах указанное противоречие между резкостью и яркостью изображения решается с помощью &lt;strong&gt;линз&lt;/strong&gt; — устройств, способных фокусировать или рассеивать свет.&lt;/p&gt;
&lt;p&gt;Если заменить отверстие (апертуру) камеры-обскуры на линзу, которая правильно расположена и имеет подходящий размер, то она будет обладать следующим свойством: все световые лучи, испускаемые некоторой точкой $P$, преломляются линзой таким образом, что они сходятся в одной точке $P'$. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 4: Схема простой модели линзы" src="https://storage.yandexcloud.net/yahosting/3d/4.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 4: Схема простой модели линзы&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;На рисунке 4 показано, как лучи от верхней точки дерева хорошо сходятся на плёнке. Однако точка, находящаяся на другом расстоянии от линзы, приводит к тому, что лучи не сходятся идеально на плёнке.&lt;/p&gt;
&lt;p&gt;Благодаря линзе проблема блокировки большинства световых лучей из-за малого отверстия устраняется (см. рисунок 4). Однако важно отметить, что это свойство выполняется не для всех точек трёхмерного пространства, а только для определённой точки $P$.&lt;/p&gt;
&lt;p&gt;Рассмотрим другую точку $Q$, которая находится ближе или дальше от плоскости изображения, чем точка $P$. Соответствующая проекция на изображение будет размытой или не в фокусе. Таким образом, у линз есть определённое расстояние, на котором объекты находятся «в фокусе».
Эффективный диапазон, в пределах которого камеры могут делать чёткие снимки называется &lt;strong&gt;глубина резкости&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 5: Фокусировка световых лучей с помощью линзы" src="https://storage.yandexcloud.net/yahosting/3d/5.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 5: Фокусировка световых лучей с помощью линзы&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;На данном рисунке демонстрируется, как линза фокусирует световые лучи, параллельные оптической оси, в &lt;strong&gt;фокусе&lt;/strong&gt; (фокальной точке). Эта схема также иллюстрирует &lt;strong&gt;модель параксиального преломления&lt;/strong&gt; — упрощённую модель, которая помогает установить взаимосвязь между точками на плоскости изображения и объектами в трёхмерном пространстве для камер с линзами.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Параксиальное преломление&lt;/strong&gt; — это приближение, используемое в оптике, которое позволяет:&lt;br&gt;
- точно рассчитывать траектории световых лучей;&lt;br&gt;
- определять положение точек в пространстве;&lt;br&gt;
- вычислять параметры фокусировки;&lt;br&gt;
- моделировать работу оптических систем.  &lt;/p&gt;
&lt;p&gt;Такая модель является фундаментальной для понимания принципов работы современных камер и систем компьютерного зрения. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Объективы камер&lt;/strong&gt; обладают ещё одним важным свойством: они фокусируют все световые лучи, движущиеся параллельно оптической оси, в одну точку, известную как &lt;strong&gt;фокусная точка&lt;/strong&gt; (см. рисунок 5). Расстояние между фокусной точкой и центром линзы называется &lt;strong&gt;фокусным расстоянием&lt;/strong&gt; $f$.&lt;/p&gt;
&lt;p&gt;Кроме того, световые лучи, проходящие через центр линзы, не отклоняются. Благодаря этому мы можем построить конструкцию, аналогичную модели камеры-обскуры, которая связывает точку $P$ в трёхмерном пространстве с соответствующей точкой $P'$ на плоскости изображения:&lt;/p&gt;
&lt;p&gt;$P' = \begin{pmatrix} x' \\ y' \end{pmatrix} = \begin{pmatrix} z' \frac{x}{z} \\ z' \frac{y}{z} \end{pmatrix}$ (2)&lt;/p&gt;
&lt;p&gt;Важно отметить следующие различия между моделями:&lt;br&gt;
- В модели камеры-обскуры $z' = f$&lt;br&gt;
- В модели с линзой $z' = f + z_0$  &lt;/p&gt;
&lt;p&gt;Данное соотношение основано на &lt;strong&gt;параксиальном приближении&lt;/strong&gt; (или предположении о «тонкой линзе»), а такая модель называется &lt;strong&gt;моделью параксиального преломления&lt;/strong&gt;. Подробное доказательство этой модели выходит за рамки данного курса. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 6: Подушкообразное и бочкообразное искажение изображения" src="https://storage.yandexcloud.net/yahosting/3d/6.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 6: Подушкообразное и бочкообразное искажение изображения&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Поскольку модель параксиального преломления использует приближение тонкой линзы, может возникать ряд аберраций. Наиболее распространённой из них является &lt;strong&gt;радиальное искажение&lt;/strong&gt;, которое приводит к уменьшению или увеличению увеличения изображения в зависимости от расстояния до оптической оси.&lt;/p&gt;
&lt;p&gt;Мы классифицируем радиальное искажение следующим образом:&lt;br&gt;
- &lt;strong&gt;Подушкообразное искажение&lt;/strong&gt; — когда увеличение возрастает&lt;br&gt;
- &lt;strong&gt;Бочкообразное искажение&lt;/strong&gt; — когда увеличение уменьшается.  &lt;/p&gt;
&lt;p&gt;Радиальное искажение возникает из-за того, что различные участки линзы имеют разные фокусные расстояния. Это явление наглядно показано на рисунке 6, где можно увидеть, как эти типы искажений влияют на конечное изображение.&lt;/p&gt;
&lt;p&gt;Такие искажения особенно заметны:
- По краям кадра
- При использовании широкоугольных объективов
- В системах компьютерного зрения, где важна точность геометрических измерений &lt;/p&gt;
&lt;h4&gt;4. Матричная модель камеры&lt;/h4&gt;
&lt;p&gt;В этом разделе мы рассмотрим детали параметров, которые необходимо учитывать при моделировании проекции из трёхмерного пространства на известные нам цифровые изображения. Все полученные результаты будут использовать модель камеры-обскуры, но они также применимы и к модели параксиального преломления.&lt;/p&gt;
&lt;p&gt;Как обсуждалось ранее, точка $P$ в трёхмерном пространстве может быть отображена (или спроецирована) в двумерную точку $P'$ на плоскости изображения $Π'$. Такое отображение $R^3 → R^2$ называется &lt;strong&gt;проективным преобразованием&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Однако такая проекция трёхмерных точек на плоскость изображения не соответствует напрямую тому, что мы видим в реальных цифровых изображениях по нескольким причинам:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Точки в цифровых изображениях, как правило, находятся в другой системе отсчёта, чем точки в плоскости изображения.&lt;/li&gt;
&lt;li&gt;Цифровые изображения разделены на дискретные пиксели, тогда как точки в плоскости изображения являются непрерывными.&lt;/li&gt;
&lt;li&gt;Физические датчики могут вносить нелинейные искажения в отображение.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Чтобы учесть эти различия, мы введём ряд дополнительных преобразований, которые позволят нам отображать любую точку из трёхмерного мира в координаты пикселей.&lt;/p&gt;
&lt;p&gt;Таким образом, нам необходимо: &lt;br&gt;
- Учесть различия в системах координат;&lt;br&gt;
- Преобразовать непрерывные координаты в дискретные пиксельные;&lt;br&gt;
- Компенсировать возможные искажения сенсора.  &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Матричная модель камеры&lt;/strong&gt; описывает набор важных параметров, влияющих на то, как точка мира $P$ отображается в координаты изображения $P'$. Как следует из названия, эти параметры представлены в матричной форме.&lt;/p&gt;
&lt;p&gt;Рассмотрим основные параметры:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Параметры $c_x$ и $c_y$&lt;/strong&gt; описывают разницу между координатами плоскости изображения и цифровыми координатами изображения через перенос.&lt;br&gt;
   - Координаты плоскости изображения имеют начало координат $C_0$ в центре изображения, где ось $k$ пересекает плоскость изображения.&lt;br&gt;
   - Цифровые координаты изображения обычно имеют начало в левом нижнем углу изображения.&lt;br&gt;
   - Таким образом, 2D точки на плоскости изображения и 2D точки в цифровом изображении смещаются на вектор переноса $\begin{pmatrix} c_x \\ c_y \end{pmatrix}^T$.  &lt;/p&gt;
&lt;p&gt;С учётом этого изменения систем координат отображение теперь выглядит так:&lt;/p&gt;
&lt;p&gt;$P' = \begin{pmatrix} x' \\ y' \end{pmatrix} = \begin{pmatrix} \frac{f}{z}x + c_x \\ \frac{f}{z}y + c_y \end{pmatrix}$ (3)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Второй важный эффект&lt;/strong&gt; — это то, что точки в цифровых изображениях выражаются в пикселях, в то время как точки на плоскости изображения представлены в физических измерениях (например, сантиметрах).&lt;/p&gt;
&lt;p&gt;Для учёта этого изменения единиц измерения необходимо ввести два новых параметра $k$ и $l$. Эти параметры имеют размерность [пиксель на сантиметр], соответствуют изменению единиц измерения по двум осям плоскости изображения. Важно отметить, что $k$ и $l$ могут быть разными, поскольку соотношение сторон пикселя не обязательно равно единице. Если $k = l$, мы говорим, что камера имеет квадратные пиксели. 
Мы модифицируем наше предыдущее отображение следующим образом:&lt;/p&gt;
&lt;p&gt;$P_0 = \begin{pmatrix} x' \\ y' \end{pmatrix} = \begin{pmatrix} f k \frac{x}{z} + c_x \\ f l \frac{y}{z} + c_y \end{pmatrix} = \begin{pmatrix} \alpha\frac{x}{z} + c_x \\ \beta\frac{y}{z} + c_y \end{pmatrix}$ (4)&lt;/p&gt;
&lt;p&gt;где&lt;br&gt;
$\alpha = f \cdot k$&lt;br&gt;
$\beta = f \cdot l$&lt;br&gt;
$f$ — фокусное расстояние в мм,&lt;br&gt;
$k$ — размер пикселя по оси x, пикс/мм. &lt;br&gt;
$l$ — размер пикселя по оси x, пикс/мм.  &lt;/p&gt;
&lt;p&gt;Сокращение размерностей приводит к тому, что параметры $\alpha$ и $\beta$ выражаются в пикселях.&lt;br&gt;
Это логично, так как коэффициенты связывают физические измерения (метры) с дискретными единицами цифрового изображения (пиксели).&lt;/p&gt;
&lt;p&gt;Геометрический смысл состоит в том, сколько в пикселях будет объект, размер которого на плоскости проекции равен фокусному расстоянию камеры. &lt;/p&gt;
&lt;p&gt;Таким образом, измерение $\alpha$ и $\beta$ в пикселях является необходимым для:&lt;br&gt;
- Точного проецирования точек;&lt;br&gt;
- Корректной калибровки камеры;&lt;br&gt;
- Работы алгоритмов обработки изображений;&lt;br&gt;
- Взаимодействия между физическим и цифровым пространством.  &lt;/p&gt;
&lt;h4&gt;5. Однородные координаты&lt;/h4&gt;
&lt;p&gt;Теперь рассмотрим вопрос: существует ли линейный способ представления проецирования $P \rightarrow P'$?&lt;/p&gt;
&lt;p&gt;Линейное преобразование на практике является более удобным, т.к. его можно представить как произведение входного вектора $P$ на некоторую матрицу. 
Из уравнения (4) видно, что  проецирование $P \rightarrow P'$ не является линейным, поскольку операция включает деление на один из входных параметров, а именно на $z$.
Тем не менее, представление этого проецирования в виде произведения вектора на матрицу возможно.
Решение заключается в использовании &lt;strong&gt;однородных координат&lt;/strong&gt;. &lt;/p&gt;
&lt;p&gt;Рассмотрим этот подход:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Введение новой координаты&lt;/strong&gt;:&lt;br&gt;
Любая точка на плоскости $P' = (x', y')$ преобразуется в $(x', y', 1)$&lt;br&gt;
Любая точка в трехмерном пространстве $P = (x, y, z)$ преобразуется в $(x, y, z, 1)$  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Такое расширенное пространство называется &lt;strong&gt;системой однородных координат&lt;/strong&gt;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Преобразование координат&lt;/strong&gt;:&lt;br&gt;
Для преобразования евклидова вектора $(v_1, ..., v_n)$ в однородные координаты мы просто добавляем 1 в новое измерение, получая $(v_1, ..., v_n, 1)$&lt;br&gt;
Важно отметить: равенство между вектором и его однородными координатами выполняется только когда последняя координата равна единице&lt;br&gt;
При обратном преобразовании из произвольных однородных координат $(v_1, ..., v_n, w)$ мы получаем евклидовы координаты $(\frac{v_1}{w}, ..., \frac{v_n}{w})$  &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Используя однородные координаты, мы можем сформулировать преобразование следующим образом:&lt;/p&gt;
&lt;p&gt;$P'_h = \begin{bmatrix} \alpha x + c_x z \\ \beta y + c_y z \\ z \end{bmatrix} = \begin{bmatrix} \alpha &amp;amp; 0 &amp;amp; c_x &amp;amp; 0 \\ 0 &amp;amp; \beta &amp;amp; c_y &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{bmatrix} \begin{bmatrix} x \\ y \\ z \\ 1 \end{bmatrix} = \begin{bmatrix} \alpha &amp;amp; 0 &amp;amp; c_x &amp;amp; 0 \\ 0 &amp;amp; \beta &amp;amp; c_y &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{bmatrix} P_h$ (5)&lt;/p&gt;
&lt;p&gt;Преимущества использования однородных координат:&lt;br&gt;
- Позволяют представить нелинейное преобразование в виде матричного умножения;&lt;br&gt;
- Упрощают дальнейшие математические выкладки;&lt;br&gt;
- Обеспечивают единый способ работы с проективными преобразованиями.  &lt;/p&gt;
&lt;p&gt;С этого момента будем работать преимущественно в &lt;strong&gt;однородных координатах&lt;/strong&gt;, если не указано иное. Индекс $h$ опустим, подразумевая, что любая точка $P$ или $P'$ задана в однородных координатах.&lt;/p&gt;
&lt;p&gt;Как видно из уравнения (5), мы можем представить связь между точкой в трёхмерном пространстве и её координатами изображения в виде матрично-векторного соотношения:&lt;/p&gt;
&lt;p&gt;$P' = \begin{bmatrix} x' \\ y' \\ z \end{bmatrix} = \begin{bmatrix} \alpha &amp;amp; 0 &amp;amp; c_x &amp;amp; 0 \\ 0 &amp;amp; \beta &amp;amp; c_y &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{bmatrix} \begin{bmatrix} x \\ y \\ z \\ 1 \end{bmatrix} = \begin{bmatrix} \alpha &amp;amp; 0 &amp;amp; c_x &amp;amp; 0 \\ 0 &amp;amp; \beta &amp;amp; c_y &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \end{bmatrix} P = MP$ (6)&lt;/p&gt;
&lt;p&gt;где:
- $M$ — &lt;strong&gt;матрица камеры&lt;/strong&gt;&lt;br&gt;
- $P$ — точка в однородных координатах трёхмерного пространства&lt;br&gt;
- $P'$ — проекция точки на плоскость изображения  &lt;/p&gt;
&lt;h4&gt;6. Внутренние параметры камеры&lt;/h4&gt;
&lt;p&gt;Важные параметры матрицы камеры:&lt;br&gt;
- $\alpha$ и $\beta$ — масштабные коэффициенты в направлениях $x$ и $y$&lt;br&gt;
- $c_x$ и $c_y$ — координаты главной точки (principal point)&lt;br&gt;
- Последний столбец матрицы $M$ содержит нули, что характерно для проективных преобразований.  &lt;/p&gt;
&lt;p&gt;Давайте разберем это матричное разложение более подробно:&lt;/p&gt;
&lt;p&gt;Мы можем представить преобразование в виде:&lt;/p&gt;
&lt;p&gt;$P' = MP = \begin{bmatrix} \alpha &amp;amp; 0 &amp;amp; c_x \\ 0 &amp;amp; \beta &amp;amp; c_y \\ 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix} \begin{bmatrix} I &amp;amp; 0 \end{bmatrix} P = K \begin{bmatrix} I &amp;amp; 0 \end{bmatrix} P$ (7)&lt;/p&gt;
&lt;p&gt;где:
- $P'$ — координаты точки на плоскости изображения&lt;br&gt;
- $M$ — полная матрица преобразования&lt;br&gt;
- $K$ — *&lt;em&gt;матрица камеры&lt;/em&gt;- (внутренняя калибровка)&lt;br&gt;
- $I$ — единичная матрица размером 3×3&lt;br&gt;
- $0$ — нулевой вектор размером 3×1&lt;br&gt;
- $P$ — координаты точки в пространстве в однородных координатах.  &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 7: Проекция точки с помощью матрицы камеры" src="https://storage.yandexcloud.net/yahosting/3d/7.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 7: Проекция точки с помощью матрицы камеры&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Матрица камеры $K$ имеет следующий вид:&lt;/p&gt;
&lt;p&gt;$K = \begin{bmatrix} \alpha &amp;amp; 0 &amp;amp; c_x \\ 0 &amp;amp; \beta &amp;amp; c_y \\ 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix}$&lt;/p&gt;
&lt;p&gt;где:
- $\alpha$ и $\beta$ — масштабные коэффициенты, связанные с фокусным расстоянием&lt;br&gt;
- $c_x$ и $c_y$ — координаты главной точки (principal point)&lt;br&gt;
- Последняя строка [0 0 1] обеспечивает сохранение однородных координат  &lt;/p&gt;
&lt;p&gt;Такое разложение позволяет:
- Выделить внутренние параметры камеры и работать с ними отдельно от внешних;&lt;br&gt;
- Упрощать вычисления при работе с проективными преобразованиями;&lt;br&gt;
- Более эффективно выполнять калибровку камеры;&lt;br&gt;
- Разделять влияние различных параметров на процесс проецирования.  &lt;/p&gt;
&lt;p&gt;Матрица $K$ содержит всю необходимую информацию об &lt;strong&gt;внутренней калибровке&lt;/strong&gt; камеры, что делает её ключевым элементом в задачах компьютерного зрения и обработки изображений. &lt;/p&gt;
&lt;p&gt;&lt;img alt="Рисунок 8: Расположение главной точки С'" src="https://storage.yandexcloud.net/yahosting/3d/8.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Рисунок 8: Расположение главной точки С'&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Полная матричная модель камеры $K$ содержит ключевые параметры, описывающие характеристики камеры и её модель, включая параметры $c_x$, $c_y$, $k$ и $l$, как обсуждалось ранее.&lt;/p&gt;
&lt;p&gt;В текущей формулировке отсутствуют два важных параметра:
* &lt;strong&gt;Скос (skewness)&lt;/strong&gt;
* &lt;strong&gt;Дисторсия (distortion)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Скос изображения&lt;/strong&gt; возникает, когда система координат камеры имеет неточный угол между осями (отличающийся от 90 градусов). Большинство камер имеют нулевой скос, однако некоторое его значение может появиться из-за погрешностей при производстве сенсора.&lt;/p&gt;
&lt;p&gt;Матрица камеры с учётом скоса имеет вид:&lt;/p&gt;
&lt;p&gt;$K = \begin{bmatrix} x' \\ y' \\ z \end{bmatrix} = \begin{bmatrix} \alpha &amp;amp; -\alpha \cot \theta &amp;amp; c_x \\ 0 &amp;amp; \frac{\beta}{\sin \theta} &amp;amp; c_y \\ 0 &amp;amp; 0 &amp;amp; 1 \end{bmatrix}$ (8)&lt;/p&gt;
&lt;p&gt;где:&lt;br&gt;
- $\alpha$ и $\beta$ — масштабные коэффициенты&lt;br&gt;
- $\theta$ — угол скоса&lt;br&gt;
- $c_x$ и $c_y$ — координаты главной точки  &lt;/p&gt;
&lt;p&gt;В рамках данного курса мы рассматриваем матрицу камеры $K$ с 5 степенями свободы:&lt;br&gt;
- 2 параметра для фокусного расстояния &lt;br&gt;
- 2 параметра для смещения&lt;br&gt;
- 1 параметр для скоса  &lt;/p&gt;
&lt;p&gt;Эти параметры называются &lt;strong&gt;внутренними параметрами камеры&lt;/strong&gt; (intrinsic parameters), так как они:&lt;br&gt;
- Уникальны для каждой конкретной камеры&lt;br&gt;
- Связаны с её конструктивными особенностями&lt;br&gt;
- Определяются при производстве  &lt;/p&gt;
&lt;p&gt;Важно отметить, что большинство методов компьютерного зрения игнорируют эффекты дисторсии, позволяя состедоточиться на 4 основных параметрах камеры.&lt;/p&gt;
&lt;h4&gt;7. Внешние параметры камеры&lt;/h4&gt;
&lt;p&gt;До сих пор мы описывали отображение точки $P$ из трёхмерной системы координат камеры в точку $P'$ на двумерной плоскости изображения, используя внутренние параметры камеры в матричной форме.&lt;/p&gt;
&lt;p&gt;Однако возникает вопрос: что делать, если информация о трёхмерном мире представлена в другой системе координат? В этом случае необходимо добавить дополнительное преобразование, связывающее точки из мировой системы координат с системой координат камеры.&lt;/p&gt;
&lt;p&gt;Это преобразование описывается:
- &lt;strong&gt;Матрицей вращения&lt;/strong&gt; $R$
- &lt;strong&gt;Вектором переноса&lt;/strong&gt; $T$&lt;/p&gt;
&lt;p&gt;Таким образом, для точки $P_w$ в мировой системе координат её координаты в системе камеры можно вычислить следующим образом:&lt;/p&gt;
&lt;p&gt;$P = \begin{bmatrix} R &amp;amp; T \\ 0 &amp;amp; 1 \end{bmatrix} P_w$ (9)&lt;/p&gt;
&lt;p&gt;где:
- $R$ — матрица вращения размером 3×3&lt;br&gt;
- $T$ — вектор переноса размером 3×1&lt;br&gt;
- $P_w$ — координаты точки в мировой системе&lt;br&gt;
- $P$ — координаты точки в системе камеры  &lt;/p&gt;
&lt;p&gt;Подставляя это в уравнение (7) и упрощая, получаем:&lt;/p&gt;
&lt;p&gt;$P' = K \begin{bmatrix} R &amp;amp; T \end{bmatrix} P_w = MP_w$ (10)&lt;/p&gt;
&lt;p&gt;Параметры $R$ и $T$ называются &lt;strong&gt;внешними параметрами&lt;/strong&gt;, поскольку они:&lt;br&gt;
- Находятся вне камеры&lt;br&gt;
- Не зависят от характеристик камеры  &lt;/p&gt;
&lt;p&gt;Это завершает описание отображения трёхмерной точки $P$ из произвольной мировой системы координат на плоскость изображения.&lt;/p&gt;
&lt;h4&gt;Резюме&lt;/h4&gt;
&lt;p&gt;Полная матрица проекции $M$ состоит из двух типов параметров:
- &lt;strong&gt;Внутренние параметры&lt;/strong&gt; (intrinsic parameters) — содержатся в матрице камеры $K$, меняются при смене типа камеры&lt;br&gt;
- &lt;strong&gt;Внешние параметры&lt;/strong&gt; (extrinsic parameters) — включают вращение и перенос, не зависят от конструкции камеры  &lt;/p&gt;
&lt;p&gt;Полная матрица проекции $M$ размером 3×4 имеет 11 степеней свободы:&lt;br&gt;
- 5 степеней свободы от внутренней матрицы камеры&lt;br&gt;
- 3 степени свободы от внешнего вращения&lt;br&gt;
- 3 степени свободы от внешнего переноса  &lt;/p&gt;
&lt;p&gt;Таким образом, мы получили полное описание процесса проецирования точки из трёхмерного пространства на плоскость изображения, учитывающее как характеристики самой камеры, так и её положение в пространстве относительно наблюдаемой сцены.&lt;/p&gt;</description><category>cs231a</category><guid>https://mldl.ru/posts/base-3d/</guid><pubDate>Mon, 29 Sep 2025 11:00:00 GMT</pubDate></item></channel></rss>