<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="ru">
<head>
<meta charset="utf-8">
<meta name="description" content="Заметки по machine learning, deep learning.">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Заметки по ML, DL (1 страница со старыми записями) | Заметки по ML, DL</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:700,900" rel="stylesheet">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="ru" href="rss.xml">
<link rel="canonical" href="https://mldl.ru/index-1.html">
<link rel="prev" href="." type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Перейти к главному содержимому</a>

<!-- Header and menu bar -->
<div class="container">
      <header class="blog-header py-3"><div class="row nbb-header align-items-center">
          <div class="col-md-3 col-xs-2 col-sm-2" style="width: auto;">
            <button class="navbar-toggler navbar-light bg-light nbb-navbar-toggler" type="button" data-toggle="collapse" data-target=".bs-nav-collapsible" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse bs-nav-collapsible bootblog4-search-form-holder">
                
            </div>
        </div>
          <div class="col-md-6 col-xs-10 col-sm-10 bootblog4-brand" style="width: auto;">
            <a class="navbar-brand blog-header-logo text-dark" href=".">

            <span id="blog-title">Заметки по ML, DL</span>
        </a>
          </div>
            <div class="col-md-3 justify-content-end align-items-center bs-nav-collapsible collapse flex-collapse bootblog4-right-nav">
            <nav class="navbar navbar-light bg-white"><ul class="navbar-nav bootblog4-right-nav"></ul></nav>
</div>
    </div>
</header><nav class="navbar navbar-expand-md navbar-light bg-white static-top"><div class="collapse navbar-collapse bs-nav-collapsible" id="bs-navbar">
            <ul class="navbar-nav nav-fill d-flex w-100">
<li class="nav-item">
<a href="archive.html" class="nav-link">Archive</a>
                </li>
<li class="nav-item">
<a href="categories/" class="nav-link">Tags</a>

                
            </li>
</ul>
</div>
<!-- /.navbar-collapse -->
</nav>
</div>

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        
    
        

    
        
    <div class="postindex">
            <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/convnets-2/" class="u-url">Предобработка, инициализация весов, функции потерь</a></h1>
                <div class="metadata">
                    <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                        Андрей Лабинцев
                    </span></p>
            <p class="dateline">
            <a href="posts/convnets-2/" rel="bookmark">
            <time class="published dt-published" datetime="2025-03-09T19:42:16+03:00" itemprop="datePublished" title="2025-03-09 19:42">2025-03-09 19:42</time></a>
            </p>
                </div>
            </header><div class="e-content entry-content">
                    <h2>Предобработка, инициализация весов, функции потерь</h2>
<p>Содержание:
- <a href="posts/convnets-2/">Настройка данных и модели</a>
    + <a href="posts/convnets-2/">Предварительная обработка данных</a>
    + <a href="posts/convnets-2/">Инициализация веса</a>
    + <a href="posts/convnets-2/">Нормализация партии</a>
    + <a href="posts/convnets-2/">Регуляризация</a> (L2/L1/Maxnorm/Dropout)
- <a href="posts/convnets-2/">Функции потерь</a>
- <a href="posts/convnets-2/">Краткая сводка</a>  </p>
<h2>Настройка данных и модели</h2>
<p>В предыдущем разделе мы представили модель нейрона, который вычисляет скалярное произведение с помощью нелинейности, и нейронные сети, которые объединяют нейроны в слои. Вместе эти решения определяют новую форму <strong>функции оценки</strong>, которую мы расширили по сравнению с простым линейным отображением, которое мы рассматривали в разделе «Линейная классификация». В частности, нейронная сеть выполняет последовательность линейных отображений с вложенными нелинейностями. В этом разделе мы обсудим дополнительные решения, касающиеся предварительной обработки данных, инициализации весов и функций потерь.  </p>
<h3>Предварительная обработка данных</h3>
<p>Существует три распространённые формы предварительной обработки данных в матрице данных <code>X</code>, где мы будем предполагать, что <code>X</code> имеет размер <code>[N x D]</code> (<code>N</code> — количество данных, <code>D</code> — их размерность).  </p>
<p><strong>Вычитание среднего значения</strong> — наиболее распространённая форма предварительной обработки. Она заключается в вычитании среднего значения для каждого отдельного признака в данных и имеет геометрическую интерпретацию центрирования облака данных вокруг начала координат по каждому измерению. В <strong>numpy</strong> эта операция будет реализована следующим образом: (<code>X -= np.mean(X, axis = 0)</code>. В случае с изображениями для удобства можно вычесть одно значение из всех пикселей (например, <code>X -= np.mean(X)</code>), либо сделать это отдельно для трёх цветовых каналов.  </p>
<p><strong>Нормализация</strong> — это приведение размерностей данных к примерно одинаковому масштабу. Существует два распространённых способа достижения такой нормализации:
- Один из них — разделить каждую размерность на её стандартное отклонение после центрирования по нулю: (<code>X /= np.std(X, axis = 0)</code>). 
- Другой способ предварительной обработки — нормализовать каждую размерность так, чтобы минимальное и максимальное значения по каждой размерности составляли -1 и 1 соответственно. Имеет смысл применять эту предварительную обработку только в том случае, если у вас есть основания полагать, что разные входные параметры имеют разные масштабы (или единицы измерения), но они должны быть примерно одинаково важны для алгоритма обучения. В случае изображений относительные масштабы пикселей уже примерно одинаковы (и находятся в диапазоне от 0 до 255), поэтому нет необходимости выполнять этот дополнительный этап предварительной обработки.  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/nn2/prepro1.jpeg"><br>
Общий конвейер предварительной обработки данных. <strong>Слева</strong>: исходные данные, 2-мерные входные данные. <strong>В центре</strong>: данные центрируются по нулевому значению путём вычитания среднего значения в каждом измерении. Облако данных теперь центрировано относительно начала координат. <strong>Справа</strong>: каждое измерение дополнительно масштабируется с помощью стандартного отклонения. Красные линии указывают на границы данных — в центре они разной длины, а справа — одинаковой.  </p>
<hr>
<p><strong>Метод главных компонент и отбеливание</strong> — это ещё одна форма предварительной обработки. В этом процессе данные сначала центрируются, как описано выше. Затем мы можем вычислить ковариационную матрицу, которая показывает корреляционную структуру данных:  </p>
<div class="code"><pre class="code literal-block"><span class="c1"># Assume input data matrix X of size [N x D]</span>
<span class="n">X</span><span class="w"> </span><span class="o">-=</span><span class="w"> </span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">axis</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="c1"># zero-center the data (important)</span>
<span class="n">cov</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span><span class="w"> </span><span class="n">X</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="c1"># get the data covariance matrix</span>
</pre></div>

<p>Элемент (i,j) ковариационной матрицы данных содержит ковариацию между i-м и j-м измерениями данных. В частности, диагональ этой матрицы содержит дисперсии. Кроме того, ковариационная матрица является симметричной и <a href="http://en.wikipedia.org/wiki/Positive-definite_matrix#Negative-definite.2C_semidefinite_and_indefinite_matrices">положительно определённой</a>. Мы можем вычислить разложение ковариационной матрицы данных по методу сингулярного разложения:  </p>
<div class="code"><pre class="code literal-block">U,S,V = np.linalg.svd(cov)
</pre></div>

<p>где столбцы <code>U</code> являются собственными векторами, а <code>S</code> — одномерным массивом сингулярных значений. Чтобы устранить корреляцию в данных, мы проецируем исходные (но центрированные по нулю) данные на собственный базис:  </p>
<div class="code"><pre class="code literal-block">Xrot = np.dot(X, U) # decorrelate the data
</pre></div>

<p>Обратите внимание, что столбцы <code>U</code> представляют собой набор ортогональных векторов (норма которых равна 1 и которые ортогональны друг другу), поэтому их можно рассматривать как базисные векторы. Таким образом, проекция соответствует повороту данных в <code>X</code> таким образом, чтобы новые оси были собственными векторами. Если бы мы вычислили ковариационную матрицу <code>Xrot</code>, то увидели бы, что теперь она диагональная. Преимущество <code>np.linalg.svd</code> в том, что в возвращаемом значении <code>U</code> столбцы собственных векторов отсортированы по собственным значениям. Мы можем использовать это для уменьшения размерности данных, используя только несколько главных собственных векторов и отбрасывая измерения, в которых данные не имеют дисперсии. Это также иногда называют <a href="http://en.wikipedia.org/wiki/Principal_component_analysis">анализом главных компонент (PCA)</a> для уменьшения размерности:  </p>
<div class="code"><pre class="code literal-block">Xrot_reduced = np.dot(X, U[:,:100]) # Xrot_reduced becomes [N x 100]
</pre></div>

<p>После этой операции мы уменьшили исходный набор данных размером [N x D] до размера [N x 100], сохранив 100 измерений данных, которые содержат наибольшую дисперсию. Очень часто можно добиться очень хорошей производительности, обучая линейные классификаторы или нейронные сети на наборах данных, уменьшенных с помощью метода главных компонент, что позволяет сэкономить место и время.  </p>
<p>Последнее преобразование, которое вы можете увидеть на практике, — это <strong>отбеливание</strong>. Операция отбеливания преобразует данные в собственный базис и делит каждое измерение на собственное значение, чтобы нормализовать масштаб. Геометрическая интерпретация этого преобразования заключается в том, что если исходные данные представляют собой многомерную гауссову функцию, то отбелённые данные будут представлять собой гауссову функцию с нулевым средним значением и единичной ковариационной матрицей. Этот шаг будет выглядеть следующим образом:  </p>
<div class="code"><pre class="code literal-block"># whiten the data:
# divide by the eigenvalues (which are square roots of the singular values)
Xwhite = Xrot / np.sqrt(S + 1e-5)  
</pre></div>

<p><em>Предупреждение: усиливается шум</em>. Обратите внимание, что мы добавляем <strong>1e-5</strong> (или небольшую константу), чтобы предотвратить деление на ноль. Одним из недостатков этого преобразования является то, что оно может сильно усиливать шум в данных, поскольку растягивает все измерения (включая несущественные измерения с небольшой дисперсией, которые в основном являются шумом) до одинакового размера на входе. На практике это можно смягчить более сильным сглаживанием (т. е. увеличив <strong>1e-5</strong> до большего числа).  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/nn2/prepro2.jpeg"></p>
<p>PCA / Отбеливание. <strong>Слева</strong>: оригинальная игрушка, 2-мерные входные данные. <strong>Посередине</strong>: после выполнения PCA. Данные центрируются на нуле, а затем поворачиваются в собственный базис ковариационной матрицы данных. Это декоррелирует данные (ковариационная матрица становится диагональной). <strong>Справа</strong>: каждое измерение дополнительно масштабируется по собственным значениям, преобразуя матрицу ковариации данных в единичную матрицу. Геометрически это соответствует растяжению и сжатию данных в изотропный гауссовский большой объект.  </p>
<hr>
<p>Мы также можем попытаться визуализировать эти преобразования с помощью изображений CIFAR-10. Обучающий набор CIFAR-10 имеет размер 50 000 x 3072, где каждое изображение растягивается в вектор-строку размером 3072. Затем мы можем вычислить ковариационную матрицу [3072 x 3072] и вычислить её разложение по методу сингулярного значения (что может быть относительно затратным). Как выглядят вычисленные собственные векторы визуально? Возможно, вам поможет изображение:  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/nn2/cifar10pca.jpeg"><br><strong>Слева</strong>: пример набора из 49 изображений. <strong>2-е слева</strong>: 144 главных собственных вектора из 3072. Главные собственные векторы объясняют большую часть дисперсии данных, и мы видим, что они соответствуют более низким частотам на изображениях. <strong>2-е справа</strong>: 49 изображений, уменьшенных с помощью метода главных компонент с использованием 144 показанных здесь собственных векторов. То есть вместо того, чтобы представлять каждое изображение в виде 3072-мерного вектора, где каждый элемент — это яркость конкретного пикселя в определённом месте и на определённом канале, каждое изображение выше представлено только 144-мерным вектором, где каждый элемент показывает, какая часть каждого собственного вектора составляет изображение. Чтобы увидеть, какая информация об изображении содержится в этих 144 числах, мы должны вернуться к «пиксельному» базису из 3072 чисел. Поскольку <strong>U</strong> — это поворот, этого можно добиться, умножив на <code>U.transpose()[:144,:]</code>, а затем, визуализировав полученные 3072 числа в виде изображения, вы можете заметить, что изображения немного размыты, что отражает тот факт, что верхние собственные векторы захватывают более низкие частоты. Однако большая часть информации всё равно сохраняется. <strong>Справа</strong>: визуализация «белого» представления, в котором дисперсия по каждому из 144 измерений сжата до одинаковой длины. Здесь 144 «белых» числа возвращаются к пикселям изображения путём умножения на <code>U.transpose()[:144,:]</code>. Более низкие частоты (на которые изначально приходилось больше всего дисперсии) теперь незначительны, а более высокие частоты (на которые изначально приходилось относительно мало дисперсии) становятся более выраженными.  </p>
<hr>
<p><strong>На практике</strong>. Мы упоминаем метод главных компонент/отбеливание в этих заметках для полноты картины, но эти преобразования не используются в свёрточных сетях. Однако очень важно центрировать данные по нулевому значению, и часто также выполняется нормализация каждого пикселя.  </p>
<p><strong>Распространённая ошибка</strong>. Важно отметить, что любая статистика предварительной обработки (например, среднее значение данных) должна рассчитываться только на обучающих данных, а затем применяться к проверочным/тестовым данным. Например, вычисление среднего значения и вычитание его из каждого изображения во всём наборе данных, а затем разделение данных на обучающие/проверочные/тестовые, было бы ошибкой. Вместо этого среднее значение должно рассчитываться только на обучающих данных, а затем вычитаться из всех разделов (обучающих/проверочных/тестовых).  </p>
<h3>Инициализация веса</h3>
<p>Мы рассмотрели, как построить архитектуру нейронной сети и как предварительно обработать данные. Прежде чем приступить к обучению сети, необходимо инициализировать её параметры.  </p>
<p><strong>Ловушка: инициализация всех весов нулями</strong>. Давайте начнём с того, чего делать не следует. Обратите внимание, что мы не знаем, каким должно быть конечное значение каждого веса в обученной сети, но при правильной нормализации данных разумно предположить, что примерно половина весов будет положительной, а половина — отрицательной. Тогда разумной идеей может быть установка всех начальных весов в нулевое значение, что, как мы ожидаем, будет «наилучшим предположением». Это оказалось ошибкой, потому что если каждый нейрон в сети вычисляет один и тот же результат, значит все они также будут вычислять одни и те же градиенты во время обратного распространения ошибки и подвергаться одним и тем же обновлениям параметров. Другими словами, если веса нейронов инициализированы одинаково, то между ними не будет асимметрии.  </p>
<p><strong>Небольшие случайные числа</strong>. Поэтому мы по-прежнему хотим, чтобы весовые коэффициенты были очень близки к нулю, но, как мы уже говорили выше, не равнялись нулю. В качестве решения принято инициализировать весовые коэффициенты нейронов небольшими числами и называть это <em>нарушением симметрии</em>. Идея заключается в том, что изначально все нейроны случайны и уникальны, поэтому они будут вычислять разные обновления и интегрироваться в сеть как её различные части. Реализация для одной весовой матрицы может выглядеть так: <code>W = 0.01* np.random.randn(D,H)</code>, где <code>randn</code> — выборки из гауссианы с нулевым средним и единичным стандартным отклонением. При такой формулировке вектор весов каждого нейрона инициализируется как случайный вектор, выбранный из многомерной гауссианы, поэтому нейроны ориентированы в случайном направлении во входном пространстве. Также можно использовать небольшие числа, выбранные из равномерного распределения, но на практике это, по-видимому, относительно мало влияет на конечную производительность.  </p>
<p><em>Предупреждение</em>: не обязательно, что меньшие числа будут работать лучше. Например, слой нейронной сети с очень маленькими весами во время обратного распространения ошибки будет вычислять очень маленькие градиенты для своих данных (поскольку этот градиент пропорционален значению весов). Это может значительно уменьшить «сигнал градиента», проходящий через сеть в обратном направлении, и стать проблемой для глубоких сетей.  </p>
<p><strong>Калибровка дисперсии с помощью 1/sqrt(n)</strong>. Одна из проблем, связанных с вышеописанным предложением, заключается в том, что дисперсия выходных данных случайно инициализированного нейрона растёт с увеличением количества входных данных. Оказывается, мы можем нормализовать дисперсию выходных данных каждого нейрона до 1, масштабируя его вектор весов на квадратный корень из <em>количества входов</em> (т. е. количества входных данных). То есть рекомендуемая эвристика заключается в инициализации вектора весов каждого нейрона следующим образом: <code>w = np.random.randn(n) / sqrt(n)</code>, где <code>n</code> — количество входных данных. Это гарантирует, что все нейроны в сети изначально имеют примерно одинаковое распределение выходных данных, и эмпирически улучшает скорость сходимости.  </p>
<p><strong>Схема вывода выглядит следующим образом</strong>:Рассмотрим внутренний продукт <strong>\(s = \sum_i^n w_i x_i\)</strong> между весами <strong>w</strong> и входные данные <strong>x</strong>, что даёт исходную активацию нейрона до нелинейности. Мы можем изучить дисперсию <strong>s</strong>:  </p>
<p>$$
\begin{align}
\text{Var}(s) &amp;= \text{Var}(\sum_i^n w_ix_i) \\
&amp;= \sum_i^n \text{Var}(w_ix_i) \\
&amp;= \sum_i^n [E(w_i)]^2\text{Var}(x_i) + [E(x_i)]^2\text{Var}(w_i) + \text{Var}(x_i)\text{Var}(w_i) \\
&amp;= \sum_i^n \text{Var}(x_i)\text{Var}(w_i) \\
&amp;= \left( n \text{Var}(w) \right) \text{Var}(x)
\end{align}
$$  </p>
<p>где на первых двух этапах мы использовали <a href="http://en.wikipedia.org/wiki/Variance"> свойства дисперсии</a> . На третьем этапе мы предположили, что входные данные и веса имеют нулевое среднее значение, поэтому <strong>\(E[x_i] = E[w_i] = 0\)</strong>. Обратите внимание, что в общем случае это не так: например, блоки ReLU будут иметь положительное среднее значение. На последнем этапе мы предположили, что все <strong>\(w_i, x_i\)</strong> являются одинаково распределёнными. Из этого вывода следует, что если мы хотим <strong>s</strong> иметь ту же дисперсию, что и все его входные данные <strong>x</strong>, тогда во время инициализации мы должны убедиться, что дисперсия каждого веса <strong>w</strong> является <strong>1/n</strong>. Следовательно при учете <strong>\(\text{Var}(aX) = a^2\text{Var}(X)\)</strong>) для случайной величины <strong>X</strong> и скаляра <strong>a</strong> говорит о необходимости взять единичный гауссовское распределение, а затем масштабировать его <strong>\(a = \sqrt{1/n}\)</strong>, чтобы внести свой вклад в его дисперсию <strong>1/n</strong>. Это дает инициализацию <code>w = np.random.randn(n) / sqrt(n)</code>.  </p>
<p>Аналогичный анализ проводится в статье <a href="http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf">«Понимание сложности обучения глубоких нейронных сетей прямого распространения»</a> Глоро и др. В этой статье авторы в итоге рекомендуют инициализацию в виде <strong>Var(w)=2/(nin+nout)</strong>, где <strong>\(n_in\), \(n_out)\</strong> - это количество единиц в предыдущем слое и в следующем слое. Это основано на компромиссе и эквивалентном анализе градиентов обратного распространения. В более поздней статье на эту тему <a href="http://arxiv-web3.library.cornell.edu/abs/1502.01852">«Глубокое изучение выпрямителей: превосходные результаты на уровне человека при классификации ImageNet»</a> Хе и др. выводится инициализация специально для нейронов ReLU, и делается вывод, что дисперсия нейронов в сети должна быть <strong>2.0/n</strong>. Это даёт инициализацию <code>w = np.random.randn(n) * sqrt(2.0/n)</code> и является текущей рекомендацией для использования на практике в конкретном случае нейронных сетей с нейронами ReLU.  </p>
<p><strong>Разреженная инициализация</strong>. Другой способ решить проблему некалиброванных дисперсий — установить все весовые матрицы в нулевое значение, но для нарушения симметрии каждый нейрон случайным образом соединяется (с весами, выбранными из небольшого гауссовского распределения, как описано выше) с фиксированным количеством нейронов под ним. Типичное количество нейронов, с которыми можно соединиться, может составлять всего 10.  </p>
<p><strong>Инициализация смещений</strong>. Можно и часто бывает нужно инициализировать смещения равными нулю, поскольку асимметрия устраняется с помощью небольших случайных чисел в весовых коэффициентах. Для нелинейностей ReLU некоторые предпочитают использовать небольшое постоянное значение, например <strong>0,01</strong>, для всех смещений, потому что это гарантирует, что все блоки ReLU срабатывают в начале и, следовательно, получают и передают некоторый градиент. Однако неясно, обеспечивает ли это стабильное улучшение (на самом деле некоторые результаты указывают на то, что это ухудшает производительность), и чаще всего используется просто инициализация с нулевым смещением.  </p>
<p>На практике в настоящее время рекомендуется использовать блоки ReLU и <code>w = np.random.randn(n) * sqrt(2.0/n)</code> в соответствии с <a href="http://arxiv-web3.library.cornell.edu/abs/1502.01852">Хе и др.</a>.  </p>
<h3>Нормализация партии</h3>
<p><strong>Нормализация с помощью пакетов</strong>. Недавно разработанная Иоффе и Сегеди техника под названием <a href="http://arxiv.org/abs/1502.03167">«Нормализация с помощью пакетов»</a> избавляет от многих проблем, связанных с правильной инициализацией нейронных сетей, поскольку в начале обучения активации во всей сети принудительно распределяются по единичному гауссовскому распределению. Основное наблюдение заключается в том, что это возможно, потому что нормализация — это простая дифференцируемая операция. При реализации этой техники обычно вставляется слой <strong>BatchNorm</strong> сразу после полносвязных слоёв (или свёрточных слоёв, как мы вскоре увидим) и перед нелинейностями. Мы не будем подробно останавливаться на этом методе, поскольку он хорошо описан в статье по ссылке, но отметим, что использование пакетной нормализации в нейронных сетях стало очень распространённой практикой. На практике сети, использующие пакетную нормализацию, значительно более устойчивы к неправильной инициализации. Кроме того, пакетную нормализацию можно интерпретировать как предварительную обработку на каждом слое сети, но интегрированную в саму сеть дифференцируемым образом. Здорово!  </p>
<h3>Регуляризация</h3>
<p>Существует несколько способов контроля возможностей нейронных сетей для предотвращения переобучения:  </p>
<p><strong>Регуляризация L2</strong> — это, пожалуй, самая распространённая форма регуляризации. Её можно реализовать, штрафуя за квадраты значений всех параметров непосредственно в целевой функции. То есть для каждого веса <strong>w</strong> в сети мы добавляем термин <strong>\(\frac{1}{2} \lambda w^2\)</strong> к цели, где <strong>λ</strong> является силой регуляризации. Обычно наблюдается фактор <strong>\(\frac{1}{2}\)</strong> впереди, потому что тогда градиент этого члена по отношению к параметру <strong>w</strong> это просто <strong>λw</strong> вместо <strong>2λw</strong>.Регуляризация <strong>\(L_2\)</strong> интуитивно понятна: она сильно штрафует векторы с пиковыми значениями и отдаёт предпочтение векторам с размытыми значениями. Как мы обсуждали в разделе «Линейная классификация», из-за мультипликативных взаимодействий между весами и входными данными это позволяет сети использовать все входные данные понемногу, а не некоторые из них — по максимуму. Наконец, обратите внимание, что при обновлении параметров методом градиентного спуска использование регуляризации <strong>\(L_2\)</strong> в конечном итоге означает, что каждый вес уменьшается линейно: <code>W += -lambda * W</code> по направлению к нулю.  </p>
<p><strong>Регуляризация L1</strong> — ещё одна относительно распространённая форма регуляризации, при которой для каждого веса <strong>w</strong> мы добавляем термин <strong>λ∣w∣</strong> к цели. Можно комбинировать регуляризацию <strong>\(L_1\)</strong> с регуляризацией <strong>\(L_2\)</strong>: <strong>\(\lambda_1 \mid w \mid + \lambda_2 w^2\)</strong> (это называется <a href="http://web.stanford.edu/~hastie/Papers/B67.2%20%282005%29%20301-320%20Zou%20&amp;%20Hastie.pdf">регуляризацией эластичной сети</a>). Регуляризация <strong>\(L_1\)</strong> обладает интригующим свойством: она приводит к тому, что весовые векторы во время оптимизации становятся разреженными (то есть очень близкими к нулю). Другими словами, нейроны с регуляризацией <strong>\(L_1\)</strong> в конечном итоге используют только разреженное подмножество наиболее важных входных данных и становятся почти невосприимчивыми к «зашумлённым» входным данным. Для сравнения, конечные весовые векторы при регуляризации <strong>\(L_2\)</strong> обычно представляют собой размытые, небольшие числа. На практике, если вас не интересует явный выбор признаков, можно ожидать, что регуляризация <strong>\(L_2\)</strong> будет работать лучше, чем регуляризация <strong>\(L_1\)</strong>.  </p>
<p><strong>Ограничения по максимальной норме</strong>. Другой формой регуляризации является установление абсолютной верхней границы для величины вектора весов каждого нейрона и использование проецируемого градиентного спуска для обеспечения соблюдения ограничения. На практике это соответствует обычному обновлению параметров, а затем обеспечению соблюдения ограничения путём ограничения вектора весов <strong>\(\vec{w}\)</strong> каждого нейрона, чтобы удовлетворить <strong>\(\Vert \vec{w} \Vert_2 &lt; c\)</strong>. Типичные значения <strong>c</strong>. Они составляют порядка 3 или 4. Некоторые пользователи сообщают об улучшениях при использовании этой формы регуляризации. Одно из её привлекательных свойств заключается в том, что сеть не может «взрывообразно» расти, даже если скорость обучения установлена слишком высокой, потому что обновления всегда ограничены.  </p>
<p><strong>Выпадение</strong> — чрезвычайно эффективный, простой и недавно представленный метод регуляризации, описанный Шриваставой и др. в <a href="http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf">«Выпадении: простом способе предотвращения переобучения нейронных сетей»</a> <em>(pdf)</em>, который дополняет другие методы (<strong>\(L_1\)</strong>, <strong>\(L_2\)</strong>, <em>maxnorm</em>). Во время обучения выпадение реализуется путём активации нейрона только с некоторой вероятностью <strong>p</strong> (гиперпараметр), или в противном случае установив его равным нулю.  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/nn2/dropout.jpeg"></p>
<p>Рисунок, взятый из <a href="http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf">статьи о выпадении</a>, иллюстрирует эту идею. Во время обучения выпадение можно интерпретировать как выборку нейронной сети из полной нейронной сети и обновление параметров выбранной сети только на основе входных данных. (Однако экспоненциальное количество возможных выбранных сетей не является независимым, поскольку они имеют общие параметры.) Во время тестирования выпадение не применяется, а интерпретируется как оценка усреднённого прогноза по экспоненциально большому ансамблю всех подсетей (подробнее об ансамблях в следующем разделе).  </p>
<hr>
<p>Выпадение в примере трёхслойной нейронной сети будет реализовано следующим образом:  </p>
<p>```
 """ Vanilla Dropout: Not recommended implementation (see notes below) """</p>
<p>p = 0.5 # probability of keeping a unit active. higher = less dropout</p>
<p>def train_step(X):
  """ X contains the data """</p>
<p># forward pass for example 3-layer neural network
  H1 = np.maximum(0, np.dot(W1, X) + b1)
  U1 = np.random.rand(<em>H1.shape) &lt; p # first dropout mask
  H1 </em>= U1 # drop!
  H2 = np.maximum(0, np.dot(W2, H1) + b2)
  U2 = np.random.rand(<em>H2.shape) &lt; p # second dropout mask
  H2 </em>= U2 # drop!
  out = np.dot(W3, H2) + b3</p>
<p># backward pass: compute gradients... (not shown)
  # perform parameter update... (not shown)</p>
<p>def predict(X):
  # ensembled forward pass
  H1 = np.maximum(0, np.dot(W1, X) + b1) * p # NOTE: scale the activations
  H2 = np.maximum(0, np.dot(W2, H1) + b2) * p # NOTE: scale the activations
  out = np.dot(W3, H2) + b3
  ```  </p>
<p>В приведённом выше коде внутри функции <code>train_step</code> мы дважды применили отсев: на первом скрытом слое и на втором скрытом слое. Отсев также можно применить непосредственно на входном слое, в этом случае мы также создадим бинарную маску для входных данных <code>X</code>. Обратный проход остаётся неизменным, но, конечно, должен учитывать созданные маски <code>U1,U2</code>.  </p>
<p>Важно отметить, что в функции <code>predict</code> мы больше не отбрасываем значения, а выполняем масштабирование выходных значений скрытого слоя с помощью <strong>p</strong>.Это важно, потому что во время тестирования все нейроны видят все свои входные данные, поэтому мы хотим, чтобы выходные данные нейронов во время тестирования были идентичны ожидаемым выходным данным во время обучения. Например, в случае <strong>p=0.5</strong>. Нейроны должны вдвое уменьшить свои выходные данные во время тестирования, чтобы получить те же выходные данные, что и во время обучения (в среднем). Чтобы понять это, рассмотрим выходные данные нейрона <strong>x</strong> (до отбрасывания). При отбрасывании ожидаемый результат от этого нейрона станет <strong>px+(1−p)0</strong>, потому что выходной сигнал нейрона с вероятностью будет равен нулю <strong>1−p</strong>. Во время тестирования, когда мы поддерживаем постоянную активность нейрона, мы должны корректировать <strong>x→px</strong>, чтобы сохранить ожидаемый результат. Также можно показать, что выполнение этого ослабления во время тестирования может быть связано с процессом перебора всех возможных бинарных масок (и, следовательно, всех экспоненциально большого количества подсетей) и вычисления их совокупного прогноза.  </p>
<p>Нежелательным свойством представленной выше схемы является то, что мы должны масштабировать активации по <strong>p</strong> во время тестирования. Поскольку производительность во время тестирования очень важна, всегда предпочтительнее использовать <strong>инвертированное отбрасывание</strong>, при котором масштабирование выполняется во время обучения, а прямой проход во время тестирования остаётся нетронутым. Кроме того, это удобно тем, что код прогнозирования может оставаться нетронутым, если вы решите изменить место применения отбрасывания или отказаться от него. Инвертированное отбрасывание выглядит следующим образом:  </p>
<p>```
 """ 
Inverted Dropout: Recommended implementation example.
We drop and scale at train time and don't do anything at test time.
"""</p>
<p>p = 0.5 # probability of keeping a unit active. higher = less dropout</p>
<p>def train_step(X):
  # forward pass for example 3-layer neural network
  H1 = np.maximum(0, np.dot(W1, X) + b1)
  U1 = (np.random.rand(<em>H1.shape) &lt; p) / p # first dropout mask. Notice /p!
  H1 </em>= U1 # drop!
  H2 = np.maximum(0, np.dot(W2, H1) + b2)
  U2 = (np.random.rand(<em>H2.shape) &lt; p) / p # second dropout mask. Notice /p!
  H2 </em>= U2 # drop!
  out = np.dot(W3, H2) + b3</p>
<p># backward pass: compute gradients... (not shown)
  # perform parameter update... (not shown)</p>
<p>def predict(X):
  # ensembled forward pass
  H1 = np.maximum(0, np.dot(W1, X) + b1) # no scaling necessary
  H2 = np.maximum(0, np.dot(W2, H1) + b2)
  out = np.dot(W3, H2) + b3
  ``` </p>
<p>После первого появления метода отсева было проведено множество исследований, направленных на то, чтобы понять, в чём заключается его эффективность на практике и как он соотносится с другими методами регуляризации. Рекомендуем ознакомиться с дополнительной литературой для заинтересованных читателей:<br>
- <a href="http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf">Статья о выпадении из курса</a> Шриваставы и др., 2014.
- <a href="http://papers.nips.cc/paper/4882-dropout-training-as-adaptive-regularization.pdf">Выборочное обучение как адаптивная регуляризация</a>: «мы показываем, что регуляризация с помощью вычеркивания эквивалентна регуляризации <strong>\(L_2\)</strong> первого порядка, применяемой после масштабирования признаков с помощью оценки обратной диагональной информационной матрицы Фишера».  </p>
<p><strong>Тема шума при прямом проходе</strong>. Выпадение относится к более общей категории методов, которые вводят стохастическое поведение при прямом проходе сети. Во время тестирования шум усредняется <em>аналитически</em> (как в случае с выпадением при умножении на <strong>p</strong>) или <em>численно</em> (например, с помощью выборки, выполняя несколько прямых проходов с разными случайными решениями, а затем усредняя их). Примером других исследований в этом направлении является <a href="http://cs.nyu.edu/~wanli/dropc/">DropConnect</a>, где во время прямого прохода случайный набор весовых коэффициентов устанавливается в ноль. В качестве предвосхищения отметим, что свёрточные нейронные сети также используют эту тему с помощью таких методов, как стохастическое объединение, дробное объединение и увеличение данных. Мы подробно рассмотрим эти методы позже.  </p>
<p><strong>Регуляризация смещения</strong>. Как мы уже упоминали в разделе о линейной классификации, обычно не рекомендуется регуляризировать параметры смещения, поскольку они не взаимодействуют с данными посредством мультипликативных взаимодействий и, следовательно, не влияют на конечную цель. Однако в практических приложениях (при надлежащей предварительной обработке данных) регуляризация смещения редко приводит к значительному ухудшению производительности. Вероятно, это связано с тем, что по сравнению со всеми весовыми параметрами коэффициентов смещения очень мало, поэтому классификатор может «позволить себе» использовать коэффициенты смещения, если они нужны ему для уменьшения потерь данных.  </p>
<p><strong>Послойная регуляризация</strong>. Не очень распространена регуляризация разных слоёв с разной степенью (за исключением, возможно, выходного слоя). В литературе опубликовано относительно мало результатов, связанных с этой идеей.  </p>
<p><strong>На практике</strong>: чаще всего используется единая глобальная сила регуляризации <strong>\(L_2\)</strong>, которая проходит перекрестную проверку. Также часто применяется комбинация с отбрасыванием данных после всех слоев. Значение <strong>p=0.5</strong> это разумное значение по умолчанию, но его можно настроить на основе данных проверки.  </p>
<h2>Функции потерь</h2>
<p>Мы обсудили часть целевой функции, отвечающую за регуляризацию, которую можно рассматривать как штраф за определённую меру сложности модели. Вторая часть целевой функции — это <em>потеря данных</em>, которая в задаче обучения с учителем измеряет соответствие между прогнозом (например, оценками классов при классификации) и истинным значением. Потеря данных представляет собой среднее значение потерь данных для каждого отдельного примера. То есть, <strong>\(L = \frac{1}{N} \sum_i L_i\) where \(N\)</strong>, где <strong>N</strong> - количество обучающих данных. Давайте сократим <strong>\(f = f(x_i; W)\)</strong> активация выходного слоя в нейронной сети. Существует несколько типов задач, которые вы можете решить на практике:
- <strong>Классификация</strong> — это случай, который мы подробно обсуждали. Здесь мы предполагаем наличие набора примеров и одной правильной метки (из фиксированного набора) для каждого примера. Одной из двух наиболее часто встречающихся функций стоимости в этой задаче является SVM (<em>например, формулировка Уэстона Уоткинса</em>):<br>
$$<br>
L_i = \sum_{j\neq y_i} \max(0, f_j - f_{y_i} + 1)
$$<br>
Как мы вкратце упомянули, некоторые люди сообщают о более высокой производительности при использовании квадратичной функции потерь (т. е. вместо <strong>\(\max(0, f_j - f_{y_i} + 1)^2\)</strong>). Вторым распространенным выбором является <strong>классификатор Softmax</strong>, который использует кросс-энтропийные потери:<br>
$$<br>
L_i = -\log\left(\frac{e^{f_{y_i}}}{ \sum_j e^{f_j} }\right)
$$   </p>
<p><strong>Проблема: большое количество классов</strong>. Когда набор меток очень велик (например, слова в английском словаре или <strong>ImageNet</strong>, содержащий 22 000 категорий), вычисление полной вероятности по <strong>методу Softmax</strong> становится дорогостоящим. Для некоторых приложений популярны приближённые версии. Например, в задачах обработки естественного языка может быть полезно использовать <em>иерархический Softmax</em> (см. одно из объяснений <a href="http://arxiv.org/pdf/1310.4546.pdf">здесь</a> (pdf)).</p>
<p><em>Иерархический Softmax</em> раскладывает слова на метки в виде дерева. Затем каждая метка представляется в виде пути по дереву, и в каждом узле дерева обучается <strong>классификатор Softmax</strong>, чтобы различать левую и правую ветви. Структура дерева сильно влияет на производительность и, как правило, зависит от задачи.  </p>
<ul>
<li>
<strong>Классификация атрибутов</strong>. Оба приведённых выше примера предполагают, что существует единственный правильный ответ <strong>\(y_i\)</strong>. Но что , если <strong>\(y_i\)</strong>- это бинарный вектор, в котором каждый пример может иметь или не иметь определённый атрибут, и где атрибуты не исключают друг друга? Например, изображения <strong>Вконтакте</strong> можно рассматривать как помеченные определённым подмножеством хэштегов из большого набора всех хэштегов, и изображение может содержать несколько хэштегов. Разумным подходом в этом случае будет создание бинарного классификатора для каждого отдельного атрибута. Например, бинарный классификатор для каждой категории отдельно будет иметь вид:<br>
$$
L_i = \sum_j \max(0, 1 - y_{ij} f_j)
$$<br>
где сумма по всем категориям <strong>\(j\)</strong> и <strong>\(y_{ij}\)</strong> равно <strong>+1</strong> или <strong>-1</strong> в зависимости от того, помечен ли i-й пример j-м атрибутом, а вектор оценки <strong>\(f_j\)</strong> будет положительным, если класс прогнозируется как присутствующий, и отрицательным в противном случае. Обратите внимание, что потери накапливаются, если положительный пример имеет оценку меньше <strong>+1</strong> или если отрицательный пример имеет оценку больше <strong>-1</strong>.<br>
Альтернативой этому подходу было бы обучение классификатора логистической регрессии для каждого атрибута по отдельности. Бинарный классификатор логистической регрессии имеет только два класса <em>(0, 1)</em> и вычисляет вероятность класса <strong>1</strong> следующим образом:<br>
$$
P(y = 1 \mid x; w, b) = \frac{1}{1 + e^{-(w^Tx +b)}} = \sigma (w^Tx + b)
$$<br>
Поскольку сумма вероятностей классов <em>1 и 0</em> равна единице, вероятность класса <strong>0</strong> равна <strong>\(P(y = 0 \mid x; w, b) = 1 - P(y = 1 \mid x; w,b)\)</strong>. Таким образом, пример классифицируется как положительный <strong>(y = 1)</strong>, если <strong>\(\sigma (w^Tx + b) &gt; 0.5\)</strong>, или что эквивалентно , если оценка <strong>\(w^Tx +b &gt; 0\)</strong>. Затем функция потерь максимизирует эту вероятность. Вы можете убедиться, что это сводится к минимизации отрицательного логарифма правдоподобия:<br>
$$
L_i = -\sum_j y_{ij} \log(\sigma(f_j)) + (1 - y_{ij}) \log(1 - \sigma(f_j))
$$<br>
где этикетки <strong>\(y_{ij}\)</strong> считаются равными либо <em>1 (положительному), либо 0 (отрицательному)</em>, и  <strong>\(\sigma(\cdot)\)</strong>. Это сигмоидальная функция. Приведённое выше выражение может показаться пугающим, но градиент на <strong>f</strong> на самом деле он чрезвычайно прост и интуитивно понятен: <strong>\(\partial{L_i} / \partial{f_j} = \sigma(f_j) - y_{ij}\)</strong> (поскольку вы можете перепроверить себя, взяв производные).  </li>
<li>
<strong>Регрессия</strong> — это задача прогнозирования величин с действительными значениями, таких как цена дома или длина чего-либо на изображении. Для решения этой задачи обычно вычисляют потери между прогнозируемой величиной и истинным ответом, а затем измеряют норму <strong>\(L_2\)</strong> в квадрате или норму <strong>\(L_1\)</strong> разности. Норма <strong>\(L_2\)</strong> в квадрате вычисляет потери для одного примера в виде:<br>
$$
L_i = \Vert f - y_i \Vert_2^2
$$<br>
Причина, по которой норма <strong>\(L_2\)</strong> возводится в квадрат в целевой функции, заключается в том, что градиент становится намного проще, не меняя оптимальные параметры, поскольку возведение в квадрат — это монотонная операция. Норма <strong>\(L_1\)</strong> вычисляется путём суммирования абсолютных значений по каждому измерению:<br>
$$
L_i = \Vert f - y_i \Vert_1 = \sum_j \mid f_j - (y_i)<em>j \mid
$$<br>
_где сумма__ <strong>\(\sum_j\)</strong> это сумма по всем параметрам желаемого прогноза, если прогнозируется более одной величины. Рассмотрим только j-й параметр i-го примера и обозначим разницу между истинным и прогнозируемым значением как <strong>\(\delta_{ij}\)</strong>, градиент для этого измерения (т.е. <strong>\(\partial{L_i} / \partial{f_j}\))</strong>) легко выводится как либо <strong>\(\delta_{ij}\)</strong> с нормой <strong>\(L_2\)</strong>, или <strong>\(sign(\delta_{ij})\)</strong>.То есть градиент оценки будет либо прямо пропорционален разнице в ошибках, либо будет фиксированным и унаследует только знак разницы.<br>
_Предупреждение</em>: важно отметить, что функцию потерь <strong>\(L_2\)</strong> гораздо сложнее оптимизировать, чем более стабильную функцию потерь, такую как <strong>Softmax</strong>.  </li>
</ul>
<p>Интуитивно понятно, что для этого требуется очень хрупкое и специфическое свойство сети, чтобы она выдавала ровно одно правильное значение для каждого входного сигнала (и его расширений). Обратите внимание, что это не относится к <strong>Softmax</strong>, где точное значение каждого балла менее важно: важно только, чтобы их величины были соответствующими. Кроме того, функция потерь <strong>\(L_2\)</strong> менее устойчива, поскольку выбросы могут приводить к огромным градиентам. Столкнувшись с проблемой регрессии, сначала подумайте, абсолютно ли недостаточно квантовать выходные данные по ячейкам. Например, если вы прогнозируете звездный рейтинг продукта, возможно, гораздо лучше использовать <em>5 независимых классификаторов</em> для оценок в 1-5 звезд вместо потери регрессии. Классификация имеет дополнительное преимущество в том, что она может дать вам распределение по результатам регрессии, а не только по одному результату без указания его достоверности. Если вы уверены, что классификация не подходит, используйте <strong>\(L_2\)</strong>, но будьте осторожны: например, <strong>\(L_2\)</strong> более нестабилен, и применять отсев в сети (особенно на слое непосредственно перед потерей <strong>\(L_2\)</strong>) — не лучшая идея.  </p>
<blockquote>
<p>Сталкиваясь с задачей регрессии, в первую очередь подумайте, действительно ли она необходима. Вместо этого по возможности дискретизируйте выходные данные и выполняйте классификацию по ним.</p>
</blockquote>
<ul>
<li>
<strong>Структурированное прогнозирование</strong>. Структурированные потери относятся к случаю, когда метками могут быть произвольные структуры, такие как графы, деревья или другие сложные объекты. Обычно также предполагается, что пространство структур очень велико и его нелегко перебрать. Основная идея структурированных потерь SVM заключается в том, чтобы требовать запас между правильной структурой и <strong>\(y_i\)</strong> и набравшая наибольшее количество баллов неправильная структура. Эту проблему не принято решать как простую задачу неограниченной оптимизации с градиентным спуском. Вместо этого обычно разрабатываются специальные решатели, позволяющие воспользоваться конкретными упрощающими допущениями структурного пространства. Мы кратко упоминаем проблему, но считаем, что специфика выходит за рамки данного класса.  </li>
</ul>
<h2>Краткая сводка</h2>
<p>Подводя итог:
- Рекомендуется предварительно обработать данные, чтобы их среднее значение было равно нулю, и нормализовать их масштаб до <strong>[-1, 1]</strong> по каждому признаку
- Инициализируйте веса, извлекая их из гауссова распределения со стандартным отклонением <strong>\(\sqrt{2/n}\), where \(n\)</strong>, где <strong>n</strong> - это количество входов в нейрон. Например, в NumPy: <code>w = np.random.randn(n) * sqrt(2.0/n)</code>.
- Используйте регуляризацию <strong>\(L_2\)</strong> и отсев (перевернутая версия)
- Используйте пакетную нормализацию
- Мы обсудили различные задачи, которые вы можете выполнять на практике, и наиболее распространённые функции потерь для каждой задачи  </p>
<p>Теперь мы предварительно обработали данные, настроили и инициализировали модель. В следующем разделе мы рассмотрим процесс обучения и его динамику.</p>
                </div>
            </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/convnets-1/" class="u-url">Сверточные сети. Введение</a></h1>
                <div class="metadata">
                    <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                        Андрей Лабинцев
                    </span></p>
            <p class="dateline">
            <a href="posts/convnets-1/" rel="bookmark">
            <time class="published dt-published" datetime="2025-03-08T19:42:16+03:00" itemprop="datePublished" title="2025-03-08 19:42">2025-03-08 19:42</time></a>
            </p>
                </div>
            </header><div class="e-content entry-content">
                    <h2>Сверточные сети. Введение</h2>
<p>Сожержание: 
- <a href="posts/convnets-1/">Краткое вступление без мозговых аналогий</a>
- <a href="posts/convnets-1/">Моделирование одного нейрона</a>
    + <a href="posts/convnets-1/">Биологическая мотивация и связи</a>
    + <a href="posts/convnets-1/">Одиночный нейрон как линейный классификатор</a>
    + <a href="posts/convnets-1/">Часто используемые функции активации</a>
- <a href="posts/convnets-1/">Архитектуры нейронных сетей</a>
    + <a href="posts/convnets-1/">Многоуровневая организация</a>
    + <a href="posts/convnets-1/">Пример вычисления с прямой связью</a>
    + <a href="posts/convnets-1/">Представительская власть</a>
    + <a href="posts/convnets-1/">Настройка количества слоев и их размеров</a>
- <a href="posts/convnets-1/">Краткие сведения</a>
- <a href="posts/convnets-1/">Дополнительные ссылки</a>  </p>
<h2>Краткое вступление</h2>
<p>Можно представить нейронные сети, не прибегая к аналогам с мозгом. В разделе о линейной классификации мы вычисляли баллы для различных визуальных категорий по изображению с помощью формулы <strong>s=Wx</strong>, где <strong>W</strong> была матрицей и <strong>x</strong> был вектор входных данных, содержащий все пиксельные данные изображения. В случае CIFAR-10 <strong>x</strong> является вектором-столбцом <strong>[3072x1]</strong>, и <strong>W</strong>. Это матрица <strong>[10x3072]</strong>, так что выходные данные представляют собой вектор из 10 оценок по классам.  </p>
<p>Примерная нейронная сеть вместо этого вычисляла бы <strong>\( s = \( W_2 \max(0, W_1 x) \)</strong>. Здесь, <strong>\(W_1\)</strong> может быть, например, матрицей <strong>[100x3072]</strong>, преобразующей изображение в 100-мерный промежуточный вектор. Функция <strong>\(max(0,-) \)</strong> это нелинейность, котрая применяется поэлементно. Существует несколько вариантов нелинейности (которые мы рассмотрим ниже), но этот вариант является распространённым и просто приравнивает все значения ниже нуля к нулю. Наконец, матрица <strong>\(W_2\)</strong> тогда будет иметь размер <strong>[10x100]</strong>, так что мы снова получим 10 чисел, которые мы интерпретируем как оценки классов. Обратите внимание, что нелинейность имеет решающее значение с точки зрения вычислений — если бы мы её не использовали, то две матрицы можно было бы объединить в одну, и, следовательно, прогнозируемые оценки классов снова были бы линейной функцией входных данных. Нелинейность — это то, что даёт нам <strong>колебания</strong>. Параметры <strong>W2,W1</strong>. Они обучаются с помощью стохастического градиентного спуска, а их градиенты вычисляются с помощью правила дифференцирования (и обратного распространения ошибки).  </p>
<p>Аналогично трехслойная нейронная сеть могла бы выглядеть следующим образом  <strong>\( s = W_3 \max(0, W_2 \max(0, W_1 x)) \)</strong>, где все <strong>\(W_3, W_2, W_1\)</strong>- это параметры, которые необходимо изучить. Размеры промежуточных скрытых векторов являются гиперпараметрами сети, и мы рассмотрим, как их можно задать позже. Теперь давайте посмотрим, как можно интерпретировать эти вычисления с точки зрения нейронов/сети.  </p>
<h2>Моделирование одного нейрона</h2>
<p>Изначально область нейронных сетей была в первую очередь ориентирована на моделирование биологических нейронных систем, но с тех пор она расширилась и стала заниматься разработкой и достижением хороших результатов в задачах машинного обучения. Тем не менее, мы начнём наше обсуждение с очень краткого и общего описания биологической системы, которая послужила источником вдохновения для значительной части этой области.  </p>
<h3>Биологическая мотивация и связи</h3>
<p>Основной вычислительной единицей мозга является <strong>нейрон</strong>. В нервной системе человека насчитывается около 86 миллиардов нейронов, и они соединены примерно с <strong>10^14</strong> — <strong>10^15</strong> <strong>синапсами</strong>. На схеме ниже показан схематичный рисунок биологического нейрона (сверху) и распространённая математическая модель (снизу). Каждый нейрон получает входные сигналы от своих <strong>дендритов</strong> и выдаёт выходные сигналы по своему (единственному) <strong>аксону</strong>. В конечном итоге аксон разветвляется и соединяется через синапсы с дендритами других нейронов. В вычислительной модели нейрона сигналы, которые проходят по аксонам (например, <strong>\(x_0\)</strong> взаимодействуют мультипликативно (например, <strong>\(w_0 x_0\)</strong> с дендритами другого нейрона в зависимости от силы синапса (например, <strong>\(w_0\)</strong>. Идея заключается в том, что синаптические силы (веса <strong>w</strong>) являются обучаемыми и контролируют силу влияния (и его направление: возбуждающее (положительный вес) или тормозящее (отрицательный вес) одного нейрона на другой. В базовой модели дендриты передают сигнал в тело клетки, где он суммируется. Если итоговая сумма превышает определённый порог, нейрон может <em>сработать</em>, отправив импульс по своему аксону. В вычислительной модели мы предполагаем, что точное время срабатывания импульсов не имеет значения и что информация передаётся только частотой срабатывания. Основываясь на этой интерпретации, это <em>частотного кода</em>, мы моделируем <em>частоту срабатывания</em> нейрона с помощью <strong>функции активации f</strong>, которая представляет собой частоту импульсов вдоль аксона. Исторически сложилось так, что в качестве функции активации часто используется <strong>сигмоидальная функция σ</strong>, поскольку она принимает вещественные входные данные (силу сигнала после суммирования) и преобразует их в диапазон от 0 до 1. Подробнее об этих функциях активации мы поговорим далее в этом разделе.  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/nn1/neuron.png"><br><img alt="" src="https://cs231n.github.io/assets/nn1/neuron_model.jpeg"><br>
  Карикатурное изображение биологического нейрона (<strong>сверху</strong>) и его математическая модель (<strong>снизу</strong>).  </p>
<hr>
<p>Пример кода для прямого распространения сигнала по одному нейрону может выглядеть следующим образом:  </p>
<div class="code"><pre class="code literal-block"><span class="k">class</span> <span class="n">Neuron</span>(<span class="n">object</span>):
  <span class="c1"># ... </span>
  <span class="n">def</span> <span class="n">forward</span>(<span class="nb">self</span>, <span class="n">inputs</span>):
    <span class="s">""" assume inputs and weights are 1-D numpy arrays and bias is a number """</span>
    <span class="n">cell_body_sum</span> = <span class="n">np</span>.<span class="nb">sum</span>(<span class="n">inputs</span> * <span class="nb">self</span>.<span class="n">weights</span>) + <span class="nb">self</span>.<span class="n">bias</span>
    <span class="n">firing_rate</span> = <span class="mf">1.0</span> / (<span class="mf">1.0</span> + <span class="n">math</span>.<span class="nb">exp</span>(-<span class="n">cell_body_sum</span>)) <span class="c1"># sigmoid activation function</span>
    <span class="k">return</span> <span class="n">firing_rate</span>
</pre></div>

<p>Другими словами, каждый нейрон выполняет скалярное произведение входных данных и своих весов, добавляет смещение и применяет нелинейность (или функцию активации), в данном случае сигмоидальную ** sigmoid \(\sigma(x) = 1/(1+e^{-x})\)**. Более подробно о различных функциях активации мы расскажем в конце этого раздела.  </p>
<p><strong>Грубая модель</strong>. Важно подчеркнуть, что эта модель биологического нейрона является очень грубой: например, существует множество различных типов нейронов, каждый из которых обладает своими свойствами. Дендриты в биологических нейронах выполняют сложные нелинейные вычисления. Синапсы — это не просто один вес, это сложная нелинейная динамическая система. Известно, что точное время выходных импульсов во многих системах имеет большое значение, что позволяет предположить, что приближение кода скорости может не работать. Из-за всех этих и многих других упрощений будьте готовы к тому, что любой, кто разбирается в нейробиологии, будет возмущаться, если вы проведёте аналогию между нейронными сетями и реальным мозгом. Если вам интересно, ознакомьтесь с этим <a href="https://physics.ucsd.edu/neurophysics/courses/physics_171/annurev.neuro.28.061604.135703.pdf">обзором</a> (в формате pdf) или с этим <a href="http://www.sciencedirect.com/science/article/pii/S0959438814000130">обзором</a>, опубликованным недавно.  </p>
<h3>Одиночный нейрон как линейный классификатор</h3>
<p>Математическая форма прямого вычисления модели нейрона может показаться вам знакомой. Как мы видели на примере линейных классификаторов, нейрон может «любить» (активация близка к единице) или «не любить» (активация близка к нулю) определённые линейные области своего входного пространства. Следовательно, с помощью подходящей функции потерь на выходе нейрона мы можем превратить один нейрон в линейный классификатор:  </p>
<p><strong>Бинарный классификатор Softmax</strong>. Например, мы можем интерпретировать <strong>\(\sigma(\sum_i * w_i * x_i + b)\ )</strong>,как вероятность_ одного из классов <strong>\(P(y_i = 1 \mid x_i; w) \)</strong>. Вероятность появления другого класса была бы равна <strong>\(P(y_i = 0 \mid x_i; w) = 1 - P(y_i = 1 \mid x_i; w) \)</strong>, так как их сумма должна быть равна единице. С помощью этой интерпретации мы можем сформулировать функцию потерь перекрёстной энтропии, как мы видели в разделе «Линейная классификация», и оптимизация этой функции приведёт к созданию бинарного классификатора Softmax (также известного как <em>логистическая регрессия</em>). Поскольку сигмоидальная функция принимает значения от 0 до 1, прогнозы этого классификатора основаны на том, превышает ли выходное значение нейрона <strong>0,5</strong>.  </p>
<p><strong>Бинарный классификатор SVM</strong>. В качестве альтернативы мы могли бы добавить к выходу нейрона функцию потерь с максимальным зазором и обучить его как бинарную машину опорных векторов.  </p>
<p><strong>Интерпретация регуляризации</strong>. В этом биологическом контексте потеря регуляризации в обоих случаях SVM/Softmax может быть интерпретирована как постепенное забывание, поскольку она приводит к уменьшению всех синаптических весов <strong>w</strong> приближается к нулю после каждого обновления параметра.  </p>
<blockquote>
<p>Один нейрон можно использовать для реализации бинарного классификатора (например, бинарного классификатора Softmax или бинарного классификатора SVM)  </p>
</blockquote>
<h3>Часто используемые функции активации</h3>
<p>Каждая функция активации (или <em>нелинейность</em>) принимает одно число и выполняет над ним определённую фиксированную математическую операцию. На практике вы можете столкнуться с несколькими функциями активации: </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/nn1/sigmoid.jpeg"><br><img alt="" src="https://cs231n.github.io/assets/nn1/tanh.jpeg"><br><strong>Сверху</strong>: сигмоидальная нелинейность сжимает действительные числа до диапазона <strong>[0,1]</strong>.<br><strong>Справа</strong>: нелинейность tanh сжимает действительные числа до диапазона <strong>[-1,1]</strong>.  </p>
<hr>
<p><strong>Сигмоида</strong>. Сигмоидальная нелинейность имеет математическую форму <strong>\(\sigma(x) = 1 / (1 + e^{-x})\)</strong>. Она показана на изображении выше слева. Как упоминалось в предыдущем разделе, она принимает вещественное число и «сжимает» его до диапазона <strong>от 0 до 1</strong>. В частности, большие отрицательные числа становятся равными <strong>0</strong>, а большие положительные числа становятся равными <strong>1</strong>. Сигмоидальная функция часто использовалась в прошлом, так как её можно интерпретировать как частоту срабатывания нейрона: от полного отсутствия срабатывания (<strong>0</strong>) до полного срабатывания с предполагаемой максимальной частотой (<strong>1</strong>). На практике сигмоидальная нелинейность в последнее время вышла из моды и используется редко. У неё есть два основных недостатка:<br>
- <em>Сигмоиды насыщаются и уничтожают градиенты</em>. Очень нежелательное свойство сигмоидального нейрона заключается в том, что, когда активация нейрона насыщается на одном из концов <strong>0</strong> или <strong>1</strong>, градиент в этих областях почти равен нулю. Напомним, что во время обратного распространения ошибки этот (локальный) градиент будет умножен на градиент выхода этого нейрона для всей задачи. Поэтому, если локальный градиент очень мал, он фактически «уничтожит» градиент, и почти никакой сигнал не пройдёт через нейрон к его весам и рекурсивно к его данным. Кроме того, необходимо соблюдать особую осторожность при инициализации весов сигмоидальных нейронов, чтобы предотвратить перегрузку. Например, если начальные веса слишком велики, то большинство нейронов будут перегружены, и сеть едва ли будет обучаться.<br>
- <em>Сигмоидальные выходные данные не центрированы по нулю</em>. Это нежелательно, так как нейроны на более поздних уровнях обработки в нейронной сети (подробнее об этом позже) будут получать данные, не центрированные по нулю. Это влияет на динамику во время градиентного спуска, потому что если данные, поступающие в нейрон, всегда положительные (например, <strong>x&gt;0</strong> поэлементно в <strong>\(f = w^Tx + b\)</strong>)), тогда градиент по весам <strong>w</strong> во время обратного распространения ошибки все значения станут либо положительными, либо отрицательными (в зависимости от градиента всего выражения <strong>f</strong>). Это может привести к нежелательной зигзагообразной динамике в обновлении градиентов весовых коэффициентов. Однако обратите внимание, что после суммирования этих градиентов по пакету данных окончательное обновление весовых коэффициентов может иметь разные знаки, что несколько смягчает эту проблему. Таким образом, это неудобство, но его последствия менее серьёзны по сравнению с проблемой насыщенной активации, описанной выше.  </p>
<p><strong>Tanh</strong>. Нелинейность tanh показана на изображении выше снизу. Она сжимает вещественное число до диапазона <strong>[-1, 1]</strong>. Как и в случае с сигмоидальным нейроном, его активация насыщается, но, в отличие от сигмоидального нейрона, его выходная величина смещена относительно нуля. Поэтому на практике <em>нелинейность tanh всегда предпочтительнее сигмоидальной нелинейности</em>. Также обратите внимание, что нейрон tanh — это просто масштабированный сигмоидальный нейрон, из-за чего, в частности, верно следующее: <strong>\( \tanh(x) = 2 \sigma(2x) -1  \)</strong>.  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/nn1/relu.jpeg"><br><img alt="" src="https://cs231n.github.io/assets/nn1/alexplot.jpeg"></p>
<p><strong>Сверху</strong>: функция активации выпрямленной линейной единицы (<em>ReLU</em>), которая равна нулю, когда <strong>x &lt; 0</strong>, а затем линейна с наклоном <strong>1</strong>, когда <strong>x &gt; 0</strong>. <br><strong>Снизу</strong>: график из статьи <a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">Крижевски и др.</a> (pdf), показывающий 6-кратное улучшение сходимости с модулем ReLU по сравнению с модулем tanh.  </p>
<hr>
<p><strong>ReLU</strong>. Выпрямленный линейный блок стал очень популярным в последние несколько лет. Он вычисляет функцию <strong>\(f(x) = \max(0, x)\)</strong>. Другими словами, активация просто ограничивается нулём (см. изображение выше сверху). У использования <em>ReLU</em> есть несколько плюсов и минусов:</p>
<ul>
<li>(+) Было обнаружено, что она значительно ускоряет (например, в 6 раз в <a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">Крижевски и др.</a>) сходимость стохастического градиентного спуска по сравнению с сигмоидальными/тангенциальными функциями. Утверждается, что это связано с её линейной, ненасыщаемой формой.</li>
<li>(+) По сравнению с нейронами tanh/сигмоидными нейронами, которые требуют дорогостоящих операций (экспоненциальных и т. д.), <em>ReLU</em> можно реализовать, просто установив пороговое значение для матрицы активации равным нулю.</li>
<li>(-) К сожалению, блоки <em>ReLU</em> могут быть нестабильными во время обучения и могут <em>«умирать»</em> . Например, большой градиент, проходящий через нейрон ReLU, может привести к обновлению весов таким образом, что нейрон больше никогда не активируется ни для одной точки данных. Если это произойдёт, то градиент, проходящий через блок, с этого момента будет равен нулю. То есть блоки <em>ReLU</em> могут необратимо <em>«умирать»</em> во время обучения, поскольку они могут быть отброшены от множества данных. Например, если скорость обучения установлена слишком высокой, вы можете обнаружить, что до <strong>40%</strong> вашей сети могут быть <em>«мёртвыми»</em> (то есть нейроны, которые никогда не активируются на протяжении всего набора обучающих данных). При правильной настройке скорости обучения эта проблема возникает реже.  </li>
</ul>
<p><strong>Протекающий ReLU</strong>. Протекающий <em>ReLU</em> — это одна из попыток решить проблему <em>«умирающего</em> <em>ReLU»</em>. Вместо того чтобы быть равной нулю при <strong>x &lt; 0</strong>, функция просачивающегося <em>ReLU</em> будет иметь небольшой положительный наклон (около <strong>0,01</strong>). То есть функция вычисляет <strong>\(f(x) = \mathbb{1}(x &lt; 0) (\alpha x) + \mathbb{1}(x&gt;=0) (x) \) where \(\alpha\)</strong>, где <strong>α</strong>- это небольшая константа. Некоторые люди сообщают об успехах с использованием этой формы функции активации, но результаты не всегда стабильны. Наклон в отрицательной области также может быть параметром каждого нейрона, как в случае с нейронами <em>PReLU</em>, представленными в работе <a href="http://arxiv.org/abs/1502.01852">«Глубокое погружение в выпрямители»</a> Кайминга Хэ и др., 2015. Однако в настоящее время неясно, насколько стабильны преимущества при выполнении разных задач.  </p>
<p><strong>Maxout</strong>. Были предложены другие типы устройств, которые не имеют функциональной формы <strong>\(f(w^Tx + b)\)</strong>, где нелинейность применяется к скалярному произведению весов и данных. Одним из относительно популярных вариантов является нейрон Maxout (введённый недавно <a href="https://arxiv.org/abs/1302.4389">Goodfellowи др.</a>), который обобщает ReLU и его неидеальную версию. Нейрон Maxout вычисляет функцию <strong>\(\max(w_1^Tx+b_1, w_2^Tx + b_2)\)</strong>. Обратите внимание, что и <em>ReLU</em>, и <em>Leaky</em> <em>ReLU</em> являются частным случаем этой формы (например, для <em>ReLU</em> мы имеем <strong>\(w_1, b_1 = 0\)</strong>). Таким образом, нейрон Maxout обладает всеми преимуществами блока <em>ReLU</em> (линейный режим работы, отсутствие насыщения) и не имеет его недостатков (умирающий <em>ReLU</em>). Однако, в отличие от нейронов <em>ReLU</em>, он удваивает количество параметров для каждого отдельного нейрона, что приводит к большому общему количеству параметров.  </p>
<p>На этом мы завершаем обсуждение наиболее распространённых типов нейронов и их функций активации. В качестве последнего комментария: очень редко в одной сети сочетаются разные типы нейронов, хотя в этом нет принципиальных проблем.  </p>
<p><strong>TLDR</strong>: <em>«Какой тип нейронов мне следует использовать?»</em> Используйте нелинейность <em>ReLU</em>, будьте осторожны с темпами обучения и, возможно, отслеживайте долю «мёртвых» нейронов в сети. Если вас это беспокоит, попробуйте <em>Leaky</em> <em>ReLU</em> или Maxout. Никогда не используйте сигмоид. Попробуйте tanh, но будьте готовы к тому, что он будет работать хуже, чем <em>ReLU</em>/<em>Maxout</em>.  </p>
<h2>Архитектуры нейронных сетей</h2>
<h3>Многоуровневая организация</h3>
<p><strong>Нейронные сети как нейроны в графах</strong>. Нейронные сети моделируются как совокупности нейронов, соединённых в ациклический граф. Другими словами, выходные данные одних нейронов могут становиться входными данными для других нейронов. Циклы недопустимы, так как это привело бы к бесконечному циклу при прямом проходе сети. Вместо аморфных скоплений соединённых нейронов модели нейронных сетей часто состоят из отдельных слоёв нейронов. Для обычных нейронных сетей наиболее распространённым типом слоёв является <strong>слой с полной связью</strong>, в котором нейроны между двумя соседними слоями полностью соединены попарно, но нейроны в пределах одного слоя не имеют общих связей. Ниже приведены два примера топологий нейронных сетей, в которых используется набор слоёв с полной связью:  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/nn1/neural_net.jpeg"><br><img alt="" src="https://cs231n.github.io/assets/nn1/neural_net2.jpeg"><br><strong>Сверху</strong>: двухслойная нейронная сеть (один скрытый слой из 4 нейронов (или единиц) и один выходной слой из 2 нейронов) с тремя входами. <strong>Снизу</strong>: трёхслойная нейронная сеть с тремя входами, двумя скрытыми слоями по 4 нейрона в каждом и одним выходным слоем. Обратите внимание, что в обоих случаях между нейронами разных слоёв есть связи (синапсы), но не внутри слоя.  </p>
<hr>
<p><strong>Соглашения об именовании</strong>. Обратите внимание, что, когда мы говорим о N-слойной нейронной сети, мы не учитываем входной слой. Таким образом, однослойная нейронная сеть — это сеть без скрытых слоёв (входные данные напрямую преобразуются в выходные). В этом смысле иногда можно услышать, что логистическая регрессия или метод опорных векторов — это просто частный случай однослойных нейронных сетей. Вы также можете услышать, что эти сети называют <em>«искусственными нейронными сетями»</em> (ИНС) или <em>«многослойными перцептронами»</em> (МПП). Многим не нравятся аналогии между нейронными сетями и реальным мозгом, и они предпочитают называть нейроны <em>единицами</em>.  </p>
<p><strong>Выходной слой</strong>. В отличие от всех остальных слоёв нейронной сети, нейроны выходного слоя чаще всего не имеют функции активации (или можно считать, что у них линейная функция активации). Это связано с тем, что последний выходной слой обычно используется для представления оценок классов (например, при классификации), которые являются произвольными действительными числами, или для представления некоторой действительной цели (например, при регрессии).  </p>
<p><strong>Размер нейронных сетей</strong>. Два показателя, которые обычно используются для измерения размера нейронных сетей, — это количество нейронов или, чаще, количество параметров. Рассмотрим две сети на рисунке выше:
- В первой сети (слева) <strong>4 + 2 = 6</strong> нейронов (не считая входных данных), <strong>(3 x 4) + (4 x 2) = 20</strong> весовых коэффициентов и <strong>4 + 2 = 6</strong> смещений, всего 26 обучаемых параметров.
- Во второй сети (<strong>справа</strong>) <strong>4 + 4 + 1 = 9</strong> нейронов, <strong>(3 x 4) + (4 x 4) + (4 x 1) = 12 + 16 + 4 = 32</strong> весовых коэффициента и <strong>4 + 4 + 1 = 9</strong> смещений, всего <strong>41 обучаемый параметр</strong>.  </p>
<p>Для сравнения: современные свёрточные нейронные сети содержат порядка 100 миллионов параметров и обычно состоят примерно из 10–20 слоёв (отсюда <em>глубокое обучение</em>). Однако, как мы увидим, количество <em>эффективных</em> связей значительно больше из-за совместного использования параметров. Подробнее об этом в модуле «Свёрточные нейронные сети».  </p>
<h3>Пример вычисления с прямой связью</h3>
<p><em>Повторное матричное умножение в сочетании с функцией активации</em>. Одна из основных причин, по которой нейронные сети организованы в виде слоёв, заключается в том, что такая структура позволяет очень просто и эффективно оценивать нейронные сети с помощью матричных векторных операций. Если рассматривать трёхслойную нейронную сеть на приведённой выше схеме, то входными данными будет вектор <strong>[3x1]</strong>. Все весовые коэффициенты для слоя можно хранить в одной матрице. Например, веса первого скрытого слоя <code>W1</code> будут иметь размер <strong>[4x3]</strong>, а смещения для всех нейронов будут находиться в векторе <code>b1</code> размером <strong>[4x1]</strong>. Здесь каждый нейрон имеет свои веса в строке <code>W1</code>, поэтому умножение матрицы на вектор <code>np.dot(W1,x)</code> вычисляет активации всех нейронов в этом слое. Аналогично, <code>W2</code> будет матрицей <strong>[4x4]</strong>, которая хранит связи второго скрытого слоя, а <code>W3</code> — матрицей <strong>[1x4]</strong> для последнего (выходного) слоя. Полный прямой проход этой трёхслойной нейронной сети — это просто три матричных умножения, объединённых с применением функции активации:  </p>
<div class="code"><pre class="code literal-block">#<span class="w"> </span><span class="nv">forward</span><span class="o">-</span><span class="nv">pass</span><span class="w"> </span><span class="nv">of</span><span class="w"> </span><span class="nv">a</span><span class="w"> </span><span class="mi">3</span><span class="o">-</span><span class="nv">layer</span><span class="w"> </span><span class="nv">neural</span><span class="w"> </span><span class="nv">network</span>:
<span class="nv">f</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">lambda</span><span class="w"> </span><span class="nv">x</span>:<span class="w"> </span><span class="mi">1</span>.<span class="mi">0</span><span class="o">/</span><span class="ss">(</span><span class="mi">1</span>.<span class="mi">0</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nv">np</span>.<span class="nv">exp</span><span class="ss">(</span><span class="o">-</span><span class="nv">x</span><span class="ss">))</span><span class="w"> </span>#<span class="w"> </span><span class="nv">activation</span><span class="w"> </span><span class="nv">function</span><span class="w"> </span><span class="ss">(</span><span class="nv">use</span><span class="w"> </span><span class="nv">sigmoid</span><span class="ss">)</span>
<span class="nv">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">np</span>.<span class="k">random</span>.<span class="nv">randn</span><span class="ss">(</span><span class="mi">3</span>,<span class="w"> </span><span class="mi">1</span><span class="ss">)</span><span class="w"> </span>#<span class="w"> </span><span class="k">random</span><span class="w"> </span><span class="nv">input</span><span class="w"> </span><span class="nv">vector</span><span class="w"> </span><span class="nv">of</span><span class="w"> </span><span class="nv">three</span><span class="w"> </span><span class="nv">numbers</span><span class="w"> </span><span class="ss">(</span><span class="mi">3</span><span class="nv">x1</span><span class="ss">)</span>
<span class="nv">h1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">f</span><span class="ss">(</span><span class="nv">np</span>.<span class="nv">dot</span><span class="ss">(</span><span class="nv">W1</span>,<span class="w"> </span><span class="nv">x</span><span class="ss">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nv">b1</span><span class="ss">)</span><span class="w"> </span>#<span class="w"> </span><span class="nv">calculate</span><span class="w"> </span><span class="nv">first</span><span class="w"> </span><span class="nv">hidden</span><span class="w"> </span><span class="nv">layer</span><span class="w"> </span><span class="nv">activations</span><span class="w"> </span><span class="ss">(</span><span class="mi">4</span><span class="nv">x1</span><span class="ss">)</span>
<span class="nv">h2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">f</span><span class="ss">(</span><span class="nv">np</span>.<span class="nv">dot</span><span class="ss">(</span><span class="nv">W2</span>,<span class="w"> </span><span class="nv">h1</span><span class="ss">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nv">b2</span><span class="ss">)</span><span class="w"> </span>#<span class="w"> </span><span class="nv">calculate</span><span class="w"> </span><span class="nv">second</span><span class="w"> </span><span class="nv">hidden</span><span class="w"> </span><span class="nv">layer</span><span class="w"> </span><span class="nv">activations</span><span class="w"> </span><span class="ss">(</span><span class="mi">4</span><span class="nv">x1</span><span class="ss">)</span>
<span class="nv">out</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">np</span>.<span class="nv">dot</span><span class="ss">(</span><span class="nv">W3</span>,<span class="w"> </span><span class="nv">h2</span><span class="ss">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nv">b3</span><span class="w"> </span>#<span class="w"> </span><span class="nv">output</span><span class="w"> </span><span class="nv">neuron</span><span class="w"> </span><span class="ss">(</span><span class="mi">1</span><span class="nv">x1</span><span class="ss">)</span>
</pre></div>

<p>В приведённом выше коде <code>W1,W2,W3,b1,b2,b3</code> — это обучаемые параметры сети. Обратите внимание, что вместо одного входного вектора-столбца переменная <code>x</code> может содержать целую выборку обучающих данных (где каждый входной пример будет столбцом <code>x</code>), и тогда все примеры будут эффективно обрабатываться параллельно. Обратите внимание, что последний слой нейронной сети обычно не имеет функции активации (например, он представляет собой (числовое) значение класса в задаче классификации).  </p>
<blockquote>
<p>Прямой проход полносвязного слоя соответствует одному умножению матриц, за которым следует смещение и функция активации.  </p>
</blockquote>
<h3>Представительская власть</h3>
<p>Один из способов взглянуть на нейронные сети с полносвязными слоями заключается в том, что они определяют семейство функций, параметры которых задаются весовыми коэффициентами сети. Возникает естественный вопрос: какова репрезентативная мощность этого семейства функций? В частности, существуют ли функции, которые нельзя смоделировать с помощью нейронной сети?  </p>
<p>Оказывается, что нейронные сети, содержащие хотя бы один скрытый слой, являются универсальными аппроксиматорами. То есть можно показать (например, см. <a href="http://www.dartmouth.edu/~gvc/Cybenko_MCSS.pdf">«Аппроксимацию суперпозициями сигмоидальных функций»</a> 1989 года (pdf) или это <a href="http://neuralnetworksanddeeplearning.com/chap4.html">интуитивное объяснение</a> Майкла Нильсена), что для любой непрерывной функции <strong>f(x)</strong> и некоторые <strong>ϵ&gt;0</strong>, существует Нейронная сеть <strong>g(x)_ с одним скрытым слоем (с разумным выбором нелинейности, например, сигмоидальной) таким образом, что </strong>∀x,∣f(x)−g(x)∣&lt;ϵ__. Другими словами, нейронная сеть может аппроксимировать любую непрерывную функцию.  </p>
<p>Если для аппроксимации любой функции достаточно одного скрытого слоя, зачем использовать больше слоёв и углубляться в детали? Ответ заключается в том, что тот факт, что двухслойная нейронная сеть является универсальным аппроксиматором, хоть и выглядит красиво с математической точки зрения, на практике является относительно слабым и бесполезным утверждением. В одномерном пространстве функция «сумма пиков индикаторов» <strong>\(g(x) = \sum_i c_i \mathbb{1}(a_i &lt; x &lt; b_i)\)</strong>, где <strong>\(a,b,c\)</strong>. Векторы параметров также являются универсальным аппроксиматором, но никто не предлагает использовать эту функциональную форму в машинном обучении. Нейронные сети хорошо работают на практике, потому что они компактно выражают красивые, плавные функции, которые хорошо согласуются со статистическими свойствами данных, с которыми мы сталкиваемся на практике, а также легко обучаются с помощью наших алгоритмов оптимизации (например, градиентного спуска). Точно так же тот факт, что более глубокие сети (с несколькими скрытыми слоями) могут работать лучше, чем сети с одним скрытым слоем, является эмпирическим наблюдением, несмотря на то, что их репрезентативная мощность одинакова.  </p>
<p>Кстати, на практике часто бывает так, что 3-слойные нейронные сети превосходят 2-слойные, но ещё большее количество слоёв (4, 5, 6) редко приносит большую пользу. Это резко контрастирует с свёрточными сетями, где глубина оказалась чрезвычайно важным компонентом для хорошей системы распознавания (например, порядка 10 обучаемых слоёв). Один из аргументов в пользу этого наблюдения заключается в том, что изображения имеют иерархическую структуру (например, лица состоят из глаз, которые состоят из контуров и т. д.), поэтому несколько уровней обработки интуитивно понятны для этой области данных.  </p>
<p>Полная история, конечно, гораздо сложнее и является предметом многочисленных недавних исследований. Если вас интересуют эти темы, мы рекомендуем вам прочитать:
 - <a href="http://www.deeplearningbook.org/">Книга «Глубокое обучение»</a> Бенджио, Гудфеллоу, Курвиля, в частности <a href="http://www.deeplearningbook.org/contents/mlp.html">глава 6.4</a>.
 - <a href="http://arxiv.org/abs/1312.6184">Действительно ли Глубокие сети должны быть глубокими?</a>
 - <a href="http://arxiv.org/abs/1412.6550">ФитНеты: Советы для тонких глубоких Сеток</a>  </p>
<h3>Настройка количества слоев и их размеров</h3>
<p>Как мы решаем, какую архитектуру использовать, когда сталкиваемся с практической задачей? Следует ли нам использовать несколько скрытых слоёв? Один скрытый слой? Два скрытых слоя? Насколько большим должен быть каждый слой? Во-первых, обратите внимание, что по мере увеличения размера и количества слоёв в нейронной сети <strong>ёмкость</strong> сети увеличивается. То есть пространство представимых функций растёт, поскольку нейроны могут взаимодействовать для выражения множества различных функций. Например, предположим, что у нас есть задача бинарной классификации в двух измерениях. Мы могли бы обучить три отдельные нейронные сети, каждая из которых имеет один скрытый слой определённого размера, и получить следующие классификаторы:  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/nn1/layer_sizes.jpeg"><br>
 Более крупные нейронные сети могут представлять более сложные функции. Данные показаны в виде кружков, окрашенных в соответствии с их классом, а под ними показаны области принятия решений обученной нейронной сетью. Вы можете поиграть с этими примерами в этой <a href="http://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html">демо-версии ConvNetsJS</a>.  </p>
<hr>
<p>На приведённой выше схеме мы видим, что нейронные сети с большим количеством нейронов могут выполнять более сложные функции. Однако это одновременно и благо (поскольку мы можем научиться классифицировать более сложные данные), и проклятие (поскольку легче переобучиться на обучающих данных). <strong>Переобучение</strong> происходит, когда модель с высокой способностью к обучению подстраивается под шум в данных, а не под (предполагаемую) основную закономерность. Например, модель с 20 скрытыми нейронами подстраивается под все обучающие данные, но за счёт разделения пространства на множество непересекающихся красных и зелёных областей принятия решений. Модель с 3 скрытыми нейронами способна классифицировать данные только в общих чертах. Она моделирует данные как два сгустка и интерпретирует несколько красных точек внутри зелёного кластера как <strong>выбросы</strong> (шум). На практике это может привести к лучшему <strong>обобщению</strong> на тестовом наборе данных.  </p>
<p>Исходя из нашего обсуждения выше, можно сделать вывод, что нейронные сети меньшего размера предпочтительнее, если данные недостаточно сложны, чтобы предотвратить переобучение. Однако это неверно — существует множество других предпочтительных способов предотвращения переобучения в нейронных сетях, которые мы обсудим позже (например, регуляризация <strong>\(L_2\)</strong>, отсев, входной шум). На практике всегда лучше использовать эти методы для контроля переобучения, а не количество нейронов.  </p>
<p>Тонкая причина этого заключается в том, что небольшие сети сложнее обучать с помощью локальных методов, таких как градиентный спуск: очевидно, что у их функций потерь относительно мало локальных минимумов, но оказывается, что многие из этих минимумов легче достигаются и являются плохими (то есть с высокими потерями). И наоборот, более крупные нейронные сети содержат значительно больше локальных минимумов, но эти минимумы оказываются гораздо лучше с точки зрения фактических потерь. Поскольку нейронные сети являются невыпуклыми, их свойства трудно изучать математически, но были предприняты некоторые попытки понять эти целевые функции, например, в недавней статье <a href="http://arxiv.org/abs/1412.0233">«Поверхности потерь в многослойных сетях»</a>. На практике вы обнаружите, что если вы обучаете небольшую сеть, то конечные потери могут сильно варьироваться — в некоторых случаях вам везёт, и вы сходитесь к хорошему результату, но в некоторых случаях вы застреваете в одном из плохих минимумов. С другой стороны, если вы обучите большую сеть, вы начнёте находить множество различных решений, но разброс в итоговых потерях будет намного меньше. Другими словами, все решения примерно одинаково хороши и в меньшей степени зависят от случайной инициализации.  </p>
<p>Повторюсь, сила регуляризации — предпочтительный способ контроля переобучения нейронной сети. Мы можем рассмотреть результаты, полученные при трёх различных настройках:  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/nn1/reg_strengths.jpeg"><br>
Влияние силы регуляризации: каждая из приведённых выше нейронных сетей имеет 20 скрытых нейронов, но изменение силы регуляризации делает области окончательного принятия решений более плавными при более высокой регуляризации. Вы можете поиграть с этими примерами в <a href="http://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html">демонстрационной версии ConvNetsJS</a>.  </p>
<hr>
<p>Вывод заключается в том, что вам не следует использовать более мелкие сети, потому что вы боитесь переобучения. Вместо этого вам следует использовать настолько большую нейронную сеть, насколько позволяет ваш вычислительный бюджет, и применять другие методы регуляризации для контроля переобучения.  </p>
<h2>Краткие сведения</h2>
<p>Подводя итог:
- Мы представили очень грубую модель биологического <strong>нейрона</strong>.
- Мы рассмотрели несколько типов <strong>функций активации</strong>, которые используются на практике, и наиболее распространённым из них является ReLU.
- Мы представили <strong>нейронные сети</strong>, в которых нейроны соединены <strong>полностью связанными слоями</strong>, где нейроны в соседних слоях имеют полные парные связи, но нейроны внутри слоя не соединены.
- Мы увидели, что эта многоуровневая архитектура позволяет очень эффективно оценивать нейронные сети на основе матричных умножений, объединённых с применением функции активации.
- Мы увидели, что нейронные сети являются <strong>универсальными аппроксиматорами функций</strong>, но мы также обсудили тот факт, что это свойство мало связано с их повсеместным использованием. Они используются потому, что делают определённые «правильные» предположения о функциональных формах функций, которые встречаются на практике.
- Мы обсудили тот факт, что более крупные сети всегда будут работать лучше, чем сети меньшего размера, но их более высокая пропускная способность должна соответствующим образом регулироваться с помощью более сильной регуляризации (например, более высокого затухания весов), иначе они могут переобучаться. В следующих разделах мы рассмотрим другие формы регуляризации (особенно отсев).  </p>
<h2>Дополнительные ссылки</h2>
<ul>
<li>
<a href="http://www.deeplearning.net/tutorial/mlp.html">deeplearning.net учебное пособие</a> с Theano</li>
<li>
<a href="http://cs.stanford.edu/people/karpathy/convnetjs/">ConvNetJS</a> демонстрации для интуиции</li>
<li><a href="http://neuralnetworksanddeeplearning.com/chap1.html">Учебные пособия Майкла Нильсена</a></li>
</ul>
</div>
            </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/backpropagation/" class="u-url">Обратное распространение ошибки</a></h1>
                <div class="metadata">
                    <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                        Андрей Лабинцев
                    </span></p>
            <p class="dateline">
            <a href="posts/backpropagation/" rel="bookmark">
            <time class="published dt-published" datetime="2025-03-07T19:42:16+03:00" itemprop="datePublished" title="2025-03-07 19:42">2025-03-07 19:42</time></a>
            </p>
                </div>
            </header><div class="e-content entry-content">
                    <h2>Обратное распространение ошибки</h2>
<p>Содержание: 
- <a href="posts/backpropagation/">Введение</a>
- <a href="posts/backpropagation/">Простые выражения, интерпретирующие градиент</a>
- <a href="posts/backpropagation/">Составные выражения, цепное правило, обратное распространение</a>
- <a href="posts/backpropagation/">Интуитивное понимание обратного распространения</a>
- <a href="posts/backpropagation/">Модульность: Пример сигмовидной активации</a>
- <a href="posts/backpropagation/">Бэкпроп на практике: Поэтапное вычисление</a>
- <a href="posts/backpropagation/">Закономерности в обратном потоке</a>
- <a href="posts/backpropagation/">Градиенты для векторизованных операций</a>
- <a href="posts/backpropagation/">Краткая сводка</a>  </p>
<h2>Введение</h2>
<p><strong>Мотивация</strong>. В этом разделе мы углубимся в интуитивное понимание <strong>обратного распространения ошибки</strong>, которое представляет собой способ вычисления градиентов выражений с помощью рекурсивного применения <strong>правила дифференцирования сложной функции</strong>. Понимание этого процесса и его тонкостей крайне важно для эффективного проектирования, разработки и отладки нейронных сетей.  </p>
<p><strong>Постановка задачи</strong>. Основная задача, рассматриваемая в этом разделе, заключается в следующем: нам дана некоторая функция <strong>f(x)</strong>,где <strong>x</strong> является вектором входных данных, и мы заинтересованы в вычислении градиента <strong>f</strong> в <strong>x</strong> (т.е. <strong>∇f(x)</strong>).  </p>
<p><strong>Мотивация</strong>. Напомним, что основная причина, по которой мы интересуемся этой проблемой, заключается в том, что в конкретном случае нейронных сетей <strong>f</strong> будет соответствовать функции потерь ( <strong>L</strong> ) и входные данные <strong>x</strong> будет состоять из обучающих данных и весовых коэффициентов нейронной сети. Например, в качестве функции потерь может использоваться функция потерь SVM, а в качестве входных данных — обучающие данные <strong>\((x_i,y_i), i=1 \ldots N\)</strong>, а также веса и предубеждения <strong>W,b</strong>. Обратите внимание, что (как это обычно бывает в машинном обучении) мы рассматриваем обучающие данные как заданные и фиксированные, а весовые коэффициенты — как переменные, которыми мы можем управлять. Следовательно, даже если мы можем легко использовать обратное распространение ошибки для вычисления градиента по входным примерам <strong>\(x_i\)</strong>. На практике мы обычно вычисляем градиент только для параметров (например, <strong>W,b</strong>), чтобы мы могли использовать его для обновления параметров. Однако, как мы увидим позже, градиент по <strong>\(x_i\)</strong>, например, может быть полезен для визуализации и интерпретации того, что может делать нейронная сеть.  </p>
<p>Если вы пришли на этот курс и вам удобно вычислять градиенты с помощью правила дифференцирования сложной функции, мы всё равно рекомендуем вам хотя бы бегло просмотреть этот раздел, поскольку в нём представлен редко встречающийся взгляд на обратное распространение ошибки как на обратный поток в схемах с вещественными значениями, и любые полученные вами знания могут пригодиться вам на протяжении всего курса.  </p>
<h2>Простые выражения и интерпретация градиента</h2>
<p>Давайте начнём с простого, чтобы разработать обозначения и соглашения для более сложных выражений. Рассмотрим простую функцию умножения двух чисел <strong>f(x,y)=xy</strong>. Чтобы вычислить частную производную для любого из входных параметров, достаточно воспользоваться простым математическим расчётом:  </p>
<p>$$
f(x,y) = x y \hspace{0.5in} \rightarrow \hspace{0.5in} \frac{\partial f}{\partial x} = y \hspace{0.5in} \frac{\partial f}{\partial y} = x 
$$  </p>
<p><strong>Интерпретация</strong>. Помните, что показывают производные: они указывают на скорость изменения функции по отношению к переменной, окружающей бесконечно малую область вблизи определённой точки:  </p>
<p>$$
\frac{df(x)}{dx} = \lim_{h\ \to 0} \frac{f(x + h) - f(x)}{h}
$$  </p>
<p>Технически примечательно, что знак деления в левой части, в отличие от знака деления в правой части, не является делением. Вместо этого эта запись указывает на то, что оператор <strong>\(  \frac{d}{dx} \)</strong> применяется к функции <strong>f</strong> и возвращает другую функцию (производную). Можно представить, что приведённое выше выражение означает, что <strong>h</strong> очень мало, а значит функция хорошо аппроксимируется прямой линией, а производная — это её наклон. Другими словами, производная от каждой переменной показывает чувствительность всего выражения к её значению. Например, если <strong>x=4,y=−3</strong> тогда <strong>f(x,y)=−12</strong> и производная от <strong>\(x\) \(\frac{\partial f}{\partial x} = -3\)3</strong>. Это говорит нам о том, что если мы увеличим значение этой переменной на небольшую величину, то всё выражение уменьшится (из-за отрицательного знака) в три раза. Это можно увидеть, если переставить слагаемые в приведённом выше уравнении ( <strong>\( f(x + h) = f(x) + h \frac{df(x)}{dx} \)</strong> ). Аналогично, поскольку <strong>\(\frac{\partial f}{\partial y} = 4\)</strong>, мы ожидаем, что увеличение стоимости <strong>y</strong> на какую-то очень небольшую сумму <strong>h</strong> также увеличит результат функции (из-за положительного знака) и <strong>4h</strong>.  </p>
<blockquote>
<p>Производная по каждой переменной показывает, насколько чувствительно всё выражение к изменению её значения.</p>
</blockquote>
<p>Как уже упоминалось, градиент <strong>∇f</strong> является вектором частных производных, поэтому мы имеем, что <strong>\(\nabla f = [\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}] = [y, x]\)</strong>. Несмотря на то, что градиент технически является вектором, для простоты мы часто используем такие термины, как <em>«градиент по x»</em>, вместо технически корректного выражения <em>«частная производная по x»</em>.  </p>
<p>Мы также можем вывести производные для операции сложения:  </p>
<p>$$
f(x,y) = x + y \hspace{0.5in} \rightarrow \hspace{0.5in} \frac{\partial f}{\partial x} = 1 \hspace{0.5in} \frac{\partial f}{\partial y} = 1
$$  </p>
<p>то есть производная по обоим <strong>x,y</strong> является единым, независимо от того, какими значения <strong>x,y</strong> являются. Это имеет смысл, поскольку увеличение <strong>x или y</strong> увеличило бы выпуск продукции <strong>f</strong>. И скорость этого увеличения будет зависеть от фактических значений <strong>x,y</strong> (в отличие от случая с умножением выше). Последняя функция, которую мы будем часто использовать в этом классе, — это операция <em>max</em>:  </p>
<p>$$
f(x,y) = \max(x, y) \hspace{0.5in} \rightarrow \hspace{0.5in} \frac{\partial f}{\partial x} = \mathbb{1}(x &gt;= y) \hspace{0.5in} \frac{\partial f}{\partial y} = \mathbb{1}(y &gt;= x)
$$  </p>
<p>То есть (суб)градиент равен <strong>1</strong> для большего входного значения и <strong>0</strong> для другого входного значения. Интуитивно понятно, что если входные значения <strong>x=4,y=2</strong>тогда максимальное значение равно <strong>4</strong>, и функция не чувствительна к настройке <strong>y</strong>. То есть, если бы мы увеличили его на крошечную величину <strong>h</strong> функция бы продолжила выводить <strong>4</strong>, и поэтому градиент равен нулю: эффекта нет. Конечно, если бы мы изменили <strong>y</strong> на большую величину (например, больше <strong>2</strong>), то значение <strong>f</strong> изменилось бы, но производные ничего не говорят нам о влиянии таких больших изменений на входные данные функции. Они информативны только для крошечных, бесконечно малых изменений входных данных, как показано на <strong>\(\lim_{h \rightarrow 0}\)</strong> в его определении.  </p>
<h2>Составные выражения с правилом цепочки</h2>
<p>Теперь давайте рассмотрим более сложные выражения, включающие несколько составных функций, например <strong>f(x,y,z)=(x+y)z</strong>. Это выражение по-прежнему достаточно простое, чтобы дифференцировать его напрямую, но мы подойдём к нему с особой стороны, которая поможет понять принцип обратного распространения ошибки. В частности, обратите внимание, что это выражение можно разбить на два: <strong>q=x+y</strong> и <strong>f=qz</strong>. Более того, мы знаем, как вычислить производные обоих выражений по отдельности, как показано в предыдущем разделе. <strong>f</strong> это просто умножение <strong>q</strong> и <strong>z</strong>, так что <strong>\(\frac{\partial f}{\partial q} = z, \frac{\partial f}{\partial z} = q\)</strong>, и <strong>q</strong> является добавлением <strong>x</strong> и <strong>y</strong>, итак <strong>\( \frac{\partial q}{\partial x} = 1, \frac{\partial q}{\partial y} = 1 \)</strong>. Однако нам необязательно знать градиент для промежуточного значения <strong>q</strong> - ценность <strong>\(\frac{\partial f}{\partial q}\)</strong> нивелируется. Вместо этого нас, в конечном счете, интересует градиент <strong>f</strong> в отношении его вклада <strong>x,y,z</strong>. <strong>Правило цепочки</strong> говорит нам о том, что правильный способ «объединить» эти выражения градиента в цепочку — это умножение. Например, <strong>\(\frac{\partial f}{\partial x} = \frac{\partial f}{\partial q} \frac{\partial q}{\partial x} \)</strong>. На практике это просто умножение двух чисел, обозначающих два градиента. Давайте рассмотрим это на примере:  </p>
<div class="code"><pre class="code literal-block"><span class="gh">#</span> set some inputs
x = -2; y = 5; z = -4

<span class="gh">#</span> perform the forward pass
q = x + y # q becomes 3
f = q <span class="gs">* z # f becomes -12</span>

<span class="gs"># perform the backward pass (backpropagation) in reverse order:</span>
<span class="gs"># first backprop through f = q *</span> z
dfdz = q # df/dz = q, so gradient on z becomes 3
dfdq = z # df/dq = z, so gradient on q becomes -4
dqdx = 1.0
dqdy = 1.0
<span class="gh">#</span> now backprop through q = x + y
dfdx = dfdq <span class="gs">* dqdx  # The multiplication here is the chain rule!</span>
<span class="gs">dfdy = dfdq *</span> dqdy  
</pre></div>

<p>У нас остаётся градиент в переменных <code>[dfdx,dfdy,dfdz]</code>, который показывает чувствительность переменных <code>x,y,z</code> к <code>f</code>!. Это самый простой пример обратного распространения ошибки. Далее мы будем использовать более лаконичную запись, в которой отсутствует префикс <code>df</code>! Например, мы будем просто писать <code>dq</code> вместо <code>dfdq</code> и всегда предполагать, что градиент вычисляется для конечного результата.  </p>
<p>Это вычисление также можно хорошо визуализировать с помощью принципиальной схемы:  </p>
<hr>
<div class="fig figleft fighighlight">
<svg style="max-width: 420px" viewbox="0 0 420 220"><defs><marker id="arrowhead" refx="6" refy="2" markerwidth="6" markerheight="4" orient="auto"><path d="M 0,0 V 4 L6,2 Z"></path></marker></defs><line x1="40" y1="30" x2="110" y2="30" stroke="black" stroke-width="1"></line><text x="45" y="24" font-size="16" fill="green">-2</text><text x="45" y="47" font-size="16" fill="red">-4</text><text x="35" y="24" font-size="16" text-anchor="end" fill="black">x</text><line x1="40" y1="100" x2="110" y2="100" stroke="black" stroke-width="1"></line><text x="45" y="94" font-size="16" fill="green">5</text><text x="45" y="117" font-size="16" fill="red">-4</text><text x="35" y="94" font-size="16" text-anchor="end" fill="black">y</text><line x1="40" y1="170" x2="110" y2="170" stroke="black" stroke-width="1"></line><text x="45" y="164" font-size="16" fill="green">-4</text><text x="45" y="187" font-size="16" fill="red">3</text><text x="35" y="164" font-size="16" text-anchor="end" fill="black">z</text><line x1="210" y1="65" x2="280" y2="65" stroke="black" stroke-width="1"></line><text x="215" y="59" font-size="16" fill="green">3</text><text x="215" y="82" font-size="16" fill="red">-4</text><text x="205" y="59" font-size="16" text-anchor="end" fill="black">q</text><circle cx="170" cy="65" fill="white" stroke="black" stroke-width="1" r="20"></circle><text x="170" y="70" font-size="20" fill="black" text-anchor="middle">+</text><line x1="110" y1="30" x2="150" y2="65" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="110" y1="100" x2="150" y2="65" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="190" y1="65" x2="210" y2="65" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="380" y1="117" x2="450" y2="117" stroke="black" stroke-width="1"></line><text x="385" y="111" font-size="16" fill="green">-12</text><text x="385" y="134" font-size="16" fill="red">1</text><text x="375" y="111" font-size="16" text-anchor="end" fill="black">f</text><circle cx="340" cy="117" fill="white" stroke="black" stroke-width="1" r="20"></circle><text x="340" y="127" font-size="20" fill="black" text-anchor="middle">*</text><line x1="280" y1="65" x2="320" y2="117" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="110" y1="170" x2="320" y2="117" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="360" y1="117" x2="380" y2="117" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line></svg><div class="figcaption">
</div>
<div style="clear:both;"></div>
</div>

<p><a name="intuitive"></a> 
Реальная <em>"схема"</em> слева показывает визуальное представление вычислений. <strong>Прямой проход</strong> вычисляет значения от входных данных до выходных (показано зелёным цветом).<strong>Обратный проход</strong>, затем выполняет обратное распространение ошибки, которое начинается с конца и рекурсивно применяет правило цепочки для вычисления градиентов (показано красным цветом) вплоть до входных данных схемы. Градиенты можно представить как текущие в обратном направлении по схеме.</p>
<hr>
<h2>Интуитивное понимание обратного распространения</h2>
<p>Обратите внимание, что обратное распространение ошибки — это локальный процесс. Каждый элемент в схеме получает входные данные и может сразу вычислить две вещи:
 1. выходное значение 
 2. <em>локальный</em> градиент выходного значения по отношению к входным данным.  </p>
<p>Обратите внимание, что элементы могут делать это совершенно независимо, не зная ни о каких деталях всей схемы, в которую они встроены. Однако после завершения прямого прохода во время обратного распространения ошибки элемент в конечном итоге узнает о градиенте выходного значения по отношению к конечному результату всей схемы. Правило цепочки гласит, что функция должна взять этот градиент и умножить его на каждый градиент, который она обычно вычисляет для всех своих входных данных.  </p>
<blockquote>
<p>Это дополнительное умножение (для каждого входа) благодаря правилу цепочки может превратить один относительно бесполезный элемент в деталь сложной схемы, такой как целая нейронная сеть.  </p>
</blockquote>
<p>Давайте разберёмся, как это работает, на примере. Сложение получило на вход <strong>[-2, 5]</strong> и выдало на выходе <strong>3</strong>. Поскольку сложение вычисляет операцию сложения, его локальный градиент для обоих входных значений равен <strong>+1</strong>. Остальная часть схемы вычислила итоговое значение, равное <strong>-12</strong>. Во время обратного прохода, при котором правило цепочки рекурсивно применяется в обратном направлении, сложение (которое является входом для умножения) узнаёт, что градиент его выходного значения равен <strong>-4</strong>. Если мы представим, что схема <em>«хочет»</em> вывести более высокое значение (что может помочь с интуитивным пониманием), то мы можем представить, что схема <em>«хочет»</em>, чтобы выходное значение логического элемента <strong>«и»</strong> было ниже (из-за отрицательного знака) и с <em>силой</em> <strong>4</strong>. Чтобы продолжить рекурсию и вычислить градиент, логический элемент <strong>«и»</strong> берёт этот градиент и умножает его на все локальные градиенты для своих входов (делая градиент для <strong>x</strong> и <strong>y</strong> равным <strong>1 * -4 = -4</strong>). Обратите внимание, что это даёт желаемый эффект: если <strong>x, y</strong> уменьшатся (в соответствии с их отрицательным градиентом), то выходное значение сумматора уменьшится, что, в свою очередь, приведёт к увеличению выходного значения умножителя.  </p>
<p>Таким образом, обратное распространение ошибки можно представить как взаимодействие элементов (через сигнал градиента), которые сообщают друг другу, хотят ли они, чтобы их выходные данные увеличивались или уменьшались (и насколько сильно), чтобы итоговое значение было выше.  </p>
<h2>Модульность: Пример сигмовидной активации</h2>
<p>Введённые нами выше элементы являются относительно произвольными. В качестве элемента может выступать любая дифференцируемая функция, и мы можем объединять несколько элементов в один или разбивать функцию на несколько элементов, когда это удобно. Давайте рассмотрим другое выражение, которое иллюстрирует этот момент:  </p>
<p>$$
f(w,x) = \frac{1}{1+e^{-(w_0x_0 + w_1x_1 + w_2)}}
$$  </p>
<p>как мы увидим позже на занятии, это выражение описывает двумерный нейрон (с входными данными <strong>x</strong> и весами <strong>w</strong>), который использует функцию <em>сигмоидальной активации</em>. Но пока давайте рассматривать это очень просто как функцию, которая преобразует входные данные <em>w,x</em> в одно число. Функция состоит из нескольких логических элементов. Помимо тех, что описаны выше (сложение, умножение, максимальное значение), есть ещё четыре:  </p>
<p>$$
f(x) = \frac{1}{x} 
\hspace{1in} \rightarrow \hspace{1in} 
\frac{df}{dx} = -1/x^2 
\\
f_c(x) = c + x
\hspace{1in} \rightarrow \hspace{1in} 
\frac{df}{dx} = 1 
\\
f(x) = e^x
\hspace{1in} \rightarrow \hspace{1in} 
\frac{df}{dx} = e^x
\\
f_a(x) = ax
\hspace{1in} \rightarrow \hspace{1in} 
\frac{df}{dx} = a
$$  </p>
<p>Где функции <strong>\(f_c, f_a\)</strong> преобразуйте входные данные в константу, равную <strong>c</strong> и масштабируйте входные данные на константу, равную <strong>a</strong>, соответственно. Технически это частные случаи сложения и умножения, но мы вводим их как (новые) унарные операции, поскольку нам не нужны градиенты для констант <strong>c,a</strong>. Тогда полная схема выглядит следующим образом:  </p>
<div class="fig figleft fighighlight">
<svg style="max-width: 799px" viewbox="0 0 799 306"><g transform="scale(0.8)"><defs><marker id="arrowhead" refx="6" refy="2" markerwidth="6" markerheight="4" orient="auto"><path d="M 0,0 V 4 L6,2 Z"></path></marker></defs><line x1="50" y1="30" x2="90" y2="30" stroke="black" stroke-width="1"></line><text x="55" y="24" font-size="16" fill="green">2.00</text><text x="55" y="47" font-size="16" fill="red">-0.20</text><text x="45" y="24" font-size="16" text-anchor="end" fill="black">w0</text><line x1="50" y1="100" x2="90" y2="100" stroke="black" stroke-width="1"></line><text x="55" y="94" font-size="16" fill="green">-1.00</text><text x="55" y="117" font-size="16" fill="red">0.39</text><text x="45" y="94" font-size="16" text-anchor="end" fill="black">x0</text><line x1="50" y1="170" x2="90" y2="170" stroke="black" stroke-width="1"></line><text x="55" y="164" font-size="16" fill="green">-3.00</text><text x="55" y="187" font-size="16" fill="red">-0.39</text><text x="45" y="164" font-size="16" text-anchor="end" fill="black">w1</text><line x1="50" y1="240" x2="90" y2="240" stroke="black" stroke-width="1"></line><text x="55" y="234" font-size="16" fill="green">-2.00</text><text x="55" y="257" font-size="16" fill="red">-0.59</text><text x="45" y="234" font-size="16" text-anchor="end" fill="black">x1</text><line x1="50" y1="310" x2="90" y2="310" stroke="black" stroke-width="1"></line><text x="55" y="304" font-size="16" fill="green">-3.00</text><text x="55" y="327" font-size="16" fill="red">0.20</text><text x="45" y="304" font-size="16" text-anchor="end" fill="black">w2</text><line x1="170" y1="65" x2="210" y2="65" stroke="black" stroke-width="1"></line><text x="175" y="59" font-size="16" fill="green">-2.00</text><text x="175" y="82" font-size="16" fill="red">0.20</text><circle cx="130" cy="65" fill="white" stroke="black" stroke-width="1" r="20"></circle><text x="130" y="75" font-size="20" fill="black" text-anchor="middle">*</text><line x1="90" y1="30" x2="110" y2="65" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="90" y1="100" x2="110" y2="65" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="150" y1="65" x2="170" y2="65" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="170" y1="205" x2="210" y2="205" stroke="black" stroke-width="1"></line><text x="175" y="199" font-size="16" fill="green">6.00</text><text x="175" y="222" font-size="16" fill="red">0.20</text><circle cx="130" cy="205" fill="white" stroke="black" stroke-width="1" r="20"></circle><text x="130" y="215" font-size="20" fill="black" text-anchor="middle">*</text><line x1="90" y1="170" x2="110" y2="205" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="90" y1="240" x2="110" y2="205" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="150" y1="205" x2="170" y2="205" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="290" y1="135" x2="330" y2="135" stroke="black" stroke-width="1"></line><text x="295" y="129" font-size="16" fill="green">4.00</text><text x="295" y="152" font-size="16" fill="red">0.20</text><circle cx="250" cy="135" fill="white" stroke="black" stroke-width="1" r="20"></circle><text x="250" y="140" font-size="20" fill="black" text-anchor="middle">+</text><line x1="210" y1="65" x2="230" y2="135" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="210" y1="205" x2="230" y2="135" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="270" y1="135" x2="290" y2="135" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="410" y1="222" x2="450" y2="222" stroke="black" stroke-width="1"></line><text x="415" y="216" font-size="16" fill="green">1.00</text><text x="415" y="239" font-size="16" fill="red">0.20</text><circle cx="370" cy="222" fill="white" stroke="black" stroke-width="1" r="20"></circle><text x="370" y="227" font-size="20" fill="black" text-anchor="middle">+</text><line x1="330" y1="135" x2="350" y2="222" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="90" y1="310" x2="350" y2="222" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="390" y1="222" x2="410" y2="222" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="530" y1="222" x2="570" y2="222" stroke="black" stroke-width="1"></line><text x="535" y="216" font-size="16" fill="green">-1.00</text><text x="535" y="239" font-size="16" fill="red">-0.20</text><circle cx="490" cy="222" fill="white" stroke="black" stroke-width="1" r="20"></circle><text x="490" y="227" font-size="20" fill="black" text-anchor="middle">*-1</text><line x1="450" y1="222" x2="470" y2="222" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="510" y1="222" x2="530" y2="222" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="650" y1="222" x2="690" y2="222" stroke="black" stroke-width="1"></line><text x="655" y="216" font-size="16" fill="green">0.37</text><text x="655" y="239" font-size="16" fill="red">-0.53</text><circle cx="610" cy="222" fill="white" stroke="black" stroke-width="1" r="20"></circle><text x="610" y="227" font-size="20" fill="black" text-anchor="middle">exp</text><line x1="570" y1="222" x2="590" y2="222" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="630" y1="222" x2="650" y2="222" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="770" y1="222" x2="810" y2="222" stroke="black" stroke-width="1"></line><text x="775" y="216" font-size="16" fill="green">1.37</text><text x="775" y="239" font-size="16" fill="red">-0.53</text><circle cx="730" cy="222" fill="white" stroke="black" stroke-width="1" r="20"></circle><text x="730" y="227" font-size="20" fill="black" text-anchor="middle">+1</text><line x1="690" y1="222" x2="710" y2="222" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="750" y1="222" x2="770" y2="222" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="890" y1="222" x2="930" y2="222" stroke="black" stroke-width="1"></line><text x="895" y="216" font-size="16" fill="green">0.73</text><text x="895" y="239" font-size="16" fill="red">1.00</text><circle cx="850" cy="222" fill="white" stroke="black" stroke-width="1" r="20"></circle><text x="850" y="227" font-size="20" fill="black" text-anchor="middle">1/x</text><line x1="810" y1="222" x2="830" y2="222" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="870" y1="222" x2="890" y2="222" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line></g></svg><div class="figcaption">
  Пример схемы для двумерного нейрона с сигмоидальной функцией активации. Входные данные — [x0, x1], а (обучаемые) весовые коэффициенты нейрона — [w0, w1, w2]. Как мы увидим позже, нейрон вычисляет скалярное произведение входных данных, а затем его активация мягко сжимается сигмоидальной функцией до диапазона от 0 до 1.
</div>
<div style="clear:both;"></div>
</div>

<hr>
<p>В приведённом выше примере мы видим длинную цепочку вызовов функций, которые работают с результатом скалярного произведения <strong>w,x.</strong> Функция, которую реализуют эти операции, называется <em>сигмоидальной функцией</em> <strong>σ(x)</strong>. Оказывается, производная сигмоидальной функции по входным данным упрощается, если выполнить дифференцирование (после забавной сложной части, где мы добавляем и вычитаем <strong>1</strong> в числителе):  </p>
<p>$$
\sigma(x) = \frac{1}{1+e^{-x}} \\
\rightarrow \hspace{0.3in} \frac{d\sigma(x)}{dx} = \frac{e^{-x}}{(1+e^{-x})^2} = \left( \frac{1 + e^{-x} - 1}{1 + e^{-x}} \right) \left( \frac{1}{1+e^{-x}} \right) 
= \left( 1 - \sigma(x) \right) \sigma(x)
$$  </p>
<p>Как мы видим, градиент упрощается и становится на удивление простым. Например, сигмоидальное выражение получает на вход <strong>1,0</strong> и вычисляет на выходе <strong>0,73</strong> во время прямого прохода. Приведённый выше вывод показывает, что <em>локальный градиент</em> будет <strong>равен (1 — 0,73) * 0,73 ~= 0,2</strong>, как и в случае с предыдущей схемой (см. изображение выше), за исключением того, что в этом случае это будет сделано с помощью одного простого и эффективного выражения (и с меньшим количеством численных проблем). Таким образом, в любом реальном практическом применении было бы очень полезно объединить эти операции в один элемент управления. Давайте рассмотрим обратное распространение ошибки для этого нейрона в коде:  </p>
<div class="code"><pre class="code literal-block"><span class="n">w</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="o">-</span><span class="mi">3</span><span class="p">]</span><span class="w"> </span><span class="c1"># assume some random weights and data</span>
<span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>

<span class="c1"># forward pass</span>
<span class="n">dot</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">w</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="n">f</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">dot</span><span class="p">))</span><span class="w"> </span><span class="c1"># sigmoid function</span>

<span class="c1"># backward pass through the neuron (backpropagation)</span>
<span class="n">ddot</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">f</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">f</span><span class="w"> </span><span class="c1"># gradient on dot variable, using the sigmoid gradient derivation</span>
<span class="n">dx</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">w</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">ddot</span><span class="p">,</span><span class="w"> </span><span class="n">w</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">ddot</span><span class="p">]</span><span class="w"> </span><span class="c1"># backprop into x</span>
<span class="n">dw</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">ddot</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">ddot</span><span class="p">,</span><span class="w"> </span><span class="mf">1.0</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">ddot</span><span class="p">]</span><span class="w"> </span><span class="c1"># backprop into w</span>
<span class="c1"># we're done! we have the gradients on the inputs to the circuit</span>
</pre></div>

<p><strong>Совет по реализации: поэтапное обратное распространение ошибки</strong>. Как показано в приведенном выше коде, на практике всегда полезно разбивать прямой проход на этапы, которые легко поддаются обратному распространению ошибки. Например, здесь мы создали промежуточную переменную <code>dot</code>, которая содержит результат скалярного произведения <code>w</code> и <code>x</code>. Затем во время обратного прохода мы последовательно вычисляем (в обратном порядке) соответствующие переменные (например, <code>ddot</code> и, в конечном итоге, <code>dw, dx</code>), которые содержат градиенты этих переменных.  </p>
<p>Смысл этого раздела в том, что детали того, как выполняется обратное распространение ошибки и какие части прямой функции мы считаем логическими элементами, — это вопрос удобства. Полезно знать, какие части выражения имеют простые локальные градиенты, чтобы их можно было объединить в цепочку с наименьшим количеством кода и усилий.  </p>
<h2>Бэкпроп на практике: Поэтапное вычисление</h2>
<p>Давайте рассмотрим это на другом примере. Предположим, что у нас есть функция следующего вида:  </p>
<p>$$
f(x,y) = \frac{x + \sigma(y)}{\sigma(x) + (x+y)^2}
$$  </p>
<p>Для ясности: эта функция совершенно бесполезна, и неясно, зачем вам вообще понадобилось вычислять её градиент, за исключением того, что это хороший пример обратного распространения ошибки на практике. Очень важно подчеркнуть, что если бы вы начали вычислять производную по любому из <strong>x</strong> или <strong>y</strong>, то в результате вы получили бы очень большие и сложные выражения. Однако оказывается, что в этом нет необходимости, потому что нам не нужно записывать явную функцию, которая вычисляет градиент. Нам нужно только знать, как его вычислить. Вот как мы бы структурировали прямой проход для такого выражения:  </p>
<div class="code"><pre class="code literal-block">x = 3 # example values
y = -4

<span class="gh">#</span> forward pass
sigy = 1.0 / (1 + math.exp(-y)) # sigmoid in numerator   #(1)
num = x + sigy # numerator                               #(2)
sigx = 1.0 / (1 + math.exp(-x)) # sigmoid in denominator #(3)
xpy = x + y                                              #(4)
xpysqr = xpy**2                                          #(5)
den = sigx + xpysqr # denominator                        #(6)
invden = 1.0 / den                                       #(7)
f = num * invden # done!                                 #(8)
</pre></div>

<p>Фух, к концу выражения мы вычислили прямой проход. Обратите внимание, что мы структурировали код таким образом, что он содержит несколько промежуточных переменных, каждая из которых представляет собой простое выражение, для которого мы уже знаем локальные градиенты. Поэтому вычислить обратный путь легко: мы пойдём в обратном направлении, и для каждой переменной на пути прямого прохода (<code>sigy, num, sigx, xpy, xpysqr, den, invden</code>) у нас будет та же переменная, но начинающаяся с <code>d</code>, которая будет содержать градиент выходного сигнала схемы по отношению к этой переменной. Кроме того, обратите внимание, что каждый элемент в нашем обратном распространении ошибки будет включать вычисление локального градиента этого выражения и объединение его с градиентом этого выражения путём умножения. Для каждой строки мы также указываем, к какой части прямого прохода она относится:  </p>
<div class="code"><pre class="code literal-block"><span class="gh">#</span> backprop f = num * invden
dnum = invden # gradient on numerator                             #(8)
dinvden = num                                                     #(8)
<span class="gh">#</span> backprop invden = 1.0 / den 
dden = (-1.0 / (den**2)) <span class="gs">* dinvden                                #(7)</span>
<span class="gs"># backprop den = sigx + xpysqr</span>
<span class="gs">dsigx = (1) *</span> dden                                                #(6)
dxpysqr = (1) <span class="gs">* dden                                              #(6)</span>
<span class="gs"># backprop xpysqr = xpy*</span>*2
dxpy = (2 <span class="gs">* xpy) *</span> dxpysqr                                        #(5)
<span class="gh">#</span> backprop xpy = x + y
dx = (1) <span class="gs">* dxpy                                                   #(4)</span>
<span class="gs">dy = (1) *</span> dxpy                                                   #(4)
<span class="gh">#</span> backprop sigx = 1.0 / (1 + math.exp(-x))
dx += ((1 - sigx) <span class="gs">* sigx) *</span> dsigx # Notice += !! See notes below  #(3)
<span class="gh">#</span> backprop num = x + sigy
dx += (1) <span class="gs">* dnum                                                  #(2)</span>
<span class="gs">dsigy = (1) *</span> dnum                                                #(2)
<span class="gh">#</span> backprop sigy = 1.0 / (1 + math.exp(-y))
dy += ((1 - sigy) <span class="gs">* sigy) *</span> dsigy                                 #(1)
<span class="gh">#</span> done! phew
</pre></div>

<p>Обратите внимание на несколько вещей:  </p>
<p><strong>Кэшируйте переменные прямого пути</strong>. Для вычисления обратного пути очень полезно иметь некоторые переменные, которые использовались при прямом пути. На практике вы хотите структурировать свой код таким образом, чтобы кэшировать эти переменные и чтобы они были доступны во время обратного распространения. Если это слишком сложно, можно (но нерационально) пересчитать их.</p>
<p><strong>Градиенты суммируются в точках разветвления</strong>. В прямом выражении переменные <strong>x, y</strong> встречаются несколько раз, поэтому при обратном распространении ошибки мы должны быть внимательны и использовать <code>+=</code> вместо <code>=</code> для накопления градиента по этим переменным (иначе мы перезапишем его). Это соответствует <code>правилу дифференцирования сложной функции</code> в математическом анализе, которое гласит, что если переменная разветвляется на разные части схемы, то градиенты, которые возвращаются к ней, суммируются.  </p>
<h2>Закономерности в обратном потоке</h2>
<p>Интересно отметить, что во многих случаях обратный градиент можно интерпретировать интуитивно. Например, три наиболее часто используемых элемента в нейронных сетях (<em>сложение, умножение, максимальное значение</em>) имеют очень простую интерпретацию с точки зрения того, как они действуют во время обратного распространения ошибки. Рассмотрим этот пример схемы:  </p>
<hr>
<div class="fig figleft fighighlight">
<svg style="max-width: 460px" viewbox="0 0 460 290"><g transform="scale(1)"><defs><marker id="arrowhead" refx="6" refy="2" markerwidth="6" markerheight="4" orient="auto"><path d="M 0,0 V 4 L6,2 Z"></path></marker></defs><line x1="50" y1="30" x2="90" y2="30" stroke="black" stroke-width="1"></line><text x="55" y="24" font-size="16" fill="green">3.00</text><text x="55" y="47" font-size="16" fill="red">-8.00</text><text x="45" y="24" font-size="16" text-anchor="end" fill="black">x</text><line x1="50" y1="100" x2="90" y2="100" stroke="black" stroke-width="1"></line><text x="55" y="94" font-size="16" fill="green">-4.00</text><text x="55" y="117" font-size="16" fill="red">6.00</text><text x="45" y="94" font-size="16" text-anchor="end" fill="black">y</text><line x1="50" y1="170" x2="90" y2="170" stroke="black" stroke-width="1"></line><text x="55" y="164" font-size="16" fill="green">2.00</text><text x="55" y="187" font-size="16" fill="red">2.00</text><text x="45" y="164" font-size="16" text-anchor="end" fill="black">z</text><line x1="50" y1="240" x2="90" y2="240" stroke="black" stroke-width="1"></line><text x="55" y="234" font-size="16" fill="green">-1.00</text><text x="55" y="257" font-size="16" fill="red">0.00</text><text x="45" y="234" font-size="16" text-anchor="end" fill="black">w</text><line x1="170" y1="65" x2="210" y2="65" stroke="black" stroke-width="1"></line><text x="175" y="59" font-size="16" fill="green">-12.00</text><text x="175" y="82" font-size="16" fill="red">2.00</text><circle cx="130" cy="65" fill="white" stroke="black" stroke-width="1" r="20"></circle><text x="130" y="75" font-size="20" fill="black" text-anchor="middle">*</text><line x1="90" y1="30" x2="110" y2="65" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="90" y1="100" x2="110" y2="65" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="150" y1="65" x2="170" y2="65" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="170" y1="205" x2="210" y2="205" stroke="black" stroke-width="1"></line><text x="175" y="199" font-size="16" fill="green">2.00</text><text x="175" y="222" font-size="16" fill="red">2.00</text><circle cx="130" cy="205" fill="white" stroke="black" stroke-width="1" r="20"></circle><text x="130" y="210" font-size="20" fill="black" text-anchor="middle">max</text><line x1="90" y1="170" x2="110" y2="205" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="90" y1="240" x2="110" y2="205" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="150" y1="205" x2="170" y2="205" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="290" y1="135" x2="330" y2="135" stroke="black" stroke-width="1"></line><text x="295" y="129" font-size="16" fill="green">-10.00</text><text x="295" y="152" font-size="16" fill="red">2.00</text><circle cx="250" cy="135" fill="white" stroke="black" stroke-width="1" r="20"></circle><text x="250" y="140" font-size="20" fill="black" text-anchor="middle">+</text><line x1="210" y1="65" x2="230" y2="135" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="210" y1="205" x2="230" y2="135" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="270" y1="135" x2="290" y2="135" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="410" y1="135" x2="450" y2="135" stroke="black" stroke-width="1"></line><text x="415" y="129" font-size="16" fill="green">-20.00</text><text x="415" y="152" font-size="16" fill="red">1.00</text><circle cx="370" cy="135" fill="white" stroke="black" stroke-width="1" r="20"></circle><text x="370" y="140" font-size="20" fill="black" text-anchor="middle">*2</text><line x1="330" y1="135" x2="350" y2="135" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line><line x1="390" y1="135" x2="410" y2="135" stroke="black" stroke-width="1" marker-end="url(#arrowhead)"></line></g></svg><div class="figcaption">
  Пример схемы, демонстрирующей интуитивное понимание операций, которые выполняет обратное распространение ошибки во время обратного прохода для вычисления градиентов по входным данным. Операция суммирования равномерно распределяет градиенты по всем своим входам. Операция максимального значения направляет градиент на вход с наибольшим значением. Операция умножения принимает входные значения, меняет их местами и умножает на градиент.
</div>
<div style="clear:both;"></div>
</div>

<hr>
<p>Рассматривая приведенную выше диаграмму в качестве примера, мы можем видеть, что:  </p>
<p><strong>Сложение</strong> всегда берёт градиент на выходе и распределяет его поровну между всеми входами, независимо от того, какими были их значения во время прямого прохода. Это следует из того, что локальный градиент для операции сложения равен <strong>+1,0</strong>, поэтому градиенты на всех входах будут в точности равны градиентам на выходе, потому что они будут умножены на <strong>x1,0</strong> (и останутся неизменными). В приведённом выше примере обратите внимание, что сумматор направил градиент<strong> 2,00</strong> на оба входа, разделив его поровну и оставив без изменений.  </p>
<p><strong>Макс-сглаживатель</strong> направляет градиент. В отличие от сумматора, который распределяет градиент без изменений по всем своим входам, макс-сглаживатель распределяет градиент (без изменений) только по одному из своих входов (по входу, который имел наибольшее значение во время прямого прохода). Это связано с тем, что локальный градиент для макс-сглаживателя равен <strong>1,0</strong> для наибольшего значения и <strong>0,0</strong> для всех остальных значений. В приведённом выше примере функция max направила градиент <strong>2,00</strong> на переменную <strong>z</strong>, которая имела более высокое значение, чем <strong>w</strong>, а градиент <strong>w</strong> остался равным нулю.  </p>
<p><strong>Умножитель</strong> немного сложнее в интерпретации. Его локальные градиенты — это входные значения (кроме переключаемых), которые умножаются на градиент выходного значения в соответствии с правилом цепочки. В приведённом выше примере градиент <strong>x</strong> равен <strong>-8,00</strong>, что составляет <strong>-4,00 x 2,00</strong>.  </p>
<p><em>Неинтуитивные эффекты и их последствия</em>. Обратите внимание, что если один из входов умножителя очень мал, а другой очень велик, то умножитель сделает что-то немного неинтуитивное: он присвоит относительно большой градиент малому входу и крошечный градиент большому входу. Обратите внимание, что в линейных классификаторах, где веса умножаются на скалярное произведение, <strong>\(w^Tx_i\)</strong> (умноженные) на входные данные, это означает, что масштаб данных влияет на величину градиента весовых коэффициентов. Например, если вы умножите все примеры входных данных <strong>\(x_i\)</strong>. Если во время предварительной обработки умножить на 1000, то градиент по весам будет <strong>в 1000 раз больше</strong>, и вам придётся уменьшить скорость обучения на этот коэффициент, чтобы компенсировать разницу. <strong>Вот почему предварительная обработка так важна, иногда даже в мелочах!</strong> Интуитивное понимание того, как распределяются градиенты, может помочь вам отладить некоторые из этих случаев.  </p>
<h2>Градиенты для векторизованных операций</h2>
<p>В предыдущих разделах речь шла об отдельных переменных, но все концепции напрямую применимы к матричным и векторным операциям. Однако необходимо уделять больше внимания размерностям и транспонированию.  </p>
<p><strong>Градиент при умножении матриц</strong>. Возможно, самая сложная операция — это умножение матриц (которое обобщает все операции умножения матриц на векторы и векторов на векторы):  </p>
<div class="code"><pre class="code literal-block"><span class="gh">#</span> forward pass
W = np.random.randn(5, 10)
X = np.random.randn(10, 3)
D = W.dot(X)

<span class="gh">#</span> now suppose we had the gradient on D from above in the circuit
dD = np.random.randn(*D.shape) # same shape as D
dW = dD.dot(X.T) #.T gives the transpose of the matrix
dX = W.T.dot(dD)
</pre></div>

<p><em>Совет: используйте анализ измерений!</em> Обратите внимание, что вам не нужно запоминать выражения для <code>dW</code> и <code>dX</code>, поскольку их легко повторно вывести на основе измерений. Например, мы знаем, что градиент весов <code>dW</code> должен быть того же размера, что и <code>W</code> после его вычисления, и что он должен зависеть от матричного умножения <code>X</code> и <code>dD</code> (как в случае, когда оба <code>X,W</code> являются одиночными числами, а не матрицами). Всегда есть только один способ достичь этого, чтобы размеры соответствовали друг другу. Например, <code>X</code> имеет размер <strong>[10 x 3]</strong>, а <code>dD</code> — размер <strong>[5 x 3]</strong>, поэтому, если мы хотим, чтобы <code>dW</code> и <code>W</code> имели форму <strong>[5 x 10]</strong>, то единственный способ добиться этого — использовать <code>dD.dot(X.T)</code>, как показано выше.  </p>
<p><strong>Работайте с небольшими, понятными примерами</strong>. Некоторым людям поначалу может быть сложно вывести градиентные обновления для некоторых векторизованных выражений. Мы рекомендуем явно записать минимальный векторизованный пример, вывести градиент на бумаге, а затем обобщить шаблон до эффективной векторизованной формы.  </p>
<p>Эрик Леарнед-Миллер также написал более подробный документ о вычислении матричных/векторных производных, который может оказаться вам полезным. <a href="http://cs231n.stanford.edu/vecDerivs.pdf">Найдите его здесь</a>.  </p>
<h2>Краткая сводка</h2>
<ul>
<li>Мы интуитивно понимаем, что означают градиенты, как они распространяются по цепи и как они сообщают, какую часть цепи следует увеличить или уменьшить и с какой силой, чтобы повысить конечный результат.</li>
<li>Мы обсудили важность <strong>поэтапных вычислений</strong> для практической реализации обратного распространения ошибки. Вы всегда хотите разбить свою функцию на модули, для которых можно легко вычислить локальные градиенты, а затем объединить их с помощью правила дифференцирования сложной функции. Важно отметить, что вы почти никогда не захотите записывать эти выражения на бумаге и дифференцировать их в полной форме, потому что вам никогда не понадобится явное математическое уравнение для градиента входных переменных. Таким образом, разбейте свои выражения на этапы так, чтобы вы могли дифференцировать каждый этап независимо (этапами будут умножение матриц, операции с максимумом, операции с суммой и т. д.), а затем выполняйте обратное распространение по переменным шаг за шагом.  </li>
</ul>
<p>В следующем разделе мы начнём определять нейронные сети, а обратное распространение ошибки позволит нам эффективно вычислять градиент функции потерь по отношению к её параметрам. Другими словами, теперь мы готовы к обучению нейронных сетей, и самая сложная с концептуальной точки зрения часть этого курса осталась позади! До ConvNets останется совсем немного.  </p>
<h3>Ссылки</h3>
<ul>
<li><a href="http://arxiv.org/abs/1502.05767">Автоматическая дифференциация в машинном обучении: опрос</a></li>
</ul>
</div>
            </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/optimization/" class="u-url">Оптимизация</a></h1>
                <div class="metadata">
                    <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                        Андрей Лабинцев
                    </span></p>
            <p class="dateline">
            <a href="posts/optimization/" rel="bookmark">
            <time class="published dt-published" datetime="2025-03-06T19:42:16+03:00" itemprop="datePublished" title="2025-03-06 19:42">2025-03-06 19:42</time></a>
            </p>
                </div>
            </header><div class="e-content entry-content">
                    <h2>Оптимизация</h2>
<p>Содержание: 
- <a href="posts/optimization/">Введение</a>
- <a href="posts/optimization/">Визуализация функции потерь</a>
- <a href="posts/optimization/">Оптимизация</a>
    - <a href="posts/optimization/">Стратегия #1: Случайный поиск</a>
    - <a href="posts/optimization/">Стратегия #2: Случайный локальный поиск</a>
    - <a href="posts/optimization/">Стратегия #3: Следование градиенту</a>
- <a href="posts/optimization/">Вычисление градиента</a>
    - <a href="posts/optimization/">Численно с конечными разностями</a>
    - <a href="posts/optimization/">Аналитически с помощью исчисления</a>
- <a href="posts/optimization/">Градиентный спуск</a>
- <a href="posts/optimization/">Краткая сводка</a></p>
<h2>Введение #</h2>
<p>В предыдущем разделе мы представили два ключевых компонента в контексте задачи классификации изображений:</p>
<ol>
<li>(Параметризованная) <strong>функция оценки</strong>, сопоставляющая пиксели необработанного изображения с оценками класса (например, линейная функция)</li>
<li>
<strong>Функция потерь</strong>, которая измеряет качество определенного набора параметров на основе того, насколько хорошо индуцированные оценки согласуются с метками основной истины в обучающих данных. Мы увидели, что существует множество способов и версий этого (например, Softmax/SVM).  </li>
</ol>
<p>В частности, вспомним, что линейная функция имела вид ( f(x_i, W) = W x_i \
 и разработанная нами SVM была сформулирована следующим образом:  </p>
<p>$$
L = \frac{1}{N} \sum_i \sum_{j\neq y_i} \left[ \max(0, f(x_i; W)<em y_i>j - f(x_i; W)</em> + 1) \right] + \alpha R(W)
$$</p>
<p>Мы увидели, что настройка параметров <strong>\(W\)</strong>, которые выдавали прогнозы для примера <strong>\(x_i\)</strong>. В соответствии с их основными истинными метками <strong>\(y_i\)</strong> также будет иметь очень низкий убыток <strong>L</strong>. Теперь мы представим третий и последний ключевой компонент: <strong>оптимизацию</strong>. Оптимизация — это процесс нахождения набора параметров (W), которые минимизируют функцию потерь.</p>
<p>Предчувствие: Как только мы поймем, как эти три основных компонента взаимодействуют, мы вернемся к первому компоненту (параметризованному отображению функций) и расширим его до функций, гораздо более сложных, чем линейное отображение: сначала целые нейронные сети, а затем сверточные нейронные сети. Функции потерь и процесс оптимизации останутся относительно неизменными.  </p>
<h2>Визуализация функции потерь #</h2>
<p>Функции потерь, которые мы рассмотрим в этом классе, обычно определяются в очень больших пространствах (например, в CIFAR-10 матрица весов линейного классификатора имеет размер [10 x 3073] для всего 30 730 параметров), что затрудняет их визуализацию. Тем не менее, мы все еще можем получить некоторые интуитивные представления об единице, разрезая пространство высокой размерности вдоль лучей (1 измерение) или вдоль плоскостей (2 измерения). Например, мы можем сгенерировать случайную матрицу весов <strong>\(W\)</strong>, (которая соответствует одной точке в пространстве), затем маршировать по лучу и записывать значение функции потерь по пути. То есть мы можем сгенерировать случайное направление <strong>\(W\)</strong> и рассчитать потери в этом направлении, оценив <strong>\( L(W + a W_1 + b W_2) \)</strong> для различных значений <strong>\(a\)</strong>. В результате этого процесса создается простой график со значением <strong>\(a\)</strong> в качестве оси <strong>(X)</strong> и значение функции потерь по оси <strong>\(Y\)</strong>. Мы также можем провести ту же процедуру с двумя измерениями, оценив потери <strong>\( L(W + a W_1 + b W_2) \)</strong> по мере того, как меняются значения <strong>\(a, b\)</strong>. На графике <strong>\(a, b\)</strong> могут соответствовать осям x и y, а значение функции потерь может быть отображено цветом:  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/svm1d.png"><br><img alt="" src="https://cs231n.github.io/assets/svm_one.jpg"><br><img alt="" src="https://cs231n.github.io/assets/svm_all.jpg"><br>
Ландшафт функций потерь для многоклассовой SVM (без регуляризации) для одного единственного примера (сверху, посередине) и для сотни примеров (снизу) в CIFAR-10. Сверху: одномерные потери при изменении только a. Посередине, снизу: двумерный срез потерь, <strong>синий = низкие потери, красный = высокие потери</strong>. Обратите внимание на кусочно-линейную структуру функции потерь. Потери для нескольких примеров сочетаются со средними, поэтому форма чаши снизу является средним значением многих кусочно-линейных чаш (например, та, что посередине).  </p>
<hr>
<p>Мы можем объяснить кусочно-линейную структуру функции потерь, изучив математические расчеты. В качестве единственного примера мы имеем:  </p>
<p>$$
L_i = \sum_{j\neq y_i} \left[ \max(0, w_j^Tx_i - w_{y_i}^Tx_i + 1) \right]
$$</p>
<p>Из уравнения ясно, что потеря данных для каждого примера равна сумме (нулевой порог из-за <strong>\(\max(0,-)\</strong> функции) линейных функций <strong>\(W\)</strong>. Более того, каждый ряд <strong>\(W\)</strong> (т.е. <strong>\(w_j\)</strong>) иногда имеет перед собой положительный знак (когда он соответствует неправильному классу для примера), а иногда отрицательный знак (когда он соответствует правильному классу для этого примера). Чтобы сделать это более явным, рассмотрим простой набор данных, содержащий три одномерные точки и три класса. Полная потеря SVM (без регуляризации) становится следующей:  </p>
<p>$$
\begin{align}
L_0 = &amp; \max(0, w_1^Tx_0 - w_0^Tx_0 + 1) + \max(0, w_2^Tx_0 - w_0^Tx_0 + 1) \\
L_1 = &amp; \max(0, w_0^Tx_1 - w_1^Tx_1 + 1) + \max(0, w_2^Tx_1 - w_1^Tx_1 + 1) \\
L_2 = &amp; \max(0, w_0^Tx_2 - w_2^Tx_2 + 1) + \max(0, w_1^Tx_2 - w_2^Tx_2 + 1) \\
L = &amp; (L_0 + L_1 + L_2)/3
\end{align}
$$  </p>
<p>Поскольку эти примеры являются одномерными, данные <strong>\(x_i\)</strong> и веса <strong>\(w_j\)</strong> -  это цифры. Глядя, например, на <strong>\(w_0\)</strong>, некоторые из приведенных выше членов являются линейными функциями <strong>\(w_0\)</strong>. И каждая из них зажата в точке ноль. Мы можем визуализировать это следующим образом:  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/svmbowl.png"><br><strong>1</strong>-мерная иллюстрация потери данных:<br><strong>Ось x</strong> - это один груз<br><strong>ось y</strong> — потери.  </p>
<hr>
<p>В качестве отступления, вы, возможно, догадались по ее чашеобразному виду, что функция стоимости SVM является примером <a href="http://en.wikipedia.org/wiki/Convex_function">выпуклой функции</a>. Существует большое количество литературы, посвященной эффективной минимизации этих типов функций, и вы также можете пройти курс Стэнфорда по этой теме (<a href="http://stanford.edu/~boyd/cvxbook/">выпуклая оптимизация</a>). Как только мы расширим наши функции оценки <strong>f</strong> для нейронных сетей наши целевые функции станут невыпуклыми, и на приведенных выше визуализациях будут отображаться не чаши, а сложные, ухабистые местности.  </p>
<p><em>Недифференцируемые функции потерь</em>. В качестве технического примечания вы также можете видеть, что изломы в функции потерь (из-за максимальной операции) технически делают функцию потерь недифференцируемой, потому что при этих изломах градиент не определен. Тем не менее, субградиент все еще существует и обычно используется вместо него. В этом классе термины «субградиент» и «градиент» будут использоваться как взаимозаменяемые.  </p>
<p># Оптимизация  </p>
<p>Повторимся, что функция потерь позволяет нам количественно оценить качество любого конкретного набора весов <strong>W</strong>. Цель оптимизации — найти <strong>W</strong>, которое минимизирует функцию потерь. Теперь мы будем мотивировать и постепенно развивать подход к оптимизации функции потерь. Для тех из вас, кто приходит на этот курс с предыдущим опытом, этот раздел может показаться странным, поскольку рабочий пример, который мы будем использовать (потери SVM), является выпуклой задачей, но имейте в виду, что наша цель состоит в том, чтобы в конечном итоге оптимизировать нейронные сети там, где мы не можем легко использовать ни один из инструментов, разработанных в литературе по выпуклой оптимизации.  </p>
<h3>Стратегия #1: Первая очень плохая идея: Случайный поиск</h3>
<p>Просто проверить, насколько хорош определенный набор параметров <strong>W</strong>,что очень просто, первая (очень плохая) идея, которая может прийти в голову, — это просто попробовать множество различных случайных весов и отслеживать, что работает лучше всего. Эта процедура может выглядеть следующим образом:  </p>
<div class="code"><pre class="code literal-block"><span class="c1"># assume X_train is the data where each column is an example (e.g. 3073 x 50,000)</span>
<span class="c1"># assume Y_train are the labels (e.g. 1D array of 50,000)</span>
<span class="c1"># assume the function L evaluates the loss function</span>

<span class="n">bestloss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">)</span> <span class="c1"># Python assigns the highest possible float value</span>
<span class="k">for</span> <span class="n">num</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
  <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3073</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.0001</span> <span class="c1"># generate random parameters</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">Y_train</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="c1"># get the loss over the entire training set</span>
  <span class="k">if</span> <span class="n">loss</span> <span class="o">&lt;</span> <span class="n">bestloss</span><span class="p">:</span> <span class="c1"># keep track of the best solution</span>
    <span class="n">bestloss</span> <span class="o">=</span> <span class="n">loss</span>
    <span class="n">bestW</span> <span class="o">=</span> <span class="n">W</span>
  <span class="nb">print</span> <span class="s1">'in attempt </span><span class="si">%d</span><span class="s1"> the loss was </span><span class="si">%f</span><span class="s1">, best </span><span class="si">%f</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">bestloss</span><span class="p">)</span>

<span class="c1"># prints:</span>
<span class="c1"># in attempt 0 the loss was 9.401632, best 9.401632</span>
<span class="c1"># in attempt 1 the loss was 8.959668, best 8.959668</span>
<span class="c1"># in attempt 2 the loss was 9.044034, best 8.959668</span>
<span class="c1"># in attempt 3 the loss was 9.278948, best 8.959668</span>
<span class="c1"># in attempt 4 the loss was 8.857370, best 8.857370</span>
<span class="c1"># in attempt 5 the loss was 8.943151, best 8.857370</span>
<span class="c1"># in attempt 6 the loss was 8.605604, best 8.605604</span>
<span class="c1"># ... (trunctated: continues for 1000 lines)</span>
</pre></div>

<p>В приведенном выше коде мы видим, что мы опробовали несколько случайных векторов <strong>весов W</strong>, и некоторые из них работают лучше других. Мы можем взять лучшие веса <strong>W</strong>, найденные этим поиском, и опробовать их на тестовом наборе:  </p>
<div class="code"><pre class="code literal-block"><span class="c1"># Assume X_test is [3073 x 10000], Y_test [10000 x 1]</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">Wbest</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Xte_cols</span><span class="p">)</span> <span class="c1"># 10 x 10000, the class scores for all test examples</span>
<span class="c1"># find the index with max score in each column (the predicted class)</span>
<span class="n">Yte_predict</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="c1"># and calculate accuracy (fraction of predictions that are correct)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Yte_predict</span> <span class="o">==</span> <span class="n">Yte</span><span class="p">)</span>
<span class="c1"># returns 0.1555</span>
</pre></div>

<p>При наилучшем <strong>W</strong> это дает точность около <strong>15,5%</strong>. Учитывая, что угадывание классов полностью случайным образом дает только 10%, это не очень плохой результат для такого примитивного решения на основе случайного поиска!  </p>
<p><strong>Основная идея: итеративное уточнение</strong>. Конечно, оказывается, что мы можем добиться гораздо большего. Основная идея заключается в том, что поиск наилучшего набора весов <strong>W</strong> является очень сложной или даже невозможной задачей (особенно когда W содержит веса для целых сложных нейронных сетей), но задача уточнения конкретного набора весов <strong>W</strong> для немного лучшего уровня значительно менее сложна. Другими словами, наш подход будет заключаться в том, чтобы начать со случайной <strong>W</strong>, а затем итеративно уточнять ее, делая ее немного лучше с каждым разом.  </p>
<blockquote>
<p>Наша стратегия будет заключаться в том, чтобы начать со случайных весовых коэффициентов и итеративно уточнять их с течением времени, чтобы получить меньшие потери.   </p>
</blockquote>
<p><strong>Аналогия с туристом с завязанными глазами</strong>. Одна из аналогий, которую вы можете найти полезной в будущем - представить, что Вы идете по холмистой местности с повязкой на глазах и пытаетесь добраться до самой низины. В примере с CIFAR-10 холмы имеют размерность 30 730, так как <strong>размеры W</strong> равны 10 x 3073. В каждой точке холма мы достигаем определенной потери (высоты над уровнем моря).  </p>
<h3>Стратегия №2: Случайный локальный поиск</h3>
<p>Первая стратегия, которая приходит на ум, — это попытаться вытянуть одну ногу в случайном направлении, а затем сделать шаг, только если он ведёт вниз по склону. Конкретно мы начнём со случайного <strong>W</strong>, генерирующего случайные возмущения <strong>δW</strong> к нему, и если потеря у возмущенного __W+δW__меньше, мы выполним обновление. Код для этой процедуры выглядит следующим образом:  </p>
<div class="code"><pre class="code literal-block"><span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3073</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.001</span> <span class="c1"># generate random starting W</span>
<span class="n">bestloss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">"inf"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1000</span><span class="p">):</span>
  <span class="n">step_size</span> <span class="o">=</span> <span class="mf">0.0001</span>
  <span class="n">Wtry</span> <span class="o">=</span> <span class="n">W</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3073</span><span class="p">)</span> <span class="o">*</span> <span class="n">step_size</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">L</span><span class="p">(</span><span class="n">Xtr_cols</span><span class="p">,</span> <span class="n">Ytr</span><span class="p">,</span> <span class="n">Wtry</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">loss</span> <span class="o">&lt;</span> <span class="n">bestloss</span><span class="p">:</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">Wtry</span>
    <span class="n">bestloss</span> <span class="o">=</span> <span class="n">loss</span>
  <span class="nb">print</span> <span class="s1">'iter </span><span class="si">%d</span><span class="s1"> loss is </span><span class="si">%f</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">bestloss</span><span class="p">)</span>
</pre></div>

<p>При использовании того же количества оценок функции потерь, что и раньше (1000), этот подход обеспечивает точность классификации тестового набора <strong>21,4%</strong>. Это лучше, но всё равно неэффективно и требует больших вычислительных мощностей.  </p>
<h3>Стратегия №3: Следование градиенту</h3>
<p>В предыдущем разделе мы пытались найти направление в пространстве весов, которое улучшило бы наш вектор весов (и снизило бы потери). Оказывается, нет необходимости случайным образом искать хорошее направление: мы можем вычислить <em>лучшее</em> направление, в котором нам следует изменить наш вектор весов, чтобы оно гарантированно было направлением наискорейшего спуска (по крайней мере, в пределе, когда размер шага стремится к нулю). Это направление будет связано с <strong>градиентом</strong> функции потерь. В нашей аналогии с походом этот подход примерно соответствует тому, чтобы почувствовать наклон холма под ногами и идти в направлении, которое кажется наиболее крутым.  </p>
<p>В одномерных функциях наклон — это мгновенная скорость изменения функции в любой интересующей вас точке. Градиент — это обобщение наклона для функций, которые принимают не одно число, а вектор чисел. Кроме того, градиент — это просто вектор наклонов (более известных как <strong>производные</strong>) для каждого измерения во входном пространстве. Математическое выражение для производной одномерной функции по входным данным выглядит так:  </p>
<p>$$
\frac{df(x)}{dx} = \lim_{h\ \to 0} \frac{f(x + h) - f(x)}{h}
$$  </p>
<p>Когда интересующие нас функции принимают вектор чисел вместо одного числа, мы называем производные <strong>частными производными</strong>, а градиент — это просто вектор частных производных по каждому измерению. </p>
<h2>Вычисление градиента</h2>
<p>Существует два способа вычисления градиента: медленный, приблизительный, но простой (<strong>численный градиент</strong>) и быстрый, точный, но более подверженный ошибкам способ, требующий математических вычислений (<strong>аналитический градиент</strong>). Сейчас мы рассмотрим оба способа.  </p>
<h3>Вычисление градиента численно с конечными разностями</h3>
<p>Приведённая выше формула позволяет вычислить градиент численно. Вот универсальная функция, которая принимает градиент <code>f</code> и вектор <code>x</code> для вычисления функции и возвращает градиент <code>f</code> в точке <code>x</code>:</p>
<div class="code"><pre class="code literal-block"><span class="k">def</span><span class="w"> </span><span class="nf">eval_numerical_gradient</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="w">  </span><span class="sd">"""</span>
<span class="sd">  a naive implementation of numerical gradient of f at x</span>
<span class="sd">  - f should be a function that takes a single argument</span>
<span class="sd">  - x is the point (numpy array) to evaluate the gradient at</span>
<span class="sd">  """</span>

  <span class="n">fx</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># evaluate function value at original point</span>
  <span class="n">grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="n">h</span> <span class="o">=</span> <span class="mf">0.00001</span>

  <span class="c1"># iterate over all indexes in x</span>
  <span class="n">it</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nditer</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="p">[</span><span class="s1">'multi_index'</span><span class="p">],</span> <span class="n">op_flags</span><span class="o">=</span><span class="p">[</span><span class="s1">'readwrite'</span><span class="p">])</span>
  <span class="k">while</span> <span class="ow">not</span> <span class="n">it</span><span class="o">.</span><span class="n">finished</span><span class="p">:</span>

    <span class="c1"># evaluate function at x+h</span>
    <span class="n">ix</span> <span class="o">=</span> <span class="n">it</span><span class="o">.</span><span class="n">multi_index</span>
    <span class="n">old_value</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span>
    <span class="n">x</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="o">=</span> <span class="n">old_value</span> <span class="o">+</span> <span class="n">h</span> <span class="c1"># increment by h</span>
    <span class="n">fxh</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># evalute f(x + h)</span>
    <span class="n">x</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="o">=</span> <span class="n">old_value</span> <span class="c1"># restore to previous value (very important!)</span>

    <span class="c1"># compute the partial derivative</span>
    <span class="n">grad</span><span class="p">[</span><span class="n">ix</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">fxh</span> <span class="o">-</span> <span class="n">fx</span><span class="p">)</span> <span class="o">/</span> <span class="n">h</span> <span class="c1"># the slope</span>
    <span class="n">it</span><span class="o">.</span><span class="n">iternext</span><span class="p">()</span> <span class="c1"># step to next dimension</span>

  <span class="k">return</span> <span class="n">grad</span>
</pre></div>

<p>В соответствии с формулой градиента, которую мы привели выше, приведённый код перебирает все параметры один за другим, вносит небольшое изменение <code>h</code> в этом параметре и вычисляет частную производную функции потерь по этому параметру, определяя, насколько изменилась функция. Переменная <code>grad</code> в итоге содержит полный градиент.  </p>
<p><strong>Практические соображения</strong>. Обратите внимание, что в математической формулировке градиент определяется в пределе, когда <strong>h</strong> стремится к нулю, но на практике часто достаточно использовать очень маленькое значение (например, <strong>1e-5</strong>, как показано в примере). В идеале нужно использовать наименьший размер шага, который не приводит к численным проблемам. Кроме того, на практике часто лучше вычислять численный градиент с помощью <strong>формулы центрированной разности: [f(x+h)−f(x−h)]/2h</strong>. Смотрите <a href="http://en.wikipedia.org/wiki/Numerical_differentiation">wiki</a> для получения подробной информации.  </p>
<p>Мы можем использовать приведённую выше функцию для вычисления градиента в любой точке и для любой функции. Давайте вычислим градиент функции потерь CIFAR-10 в некоторой случайной точке в пространстве весов:  </p>
<div class="code"><pre class="code literal-block"><span class="gh">#</span> to use the generic code above we want a function that takes a single argument
<span class="gh">#</span> (the weights in our case) so we close over X_train and Y_train
def CIFAR10_loss_fun(W):
  return L(X_train, Y_train, W)

W = np.random.rand(10, 3073) * 0.001 # random weight vector
df = eval_numerical_gradient(CIFAR10_loss_fun, W) # get the gradient
</pre></div>

<p>Градиент показывает наклон функции потерь по каждому измерению, и мы можем использовать его для обновления:  </p>
<div class="code"><pre class="code literal-block">loss_original = CIFAR10_loss_fun(W) # the original loss
print 'original loss: %f' % (loss_original, )

<span class="gh">#</span> lets see the effect of multiple step sizes
for step_size_log in [-10, -9, -8, -7, -6, -5,-4,-3,-2,-1]:
  step_size = 10 ** step_size_log
  W_new = W - step_size * df # new position in the weight space
  loss_new = CIFAR10_loss_fun(W_new)
  print 'for step size %f new loss: %f' % (step_size, loss_new)

<span class="gh">#</span> prints:
<span class="gh">#</span> original loss: 2.200718
<span class="gh">#</span> for step size 1.000000e-10 new loss: 2.200652
<span class="gh">#</span> for step size 1.000000e-09 new loss: 2.200057
<span class="gh">#</span> for step size 1.000000e-08 new loss: 2.194116
<span class="gh">#</span> for step size 1.000000e-07 new loss: 2.135493
<span class="gh">#</span> for step size 1.000000e-06 new loss: 1.647802
<span class="gh">#</span> for step size 1.000000e-05 new loss: 2.844355
<span class="gh">#</span> for step size 1.000000e-04 new loss: 25.558142
<span class="gh">#</span> for step size 1.000000e-03 new loss: 254.086573
<span class="gh">#</span> for step size 1.000000e-02 new loss: 2539.370888
<span class="gh">#</span> for step size 1.000000e-01 new loss: 25392.214036
</pre></div>

<p><strong>Обновление в направлении отрицательного градиента</strong>. В приведенном выше коде обратите внимание, что для вычисления <code>W_new</code> мы выполняем обновление в направлении отрицательного градиента <code>df</code>, поскольку хотим, чтобы наша функция потерь уменьшалась, а не увеличивалась.  </p>
<p><strong>Влияние размера шага</strong>. Градиент показывает нам направление, в котором функция возрастает наиболее быстро, но не говорит нам, насколько далеко в этом направлении мы должны продвинуться. Как мы увидим далее в курсе, выбор размера шага (также называемого <em>скоростью обучения</em>) станет одним из самых важных (и самых сложных) параметров при обучении нейронной сети. В нашей аналогии со спуском с холма вслепую мы чувствуем, что склон под нашими ногами наклонён в каком-то направлении, но длина шага, который мы должны сделать, неизвестна. Если мы будем осторожно переставлять ноги, то сможем рассчитывать на последовательный, но очень медленный прогресс (это соответствует небольшому размеру шага). И наоборот, мы можем сделать большой уверенный шаг, чтобы спуститься быстрее, но это может не окупиться. Как вы можете видеть в примере кода выше, в какой-то момент более длинный шаг приведёт к большим потерям, так как мы «перешагнём».  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/stepsize.jpg"><br>
Визуализация влияния размера шага. Мы начинаем с какой-то конкретной точки <strong>W</strong> и вычисляем градиент (или, скорее, его отрицательную величину — белую стрелку), который указывает направление наиболее резкого снижения функции потерь. Маленькие шаги, скорее всего, приведут к стабильному, но медленному прогрессу. Большие шаги могут привести к более быстрому прогрессу, но они более рискованны. Обратите внимание, что в конечном итоге при большом размере шага мы совершим ошибку и увеличим потери. Размер шага (или, как мы позже назовём его, <strong>скорость обучения</strong>) станет одним из важнейших гиперпараметров, которые нам придётся тщательно настраивать.  </p>
<hr>
<p><strong>Проблема эффективности</strong>. Возможно, вы заметили, что вычисление численного градиента имеет сложность, линейную по отношению к количеству параметров. В нашем примере у нас было 30 730 параметров, и поэтому для вычисления градиента и обновления только одного параметра нам пришлось выполнить 30 731 вычисление функции потерь. Эта проблема усугубляется тем, что современные нейронные сети могут легко содержать десятки миллионов параметров. Очевидно, что эта стратегия не масштабируется, и нам нужно что-то получше.  </p>
<h3>Вычисление градиента аналитически с помощью математического анализа</h3>
<p>Численный градиент очень просто вычислить с помощью конечно-разностного приближения, но его недостатком является то, что он является приблизительным (поскольку нам нужно выбрать небольшое значение <em>h</em>, в то время как истинный градиент определяется как предел, когда <em>h</em> стремится к нулю), а также то, что его вычисление требует больших вычислительных мощностей. Второй способ вычисления градиента — аналитический, с использованием математического анализа, который позволяет вывести прямую формулу для градиента (без приближений), которая также очень быстро вычисляется. Однако, в отличие от численного градиента, его реализация может быть более подвержена ошибкам, поэтому на практике очень часто вычисляют аналитический градиент и сравнивают его с численным градиентом, чтобы проверить правильность реализации. Это называется <strong>проверкой градиента</strong>.  </p>
<p>Давайте рассмотрим пример функции потерь SVM для одной точки данных:  </p>
<p>$$
L_i = \sum_{j\neq y_i} \left[ \max(0, w_j^Tx_i - w_{y_i}^Tx_i + \Delta) \right]
$$  </p>
<p>Мы можем дифференцировать функцию по весовым коэффициентам. Например, взяв градиент по <strong>\(w_{y_i}\)</strong> мы получаем:  </p>
<p>$$
\nabla_{w_{y_i}} L_i = - \left( \sum_{j\neq y_i} \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta &gt; 0) \right) x_i
$$  </p>
<p>где <strong>\(\mathbb{1}\)</strong>- это индикаторная функция, которая принимает значение 1, если условие внутри истинно, и 0 в противном случае. Хотя это выражение может показаться пугающим, когда вы записываете его, при реализации в коде вы просто подсчитываете количество классов, которые не соответствуют желаемой погрешности (и, следовательно, влияют на функцию потерь), а затем вектор данных <strong>\(x_i\)</strong>, умноженное на это число — это градиент. Обратите внимание, что это градиент только по отношению к строке <strong>W</strong>, а это соответствует правильному классу. Для других строк, где <strong>j≠\(y_i\)</strong> градиент равен:  </p>
<p>$$
\nabla_{w_j} L_i = \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta &gt; 0) x_i
$$  </p>
<p>Как только вы получите выражение для градиента, будет несложно реализовать эти выражения и использовать их для обновления градиента.  </p>
<h2>Градиентный спуск</h2>
<p>Теперь, когда мы можем вычислить градиент функции потерь, процедура многократного вычисления градиента, а затем обновления параметров, называется градиентным спуском. Его простая версия выглядит следующим образом: </p>
<div class="code"><pre class="code literal-block"><span class="gh">#</span> Vanilla Gradient Descent

while True:
  weights_grad = evaluate_gradient(loss_fun, data, weights)
  weights += - step_size * weights_grad # perform parameter update
</pre></div>

<p>Этот простой цикл лежит в основе всех библиотек нейронных сетей. Существуют и другие способы оптимизации (например, LBFGS), но градиентный спуск в настоящее время является наиболее распространённым и устоявшимся способом оптимизации функций потерь нейронных сетей. В ходе курса мы рассмотрим некоторые детали этого цикла (например, точное уравнение обновления), но основная идея следования за градиентом до тех пор, пока нас не удовлетворят результаты, останется прежней.  </p>
<p><strong>Мини-пакетный градиентный спуск</strong>. В крупномасштабных приложениях (таких как ILSVRC) обучающие данные могут насчитывать миллионы примеров. Следовательно, вычисление полной функции потерь по всему обучающему набору данных для выполнения только одного обновления параметров кажется нецелесообразным. Очень распространённым подходом к решению этой проблемы является вычисление градиента по <strong>пакетам</strong> обучающих данных. Например, в современных сверточных нейронных сетях типичная партия содержит 256 примеров из всего обучающего набора, состоящего 1,2 миллиона примеров. Затем эта партия используется для обновления параметров:  </p>
<div class="code"><pre class="code literal-block"><span class="gh">#</span> Vanilla Minibatch Gradient Descent

while True:
  data_batch = sample_training_data(data, 256) # sample 256 examples
  weights_grad = evaluate_gradient(loss_fun, data_batch, weights)
  weights += - step_size * weights_grad # perform parameter update
</pre></div>

<p>Причина, по которой это работает, заключается в том, что примеры в обучающих данных взаимосвязаны. Чтобы понять это, рассмотрим крайний случай, когда все 1,2 миллиона изображений в ILSVRC на самом деле являются точными дубликатами всего 1000 уникальных изображений (по одному для каждого класса, или, другими словами, 1200 идентичных копий каждого изображения). Тогда очевидно, что градиенты, которые мы вычислили бы для всех 1200 идентичных копий, были бы одинаковыми, и если бы мы усреднили потерю данных по всем 1,2 миллионам изображений, то получили бы точно такую же потерю, как если бы мы оценивали только небольшое подмножество из 1000 изображений. На практике, конечно, набор данных не содержит дубликатов изображений, и градиент от мини-пакета является хорошим приближением к градиенту полной задачи. Таким образом, на практике можно добиться гораздо более быстрой сходимости, оценивая градиенты мини-пакетов для более частого обновления параметров.</p>
<p>Крайним случаем этого является ситуация, когда мини-пакет содержит только один пример. Этот процесс называется <strong>стохастическим градиентным спуском (SGD)</strong> (или иногда <strong>онлайн</strong>-градиентным спуском). Это относительно редкое явление, потому что на практике из-за оптимизации кода с помощью векторизации гораздо эффективнее вычислять градиент для 100 примеров, чем градиент для одного примера 100 раз. Несмотря на то, что SGD технически подразумевает использование одного примера для оценки градиента, вы услышите, как люди используют термин SGD даже при упоминании градиентного спуска с мини-пакетами (т. е. редко можно встретить упоминания MGD для «градиентного спуска с мини-пакетами» или BGD для «пакетного градиентного спуска»), где обычно предполагается использование мини-пакетов. Размер мини-пакета является гиперпараметром, но его нечасто проверяют на перекрёстной проверке. Обычно это зависит от ограничений памяти (если они есть) или устанавливается на какое-то значение, например 32, 64 или 128. На практике мы используем степени двойки, потому что многие реализации векторизованных операций работают быстрее, если размер входных данных равен степени двойки.  </p>
<h2>Краткая сводка</h2>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/dataflow.jpeg"><br>
Краткое описание информационного потока. Набор данных, состоящий из пар <strong>(x,y)</strong>, задан и неизменен. Веса изначально являются случайными числами и могут меняться. Во время прямого прохода функция оценки вычисляет оценки классов, которые сохраняются в векторе <strong>f</strong>. Функция потерь содержит два компонента: Функция потерь данных вычисляет соответствие между оценками <strong>f</strong> и метками <strong>y</strong>. Функция потерь регуляризации зависит только от весов. Во время градиентного спуска мы вычисляем градиент по весовым коэффициентам (и, при желании, по данным) и используем его для обновления параметров во время градиентного спуска.  </p>
<hr>
<p>В этом разделе: 
- Мы представили функцию потерь как <strong>многомерный ландшафт оптимизации</strong>, в котором мы пытаемся достичь дна. Рабочая аналогия, которую мы разработали, — это турист с завязанными глазами, который хочет добраться до дна. В частности, мы увидели, что функция стоимости SVM является кусочно-линейной и имеет форму чаши.
- Мы обосновали идею оптимизации функции потерь с помощью <strong>итеративного уточнения</strong>, при котором мы начинаем со случайного набора весовых коэффициентов и шаг за шагом уточняем их, пока потери не будут минимизированы.
- Мы увидели, что <strong>градиент</strong> функции указывает направление наискорейшего подъёма, и обсудили простой, но неэффективный способ его численного вычисления с помощью конечно-разностной аппроксимации (конечно-разностная аппроксимация — это значение <em>h</em>, используемое при вычислении численного градиента).
- Мы увидели, что для обновления параметров требуется сложная настройка <strong>размера шага</strong> (или <strong>скорости обучения</strong>), который должен быть установлен правильно: если он слишком мал, прогресс будет стабильным, но медленным. Если он слишком велик, прогресс может быть быстрее, но более рискованным. Мы рассмотрим этот компромисс более подробно в следующих разделах.
- Мы обсудили компромиссы между вычислением <strong>численного</strong> и <strong>аналитического</strong> градиента. Численный градиент прост, но он приблизителен и требует больших вычислительных затрат. Аналитический градиент точен, быстро вычисляется, но более подвержен ошибкам, поскольку требует вычисления градиента с помощью математики. Поэтому на практике мы всегда используем аналитический градиент, а затем выполняем <strong>проверку градиента</strong>, в ходе которой его реализация сравнивается с численным градиентом.
- Мы представили алгоритм <strong>градиентного спуска</strong>, который итеративно вычисляет градиент и выполняет обновление параметров в цикле.  </p>
<p><strong>Далее</strong>: основной вывод из этого раздела заключается в том, что способность вычислять градиент функции потерь по отношению к её весовым коэффициентам (и иметь некоторое интуитивное представление об этом) — самый важный навык, необходимый для проектирования, обучения и понимания нейронных сетей. В следующем разделе мы научимся вычислять градиент аналитически с помощью правила дифференцирования сложной функции, также известного как <strong>обратное распространение ошибки</strong>. Это позволит нам эффективно оптимизировать относительно произвольные функции потерь, которые используются во всех видах нейронных сетей, включая свёрточные нейронные сети.</p>
                </div>
            </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/linear-classifier/" class="u-url">Линейный классификатор </a></h1>
                <div class="metadata">
                    <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                        Андрей Лабинцев
                    </span></p>
            <p class="dateline">
            <a href="posts/linear-classifier/" rel="bookmark">
            <time class="published dt-published" datetime="2025-03-05T19:42:16+03:00" itemprop="datePublished" title="2025-03-05 19:42">2025-03-05 19:42</time></a>
            </p>
                </div>
            </header><div class="e-content entry-content">
                    <h2>Линейный классификатор</h2>
<p>Содержание: 
- <a href="posts/linear-classifier/#%D0%BB%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D0%B0%D1%8F-%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D1%8F">Линейная классификация</a>
- <a href="posts/linear-classifier/#%D0%BF%D0%B0%D1%80%D0%B0%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D0%B7%D0%BE%D0%B2%D0%B0%D0%BD%D0%BD%D0%BE%D0%B5-%D1%81%D0%BE%D0%BF%D0%BE%D1%81%D1%82%D0%B0%D0%B2%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5-%D0%B8%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B9-%D1%81-%D0%BE%D1%86%D0%B5%D0%BD%D0%BA%D0%B0%D0%BC%D0%B8-%D0%BC%D0%B5%D1%82%D0%BE%D0%BA">Параметризованное сопоставление изображений с оценками меток</a>
- <a href="posts/linear-classifier/#%D0%B8%D0%BD%D1%82%D0%B5%D1%80%D0%BF%D1%80%D0%B5%D1%82%D0%B0%D1%86%D0%B8%D1%8F-%D0%BB%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D0%BE%D0%B3%D0%BE-%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%82%D0%BE%D1%80%D0%B0">Интерпретация линейного классификатора</a>
- <a href="posts/linear-classifier/#%D1%84%D1%83%D0%BD%D0%BA%D1%86%D0%B8%D1%8F-%D0%BF%D0%BE%D1%82%D0%B5%D1%80%D1%8C">Функция потерь</a>
- <a href="posts/linear-classifier/#%D0%BF%D0%BE%D1%82%D0%B5%D1%80%D1%8F-%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D1%8B-%D0%BC%D1%83%D0%BB%D1%8C%D1%82%D0%B8%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%BE%D0%B2%D0%BE%D0%B3%D0%BE-%D0%BE%D0%BF%D0%BE%D1%80%D0%BD%D0%BE%D0%B3%D0%BE-%D0%B2%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%B0">Потеря машины мультиклассового опорного вектора</a>
- <a href="posts/linear-classifier/#%D0%BF%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B5-%D1%81%D0%BE%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F">Практические соображения</a>
- <a href="posts/linear-classifier/#%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%82%D0%BE%D1%80-softmax">Классификатор Softmax</a>
- <a href="posts/linear-classifier/#svm-%D0%BF%D1%80%D0%BE%D1%82%D0%B8%D0%B2-softmax">SVM против Softmax</a>
- <a href="posts/linear-classifier/#%D0%B8%D0%BD%D1%82%D0%B5%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%B2%D0%BD%D0%B0%D1%8F-%D0%B2%D0%B5%D0%B1-%D0%B4%D0%B5%D0%BC%D0%BE%D0%BD%D1%81%D1%82%D1%80%D0%B0%D1%86%D0%B8%D1%8F">Интерактивная веб-демонстрация</a>
- <a href="posts/linear-classifier/#%D0%BA%D1%80%D0%B0%D1%82%D0%BA%D0%B0%D1%8F-%D1%81%D0%B2%D0%BE%D0%B4%D0%BA%D0%B0">Краткая сводка</a>
- <a href="posts/linear-classifier/#%D0%B4%D0%BE%D0%BF%D0%BE%D0%BB%D0%BD%D0%B8%D1%82%D0%B5%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5-%D0%BC%D0%B0%D1%82%D0%B5%D1%80%D0%B8%D0%B0%D0%BB%D1%8B">Дополнительные материалы</a></p>
<h3>Линейная классификация</h3>
<p>В предыдущем разделе мы рассмотрели задачу классификации изображений, которая заключается в присвоении изображению одного из фиксированного набора категорий. Кроме того, мы описали классификатор k-ближайших соседей (kNN), который присваивает изображениям метки, сравнивая их с (помеченными) изображениями из обучающей выборки. Как мы увидели, у kNN есть ряд недостатков:
- Классификатор должен запоминать все обучающие данные и сохранять их для последующего сравнения с тестовыми данными. Это неэффективно с точки зрения использования памяти, поскольку размер наборов данных может легко достигать гигабайтов.
- Классификация тестового изображения обходится дорого, поскольку требует сравнения со всеми обучающими изображениями.  </p>
<p><strong>Обзор</strong>. Теперь мы собираемся разработать более эффективный подход к классификации изображений, который в конечном итоге естественным образом распространится на нейронные сети и свёрточные нейронные сети. Этот подход будет состоять из двух основных компонентов: <strong>функции оценки</strong>, которая преобразует исходные данные в оценки классов, и <strong>функции потерь</strong>, которая количественно оценивает соответствие между прогнозируемыми оценками и истинными метками. Затем мы сформулируем это, как задачу оптимизации, в которой мы минимизируем функцию потерь по отношению к параметрам функции оценки.   </p>
<h3>Параметризованное сопоставление изображений с оценками меток</h3>
<p>Первым компонентом этого подхода является определение функции оценки, которая сопоставляет значения пикселей изображения со значениями уверенности для каждого класса. Мы рассмотрим этот подход на конкретном примере. Как и прежде, предположим, что у нас есть набор обучающих изображений $x_i \ in R^D $ каждый из которых связан с меткой  $ y_i $. Здесь $i=1 ... N $ и $y_i \in { 1 ... K } $. </p>
<p>То есть у нас есть <strong>N</strong> примеров (каждый из которых имеет размерность <strong>D</strong>) и <strong>K</strong> различных категорий. Например, в CIFAR-10 у нас есть обучающий набор из <strong>N</strong> = 50 000 изображений, каждое из которых имеет <strong>D</strong> = 32 x 32 x 3 = 3072 пикселя, и <strong>K</strong> = 10, так как существует 10 различных классов (собака, кошка, автомобиль и т. д.). Теперь мы определим функцию оценки $f: R^D \mapsto R^K$, которое сопоставляет пиксели необработанного изображения с оценками класса.   </p>
<p><strong>Линейный классификатор</strong>. В этом модуле мы начнём с, пожалуй, самой простой из возможных функций — линейного отображения:  </p>
<p>$$
f(x_i, W, b) = W x_i + b
$$   </p>
<p>В приведенном выше уравнении мы предполагаем, что изображение $x_i$ все его пиксели сглаживаются до одного вектора-столбца размером [D x 1] . Матрица <strong>W</strong> (размером [K x D]) и вектор <strong>b</strong> (размером [K x 1]) являются <strong>параметрами</strong> функции. В CIFAR-10 $x_i$ содержит все пиксели в i-м изображении, объединённые в один столбец [3072 x 1], <strong>W</strong> имеет размер [10 x 3072], а <strong>b</strong> имеет размер [10 x 1], то есть в функцию поступает 3072 числа (исходные значения пикселей), а выходит 10 чисел (оценки классов). Параметры в <strong>W</strong> часто называют весами, а <strong>b</strong> называют <strong>вектором смещения</strong>, потому что он влияет на выходные оценки, но не взаимодействует с фактическими данными $x_i$. Однако вы часто будете слышать, как люди используют термины веса и параметры как взаимозаменяемые. 
Есть несколько вещей, на которые следует обратить внимание:
- Во-первых, обратите внимание, что умножение одной матрицы $W x_1$. Фактически выполняется параллельная оценка 10 отдельных классификаторов (по одному для каждого класса), где каждый классификатор представляет собой строку <strong>W</strong>.
- Обратите также внимание, что мы думаем о входных данных $ (x_i, y_i) $
Мы считаем, что они заданы и неизменны, но мы можем управлять параметрами <strong>W</strong>, <strong>b</strong>. Наша цель — настроить их таким образом, чтобы вычисленные оценки соответствовали истинным меткам во всём обучающем наборе данных. Мы подробно рассмотрим, как это сделать, но интуитивно понятно, что мы хотим, чтобы оценка правильного класса была выше, чем оценка неправильных классов.
- Преимущество этого подхода заключается в том, что обучающие данные используются для определения параметров <strong>W</strong>, <strong>b</strong>, но после завершения обучения мы можем отбросить весь обучающий набор данных и оставить только полученные параметры. Это связано с тем, что новое тестовое изображение можно просто передать в функцию и классифицировать на основе вычисленных показателей.
- Наконец, обратите внимание, что классификация тестового изображения включает в себя одно матричное умножение и сложение, что значительно быстрее, чем сравнение тестового изображения со всеми обучающими изображениями. </p>
<blockquote>
<p>Предвосхищая вопрос: свёрточные нейронные сети будут сопоставлять пиксели изображения со значениями точно так же, как показано выше, но сопоставление ( f ) будет более сложным и будет содержать больше параметров.</p>
</blockquote>
<h3>Интерпретация линейного классификатора</h3>
<p>Обратите внимание, что линейный классификатор вычисляет оценку класса как взвешенную сумму всех значений пикселей по всем трём цветовым каналам. В зависимости от того, какие именно значения мы задаём для этих весов, функция может любить или не любить (в зависимости от знака каждого веса) определённые цвета в определённых местах изображения. Например, можно представить, что класс «корабль» может быть более вероятным, если по краям изображения много синего (что, скорее всего, соответствует воде). Можно было бы ожидать, что классификатор «корабль» будет иметь множество положительных весовых коэффициентов для синего канала (присутствие синего повышает оценку корабля) и отрицательные весовые коэффициенты для красного/зелёного каналов (присутствие красного/зелёного понижает оценку корабля). </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/imagemap.jpg"><br>
Пример сопоставления изображения с баллами по классам. Для наглядности предположим, что изображение состоит всего из 4 пикселей (4 монохромных пикселя, в этом примере мы не рассматриваем цветовые каналы для краткости) и что у нас есть 3 класса (красный (кошка), зелёный (собака), синий (корабль)). (Уточнение: в частности, цвета здесь просто обозначают 3 класса и не связаны с каналами RGB.) Мы растягиваем пиксели изображения в столбец и выполняем умножение матриц, чтобы получить баллы по каждому классу. Обратите внимание, что этот конкретный набор весовых коэффициентов W совсем не хорош: весовые коэффициенты присваивают нашему изображению кошки очень низкий балл. В частности, этот набор весовых коэффициентов, похоже, убеждён, что видит собаку. </p>
<hr>
<p><strong>Аналогия изображений с многомерными точками</strong>. Поскольку изображения растягиваются в многомерные векторы-столбцы, мы можем интерпретировать каждое изображение как отдельную точку в этом пространстве (например, каждое изображение в CIFAR-10 — это точка в 3072-мерном пространстве размером 32x32x3 пикселя). Аналогично, весь набор данных — это (помеченный) набор точек.   </p>
<p>Поскольку мы определили оценку каждого класса как взвешенную сумму всех пикселей изображения, оценка каждого класса является линейной функцией в этом пространстве. Мы не можем визуализировать 3072-мерное пространство, но если мы представим, что все эти измерения сведены к двум, то сможем попытаться визуализировать, что может делать классификатор: </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/pixelspace.jpeg"><br>
Мультяшное представление пространства изображений, где каждое изображение представляет собой одну точку, а три классификатора визуализированы. На примере классификатора автомобилей (красным цветом) красная линия показывает все точки в пространстве, которые получают нулевой балл за класс автомобилей. Красная стрелка показывает направление увеличения, поэтому все точки справа от красной линии имеют положительные (и линейно возрастающие) баллы, а все точки слева — отрицательные (и линейно убывающие) баллы. </p>
<hr>
<p>Как мы видели выше, каждый ряд <strong>W</strong> является классификатором для одного из классов. Геометрическая интерпретация этих чисел заключается в том, что при изменении одного из столбцов <strong>W</strong> соответствующая линия в пиксельном пространстве будет поворачиваться в разных направлениях. Смещение <strong>b</strong>. С другой стороны, наши классификаторы позволяют переводить строки. В частности, обратите внимание, что без коэффициентов смещения подстановка <strong>$ x_i = 0 $</strong> всегда будет давать нулевой результат независимо от весов, поэтому все линии будут вынуждены пересекать начало координат.   </p>
<p><strong>Интерпретация линейных классификаторов как сопоставление шаблонов</strong>. Другая интерпретация весовых коэффициентов <strong>W</strong> заключается в том, что каждая строка <strong>W</strong> соответствует <em>шаблону</em> (или, как его иногда называют, <em>прототипу</em>) для одного из классов. Оценка каждого класса для изображения затем получается путём сравнения каждого шаблона с изображением с помощью <em>скалярного произведения</em> (или <em>точечного произведения</em>) по очереди, чтобы найти наиболее подходящий. В этой терминологии линейный классификатор выполняет сопоставление шаблонов, которые он изучает. Другой способ взглянуть на это — представить, что мы по-прежнему используем метод ближайшего соседа, но вместо тысяч обучающих изображений мы используем только одно изображение для каждого класса (хотя мы его изучим, и оно не обязательно должно быть одним из изображений в обучающем наборе), и в качестве расстояния мы используем (отрицательное) скалярное произведение вместо расстояния L1 или L2. </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/templates.jpg"><br>
Немного забегая вперёд: пример изученных весовых коэффициентов в конце обучения для CIFAR-10. Обратите внимание, что, например, шаблон корабля содержит много синих пикселей, как и ожидалось. Таким образом, этот шаблон будет давать высокий балл при сопоставлении с изображениями кораблей в океане с помощью скалярного произведения. </p>
<hr>
<p>Кроме того, обратите внимание, что шаблон лошади, по-видимому, содержит двухголовую лошадь, что связано с тем, что в наборе данных есть лошади, смотрящие как влево, так и вправо. Линейный классификатор <em>объединяет</em> эти два вида лошадей в данных в один шаблон. Аналогичным образом, классификатор автомобилей, по-видимому, объединил несколько видов в один шаблон, который должен распознавать автомобили со всех сторон и всех цветов. В частности, этот шаблон оказался красным, что указывает на то, что в наборе данных CIFAR-10 больше красных автомобилей, чем автомобилей любого другого цвета. Линейный классификатор слишком слаб, чтобы правильно распознавать автомобили разных цветов, но, как мы увидим позже, нейронные сети позволят нам выполнить эту задачу. Забегая немного вперёд, скажу, что нейронная сеть сможет создавать промежуточные нейроны в своих скрытых слоях, которые смогут распознавать определённые типы автомобилей (например, зелёный автомобиль, поворачивающий налево, синий автомобиль, поворачивающий вперёд, и т. д.), а нейроны на следующем слое смогут объединять их в более точную оценку автомобиля с помощью взвешенной суммы отдельных детекторов автомобилей.   </p>
<p><strong>Уловка с предвзятостью</strong>. Прежде чем двигаться дальше, мы хотим упомянуть распространённую упрощающую уловку для представления двух параметров <strong>W</strong>,<strong>b</strong> как один. Напомним, что мы определили функцию оценки как:   </p>
<p>$$
f(x_i, W, b) = W x_i + b
$$</p>
<p>По мере изучения материала становится немного сложнее отслеживать два набора параметров (смещения <strong>b</strong> и веса <strong>W</strong>) по отдельности. Часто используемый приём заключается в объединении двух наборов параметров в одну матрицу, которая содержит их оба, путём расширения вектора $ x_i $ с одним дополнительным измерением, которое всегда сохраняет константу 1 - <em>измерение смещения</em> по умолчанию. С дополнительным измерением новая функция оценки упростится до простого умножения матриц: 
$$
f(x_i, W) = W x_i
$$
С нашим примером CIFAR-10, $ x_i $ теперь [3073 x 1] вместо [3072 x 1] — (с дополнительным измерением, содержащим константу 1), и <strong>W</strong> теперь имеет значение [10 x 3073] вместо [10 x 3072]. Дополнительный столбец, который <strong>W</strong> теперь соответствует смещению <strong>b</strong>. Иллюстрация могла бы помочь прояснить ситуацию: </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/wb.jpeg"><br>
Иллюстрация трюка с предвзятостью. Выполнение матричного умножения с последующим добавлением вектора смещения (слева) эквивалентно добавлению размера смещения с константой 1 ко всем входным векторам и расширению весовой матрицы на 1 столбец - столбец смещения (справа). Таким образом, если мы предварительно обработаем наши данные, добавив единицы ко всем векторам, нам нужно будет выучить только одну матрицу весов вместо двух матриц, которые содержат веса и отклонения. </p>
<hr>
<p><strong>Предварительная обработка данных изображения</strong>. В качестве примечания: в приведённых выше примерах мы использовали необработанные значения пикселей (которые находятся в диапазоне [0…255]). В машинном обучении очень распространена практика нормализации входных признаков (в случае изображений каждый пиксель считается признаком). В частности, важно <strong>центрировать данные</strong>, вычитая среднее значение из каждого признака. В случае с изображениями это соответствует вычислению <em>среднего значения изображения</em> по обучающим изображениям и вычитанию его из каждого изображения, чтобы получить изображения, в которых пиксели находятся в диапазоне примерно от [-127 до 127]. Далее обычно выполняется предварительная обработка, при которой каждый входной признак масштабируется так, чтобы его значения находились в диапазоне от [-1 до 1]. Из них, пожалуй, более важным является центрирование относительно нуля, но нам придётся подождать с его обоснованием, пока мы не поймём динамику градиентного спуска.   </p>
<h3>Функция потерь</h3>
<p>В предыдущем разделе мы определили функцию преобразования значений пикселей в оценки классов, которая параметризуется набором весовых коэффициентов <strong>W</strong>. Более того, мы увидели, что у нас нет контроля над данными $(x_i, y_i)$ (это фиксировано и задано), но мы можем управлять этими весами и хотим установить их так, чтобы прогнозируемые оценки классов соответствовали исходным меткам в обучающих данных. 
Например, если вернуться к примеру с изображением кошки и её оценками для классов «кошка», «собака» и «корабль», то мы увидим, что конкретный набор весов в этом примере был не очень хорошим: мы ввели пиксели, изображающие кошку, но оценка кошки получилась очень низкой (-96,8) по сравнению с другими классами (оценка собаки 437,9, а оценка корабля 61,95). Мы будем измерять степень нашего недовольства такими результатами, как этот, с помощью <strong>функции потерь</strong> (иногда также называемой <strong>функцией затрат</strong> или <strong>целевой функцией</strong>). Интуитивно понятно, что потери будут высокими, если мы плохо справляемся с классификацией обучающих данных, и низкими, если мы хорошо справляемся.  </p>
<h4>Потеря машины мультиклассового опорного вектора</h4>
<p>Существует несколько способов определения параметров функции потерь. В качестве первого примера мы рассмотрим часто используемую функцию потерь, называемую <strong>многоклассовой функцией потерь машины опорных векторов</strong> (SVM). Функция потерь SVM настроена таким образом, что SVM «хочет», чтобы правильный класс для каждого изображения имел оценку выше, чем у неправильных классов, на некоторую фиксированную величину <strong>Δ</strong>. Обратите внимание, что иногда полезно очеловечить функции потерь, как мы сделали выше: SVM «хочет» определённого результата в том смысле, что этот результат приведёт к меньшим потерям (что хорошо).   </p>
<p>Теперь давайте уточним. Напомним, что для i-го примера нам даны пиксели изображения $ x_i $ и этикетка $ y_i $ которая определяет индекс правильного класса. Функция оценки принимает пиксели и вычисляет вектор $ f(x_i, W) $ оценок за класс, которые мы будем сокращать до <strong>s</strong> (сокращение от «баллы»). Например, балл за j-й класс — это j-й элемент: $ s_j = f(x_i, W)_j $. Потери многоклассового SVM для i-го примера формализуются следующим образом:   </p>
<p>$$
L_i = Σ_{j\neq y_i} max(0, s_j - s_{y_i} + \Delta)
$$ </p>
<p><strong>Пример</strong>. Давайте разберём это на примере, чтобы понять, как это работает. Предположим, что у нас есть три класса, которые получают оценки <strong>s=[13,−7,11]</strong>, и что первый класс является истинным классом (т.е. $ y_i = 0 $ ). Также предположим, что <strong>Δ</strong> (гиперпараметр, о котором мы вскоре поговорим подробнее) равен 10. Приведенное выше выражение суммирует все неправильные классы ($ j \neq y_i $), таким образом, мы получаем два термина:   </p>
<p>$$
L_i = max(0, -7 - 13 + 10) + \max(0, 11 - 13 + 10)
$$ </p>
<p>Вы видите, что первый член даёт ноль, так как [-7 - 13 + 10] даёт отрицательное число, которое затем округляется до ннля с помощью <strong>max(0,−)</strong>
функция. Мы получаем нулевые потери для этой пары, потому что оценка правильного класса (13) была больше, чем оценка неправильного класса (-7), как минимум на 10. На самом деле разница составляла 20, что намного больше 10, но SVM интересует только то, что разница составляет не менее 10; любая дополнительная разница, превышающая 10, ограничивается нулём с помощью операции <em>max</em>. Второй член вычисляет [11 - 13 + 10], что даёт 8. То есть, даже если правильный класс имел более высокий балл, чем неправильный (13 &gt; 11), он не был выше желаемого значения в 10 баллов. Разница составила всего 2, поэтому проигрыш равен 8 (т. Е. Насколько выше должна быть разница, чтобы соответствовать марже). Таким образом, функция SVM loss запрашивает оценку правильного класса $ y_i = 0 $ быть больше, чем неправильные оценки класса, по крайней мере, на <strong>Δ</strong> (дельта). Если это не так, мы понесём убытки.   </p>
<p>Обратите внимание, что в этом конкретном модуле мы работаем с линейными функциями оценки ( $ f(x_i; W) = W x_i $ ), поэтому мы также можем переписать функцию потерь в этой эквивалентной форме:   </p>
<p>$$
L_i = Σ_{j\neq y_i} max(0, w_j^T x_i - w_{y_i}^T x_i + \Delta)
$$  </p>
<p>где $ w_j$ является j-й строкой <strong>W</strong> преобразован в столбец. Однако это не обязательно будет так, если мы начнём рассматривать более сложные формы функции оценки <strong>f</strong>.   </p>
<p>Последний термин, который мы упомянем, прежде чем закончить этот раздел, — это нулевой порог <strong>max(0,−)</strong>. Эта функция часто называется <strong>потерей от перегиба</strong>. Иногда можно услышать, что вместо этого люди используют SVM с квадратичной потерей от перегиба (или L2-SVM), которая имеет вид <strong>$max(0,−) ^ 2$</strong>
это сильнее6 сказывается на нарушении границ (квадратично, а не линейно). Неквадратичная версия является более стандартной, но в некоторых наборах данных квадратичная функция потерь может работать лучше. Это можно определить во время перекрестной проверки.   </p>
<blockquote>
<p>Функция потерь количественно определяет наше недовольство прогнозами на обучающем наборе</p>
</blockquote>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/margin.jpg"></p>
<p>Многоклассовая машина опорных векторов «хочет», чтобы оценка правильного класса была выше, чем у всех остальных классов, как минимум на величину дельты. Если оценка какого-либо класса находится в красной области (или выше), то будет накоплен убыток. В противном случае убыток будет равен нулю. Наша цель — найти веса, которые одновременно удовлетворят этому ограничению для всех примеров в обучающих данных и обеспечат минимально возможный общий убыток.  </p>
<hr>
<p><strong>Регуляризация</strong>. Есть одна ошибка с функцией потерь, которую мы представили выше. Предположим, что у нас есть набор данных и набор параметров <strong>W</strong>, которые правильно классифицируют каждый пример (т.е. все оценки таковы, что все поля соблюдены, и <strong>$L_i = 0)\</strong> для всех i). Проблема в том, что этот набор <strong>W</strong> не обязательно уникален: может быть много похожих <strong>W</strong>, которые правильно классифицируют примеры. Один из простых способов увидеть это заключается в том, что если некоторые параметры <strong>W</strong> правильно классифицируют все примеры (так что потери равны нулю для каждого примера), то любое кратное этим параметрам <strong>λW</strong>, где <strong>λ&gt;1</strong> также даст нулевой убыток, потому что это преобразование равномерно растягивает все величины счета и, следовательно, их абсолютные разности. Например, если разница в оценках между правильным классом и ближайшим неправильным классом равна 15, то умножение всех элементов <strong>W</strong> на 2 даст новую разницу 30.  </p>
<p>Другими словами, мы хотим закодировать некоторое предпочтение для определенного набора весов <strong>W</strong> по сравнению с другими, чтобы устранить эту двусмысленность. Мы можем сделать это, расширив функцию потерь штрафом за регуляризацию <strong>R(W)</strong>. Наиболее распространенным штрафом за регуляризацию является квадрат нормы <strong>L2</strong>, который препятствует использованию больших весов с помощью квадратичного штрафа по всем параметрам:  </p>
<p>$$
R(W) = \sum_k\sum_l W_{k,l}^2
$$  </p>
<p>В приведенном выше выражении мы суммируем все возведенные в квадрат элементы <strong>W</strong>
Обратите внимание, что функция регуляризации не зависит от данных, она зависит только от весовых коэффициентов. Включение штрафа за регуляризацию завершает формирование полной функции потерь многоклассовой машины опорных векторов, которая состоит из двух компонентов: <strong>потерь данных</strong> (которые представляют собой средние потери <strong>$Li$</strong> по всем примерам) и <strong>потери от регуляризации</strong>. То есть полная потеря многоклассового SVM становится:  </p>
<p>$$
L =  \underbrace{ \frac{1}{N} \sum_i L_i }<em>\text{потеря данных} + \underbrace{ \lambda R(W) }</em>\text{потеря регуляризации} \\
$$  </p>
<p>Или расширить это в его полной форме:  </p>
<p>$$
L = \frac{1}{N} \sum_i \sum_{j\neq y_i} \left[ \max(0, f(x_i; W)<em y_i>j - f(x_i; W)</em>^2
$$  } + \Delta) \right] + \lambda \sum_k\sum_l W_{k,l</p>
<p>Где <strong>N</strong>— это количество обучающих примеров. Как видите, мы добавляем штраф за регуляризацию к функции потерь, взвешенной с помощью гиперпараметра <strong>λ</strong>.
Не существует простого способа задать этот гиперпараметр, и обычно он определяется методом перекрёстной проверки.   </p>
<p>Помимо мотивации, которую мы привели выше, существует множество желательных свойств, связанных с включением штрафа за регуляризацию, к которым мы вернёмся в следующих разделах. Например, оказывается, что включение штрафа L2 приводит к привлекательному свойству <strong>максимального запаса прочности</strong> в SVM (если вам интересно, см. <a href="http://cs229.stanford.edu/notes/cs229-notes3.pdf">CS229</a> для получения полной информации).  </p>
<p>Наиболее привлекательным свойством является то, что штрафные санкции за большие веса, как правило, улучшают обобщение, поскольку это означает, что ни один входной параметр сам по себе не может оказывать очень сильное влияние на оценки. Например, предположим, что у нас есть некоторый входной вектор <strong>$x=[1,1,1,1] ))</strong> и два весовых вектора__$w1=[1,0,0,0] $<strong>, </strong>$w2=[0,25,0,25,0,25,0,25]  $__. Затем $w_1^Tx = w_2^Tx = 1$. Таким образом, оба вектора весов приводят к одному и тому же скалярному произведению, но штраф L2 $w_1$ равно 1.0, в то время как штраф L2 равен $w_2$ составляет всего 0,5. Следовательно, согласно штрафу L2, вектор весов $w_2$ это предпочтительнее, так как достигается меньшая потеря при регуляризации. Интуитивно понятно, что это происходит потому, что веса в $w_2$ являются более компактными и менее размытыми. Поскольку штраф L2 предпочитает более компактные и менее размытые векторы весов, итоговому классификатору рекомендуется учитывать все входные параметры в небольших количествах, а не несколько входных параметров в очень больших количествах. Как мы увидим далее в этом курсе, этот эффект может улучшить обобщающую способность классификаторов на тестовых изображениях и привести к меньшему <em>переобучению</em>.  </p>
<p>Обратите внимание, что смещения не оказывают такого же эффекта, поскольку, в отличие от весовых коэффициентов, они не контролируют силу влияния входного параметра. Поэтому обычно нормализуют только весовые коэффициенты <strong>W</strong> но не из - за предубеждений <strong>b</strong>. Однако на практике это часто оказывается несущественным. Наконец, обратите внимание, что из-за штрафа за регуляризацию мы никогда не сможем добиться потери точности, равной 0,0, во всех примерах, потому что это возможно только в патологических условиях <strong>W=0</strong>.  </p>
<p><strong>Код</strong>. Вот функция потерь (без регуляризации), реализованная на Python как в не векторизованной, так и в полувекторной форме:  </p>
<div class="code"><pre class="code literal-block"><span class="n">def</span><span class="w"> </span><span class="n">L_i</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">W</span><span class="p">)</span><span class="err">:</span>
<span class="w">  </span><span class="ss">"""</span>
<span class="ss">  unvectorized version. Compute the multiclass svm loss for a single example (x,y)</span>
<span class="ss">  - x is a column vector representing an image (e.g. 3073 x 1 in CIFAR-10)</span>
<span class="ss">    with an appended bias dimension in the 3073-rd position (i.e. bias trick)</span>
<span class="ss">  - y is an integer giving index of correct class (e.g. between 0 and 9 in CIFAR-10)</span>
<span class="ss">  - W is the weight matrix (e.g. 10 x 3073 in CIFAR-10)</span>
<span class="ss">  """</span>
<span class="w">  </span><span class="n">delta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span><span class="w"> </span><span class="err">#</span><span class="w"> </span><span class="n">see</span><span class="w"> </span><span class="n">notes</span><span class="w"> </span><span class="n">about</span><span class="w"> </span><span class="n">delta</span><span class="w"> </span><span class="n">later</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="k">section</span>
<span class="w">  </span><span class="n">scores</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">W</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="err">#</span><span class="w"> </span><span class="n">scores</span><span class="w"> </span><span class="n">becomes</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="k">size</span><span class="w"> </span><span class="mi">10</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">scores</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="k">each</span><span class="w"> </span><span class="k">class</span>
<span class="w">  </span><span class="n">correct_class_score</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">scores</span><span class="o">[</span><span class="n">y</span><span class="o">]</span>
<span class="w">  </span><span class="n">D</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">W</span><span class="p">.</span><span class="n">shape</span><span class="o">[</span><span class="n">0</span><span class="o">]</span><span class="w"> </span><span class="err">#</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">classes</span><span class="p">,</span><span class="w"> </span><span class="n">e</span><span class="p">.</span><span class="n">g</span><span class="p">.</span><span class="w"> </span><span class="mi">10</span>
<span class="w">  </span><span class="n">loss_i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.0</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="k">range</span><span class="p">(</span><span class="n">D</span><span class="p">)</span><span class="err">:</span><span class="w"> </span><span class="err">#</span><span class="w"> </span><span class="k">iterate</span><span class="w"> </span><span class="k">over</span><span class="w"> </span><span class="ow">all</span><span class="w"> </span><span class="n">wrong</span><span class="w"> </span><span class="n">classes</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="nl">y</span><span class="p">:</span>
<span class="w">      </span><span class="err">#</span><span class="w"> </span><span class="n">skip</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">true</span><span class="w"> </span><span class="k">class</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="k">only</span><span class="w"> </span><span class="n">loop</span><span class="w"> </span><span class="k">over</span><span class="w"> </span><span class="n">incorrect</span><span class="w"> </span><span class="n">classes</span>
<span class="w">      </span><span class="k">continue</span>
<span class="w">    </span><span class="err">#</span><span class="w"> </span><span class="n">accumulate</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">i</span><span class="o">-</span><span class="n">th</span><span class="w"> </span><span class="n">example</span>
<span class="w">    </span><span class="n">loss_i</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nf">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">scores</span><span class="o">[</span><span class="n">j</span><span class="o">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">correct_class_score</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">delta</span><span class="p">)</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">loss_i</span>

<span class="n">def</span><span class="w"> </span><span class="n">L_i_vectorized</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">W</span><span class="p">)</span><span class="err">:</span>
<span class="w">  </span><span class="ss">"""</span>
<span class="ss">  A faster half-vectorized implementation. half-vectorized</span>
<span class="ss">  refers to the fact that for a single example the implementation contains</span>
<span class="ss">  no for loops, but there is still one loop over the examples (outside this function)</span>
<span class="ss">  """</span>
<span class="w">  </span><span class="n">delta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">1.0</span>
<span class="w">  </span><span class="n">scores</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">W</span><span class="p">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="w">  </span><span class="err">#</span><span class="w"> </span><span class="k">compute</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">margins</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="ow">all</span><span class="w"> </span><span class="n">classes</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">one</span><span class="w"> </span><span class="n">vector</span><span class="w"> </span><span class="k">operation</span>
<span class="w">  </span><span class="n">margins</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">np</span><span class="p">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">scores</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">scores</span><span class="o">[</span><span class="n">y</span><span class="o">]</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">delta</span><span class="p">)</span>
<span class="w">  </span><span class="err">#</span><span class="w"> </span><span class="k">on</span><span class="w"> </span><span class="n">y</span><span class="o">-</span><span class="n">th</span><span class="w"> </span><span class="k">position</span><span class="w"> </span><span class="n">scores</span><span class="o">[</span><span class="n">y</span><span class="o">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">scores</span><span class="o">[</span><span class="n">y</span><span class="o">]</span><span class="w"> </span><span class="n">canceled</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">gave</span><span class="w"> </span><span class="n">delta</span><span class="p">.</span><span class="w"> </span><span class="n">We</span><span class="w"> </span><span class="n">want</span>
<span class="w">  </span><span class="err">#</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="k">ignore</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">y</span><span class="o">-</span><span class="n">th</span><span class="w"> </span><span class="k">position</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="k">only</span><span class="w"> </span><span class="n">consider</span><span class="w"> </span><span class="n">margin</span><span class="w"> </span><span class="k">on</span><span class="w"> </span><span class="nf">max</span><span class="w"> </span><span class="n">wrong</span><span class="w"> </span><span class="k">class</span>
<span class="w">  </span><span class="n">margins</span><span class="o">[</span><span class="n">y</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>
<span class="w">  </span><span class="n">loss_i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">margins</span><span class="p">)</span>
<span class="w">  </span><span class="k">return</span><span class="w"> </span><span class="n">loss_i</span>

<span class="n">def</span><span class="w"> </span><span class="n">L</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">W</span><span class="p">)</span><span class="err">:</span>
<span class="w">  </span><span class="ss">"""</span>
<span class="ss">  fully-vectorized implementation :</span>
<span class="ss">  - X holds all the training examples as columns (e.g. 3073 x 50,000 in CIFAR-10)</span>
<span class="ss">  - y is array of integers specifying correct class (e.g. 50,000-D array)</span>
<span class="ss">  - W are weights (e.g. 10 x 3073)</span>
<span class="ss">  """</span>
<span class="w">  </span><span class="err">#</span><span class="w"> </span><span class="n">evaluate</span><span class="w"> </span><span class="n">loss</span><span class="w"> </span><span class="k">over</span><span class="w"> </span><span class="ow">all</span><span class="w"> </span><span class="n">examples</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">X</span><span class="w"> </span><span class="k">without</span><span class="w"> </span><span class="k">using</span><span class="w"> </span><span class="ow">any</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">loops</span>
<span class="w">  </span><span class="err">#</span><span class="w"> </span><span class="nf">left</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">exercise</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">reader</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">assignment</span>
<span class="w">  </span><span class="err">```</span>

<span class="n">Из</span><span class="w"> </span><span class="n">этого</span><span class="w"> </span><span class="n">раздела</span><span class="w"> </span><span class="n">можно</span><span class="w"> </span><span class="n">сделать</span><span class="w"> </span><span class="n">вывод</span><span class="p">,</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">функция</span><span class="w"> </span><span class="n">потерь</span><span class="w"> </span><span class="n">SVM</span><span class="w"> </span><span class="n">использует</span><span class="w"> </span><span class="n">особый</span><span class="w"> </span><span class="n">подход</span><span class="w"> </span><span class="n">к</span><span class="w"> </span><span class="n">измерению</span><span class="w"> </span><span class="n">того</span><span class="p">,</span><span class="w"> </span><span class="n">насколько</span><span class="w"> </span><span class="n">прогнозы</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">основе</span><span class="w"> </span><span class="n">обучающих</span><span class="w"> </span><span class="n">данных</span><span class="w"> </span><span class="n">соответствуют</span><span class="w"> </span><span class="n">истинным</span><span class="w"> </span><span class="n">значениям</span><span class="p">.</span><span class="w"> </span><span class="n">Кроме</span><span class="w"> </span><span class="n">того</span><span class="p">,</span><span class="w"> </span><span class="n">делать</span><span class="w"> </span><span class="n">хорошие</span><span class="w"> </span><span class="n">прогнозы</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">основе</span><span class="w"> </span><span class="n">обучающего</span><span class="w"> </span><span class="n">набора</span><span class="w"> </span><span class="n">данных</span><span class="w"> </span><span class="n">равносильно</span><span class="w"> </span><span class="n">минимизации</span><span class="w"> </span><span class="n">функции</span><span class="w"> </span><span class="n">потерь</span><span class="p">.</span><span class="w">  </span>

<span class="o">&gt;</span><span class="n">Теперь</span><span class="w"> </span><span class="n">нам</span><span class="w"> </span><span class="n">нужно</span><span class="w"> </span><span class="n">придумать</span><span class="w"> </span><span class="n">способ</span><span class="w"> </span><span class="n">найти</span><span class="w"> </span><span class="n">веса</span><span class="p">,</span><span class="w"> </span><span class="n">которые</span><span class="w"> </span><span class="n">минимизируют</span><span class="w"> </span><span class="n">потери</span><span class="p">.</span><span class="w">  </span>

<span class="err">##</span><span class="w"> </span><span class="n">Практические</span><span class="w"> </span><span class="n">соображения</span><span class="w">  </span>

<span class="n">__Устанавливаем</span><span class="w"> </span><span class="n">дельту__</span><span class="p">.</span><span class="w"> </span><span class="n">Обратите</span><span class="w"> </span><span class="n">внимание</span><span class="p">,</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">затронули</span><span class="w"> </span><span class="n">гиперпараметр</span><span class="w"> </span><span class="n">__Δ__</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">его</span><span class="w"> </span><span class="n">настройка</span><span class="p">.</span><span class="w"> </span><span class="n">Какое</span><span class="w"> </span><span class="n">значение</span><span class="w"> </span><span class="n">следует</span><span class="w"> </span><span class="n">установить</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">нужно</span><span class="w"> </span><span class="n">ли</span><span class="w"> </span><span class="n">проводить</span><span class="w"> </span><span class="n">перекрестную</span><span class="w"> </span><span class="n">проверку</span><span class="vm">?</span><span class="w"> </span><span class="n">Оказывается</span><span class="p">,</span><span class="w"> </span><span class="n">этот</span><span class="w"> </span><span class="n">гиперпараметр</span><span class="w"> </span><span class="n">можно</span><span class="w"> </span><span class="n">смело</span><span class="w"> </span><span class="n">устанавливать</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">__Δ</span><span class="o">=</span><span class="mf">1.0</span><span class="n">_</span><span class="w"> </span><span class="n">во</span><span class="w"> </span><span class="n">всех</span><span class="w"> </span><span class="n">случаях</span><span class="p">.</span><span class="w"> </span><span class="n">Гиперпараметры</span><span class="w"> </span><span class="n">__Δ__</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="nl">__λ__</span><span class="p">:</span><span class="w"> </span><span class="n">кажется</span><span class="p">,</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">это</span><span class="w"> </span><span class="n">два</span><span class="w"> </span><span class="n">разных</span><span class="w"> </span><span class="n">гиперпараметра</span><span class="p">,</span><span class="w"> </span><span class="n">но</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">самом</span><span class="w"> </span><span class="n">деле</span><span class="w"> </span><span class="n">они</span><span class="w"> </span><span class="n">оба</span><span class="w"> </span><span class="n">управляют</span><span class="w"> </span><span class="n">одним</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">тем</span><span class="w"> </span><span class="n">же</span><span class="w"> </span><span class="nl">компромиссом</span><span class="p">:</span><span class="w"> </span><span class="n">компромиссом</span><span class="w"> </span><span class="n">между</span><span class="w"> </span><span class="n">потерей</span><span class="w"> </span><span class="n">данных</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">потерей</span><span class="w"> </span><span class="n">от</span><span class="w"> </span><span class="n">регуляризации</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">целевой</span><span class="w"> </span><span class="n">функции</span><span class="p">.</span><span class="w"> </span><span class="n">Ключ</span><span class="w"> </span><span class="n">к</span><span class="w"> </span><span class="n">пониманию</span><span class="w"> </span><span class="n">этого</span><span class="w"> </span><span class="n">заключается</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">том</span><span class="p">,</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">величина</span><span class="w"> </span><span class="n">весовых</span><span class="w"> </span><span class="n">коэффициентов</span><span class="w"> </span><span class="n">__W__</span><span class="w"> </span><span class="n">оказывает</span><span class="w"> </span><span class="n">непосредственное</span><span class="w"> </span><span class="n">влияние</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">баллы</span><span class="w"> </span><span class="p">(</span><span class="n">и</span><span class="p">,</span><span class="w"> </span><span class="n">следовательно</span><span class="p">,</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">их</span><span class="w"> </span><span class="n">разницу</span><span class="p">)</span><span class="err">:</span><span class="w"> </span><span class="n">по</span><span class="w"> </span><span class="n">мере</span><span class="w"> </span><span class="n">уменьшения</span><span class="w"> </span><span class="n">всех</span><span class="w"> </span><span class="n">значений</span><span class="w"> </span><span class="n">внутри</span><span class="w"> </span><span class="n">__W__</span><span class="w"> </span><span class="n">разница</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">баллах</span><span class="w"> </span><span class="n">будет</span><span class="w"> </span><span class="n">уменьшаться</span><span class="p">,</span><span class="w"> </span><span class="n">а</span><span class="w"> </span><span class="n">по</span><span class="w"> </span><span class="n">мере</span><span class="w"> </span><span class="n">увеличения</span><span class="w"> </span><span class="n">весов</span><span class="w"> </span><span class="n">разница</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">баллах</span><span class="w"> </span><span class="n">будет</span><span class="w"> </span><span class="n">увеличиваться</span><span class="p">.</span><span class="w"> </span><span class="n">Таким</span><span class="w"> </span><span class="n">образом</span><span class="p">,</span><span class="w"> </span><span class="n">точное</span><span class="w"> </span><span class="n">значение</span><span class="w"> </span><span class="n">разницы</span><span class="w"> </span><span class="n">между</span><span class="w"> </span><span class="n">баллами</span><span class="w"> </span><span class="p">(</span><span class="n">например</span><span class="p">,</span><span class="w"> </span><span class="n">__Δ</span><span class="o">=</span><span class="mi">1</span><span class="n">__</span><span class="w"> </span><span class="p">,</span><span class="w"> </span><span class="n">или</span><span class="w"> </span><span class="n">__Δ</span><span class="o">=</span><span class="mi">100</span><span class="n">__</span><span class="p">)</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">некотором</span><span class="w"> </span><span class="n">смысле</span><span class="w"> </span><span class="n">бессмысленно</span><span class="p">,</span><span class="w"> </span><span class="n">потому</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">веса</span><span class="w"> </span><span class="n">могут</span><span class="w"> </span><span class="n">произвольно</span><span class="w"> </span><span class="n">уменьшать</span><span class="w"> </span><span class="n">или</span><span class="w"> </span><span class="n">увеличивать</span><span class="w"> </span><span class="n">разницу</span><span class="p">.</span><span class="w"> </span><span class="n">Следовательно</span><span class="p">,</span><span class="w"> </span><span class="n">единственный</span><span class="w"> </span><span class="n">реальный</span><span class="w"> </span><span class="n">компромисс</span><span class="w"> </span><span class="n">заключается</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">том</span><span class="p">,</span><span class="w"> </span><span class="n">насколько</span><span class="w"> </span><span class="n">сильно</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">позволяем</span><span class="w"> </span><span class="n">весам</span><span class="w"> </span><span class="n">увеличиваться</span><span class="w"> </span><span class="p">(</span><span class="n">с</span><span class="w"> </span><span class="n">помощью</span><span class="w"> </span><span class="n">силы</span><span class="w"> </span><span class="n">регуляризации</span><span class="w"> </span><span class="n">__λ__</span><span class="p">).</span><span class="w">  </span>

<span class="n">__Связь</span><span class="w"> </span><span class="n">с</span><span class="w"> </span><span class="n">бинарной</span><span class="w"> </span><span class="n">машиной</span><span class="w"> </span><span class="n">опорных</span><span class="w"> </span><span class="n">векторов__</span><span class="p">.</span><span class="w"> </span><span class="n">Возможно</span><span class="p">,</span><span class="w"> </span><span class="n">вы</span><span class="w"> </span><span class="n">пришли</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">этот</span><span class="w"> </span><span class="n">курс</span><span class="p">,</span><span class="w"> </span><span class="n">уже</span><span class="w"> </span><span class="n">имея</span><span class="w"> </span><span class="n">опыт</span><span class="w"> </span><span class="n">работы</span><span class="w"> </span><span class="n">с</span><span class="w"> </span><span class="n">бинарными</span><span class="w"> </span><span class="n">машинами</span><span class="w"> </span><span class="n">опорных</span><span class="w"> </span><span class="n">векторов</span><span class="p">,</span><span class="w"> </span><span class="n">где</span><span class="w"> </span><span class="n">потери</span><span class="w"> </span><span class="n">для</span><span class="w"> </span><span class="n">i</span><span class="o">-</span><span class="n">го</span><span class="w"> </span><span class="n">примера</span><span class="w"> </span><span class="n">можно</span><span class="w"> </span><span class="n">записать</span><span class="w"> </span><span class="nl">как</span><span class="p">:</span><span class="w">  </span>

<span class="err">$$</span>
<span class="n">L_i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">C</span><span class="w"> </span><span class="err">\</span><span class="nf">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">y_i</span><span class="w"> </span><span class="n">w</span><span class="o">^</span><span class="n">Tx_i</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">R</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
<span class="err">$$</span><span class="w">  </span>

<span class="n">где</span><span class="w"> </span><span class="n">__C__</span><span class="w"> </span><span class="n">является</span><span class="w"> </span><span class="n">гиперпараметром</span><span class="p">,</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="err">$</span><span class="n">y_i</span><span class="w"> </span><span class="err">\</span><span class="ow">in</span><span class="w"> </span><span class="err">\\{</span><span class="w"> </span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="w"> </span><span class="err">\\}</span><span class="w"> </span><span class="err">$</span><span class="p">.</span><span class="w"> </span><span class="n">Вы</span><span class="w"> </span><span class="n">можете</span><span class="w"> </span><span class="n">убедиться</span><span class="p">,</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">представленная</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">этом</span><span class="w"> </span><span class="n">разделе</span><span class="w"> </span><span class="n">формулировка</span><span class="w"> </span><span class="n">содержит</span><span class="w"> </span><span class="n">бинарный</span><span class="w"> </span><span class="n">SVM</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">качестве</span><span class="w"> </span><span class="n">частного</span><span class="w"> </span><span class="n">случая</span><span class="p">,</span><span class="w"> </span><span class="n">когда</span><span class="w"> </span><span class="n">есть</span><span class="w"> </span><span class="n">только</span><span class="w"> </span><span class="n">два</span><span class="w"> </span><span class="n">класса</span><span class="p">.</span><span class="w"> </span><span class="n">То</span><span class="w"> </span><span class="n">есть</span><span class="p">,</span><span class="w"> </span><span class="n">если</span><span class="w"> </span><span class="n">бы</span><span class="w"> </span><span class="n">у</span><span class="w"> </span><span class="n">нас</span><span class="w"> </span><span class="n">было</span><span class="w"> </span><span class="n">только</span><span class="w"> </span><span class="n">два</span><span class="w"> </span><span class="n">класса</span><span class="p">,</span><span class="w"> </span><span class="n">то</span><span class="w"> </span><span class="n">потери</span><span class="w"> </span><span class="n">сводились</span><span class="w"> </span><span class="n">бы</span><span class="w"> </span><span class="n">к</span><span class="w"> </span><span class="n">бинарному</span><span class="w"> </span><span class="n">SVM</span><span class="p">,</span><span class="w"> </span><span class="n">показанному</span><span class="w"> </span><span class="n">выше</span><span class="p">.</span><span class="w"> </span><span class="n">Кроме</span><span class="w"> </span><span class="n">того</span><span class="p">,</span><span class="w"> </span><span class="n">__C__</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">этой</span><span class="w"> </span><span class="n">формулировке</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">__λ__</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">нашей</span><span class="w"> </span><span class="n">формулировке</span><span class="w"> </span><span class="n">контролируется</span><span class="w"> </span><span class="n">один</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">тот</span><span class="w"> </span><span class="n">же</span><span class="w"> </span><span class="n">компромисс</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">они</span><span class="w"> </span><span class="n">связаны</span><span class="w"> </span><span class="n">через</span><span class="w"> </span><span class="n">взаимное</span><span class="w"> </span><span class="n">отношение</span><span class="w"> </span><span class="err">$</span><span class="n">C</span><span class="w"> </span><span class="err">\</span><span class="n">propto</span><span class="w"> </span><span class="err">\</span><span class="n">frac</span><span class="err">{</span><span class="mi">1</span><span class="err">}{\</span><span class="n">lambda</span><span class="err">}$</span><span class="p">.</span><span class="w">  </span>

<span class="nl">__Примечание</span><span class="p">:</span><span class="w"> </span><span class="n">оптимизация</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">прямой</span><span class="w"> </span><span class="n">форме__</span><span class="p">.</span><span class="w"> </span><span class="n">Если</span><span class="w"> </span><span class="n">вы</span><span class="w"> </span><span class="n">пришли</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">этот</span><span class="w"> </span><span class="n">курс</span><span class="p">,</span><span class="w"> </span><span class="n">уже</span><span class="w"> </span><span class="n">имея</span><span class="w"> </span><span class="n">представление</span><span class="w"> </span><span class="n">о</span><span class="w"> </span><span class="n">SVM</span><span class="p">,</span><span class="w"> </span><span class="n">то</span><span class="p">,</span><span class="w"> </span><span class="n">возможно</span><span class="p">,</span><span class="w"> </span><span class="n">слышали</span><span class="w"> </span><span class="n">о</span><span class="w"> </span><span class="n">ядрах</span><span class="p">,</span><span class="w"> </span><span class="n">двойственных</span><span class="w"> </span><span class="n">задачах</span><span class="p">,</span><span class="w"> </span><span class="n">алгоритме</span><span class="w"> </span><span class="n">SMO</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">т</span><span class="p">.</span><span class="w"> </span><span class="n">д</span><span class="p">.</span><span class="w"> </span><span class="n">В</span><span class="w"> </span><span class="n">этом</span><span class="w"> </span><span class="n">курсе</span><span class="w"> </span><span class="p">(</span><span class="n">как</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">случае</span><span class="w"> </span><span class="n">с</span><span class="w"> </span><span class="n">нейронными</span><span class="w"> </span><span class="n">сетями</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">целом</span><span class="p">)</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">всегда</span><span class="w"> </span><span class="n">будем</span><span class="w"> </span><span class="n">работать</span><span class="w"> </span><span class="n">с</span><span class="w"> </span><span class="n">задачами</span><span class="w"> </span><span class="n">оптимизации</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">их</span><span class="w"> </span><span class="n">прямой</span><span class="w"> </span><span class="n">форме</span><span class="w"> </span><span class="n">без</span><span class="w"> </span><span class="n">ограничений</span><span class="p">.</span><span class="w"> </span><span class="n">Многие</span><span class="w"> </span><span class="n">из</span><span class="w"> </span><span class="n">этих</span><span class="w"> </span><span class="n">задач</span><span class="w"> </span><span class="n">технически</span><span class="w"> </span><span class="n">не</span><span class="w"> </span><span class="n">являются</span><span class="w"> </span><span class="n">дифференцируемыми</span><span class="w"> </span><span class="p">(</span><span class="n">например</span><span class="p">,</span><span class="w"> </span><span class="n">функция</span><span class="w"> </span><span class="nf">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span><span class="w"> </span><span class="n">не</span><span class="w"> </span><span class="n">является</span><span class="w"> </span><span class="n">дифференцируемой</span><span class="p">,</span><span class="w"> </span><span class="n">потому</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">имеет</span><span class="w"> </span><span class="n">излом</span><span class="w"> </span><span class="n">при</span><span class="w"> </span><span class="n">x</span><span class="o">=</span><span class="n">y</span><span class="p">),</span><span class="w"> </span><span class="n">но</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">практике</span><span class="w"> </span><span class="n">это</span><span class="w"> </span><span class="n">не</span><span class="w"> </span><span class="n">является</span><span class="w"> </span><span class="n">проблемой</span><span class="p">,</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">обычно</span><span class="w"> </span><span class="n">используется</span><span class="w"> </span><span class="n">субградиент</span><span class="p">.</span><span class="w">  </span>

<span class="nl">Примечание</span><span class="p">:</span><span class="w"> </span><span class="n">другие</span><span class="w"> </span><span class="n">многоклассовые</span><span class="w"> </span><span class="n">формулировки</span><span class="w"> </span><span class="n">SVM</span><span class="p">.</span><span class="w"> </span><span class="n">Стоит</span><span class="w"> </span><span class="n">отметить</span><span class="p">,</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">многоклассовая</span><span class="w"> </span><span class="n">формулировка</span><span class="w"> </span><span class="n">SVM</span><span class="p">,</span><span class="w"> </span><span class="n">представленная</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">этом</span><span class="w"> </span><span class="n">разделе</span><span class="p">,</span><span class="w"> </span><span class="n">является</span><span class="w"> </span><span class="n">одним</span><span class="w"> </span><span class="n">из</span><span class="w"> </span><span class="n">немногих</span><span class="w"> </span><span class="n">способов</span><span class="w"> </span><span class="n">формулировки</span><span class="w"> </span><span class="n">SVM</span><span class="w"> </span><span class="n">для</span><span class="w"> </span><span class="n">нескольких</span><span class="w"> </span><span class="n">классов</span><span class="p">.</span><span class="w"> </span><span class="n">Другой</span><span class="w"> </span><span class="n">часто</span><span class="w"> </span><span class="n">используемой</span><span class="w"> </span><span class="n">формой</span><span class="w"> </span><span class="n">является</span><span class="w"> </span><span class="n">SVM</span><span class="w"> </span><span class="n">_</span><span class="err">«</span><span class="n">один</span><span class="w"> </span><span class="n">против</span><span class="w"> </span><span class="n">всех</span><span class="err">»</span><span class="n">_</span><span class="w"> </span><span class="p">(</span><span class="n">OVA</span><span class="p">),</span><span class="w"> </span><span class="n">которая</span><span class="w"> </span><span class="n">обучает</span><span class="w"> </span><span class="n">независимый</span><span class="w"> </span><span class="n">бинарный</span><span class="w"> </span><span class="n">SVM</span><span class="w"> </span><span class="n">для</span><span class="w"> </span><span class="n">каждого</span><span class="w"> </span><span class="n">класса</span><span class="w"> </span><span class="n">по</span><span class="w"> </span><span class="n">сравнению</span><span class="w"> </span><span class="n">со</span><span class="w"> </span><span class="n">всеми</span><span class="w"> </span><span class="n">остальными</span><span class="w"> </span><span class="n">классами</span><span class="p">.</span><span class="w"> </span><span class="n">С</span><span class="w"> </span><span class="n">ней</span><span class="w"> </span><span class="n">связана</span><span class="p">,</span><span class="w"> </span><span class="n">но</span><span class="w"> </span><span class="n">реже</span><span class="w"> </span><span class="n">встречается</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">практике</span><span class="w"> </span><span class="n">стратегия</span><span class="w"> </span><span class="n">_</span><span class="err">«</span><span class="n">все</span><span class="w"> </span><span class="n">против</span><span class="w"> </span><span class="n">всех</span><span class="err">»</span><span class="n">_</span><span class="w"> </span><span class="p">(</span><span class="n">AVA</span><span class="p">).</span><span class="w"> </span><span class="n">Наша</span><span class="w"> </span><span class="n">формулировка</span><span class="w"> </span><span class="n">основана</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">версии</span><span class="w"> </span><span class="o">[</span><span class="n">Weston and Watkins 1999</span><span class="o">]</span><span class="p">(</span><span class="nl">https</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="p">.</span><span class="n">elen</span><span class="p">.</span><span class="n">ucl</span><span class="p">.</span><span class="n">ac</span><span class="p">.</span><span class="n">be</span><span class="o">/</span><span class="n">Proceedings</span><span class="o">/</span><span class="n">esann</span><span class="o">/</span><span class="n">esannpdf</span><span class="o">/</span><span class="n">es1999</span><span class="o">-</span><span class="mf">461.</span><span class="n">pdf</span><span class="p">)</span><span class="w"> </span><span class="p">(</span><span class="n">pdf</span><span class="p">),</span><span class="w"> </span><span class="n">которая</span><span class="w"> </span><span class="n">является</span><span class="w"> </span><span class="n">более</span><span class="w"> </span><span class="n">мощной</span><span class="w"> </span><span class="n">версией</span><span class="p">,</span><span class="w"> </span><span class="n">чем</span><span class="w"> </span><span class="n">OVA</span><span class="w"> </span><span class="p">(</span><span class="n">в</span><span class="w"> </span><span class="n">том</span><span class="w"> </span><span class="n">смысле</span><span class="p">,</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">вы</span><span class="w"> </span><span class="n">можете</span><span class="w"> </span><span class="n">создавать</span><span class="w"> </span><span class="n">многоклассовые</span><span class="w"> </span><span class="n">наборы</span><span class="w"> </span><span class="n">данных</span><span class="p">,</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">которых</span><span class="w"> </span><span class="n">эта</span><span class="w"> </span><span class="n">версия</span><span class="w"> </span><span class="n">может</span><span class="w"> </span><span class="n">обеспечить</span><span class="w"> </span><span class="n">нулевую</span><span class="w"> </span><span class="n">потерю</span><span class="w"> </span><span class="n">данных</span><span class="p">,</span><span class="w"> </span><span class="n">а</span><span class="w"> </span><span class="n">OVA</span><span class="w"> </span><span class="err">—</span><span class="w"> </span><span class="n">нет</span><span class="p">.</span><span class="w"> </span><span class="n">Если</span><span class="w"> </span><span class="n">интересно</span><span class="p">,</span><span class="w"> </span><span class="n">подробности</span><span class="w"> </span><span class="n">можно</span><span class="w"> </span><span class="n">найти</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">статье</span><span class="p">).</span><span class="w"> </span><span class="n">Последняя</span><span class="w"> </span><span class="n">формулировка</span><span class="p">,</span><span class="w"> </span><span class="n">которую</span><span class="w"> </span><span class="n">вы</span><span class="w"> </span><span class="n">можете</span><span class="w"> </span><span class="n">увидеть</span><span class="p">,</span><span class="w"> </span><span class="err">—</span><span class="w"> </span><span class="n">это</span><span class="w"> </span><span class="n">_структурированный_</span><span class="w"> </span><span class="n">SVM</span><span class="p">,</span><span class="w"> </span><span class="n">который</span><span class="w"> </span><span class="n">максимизирует</span><span class="w"> </span><span class="n">разницу</span><span class="w"> </span><span class="n">между</span><span class="w"> </span><span class="n">оценкой</span><span class="w"> </span><span class="n">правильного</span><span class="w"> </span><span class="n">класса</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">оценкой</span><span class="w"> </span><span class="n">наиболее</span><span class="w"> </span><span class="n">близкого</span><span class="w"> </span><span class="n">к</span><span class="w"> </span><span class="n">нему</span><span class="w"> </span><span class="n">неправильного</span><span class="w"> </span><span class="n">класса</span><span class="p">.</span><span class="w"> </span><span class="n">Понимание</span><span class="w"> </span><span class="n">различий</span><span class="w"> </span><span class="n">между</span><span class="w"> </span><span class="n">этими</span><span class="w"> </span><span class="n">формулировками</span><span class="w"> </span><span class="n">выходит</span><span class="w"> </span><span class="n">за</span><span class="w"> </span><span class="n">рамки</span><span class="w"> </span><span class="n">данного</span><span class="w"> </span><span class="n">курса</span><span class="p">.</span><span class="w"> </span><span class="n">Версия</span><span class="p">,</span><span class="w"> </span><span class="n">представленная</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">этих</span><span class="w"> </span><span class="n">заметках</span><span class="p">,</span><span class="w"> </span><span class="n">безопасна</span><span class="w"> </span><span class="n">для</span><span class="w"> </span><span class="n">использования</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">практике</span><span class="p">,</span><span class="w"> </span><span class="n">но</span><span class="p">,</span><span class="w"> </span><span class="n">возможно</span><span class="p">,</span><span class="w"> </span><span class="n">самая</span><span class="w"> </span><span class="n">простая</span><span class="w"> </span><span class="n">стратегия</span><span class="w"> </span><span class="n">OVA</span><span class="w"> </span><span class="n">тоже</span><span class="w"> </span><span class="n">будет</span><span class="w"> </span><span class="n">работать</span><span class="w"> </span><span class="p">(</span><span class="n">как</span><span class="w"> </span><span class="n">утверждают</span><span class="w"> </span><span class="n">Рикин</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">др</span><span class="p">.</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="mi">2004</span><span class="w"> </span><span class="n">году</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="o">[</span><span class="n">«В защиту классификации «один против всех»</span><span class="o">]</span><span class="p">(</span><span class="nl">http</span><span class="p">:</span><span class="o">//</span><span class="n">www</span><span class="p">.</span><span class="n">jmlr</span><span class="p">.</span><span class="n">org</span><span class="o">/</span><span class="n">papers</span><span class="o">/</span><span class="n">volume5</span><span class="o">/</span><span class="n">rifkin04a</span><span class="o">/</span><span class="n">rifkin04a</span><span class="p">.</span><span class="n">pdf</span><span class="p">)</span><span class="w"> </span><span class="p">(</span><span class="n">pdf</span><span class="p">)).</span><span class="w">  </span>

<span class="err">##</span><span class="w"> </span><span class="n">Классификатор</span><span class="w"> </span><span class="n">Softmax</span><span class="w">  </span>

<span class="n">Оказывается</span><span class="p">,</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">SVM</span><span class="w"> </span><span class="err">—</span><span class="w"> </span><span class="n">один</span><span class="w"> </span><span class="n">из</span><span class="w"> </span><span class="n">двух</span><span class="w"> </span><span class="n">наиболее</span><span class="w"> </span><span class="n">распространённых</span><span class="w"> </span><span class="n">классификаторов</span><span class="p">.</span><span class="w"> </span><span class="n">Другой</span><span class="w"> </span><span class="n">популярный</span><span class="w"> </span><span class="n">вариант</span><span class="w"> </span><span class="err">—</span><span class="w"> </span><span class="n">__классификатор</span><span class="w"> </span><span class="n">Softmax__</span><span class="p">,</span><span class="w"> </span><span class="n">у</span><span class="w"> </span><span class="n">которого</span><span class="w"> </span><span class="n">другая</span><span class="w"> </span><span class="n">функция</span><span class="w"> </span><span class="n">потерь</span><span class="p">.</span><span class="w"> </span><span class="n">Если</span><span class="w"> </span><span class="n">вы</span><span class="w"> </span><span class="n">раньше</span><span class="w"> </span><span class="n">слышали</span><span class="w"> </span><span class="n">о</span><span class="w"> </span><span class="n">классификаторе</span><span class="w"> </span><span class="n">бинарной</span><span class="w"> </span><span class="n">логистической</span><span class="w"> </span><span class="n">регрессии</span><span class="p">,</span><span class="w"> </span><span class="n">то</span><span class="w"> </span><span class="n">классификатор</span><span class="w"> </span><span class="n">Softmax</span><span class="w"> </span><span class="err">—</span><span class="w"> </span><span class="n">это</span><span class="w"> </span><span class="n">его</span><span class="w"> </span><span class="n">обобщение</span><span class="w"> </span><span class="n">для</span><span class="w"> </span><span class="n">нескольких</span><span class="w"> </span><span class="n">классов</span><span class="p">.</span><span class="w"> </span><span class="n">В</span><span class="w"> </span><span class="n">отличие</span><span class="w"> </span><span class="n">от</span><span class="w"> </span><span class="n">SVM</span><span class="p">,</span><span class="w"> </span><span class="n">который</span><span class="w"> </span><span class="n">обрабатывает</span><span class="w"> </span><span class="n">выходные</span><span class="w"> </span><span class="n">данные</span><span class="w"> </span><span class="err">$</span><span class="n">f</span><span class="p">(</span><span class="n">x_i</span><span class="p">,</span><span class="n">W</span><span class="p">)</span><span class="err">$</span><span class="p">.</span><span class="w"> </span><span class="n">В</span><span class="w"> </span><span class="n">качестве</span><span class="w"> </span><span class="p">(</span><span class="n">некалиброванных</span><span class="w"> </span><span class="n">и</span><span class="p">,</span><span class="w"> </span><span class="n">возможно</span><span class="p">,</span><span class="w"> </span><span class="n">трудно</span><span class="w"> </span><span class="n">интерпретируемых</span><span class="p">)</span><span class="w"> </span><span class="n">оценок</span><span class="w"> </span><span class="n">для</span><span class="w"> </span><span class="n">каждого</span><span class="w"> </span><span class="n">класса</span><span class="w"> </span><span class="n">классификатор</span><span class="w"> </span><span class="n">Softmax</span><span class="w"> </span><span class="n">даёт</span><span class="w"> </span><span class="n">чуть</span><span class="w"> </span><span class="n">более</span><span class="w"> </span><span class="n">понятный</span><span class="w"> </span><span class="n">результат</span><span class="w"> </span><span class="p">(</span><span class="n">нормализованные</span><span class="w"> </span><span class="n">вероятности</span><span class="w"> </span><span class="n">классов</span><span class="p">),</span><span class="w"> </span><span class="n">а</span><span class="w"> </span><span class="n">также</span><span class="w"> </span><span class="n">имеет</span><span class="w"> </span><span class="n">вероятностную</span><span class="w"> </span><span class="n">интерпретацию</span><span class="p">,</span><span class="w"> </span><span class="n">которую</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">вскоре</span><span class="w"> </span><span class="n">опишем</span><span class="p">.</span><span class="w"> </span><span class="n">В</span><span class="w"> </span><span class="n">классификаторе</span><span class="w"> </span><span class="n">Softmax</span><span class="w"> </span><span class="n">функция</span><span class="p">,</span><span class="w"> </span><span class="n">отображающая</span><span class="w"> </span><span class="err">$</span><span class="n">f</span><span class="p">(</span><span class="n">x_i</span><span class="p">;</span><span class="w"> </span><span class="n">W</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="n">W</span><span class="w"> </span><span class="n">x_i</span><span class="err">$</span><span class="w"> </span><span class="n">остаётся</span><span class="w"> </span><span class="n">неизменным</span><span class="p">,</span><span class="w"> </span><span class="n">но</span><span class="w"> </span><span class="n">теперь</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">интерпретируем</span><span class="w"> </span><span class="n">эти</span><span class="w"> </span><span class="n">оценки</span><span class="w"> </span><span class="n">как</span><span class="w"> </span><span class="n">ненормированные</span><span class="w"> </span><span class="n">логарифмические</span><span class="w"> </span><span class="n">вероятности</span><span class="w"> </span><span class="n">для</span><span class="w"> </span><span class="n">каждого</span><span class="w"> </span><span class="n">класса</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">заменяем</span><span class="w">  </span><span class="n">_потерю</span><span class="w"> </span><span class="n">от</span><span class="w"> </span><span class="n">перегиба_</span><span class="w"> </span><span class="n">__потерю</span><span class="w"> </span><span class="n">от</span><span class="w"> </span><span class="n">перекрёстной</span><span class="w"> </span><span class="n">энтропии__</span><span class="p">,</span><span class="w"> </span><span class="n">которая</span><span class="w"> </span><span class="n">имеет</span><span class="w"> </span><span class="nl">вид</span><span class="p">:</span><span class="w">  </span>

<span class="err">$$</span>
<span class="n">L_i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="err">\</span><span class="nf">log</span><span class="err">\</span><span class="nf">left</span><span class="p">(</span><span class="err">\</span><span class="n">frac</span><span class="err">{</span><span class="n">e</span><span class="o">^</span><span class="err">{</span><span class="n">f_</span><span class="err">{</span><span class="n">y_i</span><span class="err">}}}{</span><span class="w"> </span><span class="err">\</span><span class="n">sum_j</span><span class="w"> </span><span class="n">e</span><span class="o">^</span><span class="err">{</span><span class="n">f_j</span><span class="err">}</span><span class="w"> </span><span class="err">}\</span><span class="nf">right</span><span class="p">)</span><span class="w"> </span><span class="err">\</span><span class="n">hspace</span><span class="err">{</span><span class="mf">0.5</span><span class="ow">in</span><span class="err">}</span><span class="w"> </span><span class="err">\</span><span class="nc">text</span><span class="err">{</span><span class="ow">or</span><span class="w"> </span><span class="n">equivalently</span><span class="err">}</span><span class="w"> </span><span class="err">\</span><span class="n">hspace</span><span class="err">{</span><span class="mf">0.5</span><span class="ow">in</span><span class="err">}</span><span class="w"> </span><span class="n">L_i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="n">f_</span><span class="err">{</span><span class="n">y_i</span><span class="err">}</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">\</span><span class="nf">log</span><span class="err">\</span><span class="n">sum_j</span><span class="w"> </span><span class="n">e</span><span class="o">^</span><span class="err">{</span><span class="n">f_j</span><span class="err">}</span>
<span class="err">$$</span><span class="w">  </span>

<span class="n">где</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">используем</span><span class="w"> </span><span class="n">обозначение</span><span class="w"> </span><span class="n">__</span><span class="err">$</span><span class="n">f_j</span><span class="err">$</span><span class="n">__</span><span class="w"> </span><span class="n">для</span><span class="w"> </span><span class="n">обозначения</span><span class="w"> </span><span class="n">j</span><span class="o">-</span><span class="n">го</span><span class="w"> </span><span class="n">элемента</span><span class="w"> </span><span class="n">вектора</span><span class="w"> </span><span class="n">оценок</span><span class="w"> </span><span class="n">класса</span><span class="w"> </span><span class="n">__f__</span><span class="p">.</span><span class="w"> </span><span class="n">Как</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">прежде</span><span class="p">,</span><span class="w"> </span><span class="n">полная</span><span class="w"> </span><span class="n">потеря</span><span class="w"> </span><span class="n">набора</span><span class="w"> </span><span class="n">данных</span><span class="w"> </span><span class="n">является</span><span class="w"> </span><span class="n">средним</span><span class="w"> </span><span class="n">значением</span><span class="w"> </span><span class="n">__</span><span class="err">$</span><span class="n">L_i</span><span class="err">$</span><span class="n">__</span>
<span class="w"> </span><span class="n">по</span><span class="w"> </span><span class="n">всем</span><span class="w"> </span><span class="n">обучающим</span><span class="w"> </span><span class="n">примерам</span><span class="w"> </span><span class="n">вместе</span><span class="w"> </span><span class="n">с</span><span class="w"> </span><span class="n">термином</span><span class="w"> </span><span class="n">регуляризации</span><span class="w"> </span><span class="n">__</span><span class="err">$</span><span class="n">R</span><span class="p">(</span><span class="n">W</span><span class="p">)</span><span class="err">$</span><span class="n">__</span><span class="p">.</span><span class="w"> </span><span class="n">Функция</span><span class="w"> </span><span class="n">__</span><span class="err">$</span><span class="n">f_j</span><span class="p">(</span><span class="n">z</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">\</span><span class="n">frac</span><span class="err">{</span><span class="n">e</span><span class="o">^</span><span class="err">{</span><span class="n">z_j</span><span class="err">}}{\</span><span class="n">sum_k</span><span class="w"> </span><span class="n">e</span><span class="o">^</span><span class="err">{</span><span class="n">z_k</span><span class="err">}}</span><span class="w"> </span><span class="err">$</span><span class="n">__</span><span class="w"> </span><span class="n">называется</span><span class="w"> </span><span class="n">__функцией</span><span class="w"> </span><span class="nl">softmax__</span><span class="p">:</span><span class="w"> </span><span class="n">она</span><span class="w"> </span><span class="n">принимает</span><span class="w"> </span><span class="n">вектор</span><span class="w"> </span><span class="n">произвольных</span><span class="w"> </span><span class="n">числовых</span><span class="w"> </span><span class="n">значений</span><span class="w">  </span><span class="p">(</span><span class="n">в</span><span class="w"> </span><span class="err">$</span><span class="n">z</span><span class="err">$</span><span class="p">)</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">преобразует</span><span class="w"> </span><span class="n">его</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">вектор</span><span class="w"> </span><span class="n">значений</span><span class="w"> </span><span class="n">от</span><span class="w"> </span><span class="n">нуля</span><span class="w"> </span><span class="n">до</span><span class="w"> </span><span class="n">единицы</span><span class="p">,</span><span class="w"> </span><span class="n">сумма</span><span class="w"> </span><span class="n">которых</span><span class="w"> </span><span class="n">равна</span><span class="w"> </span><span class="n">единице</span><span class="p">.</span><span class="w"> </span><span class="n">Полная</span><span class="w"> </span><span class="n">функция</span><span class="w"> </span><span class="n">потерь</span><span class="w"> </span><span class="n">перекрёстной</span><span class="w"> </span><span class="n">энтропии</span><span class="p">,</span><span class="w"> </span><span class="n">включающая</span><span class="w"> </span><span class="n">функцию</span><span class="w"> </span><span class="n">softmax</span><span class="p">,</span><span class="w"> </span><span class="n">может</span><span class="w"> </span><span class="n">показаться</span><span class="w"> </span><span class="n">пугающей</span><span class="p">,</span><span class="w"> </span><span class="n">если</span><span class="w"> </span><span class="n">вы</span><span class="w"> </span><span class="n">видите</span><span class="w"> </span><span class="n">её</span><span class="w"> </span><span class="n">впервые</span><span class="p">,</span><span class="w"> </span><span class="n">но</span><span class="w"> </span><span class="n">её</span><span class="w"> </span><span class="n">относительно</span><span class="w"> </span><span class="n">легко</span><span class="w"> </span><span class="n">объяснить</span><span class="p">.</span><span class="w">  </span>

<span class="w"> </span><span class="n">__С</span><span class="w"> </span><span class="n">точки</span><span class="w"> </span><span class="n">зрения</span><span class="w"> </span><span class="n">теории</span><span class="w"> </span><span class="n">информации__</span><span class="p">.</span><span class="w"> </span><span class="n">_Перекрёстная</span><span class="w"> </span><span class="n">энтропия_</span><span class="w"> </span><span class="n">между</span><span class="w"> </span><span class="err">«</span><span class="n">истинным</span><span class="err">»</span><span class="w"> </span><span class="n">распределением</span><span class="w"> </span><span class="n">p</span>
<span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">предполагаемое</span><span class="w"> </span><span class="n">распределение</span><span class="w"> </span><span class="n">__q__</span><span class="w"> </span><span class="n">определяется</span><span class="w"> </span><span class="nl">как</span><span class="p">:</span><span class="w">  </span>

<span class="err">$$</span>
<span class="n">H</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="err">\</span><span class="n">sum_x</span><span class="w"> </span><span class="n">p</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="err">\</span><span class="nf">log</span><span class="w"> </span><span class="n">q</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="err">$$</span><span class="w">  </span>

<span class="n">Таким</span><span class="w"> </span><span class="n">образом</span><span class="p">,</span><span class="w"> </span><span class="n">классификатор</span><span class="w"> </span><span class="n">Softmax</span><span class="w"> </span><span class="n">минимизирует</span><span class="w"> </span><span class="n">перекрестную</span><span class="w"> </span><span class="n">энтропию</span><span class="w"> </span><span class="n">между</span><span class="w"> </span><span class="n">оцененными</span><span class="w"> </span><span class="n">вероятностями</span><span class="w"> </span><span class="n">классов</span><span class="w"> </span><span class="p">(</span><span class="w"> </span><span class="err">$</span><span class="n">q</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">e</span><span class="o">^</span><span class="err">{</span><span class="n">f_</span><span class="err">{</span><span class="n">y_i</span><span class="err">}}</span><span class="w">  </span><span class="o">/</span><span class="w"> </span><span class="err">\</span><span class="n">sum_j</span><span class="w"> </span><span class="n">e</span><span class="o">^</span><span class="err">{</span><span class="n">f_j</span><span class="err">}</span><span class="w"> </span><span class="err">$</span><span class="w"> </span><span class="n">как</span><span class="w"> </span><span class="n">показано</span><span class="w"> </span><span class="n">выше</span><span class="p">)</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">_</span><span class="err">«</span><span class="n">истинное</span><span class="err">»</span><span class="n">_</span><span class="w"> </span><span class="n">распределение</span><span class="p">,</span><span class="w"> </span><span class="n">которое</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">этой</span><span class="w"> </span><span class="n">интерпретации</span><span class="w"> </span><span class="n">представляет</span><span class="w"> </span><span class="n">собой</span><span class="w"> </span><span class="n">распределение</span><span class="p">,</span><span class="w"> </span><span class="n">при</span><span class="w"> </span><span class="n">котором</span><span class="w"> </span><span class="n">вся</span><span class="w"> </span><span class="n">масса</span><span class="w"> </span><span class="n">вероятностей</span><span class="w"> </span><span class="n">приходится</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">правильный</span><span class="w"> </span><span class="n">класс</span><span class="w"> </span>
<span class="n">то</span><span class="w"> </span><span class="n">есть</span><span class="w"> </span><span class="err">$</span><span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">[</span><span class="n">0, \ldots 1, \ldots, 0</span><span class="o">]</span><span class="err">\\</span><span class="w"> </span><span class="n">содержит</span><span class="w"> </span><span class="n">единственную</span><span class="w"> </span><span class="n">единицу</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">__</span><span class="err">$</span><span class="n">y_i</span><span class="err">$</span><span class="n">__</span><span class="o">-</span><span class="n">й</span><span class="w"> </span><span class="n">позиции</span><span class="p">.).</span><span class="w"> </span><span class="n">Более</span><span class="w"> </span><span class="n">того</span><span class="p">,</span><span class="w"> </span><span class="n">поскольку</span><span class="w"> </span><span class="n">кросс</span><span class="o">-</span><span class="n">энтропию</span><span class="w"> </span><span class="n">можно</span><span class="w"> </span><span class="n">записать</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">терминах</span><span class="w"> </span><span class="n">энтропии</span><span class="p">,</span><span class="w"> </span><span class="n">а</span><span class="w"> </span><span class="n">дивергенцию</span><span class="w"> </span><span class="n">Кульбака</span><span class="o">-</span><span class="n">Лейблера</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">как</span><span class="w"> </span><span class="err">$</span><span class="n">H</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">q</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">H</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">D_</span><span class="err">{</span><span class="n">KL</span><span class="err">}</span><span class="p">(</span><span class="n">p</span><span class="err">\</span><span class="o">|</span><span class="err">\</span><span class="o">|</span><span class="n">q</span><span class="p">)</span><span class="err">$</span><span class="p">,</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">энтропия</span><span class="w"> </span><span class="n">дельта</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">функции</span><span class="w"> </span><span class="n">__p__</span><span class="w"> </span><span class="n">равно</span><span class="w"> </span><span class="n">нулю</span><span class="p">,</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">также</span><span class="w"> </span><span class="n">эквивалентно</span><span class="w"> </span><span class="n">минимизации</span><span class="w"> </span><span class="n">расхождения</span><span class="w"> </span><span class="n">Кульбака</span><span class="w"> </span><span class="err">—</span><span class="w"> </span><span class="n">Лейблера</span><span class="w"> </span><span class="n">между</span><span class="w"> </span><span class="n">двумя</span><span class="w"> </span><span class="n">распределениями</span><span class="w"> </span><span class="p">(</span><span class="n">мера</span><span class="w"> </span><span class="n">расстояния</span><span class="p">).</span><span class="w"> </span><span class="n">Другими</span><span class="w"> </span><span class="n">словами</span><span class="p">,</span><span class="w"> </span><span class="n">цель</span><span class="w"> </span><span class="n">кросс</span><span class="o">-</span><span class="n">энтропии</span><span class="w"> </span><span class="n">_заключается</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">том_</span><span class="p">,</span><span class="w"> </span><span class="n">чтобы</span><span class="w"> </span><span class="n">прогнозируемое</span><span class="w"> </span><span class="n">распределение</span><span class="w"> </span><span class="n">было</span><span class="w"> </span><span class="n">сосредоточено</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">правильном</span><span class="w"> </span><span class="n">ответе</span><span class="p">.</span><span class="w">  </span>

<span class="n">__Вероятностная</span><span class="w"> </span><span class="n">интерпретация__</span><span class="p">.</span><span class="w"> </span><span class="n">Глядя</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">выражение</span><span class="p">,</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">видим</span><span class="p">,</span><span class="w"> </span><span class="nl">что</span><span class="p">:</span><span class="w">  </span>

<span class="err">$$</span>
<span class="n">P</span><span class="p">(</span><span class="n">y_i</span><span class="w"> </span><span class="err">\</span><span class="n">mid</span><span class="w"> </span><span class="n">x_i</span><span class="p">;</span><span class="w"> </span><span class="n">W</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">\</span><span class="n">frac</span><span class="err">{</span><span class="n">e</span><span class="o">^</span><span class="err">{</span><span class="n">f_</span><span class="err">{</span><span class="n">y_i</span><span class="err">}}}{\</span><span class="n">sum_j</span><span class="w"> </span><span class="n">e</span><span class="o">^</span><span class="err">{</span><span class="n">f_j</span><span class="err">}</span><span class="w"> </span><span class="err">}</span>
<span class="err">$$</span>

<span class="n">может</span><span class="w"> </span><span class="n">быть</span><span class="w"> </span><span class="n">интерпретирована</span><span class="w"> </span><span class="n">как</span><span class="w"> </span><span class="p">(</span><span class="n">нормализованная</span><span class="p">)</span><span class="w"> </span><span class="n">вероятность</span><span class="p">,</span><span class="w"> </span><span class="n">присвоенная</span><span class="w"> </span><span class="n">правильной</span><span class="w"> </span><span class="n">метке</span><span class="w"> </span><span class="n">__</span><span class="err">$</span><span class="n">y_i</span><span class="err">$</span><span class="n">__</span><span class="w"> </span><span class="n">учитывая</span><span class="w"> </span><span class="n">изображение</span><span class="w"> </span><span class="n">__</span><span class="err">$</span><span class="n">x_i</span><span class="err">$</span><span class="n">__</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">параметризуется</span><span class="w"> </span><span class="n">с</span><span class="w"> </span><span class="n">помощью</span><span class="w"> </span><span class="n">__W__</span><span class="p">.</span><span class="n">Чтобы</span><span class="w"> </span><span class="n">понять</span><span class="w"> </span><span class="n">это</span><span class="p">,</span><span class="w"> </span><span class="n">вспомните</span><span class="p">,</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">классификатор</span><span class="w"> </span><span class="n">Softmax</span><span class="w"> </span><span class="n">интерпретирует</span><span class="w"> </span><span class="n">оценки</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">выходном</span><span class="w"> </span><span class="n">векторе</span><span class="w"> </span><span class="n">__f__</span><span class="p">,</span><span class="w"> </span><span class="n">как</span><span class="w"> </span><span class="n">ненормированные</span><span class="w"> </span><span class="n">логарифмические</span><span class="w"> </span><span class="n">вероятности</span><span class="p">.</span><span class="w"> </span><span class="n">Возведение</span><span class="w"> </span><span class="n">этих</span><span class="w"> </span><span class="n">величин</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">степень</span><span class="w"> </span><span class="n">даёт</span><span class="w"> </span><span class="p">(</span><span class="n">ненормированные</span><span class="p">)</span><span class="w"> </span><span class="n">вероятности</span><span class="p">,</span><span class="w"> </span><span class="n">а</span><span class="w"> </span><span class="n">деление</span><span class="w"> </span><span class="n">выполняет</span><span class="w"> </span><span class="n">нормализацию</span><span class="p">,</span><span class="w"> </span><span class="n">чтобы</span><span class="w"> </span><span class="n">сумма</span><span class="w"> </span><span class="n">вероятностей</span><span class="w"> </span><span class="n">равнялась</span><span class="w"> </span><span class="n">единице</span><span class="p">.</span><span class="w"> </span><span class="n">Таким</span><span class="w"> </span><span class="n">образом</span><span class="p">,</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">вероятностной</span><span class="w"> </span><span class="n">интерпретации</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">минимизируем</span><span class="w"> </span><span class="n">отрицательную</span><span class="w"> </span><span class="n">логарифмическую</span><span class="w"> </span><span class="n">вероятность</span><span class="w"> </span><span class="n">правильного</span><span class="w"> </span><span class="n">класса</span><span class="p">,</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">можно</span><span class="w"> </span><span class="n">интерпретировать</span><span class="w"> </span><span class="n">как</span><span class="w"> </span><span class="n">выполнение</span><span class="w"> </span><span class="n">__оценки</span><span class="w"> </span><span class="n">максимального</span><span class="w"> </span><span class="n">правдоподобия__</span><span class="w"> </span><span class="p">(</span><span class="n">MLE</span><span class="p">).</span><span class="w"> </span><span class="n">Преимущество</span><span class="w"> </span><span class="n">такого</span><span class="w"> </span><span class="n">подхода</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">том</span><span class="p">,</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">теперь</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">можем</span><span class="w"> </span><span class="n">интерпретировать</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">член</span><span class="w"> </span><span class="n">регуляризации</span><span class="w"> </span><span class="n">__R</span><span class="p">(</span><span class="n">W</span><span class="p">)</span><span class="n">__</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">полной</span><span class="w"> </span><span class="n">функции</span><span class="w"> </span><span class="n">потерь</span><span class="p">,</span><span class="w"> </span><span class="n">исходящей</span><span class="w"> </span><span class="n">из</span><span class="w"> </span><span class="n">гауссовского</span><span class="w"> </span><span class="n">априора</span><span class="w"> </span><span class="n">по</span><span class="w"> </span><span class="n">весовой</span><span class="w"> </span><span class="n">матрице</span><span class="w"> </span><span class="n">__W__</span><span class="p">,</span><span class="w"> </span><span class="n">где</span><span class="w"> </span><span class="n">вместо</span><span class="w"> </span><span class="n">MLE</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">выполняем</span><span class="w"> </span><span class="n">оценку</span><span class="w"> </span><span class="n">_максимального</span><span class="w"> </span><span class="n">апостериорного</span><span class="w"> </span><span class="n">значения_</span><span class="w"> </span><span class="p">(</span><span class="k">MAP</span><span class="p">).</span><span class="w"> </span><span class="n">Мы</span><span class="w"> </span><span class="n">приводим</span><span class="w"> </span><span class="n">эти</span><span class="w"> </span><span class="n">интерпретации</span><span class="p">,</span><span class="w"> </span><span class="n">чтобы</span><span class="w"> </span><span class="n">помочь</span><span class="w"> </span><span class="n">вам</span><span class="w"> </span><span class="n">разобраться</span><span class="p">,</span><span class="w"> </span><span class="n">но</span><span class="w"> </span><span class="n">подробное</span><span class="w"> </span><span class="n">описание</span><span class="w"> </span><span class="n">этого</span><span class="w"> </span><span class="n">вывода</span><span class="w"> </span><span class="n">выходит</span><span class="w"> </span><span class="n">за</span><span class="w"> </span><span class="n">рамки</span><span class="w"> </span><span class="n">данного</span><span class="w"> </span><span class="n">курса</span><span class="p">.</span><span class="w">  </span>

<span class="n">__Практические</span><span class="w"> </span><span class="nl">вопросы</span><span class="p">:</span><span class="w"> </span><span class="n">числовая</span><span class="w"> </span><span class="n">стабильность__</span><span class="p">.</span><span class="w"> </span><span class="n">Когда</span><span class="w"> </span><span class="n">вы</span><span class="w"> </span><span class="n">пишете</span><span class="w"> </span><span class="n">код</span><span class="w"> </span><span class="n">для</span><span class="w"> </span><span class="n">вычисления</span><span class="w"> </span><span class="n">функции</span><span class="w"> </span><span class="n">Softmax</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">практике</span><span class="p">,</span><span class="w"> </span><span class="n">промежуточные</span><span class="w"> </span><span class="n">значения</span><span class="err">$</span><span class="n">e</span><span class="o">^</span><span class="err">{</span><span class="n">f_</span><span class="err">{</span><span class="n">y_i</span><span class="err">}}$</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="err">$\</span><span class="n">sum_j</span><span class="w"> </span><span class="n">e</span><span class="o">^</span><span class="err">{</span><span class="n">f_j</span><span class="err">}$</span><span class="w"> </span><span class="n">может</span><span class="w"> </span><span class="n">быть</span><span class="w"> </span><span class="n">очень</span><span class="w"> </span><span class="n">большим</span><span class="w"> </span><span class="n">из</span><span class="o">-</span><span class="n">за</span><span class="w"> </span><span class="n">экспоненциальных</span><span class="w"> </span><span class="n">функций</span><span class="p">.</span><span class="w"> </span><span class="n">Деление</span><span class="w"> </span><span class="n">больших</span><span class="w"> </span><span class="n">чисел</span><span class="w"> </span><span class="n">может</span><span class="w"> </span><span class="n">быть</span><span class="w"> </span><span class="n">неустойчивым</span><span class="w"> </span><span class="n">с</span><span class="w"> </span><span class="n">точки</span><span class="w"> </span><span class="n">зрения</span><span class="w"> </span><span class="n">вычислений</span><span class="p">,</span><span class="w"> </span><span class="n">поэтому</span><span class="w"> </span><span class="n">важно</span><span class="w"> </span><span class="n">использовать</span><span class="w"> </span><span class="n">приём</span><span class="w"> </span><span class="n">нормализации</span><span class="p">.</span><span class="w"> </span><span class="n">Обратите</span><span class="w"> </span><span class="n">внимание</span><span class="p">,</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">если</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">умножим</span><span class="w"> </span><span class="n">числитель</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">знаменатель</span><span class="w"> </span><span class="n">дроби</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">константу</span><span class="w"> </span><span class="n">__C__</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">подставим</span><span class="w"> </span><span class="n">его</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">сумму</span><span class="p">,</span><span class="w"> </span><span class="n">получим</span><span class="w"> </span><span class="n">следующее</span><span class="w"> </span><span class="p">(</span><span class="n">математически</span><span class="w"> </span><span class="n">эквивалентное</span><span class="p">)</span><span class="w"> </span><span class="nl">выражение</span><span class="p">:</span><span class="w">  </span>

<span class="err">$$</span>
<span class="err">\</span><span class="n">frac</span><span class="err">{</span><span class="n">e</span><span class="o">^</span><span class="err">{</span><span class="n">f_</span><span class="err">{</span><span class="n">y_i</span><span class="err">}}}{\</span><span class="n">sum_j</span><span class="w"> </span><span class="n">e</span><span class="o">^</span><span class="err">{</span><span class="n">f_j</span><span class="err">}}</span>
<span class="o">=</span><span class="w"> </span><span class="err">\</span><span class="n">frac</span><span class="err">{</span><span class="n">Ce</span><span class="o">^</span><span class="err">{</span><span class="n">f_</span><span class="err">{</span><span class="n">y_i</span><span class="err">}}}{</span><span class="n">C</span><span class="err">\</span><span class="n">sum_j</span><span class="w"> </span><span class="n">e</span><span class="o">^</span><span class="err">{</span><span class="n">f_j</span><span class="err">}}</span>
<span class="o">=</span><span class="w"> </span><span class="err">\</span><span class="n">frac</span><span class="err">{</span><span class="n">e</span><span class="o">^</span><span class="err">{</span><span class="n">f_</span><span class="err">{</span><span class="n">y_i</span><span class="err">}</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">\</span><span class="nf">log</span><span class="w"> </span><span class="n">C</span><span class="err">}}{\</span><span class="n">sum_j</span><span class="w"> </span><span class="n">e</span><span class="o">^</span><span class="err">{</span><span class="n">f_j</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="err">\</span><span class="nf">log</span><span class="w"> </span><span class="n">C</span><span class="err">}}</span>
<span class="err">$$</span><span class="w">  </span>

<span class="n">Мы</span><span class="w"> </span><span class="n">вольны</span><span class="w"> </span><span class="n">выбирать</span><span class="w"> </span><span class="n">стоимость</span><span class="w"> </span><span class="n">__C__</span><span class="p">.</span><span class="w"> </span><span class="n">Это</span><span class="w"> </span><span class="n">не</span><span class="w"> </span><span class="n">повлияет</span><span class="w"> </span><span class="n">ни</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">один</span><span class="w"> </span><span class="n">из</span><span class="w"> </span><span class="n">результатов</span><span class="p">,</span><span class="w"> </span><span class="n">но</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">можем</span><span class="w"> </span><span class="n">использовать</span><span class="w"> </span><span class="n">это</span><span class="w"> </span><span class="n">значение</span><span class="w"> </span><span class="n">для</span><span class="w"> </span><span class="n">повышения</span><span class="w"> </span><span class="n">численной</span><span class="w"> </span><span class="n">стабильности</span><span class="w"> </span><span class="n">вычислений</span><span class="p">.</span><span class="w"> </span><span class="n">Обычно</span><span class="w"> </span><span class="n">выбирают</span><span class="w"> </span><span class="n">__C__</span><span class="w"> </span><span class="n">заключается</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">том</span><span class="p">,</span><span class="w"> </span><span class="n">чтобы</span><span class="w"> </span><span class="n">установить</span><span class="w"> </span><span class="n">__</span><span class="err">$\</span><span class="nf">log</span><span class="w"> </span><span class="n">C</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">-</span><span class="err">\</span><span class="n">max_j</span><span class="w"> </span><span class="n">f_j</span><span class="w"> </span><span class="err">$</span><span class="n">__</span><span class="p">.</span><span class="w"> </span><span class="n">Это</span><span class="w"> </span><span class="n">просто</span><span class="w"> </span><span class="n">указывает</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">то</span><span class="p">,</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">должны</span><span class="w"> </span><span class="n">сместить</span><span class="w"> </span><span class="n">значения</span><span class="w"> </span><span class="n">внутри</span><span class="w"> </span><span class="n">вектора</span><span class="w"> </span><span class="n">__f__</span><span class="w"> </span><span class="n">так</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">наибольшее</span><span class="w"> </span><span class="n">значение</span><span class="w"> </span><span class="n">равно</span><span class="w"> </span><span class="n">нулю</span><span class="p">.</span><span class="w"> </span><span class="n">В</span><span class="w"> </span><span class="nl">коде</span><span class="p">:</span><span class="w">  </span>


<span class="err">```</span><span class="n">py</span>
<span class="n">f</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">np</span><span class="p">.</span><span class="k">array</span><span class="p">(</span><span class="o">[</span><span class="n">123, 456, 789</span><span class="o">]</span><span class="p">)</span><span class="w"> </span><span class="err">#</span><span class="w"> </span><span class="n">example</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="mi">3</span><span class="w"> </span><span class="n">classes</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="k">each</span><span class="w"> </span><span class="k">having</span><span class="w"> </span><span class="k">large</span><span class="w"> </span><span class="n">scores</span>
<span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">f</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">f</span><span class="p">))</span><span class="w"> </span><span class="err">#</span><span class="w"> </span><span class="nl">Bad</span><span class="p">:</span><span class="w"> </span><span class="nc">Numeric</span><span class="w"> </span><span class="n">problem</span><span class="p">,</span><span class="w"> </span><span class="n">potential</span><span class="w"> </span><span class="n">blowup</span>

<span class="err">#</span><span class="w"> </span><span class="nl">instead</span><span class="p">:</span><span class="w"> </span><span class="k">first</span><span class="w"> </span><span class="n">shift</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="k">values</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">f</span><span class="w"> </span><span class="n">so</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">highest</span><span class="w"> </span><span class="n">number</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="mi">0</span><span class="err">:</span>
<span class="n">f</span><span class="w"> </span><span class="o">-=</span><span class="w"> </span><span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">f</span><span class="p">)</span><span class="w"> </span><span class="err">#</span><span class="w"> </span><span class="n">f</span><span class="w"> </span><span class="n">becomes</span><span class="w"> </span><span class="o">[</span><span class="n">-666, -333, 0</span><span class="o">]</span>
<span class="n">p</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">f</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">f</span><span class="p">))</span><span class="w"> </span><span class="err">#</span><span class="w"> </span><span class="n">safe</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">do</span><span class="p">,</span><span class="w"> </span><span class="n">gives</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">correct</span><span class="w"> </span><span class="n">answer</span>
</pre></div>

<p><strong>Возможно, сбивающие с толку соглашения об именовании</strong>. Чтобы быть точным, в классификаторе SVM используется потеря шарнира, или также иногда называемая <em>потерей максимальной маржи</em>. <em>Классификатор Softmax</em> использует <em>кросс-энтропийные</em> потери. Классификатор Softmax получил свое название от <em>функции softmax</em>, которая используется для преобразования необработанных оценок класса в нормализованные положительные значения, которые в сумме равны единице, чтобы можно было применить потери от перекрестной энтропии. В частности, обратите внимание, что технически не имеет смысла говорить о «потере при softmax», поскольку softmax — это просто функция сжатия, но это относительно часто используемое сокращение.  </p>
<h3>SVM против Softmax</h3>
<p>Изображение может помочь прояснить разницу между классификаторами Softmax и SVM:  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/svmvssoftmax.png"></p>
<p>Пример разницы между классификаторами SVM и Softmax для одной точки данных. В обоих случаях мы вычисляем один и тот же вектор оценок <strong>f</strong> (например, путём умножения матриц в этом разделе). Разница заключается в интерпретации оценок в <strong>f</strong>: SVM интерпретирует их как оценки классов, и его функция потерь поощряет правильный класс (класс 2, выделен синим цветом) к получению более высокой оценки, чем у других классов. Вместо этого классификатор Softmax интерпретирует баллы как (ненормализованные) логарифмические вероятности для каждого класса, а затем стремится к тому, чтобы (нормализованная) логарифмическая вероятность правильного класса была высокой (эквивалентно, чтобы её отрицательная величина была низкой). Окончательное значение потерь для этого примера составляет 1,58 для SVM и 1,04 (обратите внимание, что это 1,04 с использованием натурального логарифма, а не логарифма по основанию 2 или 10) для классификатора Softmax, но обратите внимание, что эти числа несопоставимы. Они имеют смысл только в сравнении с потерями, рассчитанными для того же классификатора и с теми же данными.  </p>
<hr>
<p><strong>Классификатор Softmax предоставляет «вероятности» для каждого класса</strong>. В отличие от SVM, который вычисляет некалиброванные и трудно интерпретируемые оценки для всех классов, классификатор Softmax позволяет вычислять «вероятности» для всех меток. Например, для изображения классификатор SVM может выдать оценки [12,5, 0,6, -23,0] для классов «кошка», «собака» и «корабль». Вместо этого классификатор softmax может вычислить вероятности трёх меток как [0,9, 0,09, 0,01], что позволяет интерпретировать его уверенность в каждом классе. Однако мы взяли слово «вероятности» в кавычки, потому что то, насколько выраженными или размытыми будут эти вероятности, напрямую зависит от силы регуляризации <strong>λ</strong>, которые вы вводите в систему в качестве входных данных. Например, предположим, что ненормированные логарифмические вероятности для трёх классов равны [1, -2, 0]. Тогда функция softmax вычислит:  </p>
<p>$$
[1, -2, 0] \rightarrow [e^1, e^{-2}, e^0] = [2.71, 0.14, 1] \rightarrow [0.7, 0.04, 0.26]
$$  </p>
<p>Где шаги, предпринятые для возведения в степень и нормализации, суммируются до единицы. Теперь, если сила регуляризации <strong>λ</strong> был выше, вес <strong>W</strong> будет больше штрафоваться, и это приведёт к уменьшению весов. Например, предположим, что веса стали в два раза меньше ([0,5, -1, 0]). Теперь <em>softmax</em> будет вычислять:  </p>
<p>$$
[0.5, -1, 0] \rightarrow [e^{0.5}, e^{-1}, e^0] = [1.65, 0.37, 1] \rightarrow [0.55, 0.12, 0.33]
$$  </p>
<p>где вероятности теперь более размыты. Более того, в пределе, когда веса стремятся к малым значениям из-за очень сильной регуляризации __λ__Выходные вероятности были бы почти равномерными. Следовательно, вероятности, вычисляемые классификатором Softmax, лучше рассматривать как степени уверенности, где, как и в случае с SVM, порядок значений интерпретируется, но абсолютные значения (или их разница) технически не интерпретируются.  </p>
<p>На практике SVM и Softmax обычно сопоставимы по эффективности. Разница в производительности между SVM и Softmax обычно очень мала, и разные люди по-разному оценивают, какой классификатор работает лучше. По сравнению с классификатором Softmax, SVM является более <em>локальной</em> целью, что можно рассматривать как недостаток или преимущество. Рассмотрим пример, в котором достигаются баллы [10, -2, 3] и где первый класс является правильным. SVM (например, с желаемым запасом прочности <strong>Δ=1</strong>) увидит, что правильный класс уже имеет оценку выше, чем разница между классами, и вычислит нулевую потерю. SVM не обращает внимания на детали отдельных оценок: если бы они были [10, -100, -100] или [10, 9, 9], SVM было бы всё равно, так как разница в 1 соблюдена и, следовательно, потеря равна нулю. Однако эти сценарии не эквивалентны классификатору Softmax, который привёл бы к гораздо более высоким потерям для оценок [10, 9, 9], чем для [10, -100, -100]. Другими словами, классификатор Softmax никогда не будет полностью удовлетворён полученными оценками: правильный класс всегда может иметь более высокую вероятность, а неправильные классы — более низкую, и потери всегда будут уменьшаться. Однако SVM доволен, если соблюдены границы, и не контролирует точные оценки за пределами этого ограничения. Это можно интуитивно воспринимать как особенность: например, классификатор автомобилей, который, скорее всего, тратит большую часть своих «усилий» на решение сложной задачи по отделению автомобилей от грузовиков, не должен подвергаться влиянию примеров с лягушками, которым он уже присваивает очень низкие баллы и которые, скорее всего, группируются в совершенно другой части облака данных.  </p>
<h3>Интерактивная веб-демонстрация</h3>
<hr>
<p><img alt="" src="http://vision.stanford.edu/teaching/cs231n/linear-classify-demo"></p>
<p>Мы написали интерактивную веб-демонстрацию, чтобы помочь вашей интуиции в работе с линейными классификаторами. Демонстрация визуализирует функции потерь, обсуждаемые в этом разделе, с использованием игрушечной трехмерной классификации на 2D-данных. Демонстрационная версия также немного забегает вперед и выполняет оптимизацию, которую мы подробно обсудим в следующем разделе.  </p>
<hr>
<h3>Краткая сводка</h3>
<p>Подводя итог: 
- Мы определили <strong>функцию оценки</strong> от пикселей изображения к оценкам классов (в этом разделе — линейную функцию, которая зависит от весовых коэффициентов <strong>W</strong> и смещений <strong>b</strong>).
- В отличие от классификатора kNN, преимущество этого <strong>параметрического подхода</strong> заключается в том, что после определения параметров мы можем отказаться от обучающих данных. Кроме того, прогнозирование для нового тестового изображения выполняется быстро, поскольку требует лишь одного умножения матрицы на <strong>W</strong>, а не исчерпывающего сравнения с каждым отдельным обучающим примером.
- Мы ввели <strong>уловку со смещением</strong>, которая позволяет нам сложить вектор смещения в весовую матрицу для удобства, чтобы отслеживать только одну матрицу параметров.
- Мы определили <strong>функцию потерь</strong> (мы ввели две часто используемые функции потерь для линейных классификаторов: <strong>SVM</strong> и <strong>Softmax</strong>), которая измеряет, насколько заданный набор параметров соответствует истинным меткам в обучающем наборе данных. Мы также увидели, что функция потерь определена таким образом, что хорошие прогнозы на обучающих данных эквивалентны небольшим потерям.</p>
<p>Теперь мы увидели один из способов взять набор изображений и сопоставить каждое из них с баллами классов на основе набора параметров, а также увидели два примера функций потерь, которые можно использовать для оценки качества прогнозов. Но как эффективно определить параметры, которые дают наилучшие (наименьшие) потери? Этот процесс называется <strong>оптимизацией</strong>, и ему посвящён следующий раздел.  </p>
<h3>Дополнительные материалы</h3>
<p>Эти показания являются необязательными и содержат указания, представляющие интерес: 
- <a href="https://arxiv.org/abs/1306.0239">«Глубокое обучение с использованием линейных машин опорных векторов»</a> от Чарли Танга, 2013 г., представляет некоторые результаты, согласно которым L2SVM превосходит Softmax.</p>
                </div>
            </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/transfer-learning/" class="u-url">Трансфер обучения</a></h1>
                <div class="metadata">
                    <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                        Андрей Лабинцев
                    </span></p>
            <p class="dateline">
            <a href="posts/transfer-learning/" rel="bookmark">
            <time class="published dt-published" datetime="2025-02-14T19:42:16+03:00" itemprop="datePublished" title="2025-02-14 19:42">2025-02-14 19:42</time></a>
            </p>
                </div>
            </header><div class="e-content entry-content">
                    <h2>Трансфер обучения</h2>
<p><strong><em>(Эти заметки в настоящее время находятся в черновой форме и находятся в разработке)</em></strong></p>
<p>Содержание:
- <a href="posts/transfer-learning/">Трансферное обучение</a>
- <a href="posts/transfer-learning/">Дополнительные примечания</a></p>
<h3>Трансферное обучение</h3>
<p>На практике очень немногие обучают всю сверточную сеть с нуля (со случайной инициализацией), потому что относительно редко удается иметь набор данных достаточного размера. Вместо этого обычно предварительно обучают <em>ConvNet</em> на очень большом наборе данных (например, <em>ImageNet</em>, который содержит 1,2 миллиона изображений с 1000 категориями), а затем используют ConvNet либо в качестве инициализации, либо в качестве фиксированного экстрактора признаков для интересующей задачи. Три основных сценария трансферного обучения выглядят следующим образом:
- <strong>ConvNet в качестве фиксированного экстрактора признаков</strong>. Возьмите предварительно обученный <em>ConvNet</em> на <em>ImageNet</em>, удалите последний полностью подключенный слой (выходные данные этого слоя представляют собой 1000 баллов класса для другой задачи, такой как <em>ImageNet</em>), а затем обрабатывайте остальную часть <em>ConvNet</em> как фиксированный экстрактор признаков для нового набора данных. В <em>AlexNet</em> это позволило бы вычислить вектор <strong>4096-D</strong> для каждого изображения, содержащего активации скрытого слоя непосредственно перед классификатором. Мы называем эти функции <strong>кодами CNN</strong>. Для производительности важно, чтобы эти коды были <em>ReLUd</em> (т.е. пороговыми на нуле), если они также были пороговыми во время обучения <em>ConvNet</em> на <em>ImageNet</em> (как это обычно бывает). После извлечения кодов <strong>4096-D</strong> для всех изображений обучите линейный классификатор (например, Linear <em>SVM</em> или классификатор Softmax) для нового набора данных.
- <strong>Тонкая настройка ConvNet</strong>. Вторая стратегия заключается не только в замене и переобучении классификатора поверх <em>ConvNet</em> на новом наборе данных, но и в тонкой настройке весов предварительно обученной сети путем продолжения обратного распространения. Можно тонко настроить все уровни <em>ConvNet</em>, или можно оставить некоторые из более ранних уровней фиксированными (из-за опасений переобучения) и выполнить тонкую настройку только некоторой части сети более высокого уровня. Это мотивировано наблюдением, что более ранние функции <em>ConvNet</em> содержат более общие функции (например, детекторы краев или детекторы цветных пятен), которые должны быть полезны для многих задач, но более поздние уровни <em>ConvNet</em> становятся все более специфичными для деталей классов, содержащихся в исходном наборе данных. Например, в случае <em>ImageNet</em>, который содержит множество пород собак, значительная часть репрезентативной мощности <em>ConvNet</em> может быть направлена на функции, специфичные для дифференциации между породами собак.
- <strong>Предварительно обученные модели</strong>. Поскольку обучение современных <em>ConvNet</em> на нескольких графических процессорах <em>ImageNet</em> занимает 2–3 недели, часто можно увидеть, как люди выпускают свои окончательные контрольные точки <em>ConvNet</em> в пользу других пользователей, которые могут использовать сети для тонкой настройки. Например, в библиотеке <em>Caffe</em> есть <a href="https://github.com/BVLC/caffe/wiki/Model-Zoo">Model Zoo</a>, где люди делятся своими сетевыми весами.  </p>
<p><strong>Когда и как проводить тонкую настройку?</strong> Как вы решаете, какой тип переносного обучения вы должны выполнять на новом наборе данных? Это зависит от нескольких факторов, но два наиболее важных из них — это размер нового набора данных (маленький или большой) и его сходство с исходным набором данных (например, похожий на ImageNet с точки зрения содержимого изображений и классов, или сильно отличающийся, например, изображения микроскопа). Помня о том, что объекты <em>ConvNet</em> более универсальны в ранних слоях и более специфичны для исходного набора данных в более поздних слоях, вот некоторые общие эмпирические правила для навигации по <em>4</em> основным сценариям:<br>
1. <em>Новый набор данных имеет небольшой размер и похож на исходный набор данных</em>. Поскольку объем данных невелик, тонкая настройка <em>ConvNet</em> не является хорошей идеей из-за проблем с переобучением. Поскольку данные аналогичны исходным данным, мы ожидаем, что функции более высокого уровня в <em>ConvNet</em> также будут иметь отношение к этому набору данных. Следовательно, лучшей идеей может быть обучение линейного классификатора на кодах <em>CNN</em>.
2. <em>Новый набор данных имеет большой размер и похож на исходный набор данных</em>. Поскольку у нас больше данных, мы можем быть уверены в том, что не переучимся, если попытаемся выполнить тонкую настройку через всю сеть.
3. <em>Новый набор данных небольшой, но сильно отличается от исходного</em>. Поскольку данные невелики, вероятно, лучше всего обучить только линейный классификатор. Поскольку набор данных сильно отличается, возможно, не стоит обучать классификатор с вершины сети, которая содержит больше функций, специфичных для набора данных. Вместо этого, возможно, лучше обучить классификатор <em>SVM</em> от активаций где-то раньше в сети.
4. <em>Новый набор данных имеет большой размер и сильно отличается от исходного набора данных</em>. Поскольку набор данных очень большой, можно ожидать, что мы сможем позволить себе обучить <em>ConvNet</em> с нуля. Однако на практике очень часто все же полезно инициализировать весами из предварительно обученной модели. В этом случае у нас было бы достаточно данных и уверенности для тонкой настройки по всей сети.  </p>
<p><strong>Практические советы</strong>. Есть несколько дополнительных моментов, о которых следует помнить при выполнении <em>Transfer Learning</em>:</p>
<ul>
<li>
<em>Ограничения из предварительно обученных моделей</em>. Обратите внимание, что если вы хотите использовать предварительно обученную сеть, вы можете быть немного ограничены с точки зрения архитектуры, которую вы можете использовать для вашего нового набора данных. Например, вы не можете произвольно удалять слои Conv из предварительно обученной сети. Тем не менее, некоторые изменения просты: благодаря совместному использованию параметров вы можете легко запустить предварительно обученную сеть на изображениях разного пространственного размера. Это ясно видно в случае слоев Conv/Pool, потому что их прямая функция не зависит от пространственного размера входного объема (до тех пор, пока шаги «подходят»). В случае слоев FC это по-прежнему верно, потому что слои FC могут быть преобразованы в сверточный слой: например, в AlexNet окончательный объем пула перед первым слоем <em>FC</em> имеет размер <strong>[6x6x512]</strong>. Следовательно, слой <em>FC</em>, рассматривающий этот объем, эквивалентен наличию сверточного слоя, который имеет размер рецептивного поля 6x6 и применяется с отступом <strong>0</strong>.</li>
<li>
<em>Скорость обучения</em>. Обычно для тонко настраиваемых весов <em>ConvNet</em> используется меньшая скорость обучения по сравнению с весами (случайно инициализированными) для нового линейного классификатора, который вычисляет баллы классов нового набора данных. Это связано с тем, что мы ожидаем, что веса <em>ConvNet</em> относительно хороши, поэтому мы не хотим искажать их слишком быстро и слишком сильно (особенно когда новый линейный классификатор над ними обучается на основе случайной инициализации).  </li>
</ul>
<h3>Дополнительные примечания</h3>
<ul>
<li>
<a href="http://arxiv.org/abs/1403.6382">Готовые функции CNN: A Astounding Baseline for Recognition</a> обучает <em>SVM</em> функциям из предварительно обученного <em>ImageNet</em> <em>ConvNet</em> и сообщает о нескольких современных результатах.</li>
<li>
<a href="http://arxiv.org/abs/1310.1531">DeCAF</a> сообщал об аналогичных выводах в 2013 году. Фреймворк в этой статье (<em>DeCAF</em>) был предшественником библиотеки <em>C++</em> <em>Caffe</em> на основе <em>Python</em>.</li>
<li>
<a href="http://arxiv.org/abs/1411.1792">Насколько переносимы функции в глубоких нейронных сетях?</a> Подробно изучает эффективность обучения переносу, включая некоторые неинтуитивные выводы о коадаптациях слоев.</li>
</ul>
</div>
            </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/nlp-za-90-minut/" class="u-url">NLP за 90 минут</a></h1>
                <div class="metadata">
                    <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                        Андрей Лабинцев
                    </span></p>
            <p class="dateline">
            <a href="posts/nlp-za-90-minut/" rel="bookmark">
            <time class="published dt-published" datetime="2023-06-16T11:44:44+03:00" itemprop="datePublished" title="2023-06-16 11:44">2023-06-16 11:44</time></a>
            </p>
                </div>
            </header><div class="e-content entry-content">
                    <h2>Основы обработки естественного языка</h2>
<h4>Вопросы:</h4>
<ol>
<li>Краткая история машинной обработки текстов (5 мин)</li>
<li>Основные определения (5 мин)</li>
<li>Методы предварительной обработки текста (10 мин)</li>
<li>Моделирование языка (языковые модели) (10 мин)</li>
<li>Нейронные сети в NLP (30 мин)</li>
<li>GPT модели (30 мин)</li>
</ol>
<h4>1. Краткая история машинной обработки текстов</h4>
<p><strong>NLP (Natural Language Processing)</strong> - это область науки, которая изучает методы обработки текстов на естественных языках с помощью вычислительных машин. 
Основной акцент в NLP делается на прикладные методы, которые можно реализовать на языке программирования. 
Для вычислительно сложных методов используют языки низкого уровня (С, С++), потому что важна эффективность вычислений. 
Для проведение экспериментов используют языки высокого уровня (python), потому что  для проверки гипотез важна скорость написания кода. 
Сегодня исследователям доступно множество библиотек на python, которые служат оберткой для оптимизированного машинного кода.  </p>
<p>В 1913 году русский математик Андрей Андреевич Марков провел эксперимент по оценке частоты появления разных букв в тексте. 
Он выписал первые 20 000 букв поэмы А. С. Пушкина «Евгений Онегин» в одну длинную строчку из букв, опустив все пробелы и знаки пунктуации. 
Затем он переставил эти буквы в 200 решёток (по 10х10 символов в каждой), и начал подсчитывать гласные звуки в каждой строке и столбце, записывая результаты. 
Марков считал, что большинство явлений происходит по цепочке причинно-следственной связи и зависит от предыдущих результатов. 
Он хотел найти способ моделировать эти события посредством вероятностного анализа. 
Он обнаружил, что для любой буквы текста Пушкина выполнялось правило: если это была гласная, то скорее всего за ней будет стоять согласная, и наоборот.  </p>
<p>В 1950 году в работе "Вычислительные машины и разум" ученый Алан Тьюринг предложил тест разумности для искуственного интеллекта.<br>
Если компьютер сможет провести убедительную беседу с человеком в текстовом режиме, можно будет предположить, что он разумен. </p>
<p>В 1954 году в штаб-квартире корпорации IBM состоялся Джорджтаунский эксперимент — демонстрация возможностей машинного перевода. 
В ходе эксперимента был продемонстрирован полностью автоматический перевод более 60 предложений с русского языка на английский. 
Программа выполнялась на мейнфрейме IBM 701. 
В том же году первый эксперимент по машинному переводу был произведён в Институте точной механики и вычислительной техники АН СССР, на компьютере БЭСМ.  </p>
<p>В 1966 году Джозеф Вейценбаум, работавший в лаборатории ИИ при MIT, разработал первый в мире чатбот "Элиза". 
Пользователь мог ввести некое утверждение или набор утверждений на обычном языке, нажать «ввод», и получить от машины ответ.  </p>
<p>В 1986 Давид Румельхарт разработал базовую концепцию рекуррентной нейросети (recurrent neural network, RNN). 
Этот метод позволял решать такие задачи как распознавание речи и текста.  </p>
<p>В 2017 году группа исследователей Google представила архитектуру трансформера (Transformer), которая позволяет обрабатывать тексты, в которых слова расположены в произвольном порядке. 
В настоящее время трансформеры используются в сервисах многих компаний, включая Яндекс и Google, являются основой для самых современных моделей GPT, Bert и т.д.  </p>
<p>В 2023 году OpenAI опубликовала языковую модель GPT-4, которая легко проходит тест Тьюринга и порождает споры об опасности искусственного интеллекта. </p>
<h4>2. Основные определения</h4>
<p><strong>Символ</strong> - это условный знак каких-либо понятий, идей, явлений. 
Первые наскальные символы обозначали зверей, охоту, солнце и другие предметы, которые отражались в сознании первобытных людей. 
Мы и сегодня часто используем символы эмоджи для отображения своих эмоций и скрытых смыслов. 
У разных народов сформировались свои уникальные алфавиты, которы представляют собой множества допустимых символов для письма.   </p>
<p>У компьютера тоже есть уникальный набор символов, определяемый кодировкой. 
Например, кодировка ASCII (American standard code for information interchange) была стандартизована в 1963 году и определяет символы:<br>
- десятичных цифр;<br>
- латинского алфавита;<br>
- национального алфавита;<br>
- знаков препинания;<br>
- управляющих символов.  </p>
<p>С математической точки зрения алфавит как множество символов обозначается символом $V$.<br>
Всевозможные комбинации символов, образующих конечные слова, в т.ч. состоящие из одного символа и бессмысленные комбинации, образуют множество $V^*$. </p>
<p><strong>Слово</strong> - наименьшая единица языка, служащая для именования предметов, качеств, характеристик, взаимодействий, а также для служебных целей. 
Например слово "Я" состоит всего из одного символа и в русском языке обозначает меня как субъект.<br>
Большинство слов состоят из нескольких символов, связанных в последовательность по определенным правилам. </p>
<p><strong>Язык</strong> - это множество слов, которые несут в себе хоть какой-то смысл. 
Например, слово "тывщштс" не имеет смысла в русском языке, хоть и состоит из символов кириллицы. 
А слово "дом", наоборот, является вполне известным и входит в множество слов русского языка. <br>
Формально язык обозначается символом $L$. В алфавите $V$ язык является подмножеством всех конечных слов $$L \in V^*$$</p>
<p><strong>Текст</strong> - это зафиксированая на материальном носителе человеческая мысль в виде последовательности символов. 
Текст может состоять из одного или нескольких слов. </p>
<h5>Представление текста в компьютере</h5>
<p>Для человека символы, слова и тексты несут в себе определенный смысл. 
Компьютер же работает только с байтами. 
Рассмотрим пример, как реализовано посимвольное кодирование алфавита в кодировке ASCII.</p>
<table class="tg">
<thead><tr>
<th class="tg-0pky">bin</th>
    <th class="tg-0pky">dec</th>
    <th class="tg-0pky">hex</th>
    <th class="tg-0pky">symbol</th>
  </tr></thead>
<tbody>
<tr>
<td class="tg-c3ow">110 0001</td>
    <td class="tg-c3ow">97</td>
    <td class="tg-c3ow">61</td>
    <td class="tg-c3ow">a</td>
  </tr>
<tr>
<td class="tg-c3ow">110 0010</td>
    <td class="tg-c3ow">98</td>
    <td class="tg-c3ow">62</td>
    <td class="tg-c3ow">b</td>
  </tr>
<tr>
<td class="tg-c3ow">110 0011</td>
    <td class="tg-c3ow">99</td>
    <td class="tg-c3ow">63</td>
    <td class="tg-c3ow">c</td>
  </tr>
<tr>
<td class="tg-c3ow">110 1010</td>
    <td class="tg-c3ow">106</td>
    <td class="tg-c3ow">6A</td>
    <td class="tg-c3ow">j</td>
  </tr>
<tr>
<td class="tg-c3ow">110 1011</td>
    <td class="tg-c3ow">107</td>
    <td class="tg-c3ow">6B</td>
    <td class="tg-c3ow">k</td>
  </tr>
</tbody>
</table>
<p><strong>bin</strong> - двоичное представление символа,<br><strong>dec</strong> - представление в десятичной системе счисления,<br><strong>hex</strong> - представление в шестнадцатеричной системе счисления.<br>
С полной таблицей кодировки ASCII можно ознакомиться по <a href="https://en.wikipedia.org/wiki/ASCII#8-bit_codes">ссылке</a>.<br>
Для хранения одного символа латинского алфавита достаточно 7 бит. 
Для хранения одного символа небольшого национального алфавита (например, кириллицы) достаточно 8 бит. 
Для кодировки символов более объемных алфавитов (например, китайского) используют 16 бит или два байта.  <br>
Слова, как и тексты, хранятся в компьютерной памяти в виде последовательности символов. </p>
                </div>
            </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/template/" class="u-url">Шаблон для новых постов</a></h1>
                <div class="metadata">
                    <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                        Андрей Лабинцев
                    </span></p>
            <p class="dateline">
            <a href="posts/template/" rel="bookmark">
            <time class="published dt-published" datetime="2022-05-16T17:25:16+03:00" itemprop="datePublished" title="2022-05-16 17:25">2022-05-16 17:25</time></a>
            </p>
                </div>
            </header><div class="e-content entry-content">
                    <h2>Заготовка для создания новых постов</h2>
<p>Текст здесь </p>
<p>$$a^2 + b^2 = c^2$$</p>
                </div>
            </article>
</div>
    
        <ul class="pager postindexpager clearfix">
<li class="previous"><a href="." rel="prev">Новые записи</a></li>
        </ul>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha384-3lJUsx1TJHt7BA4udB5KPnDrlkO8T6J6v/op7ui0BbCjvZ9WqV4Xm6DTP6kQ/iBH" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\\(","\\\)"] ],
        displayMath: [ ['$$','$$'], ["\\\[","\\\]"] ],
        processEscapes: true
    },
    displayAlign: 'center', // Change this to 'left' if you want left-aligned equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script><!--End of body content--><footer id="footer">
            Contents © 2025         <a href="mailto:andrej.labintsev@yandex.ru">Андрей Лабинцев</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
            
        </footer>
</div>
</div>


        <script src="assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
