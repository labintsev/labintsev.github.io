<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="ru">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Обучение нейронных сетей | Заметки по ML, DL</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:700,900" rel="stylesheet">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="ru" href="../../rss.xml">
<link rel="canonical" href="https://mldl.ru/posts/convnets-3/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Андрей Лабинцев">
<link rel="prev" href="../convnets-2/" title="Предобработка, инициализация весов, функции потерь" type="text/html">
<link rel="next" href="../convnets-4/" title="Обучение нейронных сетей 2" type="text/html">
<meta property="og:site_name" content="Заметки по ML, DL">
<meta property="og:title" content="Обучение нейронных сетей">
<meta property="og:url" content="https://mldl.ru/posts/convnets-3/">
<meta property="og:description" content="Обучение нейронных сетей
Содержание:
- Проверка градиента
- Проверки здравомыслия
- Присмотр за процессом обучения
    - Функция потерь
    - Точность поезда/вала
    - Соотношение весов:обновлений 
 ">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2025-03-10T19:42:16+03:00">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Перейти к главному содержимому</a>

<!-- Header and menu bar -->
<div class="container">
      <header class="blog-header py-3"><div class="row nbb-header align-items-center">
          <div class="col-md-3 col-xs-2 col-sm-2" style="width: auto;">
            <button class="navbar-toggler navbar-light bg-light nbb-navbar-toggler" type="button" data-toggle="collapse" data-target=".bs-nav-collapsible" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse bs-nav-collapsible bootblog4-search-form-holder">
                
            </div>
        </div>
          <div class="col-md-6 col-xs-10 col-sm-10 bootblog4-brand" style="width: auto;">
            <a class="navbar-brand blog-header-logo text-dark" href="../../">

            <span id="blog-title">Заметки по ML, DL</span>
        </a>
          </div>
            <div class="col-md-3 justify-content-end align-items-center bs-nav-collapsible collapse flex-collapse bootblog4-right-nav">
            <nav class="navbar navbar-light bg-white"><ul class="navbar-nav bootblog4-right-nav">
<li class="nav-item">
    <a href="index.md" id="sourcelink" class="nav-link">Источник</a>
    </li>


                    
            </ul></nav>
</div>
    </div>
</header><nav class="navbar navbar-expand-md navbar-light bg-white static-top"><div class="collapse navbar-collapse bs-nav-collapsible" id="bs-navbar">
            <ul class="navbar-nav nav-fill d-flex w-100">
<li class="nav-item">
<a href="../../archive.html" class="nav-link">Archive</a>
                </li>
<li class="nav-item">
<a href="../../categories/" class="nav-link">Tags</a>

                
            </li>
</ul>
</div>
<!-- /.navbar-collapse -->
</nav>
</div>

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Обучение нейронных сетей</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    Андрей Лабинцев
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2025-03-10T19:42:16+03:00" itemprop="datePublished" title="2025-03-10 19:42">2025-03-10 19:42</time></a>
            </p>
            
        <p class="sourceline"><a href="index.md" class="sourcelink">Источник</a></p>

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <h2>Обучение нейронных сетей</h2>
<p>Содержание:
- <a href=".">Проверка градиента</a>
- <a href=".">Проверки здравомыслия</a>
- <a href=".">Присмотр за процессом обучения</a>
    - <a href=".">Функция потерь</a>
    - <a href=".">Точность поезда/вала</a>
    - <a href=".">Соотношение весов:обновлений </a>
    - <a href=".">Распределение активации/градиента на слой</a>
    - <a href=".">Визуализация</a>
- <a href=".">Обновление параметров</a>
    - <a href=".">Первый порядок (SGD), импульс, импульс Нестерова</a>
    - <a href=".">Отжиг темпов обучения</a>
    - <a href=".">Методы второго порядка</a>
        - <a href=".">Дополнительные материалы</a> 
    - <a href=".">Методы адаптивной скорости обучения для каждого параметра (Adagrad, RMSProp)</a>
- <a href=".">Оптимизация гиперпараметров</a>
- <a href=".">Оценка</a>
    - <a href=".">Модельные ансамбли</a>
- <a href=".">Краткая сводка</a>
- <a href=".">Дополнительные материалы</a></p>
<h2>Обучение</h2>
<p>В предыдущих разделах мы рассмотрели статические части нейронных сетей: как мы можем настроить сетевую связность, данные и функцию потерь. Этот раздел посвящен динамике, или другими словами, процессу изучения параметров и нахождения хороших гиперпараметров.  </p>
<h2>Проверка градиента</h2>
<p>Теоретически выполнить проверку градиента так же просто, как сравнить аналитический градиент с числовым градиентом. На практике этот процесс гораздо более сложный и подвержен ошибкам. Вот несколько советов, рекомендаций и проблем, на которые следует обратить внимание:  </p>
<p><strong>Используйте формулу по центру</strong>. Формула, которую вы, возможно, видели для приближения конечных разностей при вычислении численного градиента, выглядит следующим образом:</p>
<p>$$
\frac{df(x)}{dx} = \frac{f(x + h) - f(x)}{h} \hspace{0.1in} \text{(bad, do not use)}
$$  </p>
<p>где <strong>h</strong> это очень небольшое число, на практике примерно <strong>1e-5</strong> или около того. На практике оказывается, что гораздо лучше использовать формулу центрированной разности вида:  </p>
<p>$$
\frac{df(x)}{dx} = \frac{f(x + h) - f(x - h)}{2h} \hspace{0.1in} \text{(use instead)}
$$  </p>
<p>Для этого вам придется дважды оценить функцию потерь, чтобы проверить каждое измерение градиента (так что это примерно в 2 раза дороже), но аппроксимация градиента оказывается гораздо более точной. Чтобы убедиться в этом, можно использовать разложение Тейлора  <strong>\(f(x+h)\)</strong> и  <strong>\(f(x-h)\)</strong> и убедитесь, что первая формула содержит ошибку порядка <strong>O(h)</strong>, в то время как вторая формула содержит только члены ошибки порядка <strong>\(O(h^2)\)</strong> (<em>т.е. это приближение второго порядка</em>).  </p>
<p>Используйте относительную погрешность для сравнения. В чем особенности сравнения численного градиента <strong>\(f'_n\)</strong> и аналитический градиент <strong>\(f'_a\)</strong>? То есть, как мы узнаем, что они несовместимы? У вас может возникнуть соблазн отслеживать разницу <strong>\(\mid f'_a - f'_n \mid \)</strong> или его квадрат и определите проверку градиента как неудачную, если эта разница превышает пороговое значение. Однако это проблематично. Для примера рассмотрим случай, когда их разница равна <strong>1e-4</strong>. Это кажется очень подходящей разницей, если два градиента близки к <strong>1.0</strong>, поэтому мы считаем, что два градиента совпадают. Но если бы оба градиента были порядка <strong>1e-5</strong> или ниже, то мы бы считали <strong>1e-4</strong> огромной разницей и, скорее всего, неудачей. Следовательно, всегда более уместно учитывать <em>относительную ошибку</em>:  </p>
<p>$$
\frac{\mid f'_a - f'_n \mid}{\max(\mid f'_a \mid, \mid f'_n \mid)}
$$  </p>
<p>которая рассматривает отношение их разностей к отношению абсолютных значений обоих градиентов. Обратите внимание, что обычно формула относительной ошибки включает только один из двух членов (любой из них), но я предпочитаю увеличивать (или добавлять) оба, чтобы сделать его симметричным и предотвратить деление на ноль в случае, когда одно из двух равно нулю (<em>что часто случается, особенно с ReLU</em>). Тем не менее, необходимо явно отслеживать случай, когда оба равны нулю, и пройти проверку градиента в этом крайнем случае. На практике:<br>
- Относительная погрешность <strong>&gt; 1e-2</strong> обычно означает, что градиент, вероятно, неправильный
- <strong>1e-2 &gt;</strong> относительная погрешность <strong>&gt; 1e-4</strong> должна заставить вас чувствовать себя некомфортно
- <strong>1e-4 &gt;</strong> относительная погрешность обычно приемлема для целей с изломами. Но если нет перегибов (например, использование нелинейностей <strong>tanh</strong> и <strong>softmax</strong>), то <strong>1e-4</strong> слишком велико.
- <strong>1e-7</strong> и меньше вы должны быть счастливы.  </p>
<p>Также имейте в виду, что чем глубже сеть, тем выше будут относительные ошибки. Таким образом, если вы проверяете входные данные для 10-слойной сети, относительная ошибка <strong>1e-2</strong> может быть нормальной, потому что ошибки накапливаются по мере прохождения. И наоборот, ошибка <strong>1e-2</strong> для одной дифференцируемой функции, скорее всего, указывает на неправильный градиент.  </p>
<p><strong>Используйте двойную точность</strong>. Распространенной ошибкой является использование плавающей точки одинарной точности для вычисления проверки градиента. Часто бывает так, что вы можете получить высокие относительные ошибки (до <strong>1e-2</strong>) даже при правильной реализации градиента. По моему опыту, я иногда видел, как мои относительные ошибки резко уменьшались с <strong>1e-2</strong> до <strong>1e-8</strong> при переходе на двойную точность.  </p>
<p><strong>Оставайтесь в активном диапазоне плавающей запятой</strong>. Хорошей идеей будет прочитать <a href="http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html">статью «Что каждый специалист по информатике должен знать об арифметике с плавающей запятой»</a>, так как это может развеять мифы об ошибках и позволить вам писать более тщательный код. Например, в нейронных сетях может быть распространена нормализация функции потерь по пакету.  </p>
<p>Однако, если градиенты для каждой точки данных очень малы, то <em>дополнительное</em> деление их на количество точек данных начинает давать очень маленькие числа, что, в свою очередь, приведет к большему количеству числовых проблем. Вот почему я предпочитаю всегда печатать исходный числовой/аналитический градиент и следить за тем, чтобы числа, которые вы сравниваете, не были слишком маленькими (например, примерно <strong>1e-10</strong> и меньше по абсолютному значению вызывает беспокойство). Если это так, вы можете временно масштабировать функцию потерь на константу, чтобы привести их к "более хорошему" диапазону, где числа с плавающей запятой более плотные - в идеале порядка <strong>1,0</strong>, где экспонента с плавающей запятой равна <strong>0</strong>.  </p>
<p><strong>Изгибы в достижении цели.</strong> Одним из источников неточностей, о которых следует знать при проверке градиента, является проблема <em>изгибов</em>. Изгибы относятся к недифференцируемым частям целевой функции, вводимым такими функциями, как <em>ReLU</em>  <strong>(\(max(0,x)\))</strong>
) или потеря <strong>SVM</strong>, нейроны <em>Maxout</em> и т.д. Рассмотрим градиентную проверку функции <em>ReLU</em> по адресу <strong>\(x = -1e6\)</strong>. С <strong>\(x &lt; 0\)</strong>, аналитический градиент в этой точке равен нулю. Однако числовой градиент внезапно вычислит ненулевой градиент, потому что <strong>\(f(x+h)\)</strong> может пересечь излом (например, если <strong>\(h &gt; 1e-6\)</strong> ) и ввести ненулевой взнос. Вы можете подумать, что это патологический случай, но на самом деле этот случай может быть очень распространенным. Например, СВМ для CIFAR-10 содержит до 450 000 <strong>(\(max(0,x)\))</strong> термины, потому что существует 50 000 примеров, и каждый пример дает 9 терминов для цели. Более того, нейронная сеть с классификатором SVM будет содержать гораздо больше изломов из-за <em>ReLU</em>.  </p>
<p>Обратите внимание, что можно узнать, был ли пересечен излом при оценке убытка. Это можно сделать, отслеживая личности всех «победителей» в функции формы <strong>(\(max(0,x)\))</strong>; То есть был <strong>x</strong> или <strong>y</strong> выше во время паса вперед. Если при оценке изменилась личность хотя бы одного победителя <strong>\(f(x+h)\)</strong>, а в последствии <strong>\(f(x-h)\)</strong>, то был пересечен излом и числовой градиент не будет точным.  </p>
<p><strong>Используйте только несколько точек данных</strong>. Одним из решений вышеупомянутой проблемы перегибов является использование меньшего количества точек данных, поскольку функции потерь, которые содержат перегибы (например, из-за использования <em>ReLU</em> или маржинальных потерь и т. д.), будут иметь меньше перегибов с меньшим количеством точек данных, поэтому вероятность того, что вы пересечете одну из них, при выполнении конечного другого приближения, снижается. Более того, если ваш <em>gradcheck</em> всего на <strong>~2</strong> или <strong>3</strong> точки данных, то вы почти наверняка проверите весь пакет. Использование очень небольшого количества точек данных также делает проверку градиента быстрее и эффективнее.  </p>
<p><strong>Будьте осторожны с размером шага h</strong>. Не обязательно минимальный размер <strong>h</strong>- это хорошо, так как в таком случае есть шанс напороться на проблему численной точности. Иногда, при проверке корректности градиента <strong>h</strong>, возможно, что значение <strong>1е-4</strong> и <strong>1е-6</strong> будет изменяться от абсолютно неверному при увеличении этого показателя. <a href="http://en.wikipedia.org/wiki/Numerical_differentiation">Эта статья в Википедии</a> содержит диаграмму, которая отображает значение <strong>h</strong> по оси <strong>x</strong> и числовую ошибку градиента по оси <strong>y</strong>.    </p>
<p><strong>Градусная проверка во время «характерного» режима работы</strong>. Важно понимать, что проверка градиента выполняется в определенной (и обычно случайной), единственной точке в пространстве параметров. Даже если проверка градиента на этом этапе выполнена успешно, не сразу можно быть уверенным в том, что градиент правильно реализован глобально. Кроме того, случайная инициализация может быть не самой «характерной» точкой в пространстве параметров и фактически может привести к патологическим ситуациям, когда градиент кажется правильно реализованным, но на самом деле это не так. Например, <em>SVM</em> с очень малой инициализацией веса присвоит почти ровно нулевые оценки всем точкам данных, а градиенты будут демонстрировать определенную закономерность во всех точках данных. Неправильная реализация градиента все равно может привести к появлению этого шаблона и не привести к более характерному режиму работы, в котором одни баллы больше других. Поэтому, чтобы быть в безопасности, лучше всего использовать короткое время <strong>прогорания</strong>, в течение которого сеть может обучиться и выполнить градиентную проверку после того, как потери начнут снижаться. Опасность его выполнения на первой итерации заключается в том, что это может привести к патологическим пограничным случаям и замаскировать неправильную реализацию градиента.  </p>
<p><strong>Не позволяйте регуляризации перегружать данные</strong>. Часто бывает так, что функция потерь является суммой потерь данных и потерь от регуляризации (например, штраф <strong>\(L_2\)</strong> за веса). Одна из опасностей, о которой следует знать, заключается в том, что потеря регуляризации может превзойти потерю данных, и в этом случае градиенты будут в основном исходить от члена регуляризации (который обычно имеет гораздо более простое выражение градиента). Это может замаскировать неправильную реализацию градиента потери данных. Поэтому рекомендуется отключить регуляризацию и проверять сначала только потерю данных, а затем второй и независимый термин регуляризации. Одним из способов выполнения последнего является взлом кода, чтобы устранить вклад потери данных. Другой способ состоит в том, чтобы увеличить силу регуляризации, чтобы гарантировать, что ее эффектом не будет пренебрежение при проверке градиента, и что будет замечена неправильная реализация.  </p>
<p><strong>Не забудьте отключить выпадение/аугментации</strong>. Выполняя градиентную проверку, не забывайте отключать любые недетерминированные эффекты в сети, такие как выпадение, случайные аугментации данных и т. д. В противном случае это может привести к огромным ошибкам при оценке численного градиента. Недостатком отключения этих эффектов является то, что вы не будете проверять их градиент (например, может случиться так, что выпадение не будет правильно распространено). Следовательно, лучшим решением может быть принудительное использование определенного случайного начального значения перед оценкой обоих <strong>\(f(x+h)\) и \(f(x-h)\)</strong>, а также при оценке аналитического градиента.  </p>
<p><strong>Проверьте только несколько размеров</strong>. На практике градиенты могут иметь размеры в миллион параметров. В этих случаях целесообразно проверить только некоторые размеры градиента и предположить, что другие являются правильными. <strong>Будьте внимательны</strong>: Один из вопросов, с которым следует быть осторожным, заключается в том, чтобы убедиться, что градиент проверяет несколько размеров для каждого отдельного параметра. В некоторых приложениях люди объединяют параметры в один большой вектор параметров для удобства. В этих случаях, например, смещения могут занимать лишь небольшое количество параметров из всего вектора, поэтому важно не выбирать случайным образом, а учитывать это и проверять, что все параметры получают правильные градиенты.  </p>
<h2>Перед изучением: советы и рекомендации по проверке здравомыслия</h2>
<p>Вот несколько проверок здравого смысла, которые вы могли бы провести, прежде чем погрузиться в дорогостоящую оптимизацию:
- <strong>Ищите правильный проигрыш при случайном исполнении</strong>. Убедитесь, что вы получаете ожидаемые потери при инициализации с небольшими параметрами. Лучше всего сначала проверить только потерю данных (поэтому установите интенсивность регуляризации равной нулю). Например, для CIFAR-10 с классификатором <strong>Softmax</strong> мы ожидаем, что начальный убыток составит <strong>2,302</strong>, потому что мы ожидаем диффузную вероятность <strong>0,1</strong> для каждого класса (поскольку классов 10), а <strong>Softmax</strong> убыток — это отрицательная логарифмическая вероятность правильного класса, таким образом: <strong>-ln(0,1) = 2,302</strong>. Для <em>The Weston Watkins SVM</em> мы ожидаем, что все желаемые маржи будут нарушены (поскольку все баллы примерно равны нулю), и, следовательно, ожидаем потери <strong>9</strong> (поскольку маржа равна <strong>1</strong> для каждого неправильного класса). Если вы не видите этих потерь, возможно, возникла проблема с инициализацией.  </p>
<ul>
<li>В качестве второй проверки здравомыслия, увеличение силы регуляризации должно привести к увеличению потерь </li>
<li>
<strong>Переобучение крошечного подмножества данных</strong>. И последнее, и самое важное, прежде чем обучаться на полном наборе данных, попытайтесь обучиться на крошечной части (например, на <strong>20</strong> примерах) ваших данных и убедитесь, что вы можете достичь нулевой стоимости. Для этого эксперимента также лучше всего установить регуляризацию равной нулю, иначе это может помешать получению нулевой стоимости. Если вы не пройдете эту проверку на здравомыслие с небольшим набором данных, не стоит переходить к полному набору данных. Обратите внимание, что может случиться так, что вы можете переобучать очень маленький набор данных, но все равно иметь неправильную реализацию. Например, если признаки точек данных являются случайными из-за какой-либо ошибки, то можно перенаучить небольшой обучающий набор, но вы никогда не заметите обобщения при свертывании всего набора данных.  </li>
</ul>
<h2>Присмотр за процессом обучения</h2>
<p>Существует множество полезных величин, которые вы должны отслеживать во время обучения нейронной сети. Эти графики являются окном в процесс обучения и должны использоваться для получения интуиции о различных настройках гиперпараметров и о том, как их следует изменить для более эффективного обучения.  </p>
<p><strong>Ось x</strong> приведенных ниже графиков всегда указывается в единицах эпох, которые измеряют, сколько раз каждый пример был замечен во время обучения в ожидании (например, одна эпоха означает, что каждый пример был просмотрен один раз). Предпочтительнее отслеживать эпохи, а не итерации, так как количество итераций зависит от произвольной настройки размера пакета.  </p>
<h3>Функция потерь</h3>
<p>Первая величина, которую полезно отслеживать во время тренировки, — это потери, так как они оцениваются по отдельным партиям во время паса вперед. Ниже приведена мультяшная диаграмма, показывающая потери с течением времени, и особенно то, что форма может рассказать вам о скорости обучения:  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/nn3/learningrates.jpeg"><br><img alt="" src="https://cs231n.github.io/assets/nn3/loss.jpeg"></p>
<p><strong>Сверху</strong>: Мультфильм, изображающий эффекты различных скоростей обучения. При низких темпах обучения улучшения будут линейными. С высокими темпами обучения они начнут выглядеть более экспоненциально. Более высокие темпы обучения будут уменьшать потери быстрее, но они застревают на худших значениях потерь (зеленая линия). Это связано с тем, что в оптимизации слишком много «энергии», а параметры хаотично колеблются, не в силах занять хорошее место в ландшафте оптимизации. <strong>Снизу</strong>: Пример типичной функции потерь во времени при обучении небольшой сети на наборе данных CIFAR-10. Эта функция потерь выглядит разумной (она может указывать на слишком маленькую скорость обучения, основанную на скорости распада, но трудно сказать), а также указывает на то, что размер партии может быть слишком низким (поскольку стоимость слишком зашумлена).  </p>
<hr>
<p>Величина «покачивания» в потерях связана с размером партии. Когда размер партии равен <strong>1</strong>, покачивание будет относительно большим. Если размер пакета равен полному набору данных, покачивание будет минимальным, так как каждое обновление градиента должно монотонно улучшать функцию потерь (если только скорость обучения не установлена слишком высокой).  </p>
<p>Некоторые пользователи предпочитают строить графики своих функций потерь в области журнала. Поскольку прогресс в обучении обычно принимает экспоненциальную форму, график выглядит как чуть более интерпретируемая прямая линия, а не как хоккейная клюшка. Кроме того, если на одном и том же графике потерь построить несколько моделей с перекрестной проверкой, различия между ними становятся более очевидными.  </p>
<p>Иногда функции проигрыша могут выглядеть забавно <a href="http://lossfunctions.tumblr.com/">lossfunctions.tumblr.com.</a>  </p>
<h3>Точность поезда/вала</h3>
<p>Вторая важная величина, которую необходимо отслеживать при обучении классификатора, — это точность валидации/обучения. Этот график может дать вам ценную информацию о количестве переобучения в вашей модели:  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/nn3/accuracies.jpeg"></p>
<p>Разрыв между точностью обучения и валидации указывает на степень переобучения. Два возможных случая показаны на схеме слева. Синяя кривая ошибок валидации показывает очень низкую точность валидации по сравнению с точностью обучения, что указывает на сильное переобучение (обратите внимание, что точность валидации может даже начать снижаться после какого-то момента). Когда вы видите это на практике, вы, вероятно, захотите увеличить регуляризацию (сильнее штраф в весе <strong>\(L_2\)</strong>, больше отсева и т.д.) или собрать больше данных. Другой возможный случай — когда точность валидации достаточно хорошо отслеживает точность обучения. Этот случай указывает на то, что емкость вашей модели недостаточно высока: увеличьте модель, увеличив количество параметров.  </p>
<hr>
<h3>Соотношение весов:обновления</h3>
<p>Последняя величина, которую вы, возможно, захотите отслеживать, — это отношение величин обновления к величине значений. <strong>Примечание</strong>: обновления, а не исходные градиенты (например, в ванильном <em>sgd</em> это будет градиент, умноженный на скорость обучения). Возможно, вы захотите оценить и отследить это соотношение для каждого набора параметров независимо. Грубая эвристика заключается в том, что это соотношение должно быть где-то в районе <strong>1e-3</strong>. Если он ниже, то скорость обучения может быть слишком низкой. Если он выше, то, скорее всего, уровень обучения слишком высок. Вот конкретный пример:  </p>
<div class="code"><pre class="code literal-block"><span class="err">#</span><span class="w"> </span><span class="nx">assume</span><span class="w"> </span><span class="nx">parameter</span><span class="w"> </span><span class="nx">vector</span><span class="w"> </span><span class="nx">W</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="nx">its</span><span class="w"> </span><span class="nx">gradient</span><span class="w"> </span><span class="nx">vector</span><span class="w"> </span><span class="nx">dW</span>
<span class="nx">param_scale</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="nx">np</span><span class="p">.</span><span class="nx">linalg</span><span class="p">.</span><span class="nx">norm</span><span class="p">(</span><span class="nx">W</span><span class="p">.</span><span class="nx">ravel</span><span class="p">())</span>
<span class="nx">update</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="o">-</span><span class="nx">learning_rate</span><span class="o">*</span><span class="nx">dW</span><span class="w"> </span><span class="err">#</span><span class="w"> </span><span class="nx">simple</span><span class="w"> </span><span class="nx">SGD</span><span class="w"> </span><span class="nx">update</span>
<span class="nx">update_scale</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="nx">np</span><span class="p">.</span><span class="nx">linalg</span><span class="p">.</span><span class="nx">norm</span><span class="p">(</span><span class="nx">update</span><span class="p">.</span><span class="nx">ravel</span><span class="p">())</span>
<span class="nx">W</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nx">update</span><span class="w"> </span><span class="err">#</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">actual</span><span class="w"> </span><span class="nx">update</span>
<span class="nx">print</span><span class="w"> </span><span class="nx">update_scale</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="nx">param_scale</span><span class="w"> </span><span class="err">#</span><span class="w"> </span><span class="nx">want</span><span class="w"> </span><span class="o">~</span><span class="mi">1</span><span class="nx">e</span><span class="o">-</span><span class="mi">3</span>
</pre></div>

<p>Вместо того, чтобы отслеживать минимальное или максимальное значение, некоторые люди предпочитают вычислять и отслеживать норму градиентов и их обновлений. Эти метрики обычно коррелируют и часто дают примерно одинаковые результаты.  </p>
<h3>Распределение активации/градиента на слой</h3>
<p>Неправильная инициализация может замедлить или даже полностью затормозить процесс обучения. К счастью, эту проблему можно диагностировать относительно легко. Одним из способов сделать это является построение гистограмм активации/градиента для всех слоев сети. Интуитивно понятно, что не очень хорошо видеть какие-либо странные распределения - например, с нейронами <em>tanh</em> мы хотели бы видеть распределение активаций нейронов между полным диапазоном <strong>[-1,1]</strong>, вместо того, чтобы видеть, как все нейроны выдают ноль, или все нейроны полностью насыщаются либо при <strong>-1</strong>, либо при <strong>1</strong>.  </p>
<h3>Визуализации первого уровня</h3>
<p>Наконец, при работе с пикселями изображения может быть полезно и приятно визуально отобразить объекты первого слоя:  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/nn3/weights.jpeg"><br><img alt="" src="https://cs231n.github.io/assets/nn3/cnnweights.jpg"><br>
Примеры визуализированных весов для первого слоя нейронной сети. <strong>Сверху</strong>: Зашумленные функции указывают на то, что симптомом может быть неконвергентная сеть, неправильно установленная скорость обучения, очень низкий вес штрафа за регуляризацию. <strong>Снизу</strong>: Красивые, гладкие, чистые и разнообразные черты лица являются хорошим признаком того, что тренировка идет хорошо.  </p>
<hr>
<h2>Обновление параметров</h2>
<p>После вычисления аналитического градиента с помощью обратного распространения градиенты используются для обновления параметров. Существует несколько подходов к выполнению обновления, о которых мы поговорим далее.  </p>
<p>Отметим, что оптимизация для глубоких сетей в настоящее время является очень активным направлением исследований. В этом разделе мы выделим некоторые устоявшиеся и распространенные техники, которые вы можете увидеть на практике, кратко опишем их интуицию, но оставим подробный разбор за рамками занятия. Мы даем несколько дополнительных указаний для заинтересованного читателя.  </p>
<h3>Первый порядок (SGD), импульс, импульс Нестерова</h3>
<p><strong>Ванильное обновление</strong>. Простейшей формой обновления является изменение параметров в направлении отрицательного градиента (поскольку градиент указывает направление увеличения, но обычно мы хотим минимизировать функцию потерь). Предполагая вектор параметров и градиент, простейшее обновление имеет вид:<code>x</code> <code>dx</code>  </p>
<div class="code"><pre class="code literal-block"><span class="gh">#</span> Vanilla update
x += - learning_rate * dx
</pre></div>

<p>где гиперпараметр - фиксированная константа. При оценке на полном наборе данных и при достаточно низкой скорости обучения это гарантированно приведет к неотрицательному прогрессу в функции потерь.<code>learning_rate</code>  </p>
<p><strong>Обновление импульса</strong> (<em>Momentum update</em>) — еще один подход, который почти всегда имеет более высокую скорость сходимости в глубоких сетях. Это обновление может быть мотивировано с физической точки зрения задачи оптимизации. В частности, потери можно интерпретировать как высоту холмистой местности (и, следовательно, также как потенциальную энергию, так как <strong>U=mgh</strong>. И поэтому <strong>\( U \propto h \)</strong> ). Инициализация параметров случайными числами эквивалентна установке частицы с нулевой начальной скоростью в каком-либо месте. В этом случае процесс оптимизации можно рассматривать как эквивалент процесса моделирования вектора параметров (т.е. частицы) как движущейся по ландшафту.  </p>
<p>Поскольку сила, действующая на частицу, связана с градиентом потенциальной энергии (т.е. <strong>F=−∇U</strong> ), <strong>сила</strong>, ощущаемая частицей, в точности является (<em>отрицательным</em>) <strong>градиентом</strong> функции потерь. Сверх того <strong>F=ma</strong>. Таким образом, (<em>отрицательный</em>) градиент с этой точки зрения пропорционален ускорению частицы. Обратите внимание, что это отличается от показанного выше обновления <em>SGD</em>, где градиент напрямую интегрирует положение. Вместо этого физический взгляд предлагает обновление, в котором градиент только напрямую влияет на скорость, что, в свою очередь, влияет на положение:  </p>
<p>```</p>
<h2>Momentum update</h2>
<p>v = mu * v - learning_rate * dx # integrate velocity
x += v # integrate position</p>
<div class="code"><pre class="code literal-block"><span class="n">Здесь</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">видим</span><span class="w"> </span><span class="n">введение</span><span class="w"> </span><span class="n">переменной</span><span class="w"> </span><span class="n n-Quoted">`v`</span><span class="p">,</span><span class="w"> </span><span class="n">которая</span><span class="w"> </span><span class="n">инициализируется</span><span class="w"> </span><span class="n">нулем</span><span class="p">,</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">дополнительный</span><span class="w"> </span><span class="n">гиперпараметр</span><span class="w"> </span><span class="p">(</span><span class="n n-Quoted">`mu`</span><span class="p">).</span><span class="w"> </span><span class="n">К</span><span class="w"> </span><span class="n">сожалению</span><span class="p">,</span><span class="w"> </span><span class="n">эта</span><span class="w"> </span><span class="n">переменная</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">оптимизации</span><span class="w"> </span><span class="n">называется</span><span class="w"> </span><span class="n">_импульсом_</span><span class="w"> </span><span class="p">(</span><span class="n">ее</span><span class="w"> </span><span class="n">типичное</span><span class="w"> </span><span class="n">значение</span><span class="w"> </span><span class="n">составляет</span><span class="w"> </span><span class="n">около</span><span class="w"> </span><span class="o">**</span><span class="mi">0</span><span class="p">,</span><span class="mi">9</span><span class="o">**</span><span class="p">),</span><span class="w"> </span><span class="n">но</span><span class="w"> </span><span class="n">ее</span><span class="w"> </span><span class="n">физическое</span><span class="w"> </span><span class="n">значение</span><span class="w"> </span><span class="n">больше</span><span class="w"> </span><span class="n">соответствует</span><span class="w"> </span><span class="n">коэффициенту</span><span class="w"> </span><span class="n">трения</span><span class="p">.</span><span class="w"> </span><span class="n">По</span><span class="w"> </span><span class="n">сути</span><span class="p">,</span><span class="w"> </span><span class="n">эта</span><span class="w"> </span><span class="n">переменная</span><span class="w"> </span><span class="n">гасит</span><span class="w"> </span><span class="n">скорость</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">снижает</span><span class="w"> </span><span class="n">кинетическую</span><span class="w"> </span><span class="n">энергию</span><span class="w"> </span><span class="n">системы</span><span class="p">,</span><span class="w"> </span><span class="n">иначе</span><span class="w"> </span><span class="n">частица</span><span class="w"> </span><span class="n">никогда</span><span class="w"> </span><span class="n">бы</span><span class="w"> </span><span class="n">не</span><span class="w"> </span><span class="n">остановилась</span><span class="w"> </span><span class="n">у</span><span class="w"> </span><span class="n">подножия</span><span class="w"> </span><span class="n">холма</span><span class="p">.</span><span class="w"> </span><span class="n">При</span><span class="w"> </span><span class="n">перекрестной</span><span class="w"> </span><span class="n">проверке</span><span class="w"> </span><span class="n">этому</span><span class="w"> </span><span class="n">параметру</span><span class="w"> </span><span class="n">обычно</span><span class="w"> </span><span class="n">присваиваются</span><span class="w"> </span><span class="n">такие</span><span class="w"> </span><span class="n">значения</span><span class="p">,</span><span class="w"> </span><span class="n">как</span><span class="w"> </span><span class="o">**</span><span class="err">[</span><span class="mf">0.5</span><span class="p">,</span><span class="w"> </span><span class="mf">0.9</span><span class="p">,</span><span class="w"> </span><span class="mf">0.95</span><span class="p">,</span><span class="w"> </span><span class="mf">0.99</span><span class="err">]</span><span class="o">**</span><span class="p">.</span><span class="w"> </span><span class="n">Подобно</span><span class="w"> </span><span class="n">графикам</span><span class="w"> </span><span class="n">отжига</span><span class="w"> </span><span class="n">для</span><span class="w"> </span><span class="n">темпов</span><span class="w"> </span><span class="n">обучения</span><span class="w"> </span><span class="p">(</span><span class="o">*</span><span class="n">обсуждается</span><span class="w"> </span><span class="n">ниже</span><span class="o">*</span><span class="p">),</span><span class="w"> </span><span class="n">оптимизация</span><span class="w"> </span><span class="n">иногда</span><span class="w"> </span><span class="n">может</span><span class="w"> </span><span class="n">немного</span><span class="w"> </span><span class="n">выиграть</span><span class="w"> </span><span class="n">от</span><span class="w"> </span><span class="n">графиков</span><span class="w"> </span><span class="n">импульса</span><span class="p">,</span><span class="w"> </span><span class="n">где</span><span class="w"> </span><span class="n">импульс</span><span class="w"> </span><span class="n">увеличивается</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">более</span><span class="w"> </span><span class="n">поздних</span><span class="w"> </span><span class="n">этапах</span><span class="w"> </span><span class="n">обучения</span><span class="p">.</span><span class="w"> </span><span class="n">Типичная</span><span class="w"> </span><span class="n">настройка</span><span class="w"> </span><span class="n">заключается</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">том</span><span class="p">,</span><span class="w"> </span><span class="n">чтобы</span><span class="w"> </span><span class="n">начать</span><span class="w"> </span><span class="n">с</span><span class="w"> </span><span class="n">импульса</span><span class="w"> </span><span class="n">около</span><span class="w"> </span><span class="o">**</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="o">**</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">отжечь</span><span class="w"> </span><span class="n">его</span><span class="w"> </span><span class="n">до</span><span class="w"> </span><span class="o">**</span><span class="mi">0</span><span class="p">,</span><span class="mi">99</span><span class="o">**</span><span class="w"> </span><span class="n">или</span><span class="w"> </span><span class="n">около</span><span class="w"> </span><span class="n">того</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">течение</span><span class="w"> </span><span class="n">нескольких</span><span class="w"> </span><span class="n">эпох</span><span class="p">.</span><span class="n n-Quoted">`v`</span><span class="w"> </span><span class="n n-Quoted">`mu`</span><span class="w">  </span>

<span class="o">&gt;</span><span class="n">При</span><span class="w"> </span><span class="n">обновлении</span><span class="w"> </span><span class="n">Momentum</span><span class="w"> </span><span class="n">вектор</span><span class="w"> </span><span class="n">параметра</span><span class="w"> </span><span class="n">будет</span><span class="w"> </span><span class="n">наращивать</span><span class="w"> </span><span class="n">скорость</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">любом</span><span class="w"> </span><span class="n">направлении</span><span class="p">,</span><span class="w"> </span><span class="n">которое</span><span class="w"> </span><span class="n">имеет</span><span class="w"> </span><span class="n">постоянный</span><span class="w"> </span><span class="n">градиент</span><span class="p">.</span><span class="w">  </span>

<span class="n">__Импульс</span><span class="w"> </span><span class="n">Нестерова__</span><span class="w"> </span><span class="p">(</span><span class="o">*</span><span class="n">Nesterov</span><span class="w"> </span><span class="n">Momentum</span><span class="o">*</span><span class="p">)</span><span class="w"> </span><span class="n">–</span><span class="w"> </span><span class="n">это</span><span class="w"> </span><span class="n">немного</span><span class="w"> </span><span class="n">другая</span><span class="w"> </span><span class="n">версия</span><span class="w"> </span><span class="n">обновления</span><span class="w"> </span><span class="o">*</span><span class="n">Momentum</span><span class="o">*</span><span class="p">,</span><span class="w"> </span><span class="n">которое</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">последнее</span><span class="w"> </span><span class="n">время</span><span class="w"> </span><span class="n">набирает</span><span class="w"> </span><span class="n">популярность</span><span class="p">.</span><span class="w"> </span><span class="n">Он</span><span class="w"> </span><span class="n">обладает</span><span class="w"> </span><span class="n">более</span><span class="w"> </span><span class="n">сильными</span><span class="w"> </span><span class="n">теоретическими</span><span class="w"> </span><span class="n">гарантиями</span><span class="w"> </span><span class="n">сходимости</span><span class="w"> </span><span class="n">для</span><span class="w"> </span><span class="n">выпуклых</span><span class="w"> </span><span class="n">функций</span><span class="w"> </span><span class="n">и</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">практике</span><span class="w"> </span><span class="n">также</span><span class="w"> </span><span class="n">стабильно</span><span class="w"> </span><span class="n">работает</span><span class="w"> </span><span class="n">немного</span><span class="w"> </span><span class="n">лучше</span><span class="w"> </span><span class="n">стандартного</span><span class="w"> </span><span class="n">импульса</span><span class="p">.</span><span class="w">  </span>

<span class="n">Основная</span><span class="w"> </span><span class="n">идея</span><span class="w"> </span><span class="n">метода</span><span class="w"> </span><span class="n">Нестерова</span><span class="w"> </span><span class="n">заключается</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">том</span><span class="p">,</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">когда</span><span class="w"> </span><span class="n">текущий</span><span class="w"> </span><span class="n">вектор</span><span class="w"> </span><span class="n">параметров</span><span class="w"> </span><span class="n">находится</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">некотором</span><span class="w"> </span><span class="n">положении</span><span class="w"> </span><span class="n n-Quoted">`x`</span><span class="p">,</span><span class="w"> </span><span class="n">то</span><span class="p">,</span><span class="w"> </span><span class="n">глядя</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n">приведённое</span><span class="w"> </span><span class="n">выше</span><span class="w"> </span><span class="n">обновление</span><span class="w"> </span><span class="n">импульса</span><span class="p">,</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">знаем</span><span class="p">,</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">только</span><span class="w"> </span><span class="n">импульс</span><span class="w"> </span><span class="p">(</span><span class="n">то</span><span class="w"> </span><span class="n">есть</span><span class="w"> </span><span class="n">без</span><span class="w"> </span><span class="n">учёта</span><span class="w"> </span><span class="n">второго</span><span class="w"> </span><span class="n">слагаемого</span><span class="w"> </span><span class="n">с</span><span class="w"> </span><span class="n">градиентом</span><span class="p">)</span><span class="w"> </span><span class="n">должен</span><span class="w"> </span><span class="n">сдвинуть</span><span class="w"> </span><span class="n">вектор</span><span class="w"> </span><span class="n">параметров</span><span class="w"> </span><span class="n">на</span><span class="w"> </span><span class="n n-Quoted">`mu * v`</span><span class="p">.</span><span class="w"> </span><span class="n">Поэтому</span><span class="p">,</span><span class="w"> </span><span class="n">если</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">собираемся</span><span class="w"> </span><span class="n">вычислить</span><span class="w"> </span><span class="n">градиент</span><span class="p">,</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">можем</span><span class="w"> </span><span class="n">рассматривать</span><span class="w"> </span><span class="n">будущее</span><span class="w"> </span><span class="n">приблизительное</span><span class="w"> </span><span class="n">положение</span><span class="w"> </span><span class="n n-Quoted">`x + mu * v`</span><span class="w"> </span><span class="n">как</span><span class="w"> </span><span class="n">«забежание</span><span class="w"> </span><span class="n">вперёд»</span><span class="w"> </span><span class="n">—</span><span class="w"> </span><span class="n">это</span><span class="w"> </span><span class="n">точка</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">окрестности</span><span class="w"> </span><span class="n">того</span><span class="w"> </span><span class="n">места</span><span class="p">,</span><span class="w"> </span><span class="n">где</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">вскоре</span><span class="w"> </span><span class="n">окажемся</span><span class="p">.</span><span class="w"> </span><span class="n">Следовательно</span><span class="p">,</span><span class="w"> </span><span class="n">имеет</span><span class="w"> </span><span class="n">смысл</span><span class="w"> </span><span class="n">вычислять</span><span class="w"> </span><span class="n">градиент</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n n-Quoted">`x + mu * v`</span><span class="w"> </span><span class="n">вместо</span><span class="w"> </span><span class="n">«старой</span><span class="o">/</span><span class="n">устаревшей»</span><span class="w"> </span><span class="n">позиции</span><span class="w"> </span><span class="n n-Quoted">`x`</span><span class="p">.</span><span class="w">  </span>
<span class="n">___</span><span class="w">  </span>

<span class="w">  </span><span class="o">!</span><span class="err">[]</span><span class="p">(</span><span class="n">https</span><span class="o">://</span><span class="n">cs231n</span><span class="p">.</span><span class="n">github</span><span class="p">.</span><span class="k">io</span><span class="o">/</span><span class="n">assets</span><span class="o">/</span><span class="n">nn3</span><span class="o">/</span><span class="n">nesterov</span><span class="p">.</span><span class="n">jpeg</span><span class="p">)</span><span class="w">  </span>

<span class="n">Нестеровский</span><span class="w"> </span><span class="n">импульс</span><span class="p">.</span><span class="w"> </span><span class="n">Вместо</span><span class="w"> </span><span class="n">того</span><span class="p">,</span><span class="w"> </span><span class="n">чтобы</span><span class="w"> </span><span class="n">оценивать</span><span class="w"> </span><span class="n">градиент</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">текущем</span><span class="w"> </span><span class="n">положении</span><span class="w"> </span><span class="p">(</span><span class="n">красный</span><span class="w"> </span><span class="n">круг</span><span class="p">),</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">знаем</span><span class="p">,</span><span class="w"> </span><span class="n">что</span><span class="w"> </span><span class="n">наш</span><span class="w"> </span><span class="n">импульс</span><span class="w"> </span><span class="n">вот</span><span class="o">-</span><span class="n">вот</span><span class="w"> </span><span class="n">приведет</span><span class="w"> </span><span class="n">нас</span><span class="w"> </span><span class="n">к</span><span class="w"> </span><span class="n">кончику</span><span class="w"> </span><span class="n">зеленой</span><span class="w"> </span><span class="n">стрелки</span><span class="p">.</span><span class="w"> </span><span class="n">Таким</span><span class="w"> </span><span class="n">образом</span><span class="p">,</span><span class="w"> </span><span class="n">с</span><span class="w"> </span><span class="n">помощью</span><span class="w"> </span><span class="n">импульса</span><span class="w"> </span><span class="n">Нестерова</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">оцениваем</span><span class="w"> </span><span class="n">градиент</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">этой</span><span class="w"> </span><span class="n">«просматриваемой»</span><span class="w"> </span><span class="n">позиции</span><span class="p">.</span><span class="w">  </span>
<span class="w">  </span><span class="n">___</span><span class="w">  </span>

<span class="n">То</span><span class="w"> </span><span class="n">есть</span><span class="p">,</span><span class="w"> </span><span class="n">в</span><span class="w"> </span><span class="n">немного</span><span class="w"> </span><span class="n">неудобной</span><span class="w"> </span><span class="n">нотации</span><span class="p">,</span><span class="w"> </span><span class="n">мы</span><span class="w"> </span><span class="n">хотели</span><span class="w"> </span><span class="n">бы</span><span class="w"> </span><span class="n">сделать</span><span class="w"> </span><span class="n">следующее</span><span class="o">:</span><span class="w">  </span>

<span class="w">  </span><span class="n n-Quoted">`</span><span class="n n-Quoted n-Quoted-Escape">``</span>
<span class="n n-Quoted">  x_ahead = x + mu * v</span>
<span class="n n-Quoted"># evaluate dx_ahead (the gradient at x_ahead instead of at x)</span>
<span class="n n-Quoted">v = mu * v - learning_rate * dx_ahead</span>
<span class="n n-Quoted">x += v</span>
</pre></div>

<p>Однако на практике люди предпочитают выражать обновление так, чтобы оно было максимально похоже на ванильный <em>SGD</em> или на предыдущее импульсное обновление. Этого можно достичь, манипулируя приведенным выше обновлением с помощью переменной <em>transform</em> , а затем выражая обновление в терминах вместо . То есть, вектор параметров, который мы на самом деле сохраняем, всегда является опережающей версией. Уравнения в терминах (но переименовывая его обратно в ) становятся такими:<code>x_ahead = x + mu * v</code> <code>x_ahead</code> <code>x</code> <code>x_ahead</code> <code>x</code>  </p>
<div class="code"><pre class="code literal-block">v_prev = v # back this up
v = mu <span class="gs">* v - learning_rate *</span> dx # velocity update stays the same
x += -mu <span class="gs">* v_prev + (1 + mu) *</span> v # position update changes form
</pre></div>

<p>Мы рекомендуем эту дополнительную литературу, чтобы понять источник этих уравнений и математическую формулировку ускоренного импульса Нестерова (<em>NAG</em>):  </p>
<h3>Отжиг темпов обучения</h3>
<p>При обучении глубоких сетей обычно полезно отжигать скорость обучения с течением времени. Хорошая интуиция заключается в том, что при высокой скорости обучения система содержит слишком много кинетической энергии, и вектор параметров хаотично скачет, не имея возможности оседать в более глубоких, но более узких частях функции потерь. Понять, когда нужно снижать скорость обучения, может быть непросто: снижайте ее медленно, и вы будете тратить впустую вычисления, хаотично прыгая с небольшим улучшением в течение длительного времени. Но если загнить слишком агрессивно, система охладится слишком быстро, не сумев достичь наилучшего положения. Существует три распространенных типа реализации снижения скорости обучения:  </p>
<ul>
<li>
<p><strong>Шаг затухания</strong>: Уменьшайте скорость обучения в несколько раз каждые несколько эпох. Типичными значениями могут быть снижение скорости обучения вдвое каждые <strong>5</strong> эпох или на <strong>0,1</strong> каждые <strong>20</strong> эпох. Эти цифры в значительной степени зависят от типа задачи и модели. Одна из эвристик, которую вы можете увидеть на практике, заключается в том, чтобы наблюдать за ошибкой валидации во время обучения с фиксированной скоростью обучения и уменьшать скорость обучения на константу (например, <strong>0,5</strong>) всякий раз, когда ошибка валидации перестает улучшаться.   </p>
</li>
<li>
<p><strong>Экспоненциальный затухание</strong>. имеет математическую форму <strong>\(\alpha = \alpha_0 e^{-k t}\)</strong>, где <strong>\(\alpha_0, k\)</strong> являются гиперпараметрами и <strong>t</strong> — номер итерации (но можно использовать и единицы измерения эпох).</p>
</li>
<li>
<strong>Распад на 1/т</strong> имеет математический вид <strong>\(\alpha = \alpha_0 / (1 + k t )\</strong>), где <strong>\(a_0, k\)</strong> являются гиперпараметрами и <strong>t</strong> — номер итерации.</li>
</ul>
<p>На практике мы обнаруживаем, что шаг затухания немного предпочтительнее, потому что связанные с ним гиперпараметры (доля затухания и время шага в единицах эпох) более интерпретируемы, чем гиперпараметр <strong>k</strong>. Наконец, если вы можете позволить себе вычислительный бюджет, ошибитесь в сторону более медленного распада и тренируйтесь в течение более длительного времени.   </p>
<h3>Методы второго порядка</h3>
<p>Вторая, популярная группа методов оптимизации в контексте глубокого обучения основана <a href="http://en.wikipedia.org/wiki/Newton%27s_method_in_optimization">на методе Ньютона</a>, который повторяет следующее обновление:  </p>
<p>$$
x \leftarrow x - [H f(x)]^{-1} \nabla f(x)
$$  </p>
<p>Здесь <strong>Hf(x)</strong> — <a href="http://en.wikipedia.org/wiki/Hessian_matrix">матрица Гессена</a>, представляющая собой квадратную матрицу частных производных функции второго порядка. Термин <strong>∇f(x)</strong>— вектор градиента, как показано в <strong>Gradient Descent</strong>. Интуитивно <em>гессенский метод</em> описывает локальную кривизну функции потерь, что позволяет нам выполнить более эффективное обновление. В частности, умножение на обратное гессенское значение приводит к тому, что оптимизация делает более агрессивные шаги в направлениях малой кривизны и более короткие шаги в направлениях крутой кривизны. Обратите внимание, что особенно важно, на отсутствие каких-либо гиперпараметров скорости обучения в формуле обновления, что сторонники этих методов называют большим преимуществом по сравнению с методами первого порядка.    </p>
<p>Тем не менее, приведенное выше обновление непрактично для большинства приложений глубокого обучения, потому что вычисление (и инвертирование) гессена в его явной форме является очень дорогостоящим процессом как в пространстве, так и во времени. Например, нейронная сеть с одним миллионом параметров будет иметь гессенову матрицу размером [1 000 000 x 1 000 000], занимающую примерно 3725 гигабайт оперативной памяти. Следовательно, было разработано большое разнообразие квазиньютоновских методов, которые стремятся аппроксимировать обратный гессенский метод. Среди них наиболее популярным является <a href="http://en.wikipedia.org/wiki/Limited-memory_BFGS">L-BFGS</a>, который использует информацию в градиентах с течением времени для неявного формирования аппроксимации (т.е. полная матрица никогда не вычисляется).  </p>
<p>Тем не менее, даже после того, как мы устраним проблемы с памятью, большим недостатком наивного применения L-BFGS является то, что его приходится вычислять по всему обучающему набору, который может содержать миллионы примеров. В отличие от мини-партий SGD, заставить L-BFGS работать с мини-партиями сложнее и является активной областью исследований.  </p>
<p><strong>На практике</strong> в настоящее время не часто можно увидеть, чтобы <strong>L-BFGS</strong> или аналогичные методы второго порядка применялись к крупномасштабному глубокому обучению и сверточным нейронным сетям. Вместо этого варианты <em>SGD</em>, основанные на импульсе (Нестерова), более стандартны, потому что они проще и легче масштабируются.    </p>
<h4>Дополнительные материалы:</h4>
<ul>
<li>
<a href="http://research.google.com/archive/large_deep_networks_nips2012.html">Large Scale Distributed Deep Networks</a> — это статья от команды <em>Google Brain</em>, в которой сравниваются варианты <em>L-BFGS</em> и <em>SGD</em> в крупномасштабной распределенной оптимизации.</li>
<li>
<a href="http://arxiv.org/abs/1311.2115">Алгоритм SFO</a> стремится объединить преимущества <em>SGD</em> с преимуществами <em>L-BFGS</em>.  </li>
</ul>
<h3>Методы адаптивной скорости обучения для каждого параметра</h3>
<p>Все предыдущие подходы, которые мы обсуждали до сих пор, манипулировали скоростью обучения глобально и одинаково по всем параметрам. <strong>Настройка скорости обучения</strong> — дорогостоящий процесс, поэтому много работы было потрачено на разработку методов, которые могут адаптивно настраивать скорость обучения и даже делать это для каждого параметра. Многие из этих методов могут по-прежнему требовать других настроек гиперпараметров, но аргумент заключается в том, что они хорошо работают для более широкого диапазона значений гиперпараметров, чем скорость необработанного обучения. В этом разделе мы выделим некоторые распространенные адаптивные методы, с которыми вы можете столкнуться на практике:  </p>
<p><strong>Adagrad</strong> — это метод адаптивной скорости обучения, первоначально предложенный <a href="http://jmlr.org/papers/v12/duchi11a.html">Дучи и др.</a>  </p>
<div class="code"><pre class="code literal-block"><span class="gh">#</span> Assume the gradient dx and parameter vector x
cache += dx**2
x += - learning_rate * dx / (np.sqrt(cache) + eps)
</pre></div>

<p>Обратите внимание, что переменная имеет размер, равный размеру градиента, и отслеживает сумму квадратов градиентов по каждому параметру. Затем это используется для нормализации шага обновления параметров по элементам. Обратите внимание, что для весов, получающих высокие градиенты, эффективная скорость обучения будет снижена, в то время как для весов, получающих небольшие или нечастые обновления, эффективная скорость обучения будет увеличена. Забавно, но операция извлечения квадратного корня оказывается очень важной, и без нее алгоритм работает гораздо хуже. Сглаживание (обычно задается в диапазоне от <strong>1e-4</strong> до <strong>1e-8</strong>) позволяет избежать деления на ноль. Недостатком <strong>Adagrad</strong> является то, что в случае глубокого обучения монотонный темп обучения обычно оказывается слишком агрессивным и прекращает обучение слишком рано.<code>cache</code> <code>eps</code></p>
<p><strong>RMSprop</strong> — это очень эффективный, но в настоящее время неопубликованный метод адаптивной скорости обучения. Забавно, что все, кто использует этот метод в своей работе, в настоящее время цитируют <a href="http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf">слайд 29 лекции 6</a> курса Джеффа Хинтона на <em>Coursera</em>. Обновление <strong>RMSProp</strong> очень просто корректирует метод <strong>Adagrad</strong> в попытке снизить его агрессивную, монотонно снижающуюся скорость обучения. В частности, вместо этого он использует скользящее среднее квадратов градиентов, дающее:  </p>
<div class="code"><pre class="code literal-block">cache = decay_rate <span class="gs">* cache + (1 - decay_rate) *</span> dx**2
x += - learning_rate * dx / (np.sqrt(cache) + eps)
</pre></div>

<p>Здесь находится гиперпараметр <code>decay_rate</code>, типичные значения которого равны <strong>[0.9, 0.99, 0.999]</strong>. Обратите внимание, что обновление <code>x+=</code> идентично <strong>Adagrad</strong>, но переменная<code>cache</code> "учетка". Следовательно, <strong>RMSProp</strong> по-прежнему модулирует скорость обучения каждого веса на основе величин его градиентов, что имеет положительный уравнительный эффект, но в отличие от <strong>Adagrad</strong> обновления не становятся монотонно меньше.    </p>
<p><strong>Адам</strong>. <a href="http://arxiv.org/abs/1412.6980">Adam</a> — это недавно предложенное обновление, которое немного похоже на <strong>RMSProp</strong> с импульсом. (<em>Упрощённое</em>) обновление выглядит следующим образом:  </p>
<div class="code"><pre class="code literal-block">m = beta1*m + (1-beta1)*dx
v = beta2*v + (1-beta2)*(dx**2)
x += - learning_rate * m / (np.sqrt(v) + eps)
</pre></div>

<p>Обратите внимание, что обновление выглядит точно так же, как обновление <strong>RMSProp</strong>, за исключением того, что вместо необработанного (и, возможно, зашумленного) вектора градиента <code>dx</code> используется “сглаженная” версия градиента <code>m</code>. Рекомендуемые значения в документе - <code>eps = 1e-8</code>, <code>beta1 = 0,9</code>, <code>beta2 = 0,999</code>. На практике Adam в настоящее время рекомендуется использовать в качестве алгоритма по умолчанию и часто работает немного лучше, чем <strong>RMSProp</strong>. Однако часто также стоит попробовать <em>SGD+Nesterov Momentum</em> в качестве альтернативы. Полное обновление Adam также включает механизм <em>коррекции смещения</em>, который компенсирует тот факт, что на первых нескольких временных шагах векторы <code>m,v</code> инициализируются и, следовательно, смещаются на ноль, прежде чем они полностью “разогреются”. С механизмом <em>коррекции смещения</em> обновление выглядит следующим образом:  </p>
<div class="code"><pre class="code literal-block"><span class="gh">#</span> t is your iteration counter going from 1 to infinity
m = beta1*m + (1-beta1)*dx
mt = m / (1-beta1**t)
v = beta2*v + (1-beta2)*(dx**2)
vt = v / (1-beta2**t)
x += - learning_rate * mt / (np.sqrt(vt) + eps)
</pre></div>

<p>Обратите внимание, что обновление теперь является функцией итерации, а также других параметров. Мы отсылаем читателя к статье для получения подробной информации или к слайдам курса, где это подробно рассматривается.  </p>
<h3>Дополнительные ссылки:</h3>
<ul>
<li>Модульные тесты для стохастической оптимизации предлагают серию тестов в качестве стандартизированного эталона для стохастической оптимизации.</li>
</ul>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/nn3/opt2.gif"></p>
<p><img alt="" src="https://cs231n.github.io/assets/nn3/opt1.gif"></p>
<p>Анимация, которая может помочь вашей интуиции о динамике процесса обучения. <strong>Сверху</strong>: Контуры поверхности потерь и временная эволюция различных алгоритмов оптимизации. Обратите внимание на «чрезмерное» поведение методов, основанных на импульсе, из-за чего оптимизация выглядит как мяч, катящийся с горки.<br><strong>Снизу</strong>: Визуализация седловой точки в ландшафте оптимизации, где кривизна по разным размерностям имеет разные знаки (одно измерение искривляется вверх, а другое вниз). Обратите внимание, что <em>SGD</em> с трудом нарушает симметрию и застревает на вершине. И наоборот, такие алгоритмы, как <strong>RMSprop</strong>, будут видеть очень низкие градиенты в направлении седла. Из-за знаменателя в обновлении <strong>RMSprop</strong> это увеличит эффективную скорость обучения в этом направлении, что поможет <strong>RMSProp</strong> двигаться дальше. Изображения предоставлены: <a href="https://twitter.com/alecrad">Алек Рэдфорд</a>.  </p>
<hr>
<h2>Оптимизация гиперпараметров</h2>
<p>Как мы уже видели, обучение нейронных сетей может включать в себя множество настроек гиперпараметров. К наиболее распространенным гиперпараметрам в контексте нейронных сетей относятся:  </p>
<ul>
<li>начальная скорость обучения</li>
<li>График снижения скорости обучения (например, постоянная затухания)</li>
<li>регуляризация силы (<em>штраф </em><em>\(L_2\)</em><em>, сила отсева</em>)  </li>
</ul>
<p>Но, как мы видели, относительно менее чувствительных гиперпараметров гораздо больше, например, в попараметрических адаптивных методах обучения, настройке импульса и его расписания и т.д. В этом разделе мы опишем некоторые дополнительные советы и рекомендации по выполнению поиска гиперпараметров:  </p>
<p><strong>Реализация</strong>. Более крупные нейронные сети обычно требуют много времени для обучения, поэтому выполнение поиска гиперпараметров может занять много дней/недель. Важно помнить об этом, так как это влияет на дизайн вашей кодовой базы. Одна из особенностей проекта заключается в том, чтобы иметь <strong>воркер/работника</strong>, который постоянно отбирает случайные гиперпараметры и выполняет оптимизацию. Во время обучения сотрудник будет отслеживать производительность проверки после каждой эпохи и записывать контрольную точку модели (вместе с различной статистикой обучения, такой как потери с течением времени) в файл, предпочтительно в общей файловой системе. Полезно указывать производительность проверки непосредственно в имени файла, чтобы было легко проверить и отсортировать ход выполнения. Затем есть вторая программа, которую мы будем называть <strong>мастером</strong>, которая запускает или убивает рабочих по всему вычислительному кластеру, а также может дополнительно проверять контрольные точки, написанные рабочими, и строить статистику их обучения и т. д.  </p>
<p><strong>Отдайте предпочтение одной свертке проверки перекрестной проверке</strong>. В большинстве случаев один валидационный набор приличного размера существенно упрощает кодовую базу без необходимости перекрестной валидации с несколькими свертками. Вы можете услышать, как люди говорят, что они «перекрестно проверили» параметр, но часто предполагается, что они все еще использовали только один набор проверки.  </p>
<p><strong>Диапазоны гиперпараметров</strong>. Поиск гиперпараметров в логарифмической шкале. Например, типичная выборка коэффициента обучения будет выглядеть следующим образом: <code>learning_rate = 10 ** uniform(-6, 1)</code>. То есть мы генерируем случайное число из равномерного распределения, но затем возводим его в степень <strong>10</strong>. Та же стратегия должна быть использована и для силы регуляризации. Интуитивно это объясняется тем, что скорость обучения и сила регуляризации оказывают мультипликативное влияние на динамику тренировки. Например, фиксированное изменение при добавлении <strong>0,01</strong> к коэффициенту обучения оказывает огромное влияние на динамику, если коэффициент обучения равен <strong>0,001</strong>, но почти не оказывает никакого влияния, если коэффициент обучения равен <strong>10</strong>. Это связано с тем, что скорость обучения умножает вычисленный градиент в обновлении. Следовательно, гораздо естественнее рассматривать диапазон скорости обучения, умноженный или деленный на некоторую величину, чем диапазон скорости обучения, прибавленный или вычтенный на некоторую величину. Некоторые параметры (например, отсеивание) обычно ищутся в исходной шкале (например, <code>dropout = uniform(0,1)</code>).  </p>
<p><strong>Отдайте предпочтение случайному поиску, а не поиску по сетке</strong>. Как утверждают Бергстра и Бенджио в <a href="http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf">книге «Случайный поиск для оптимизации гиперпараметров»</a>, <em>«случайно выбранные испытания более эффективны для оптимизации гиперпараметров, чем испытания на сетке»</em> . Как оказалось, это тоже обычно проще реализовать.  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/nn3/gridsearchbad.jpeg"></p>
<p>Основная иллюстрация из <a href="http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf">книги «Случайный поиск для оптимизации гиперпараметров»</a> Бергстры и Бенджио. Очень часто бывает так, что некоторые гиперпараметры имеют гораздо большее значение, чем другие (например, верхний гиперпараметр против левого на этом рисунке). Выполнение случайного поиска, а не поиска по сетке, позволяет гораздо точнее находить хорошие значения для важных.  </p>
<hr>
<p><strong>Осторожнее с лучшими значениями на границе</strong>. Иногда может случиться так, что вы ищете гиперпараметр (например, скорость обучения) в плохом диапазоне. Например, предположим, что мы используем <code>learning_rate = 10 ** uniform(-6, 1)</code> . Как только мы получим результаты, важно еще раз проверить, что итоговая скорость обучения не находится на краю этого интервала, иначе вы можете пропустить более оптимальную настройку гиперпараметров за пределами интервала.  </p>
<p><strong>Этапируйте свой поиск от грубого к хорошему</strong>. На практике может быть полезно сначала искать в грубых диапазонах (например, <strong>10 ** [-6, 1]</strong>), а затем, в зависимости от того, где появляются наилучшие результаты, сужать диапазон. Кроме того, может быть полезно выполнить первоначальный грубый поиск во время обучения только за <strong>1</strong> эпоху или даже меньше, потому что многие настройки гиперпараметров могут привести к тому, что модель вообще не будет обучаться или сразу же взорвется с бесконечными затратами. Второй этап может выполнять более узкий поиск с <strong>5</strong> эпохами, а последний этап может выполнять детальный поиск в конечном диапазоне для гораздо большего количества эпох (например).  </p>
<p><strong>Байесовская оптимизация гиперпараметров</strong> — это целая область исследований, посвященная созданию алгоритмов, которые пытаются более эффективно ориентироваться в пространстве гиперпараметров. Основная идея заключается в том, чтобы правильно сбалансировать компромисс между исследованием и эксплуатацией при запросе производительности при различных гиперпараметрах. На основе этих моделей также было разработано несколько библиотек, среди наиболее известных — <a href="https://github.com/JasperSnoek/spearmint">Spearmint</a>, <a href="http://www.cs.ubc.ca/labs/beta/Projects/SMAC/">SMAC</a> и <a href="http://jaberg.github.io/hyperopt/">Hyperopt</a>. Тем не менее, в практических условиях с <em>ConvNet</em> все еще относительно сложно превзойти случайный поиск в тщательно выбранных интервалах. Смотрите дополнительную дискуссию из окопов <a href="http://nlpers.blogspot.com/2014/10/hyperparameter-search-bayesian.html">здесь</a>.  </p>
<h2>Оценка</h2>
<h3>Модельные ансамбли</h3>
<p>На практике одним из надежных подходов к повышению производительности нейронных сетей на несколько процентов является обучение нескольких независимых моделей и усреднение их прогнозов во время тестирования. По мере увеличения числа моделей в ансамбле производительность обычно монотонно улучшается (хотя и с уменьшением отдачи). Более того, улучшения более значительны с большим разнообразием моделей в ансамбле. Существует несколько подходов к формированию ансамбля:</p>
<ul>
<li>
<strong>Одна и та же модель, разные инициализации</strong>. Используйте перекрестную проверку для определения наилучших гиперпараметров, а затем обучите несколько моделей с лучшим набором гиперпараметров, но с разной случайной инициализацией. Опасность при таком подходе заключается в том, что сорт получается только за счет инициализации.</li>
<li>
<strong>Лучшие модели, обнаруженные во время перекрестной проверки</strong>. Используйте перекрестную проверку для определения наилучших гиперпараметров, а затем выберите несколько лучших (например, <strong>10</strong>) моделей для формирования ансамбля. Это повышает разнообразие ансамбля, но чревато опасностью включения неоптимальных моделей. На практике это может быть проще выполнить, так как не требует дополнительного переобучения моделей после перекрестной проверки</li>
<li>
<strong>Разные контрольные точки одной модели</strong>. Если обучение стоит очень дорого, то некоторые люди имеют ограниченный успех в прохождении различных контрольных точек одной сети с течением времени (например, после каждой эпохи) и использовании их для формирования ансамбля. Очевидно, что это страдает от некоторого недостатка разнообразия, но все же может работать достаточно хорошо на практике. Преимущество такого подхода в том, что он очень дешевый.</li>
<li>
<strong>Бегущее среднее по параметрам во время тренировки</strong>. Что касается последнего пункта, то дешевый способ почти всегда получить дополнительный процент или два производительности — это хранить в памяти вторую копию весовых коэффициентов сети, которая поддерживает экспоненциально уменьшающуюся сумму предыдущих весов во время обучения. Таким образом, вы усредняете состояние сети за последние несколько итераций. Вы обнаружите, что эта «сглаженная» версия весов за последние несколько шагов почти всегда приводит к лучшей ошибке проверки. Грубая интуиция, которую следует иметь в виду, заключается в том, что цель имеет форму чаши, и ваша сеть прыгает вокруг режима, поэтому среднее значение имеет больше шансов оказаться где-то ближе к режиму.  </li>
</ul>
<p>Одним из недостатков ансамблей моделей является то, что их оценка на тестовом примере занимает больше времени. Заинтересованного читателя может вдохновить недавняя работа Джеффа Хинтона «<a href="https://www.youtube.com/watch?v=EK61htlw8hY">Темное знание</a>», в которой идея состоит в том, чтобы «дистиллировать» хороший ансамбль обратно к одной модели, включив логарифмические правдоподобия ансамбля в модифицированную цель.  </p>
<h2>Краткая сводка</h2>
<p>Чтобы обучить нейронную сеть:</p>
<ul>
<li>
<strong>Градиент</strong>: проверьте свою реализацию с помощью небольшого пакета данных и помните о подводных камнях.</li>
<li>
<strong>В качестве проверки здравого смысла</strong> убедитесь, что ваши первоначальные потери разумны, и что вы можете достичь 100% точности обучения на очень небольшой части данных</li>
<li>
<strong>Во время обучения отслеживайте потери</strong>, точность обучения/проверки, а если вы чувствуете себя более склонным, величину обновлений по отношению к значениям параметров (она должна быть <strong>~1e-3</strong>), а при работе с <em>ConvNet</em> — веса первого слоя.</li>
<li>
<strong>Рекомендуется использовать два обновления</strong>: <em>SGD+Nesterov Momentum или Adam</em>.</li>
<li>
<strong>Снижайте скорость обучения в течение периода обучения</strong>. Например, уменьшите вдвое скорость обучения после фиксированного количества эпох или всякий раз, когда точность проверки достигает максимума.</li>
<li>Поиск хороших гиперпараметров с помощью случайного поиска (не поиска по сетке). Дифференцируйте поиск от грубого (широкие диапазоны гиперпараметров, обучение только для <strong>1-5</strong> эпох) до тонкого (более узкие рейнджеры, обучение для гораздо большего количества эпох)</li>
<li>Формируйте модельные ансамбли для дополнительной производительности  </li>
</ul>
<h2>Дополнительные материалы</h2>
<ul>
<li>
<a href="http://research.microsoft.com/pubs/192769/tricks-2012.pdf">SGD</a> советы и рекомендации от Леона Ботту</li>
<li>
<a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf">Efficient BackProp</a> (pdf) от Яна Лекуна</li>
<li>
<a href="http://arxiv.org/pdf/1206.5533v2.pdf">Практические рекомендации по градиентному обучению глубокого Архитектура</a> от Йошуа Бенджио</li>
</ul>
</div>
    <aside class="postpromonav"><nav><ul class="pager hidden-print">
<li class="previous">
                <a href="../convnets-2/" rel="prev" title="Предобработка, инициализация весов, функции потерь">Предыдущая запись</a>
            </li>
            <li class="next">
                <a href="../convnets-4/" rel="next" title="Обучение нейронных сетей 2">Следующая запись</a>
            </li>
        </ul></nav></aside><script src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script><script>
                renderMathInElement(document.body,
                    {
                        delimiters: [
                            {left: "$$", right: "$$", display: true},
                            {left: "\\[", right: "\\]", display: true},
                            {left: "\\begin{equation*}", right: "\\end{equation*}", display: true},
                            {left: "\\(", right: "\\)", display: false}
                        ]
                    }
                );
            </script></article><!--End of body content--><footer id="footer">
            Contents © 2025         <a href="mailto:andrej.labintsev@yandex.ru">Андрей Лабинцев</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
            
        </footer>
</div>
</div>


        <script src="../../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
