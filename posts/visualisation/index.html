<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="ru">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Понимание и визуализация | Заметки по ML, DL</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:700,900" rel="stylesheet">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="ru" href="../../rss.xml">
<link rel="canonical" href="https://mldl.ru/posts/visualisation/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Андрей Лабинцев">
<link rel="prev" href="../architecture/" title="Архитектура нейросетей " type="text/html">
<link rel="next" href="../image-classification/" title="Классификация изображений " type="text/html">
<meta property="og:site_name" content="Заметки по ML, DL">
<meta property="og:title" content="Понимание и визуализация">
<meta property="og:url" content="https://mldl.ru/posts/visualisation/">
<meta property="og:description" content="Понимание и визуализация
(эта страница в настоящее время находится в черновом варианте)  
В литературе было разработано несколько подходов к пониманию и визуализации сверточных сетей, отчасти в ответ ">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2025-03-13T19:42:16+03:00">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Перейти к главному содержимому</a>

<!-- Header and menu bar -->
<div class="container">
      <header class="blog-header py-3"><div class="row nbb-header align-items-center">
          <div class="col-md-3 col-xs-2 col-sm-2" style="width: auto;">
            <button class="navbar-toggler navbar-light bg-light nbb-navbar-toggler" type="button" data-toggle="collapse" data-target=".bs-nav-collapsible" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse bs-nav-collapsible bootblog4-search-form-holder">
                
            </div>
        </div>
          <div class="col-md-6 col-xs-10 col-sm-10 bootblog4-brand" style="width: auto;">
            <a class="navbar-brand blog-header-logo text-dark" href="../../">

            <span id="blog-title">Заметки по ML, DL</span>
        </a>
          </div>
            <div class="col-md-3 justify-content-end align-items-center bs-nav-collapsible collapse flex-collapse bootblog4-right-nav">
            <nav class="navbar navbar-light bg-white"><ul class="navbar-nav bootblog4-right-nav">
<li class="nav-item">
    <a href="index.md" id="sourcelink" class="nav-link">Источник</a>
    </li>


                    
            </ul></nav>
</div>
    </div>
</header><nav class="navbar navbar-expand-md navbar-light bg-white static-top"><div class="collapse navbar-collapse bs-nav-collapsible" id="bs-navbar">
            <ul class="navbar-nav nav-fill d-flex w-100">
<li class="nav-item">
<a href="../../archive.html" class="nav-link">Archive</a>
                </li>
<li class="nav-item">
<a href="../../categories/" class="nav-link">Tags</a>

                
            </li>
</ul>
</div>
<!-- /.navbar-collapse -->
</nav>
</div>

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Понимание и визуализация</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    Андрей Лабинцев
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2025-03-13T19:42:16+03:00" itemprop="datePublished" title="2025-03-13 19:42">2025-03-13 19:42</time></a>
            </p>
            
        <p class="sourceline"><a href="index.md" class="sourcelink">Источник</a></p>

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <h2>Понимание и визуализация</h2>
<p><strong><em>(эта страница в настоящее время находится в черновом варианте)</em></strong>  </p>
<p>В литературе было разработано несколько подходов к пониманию и визуализации сверточных сетей, отчасти в ответ на распространенную критику о том, что изученные признаки в нейронной сети не поддаются интерпретации. В этом разделе мы кратко рассмотрим некоторые из этих подходов и связанную с ними работу.</p>
<h3>Визуализация активаций и веса первого слоя</h3>
<p><strong>Активации слоев</strong>. Наиболее простой метод визуализации заключается в том, чтобы показать активации сети во время прямого прохода. В сетях <em>ReLU</em> активации обычно выглядят относительно неровными и плотными, но по мере обучения активации обычно становятся более редкими и локализованными. Одна из опасных ловушек, которую можно легко заметить с помощью этой визуализации, заключается в том, что некоторые карты активации могут быть равны нулю для множества различных входных данных, что может указывать на <em>мертвые фильтры</em> и может быть симптомом высокой скорости обучения.    </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/cnnvis/act1.jpeg"><br><img alt="" src="https://cs231n.github.io/assets/cnnvis/act2.jpeg"><br>
Типичные активации на первом слое <em>CONV</em> (<strong>сверху</strong>) и на 5-м слое <em>CONV</em> (снизу) обученного <em>AlexNet</em> смотрят на изображение кошки. В каждом боксе отображается карта активации, соответствующая какому-либо фильтру. Обратите внимание, что активации редкие (большинство значений равны нулю, на этой визуализации показаны черным цветом) и в основном локальные.  </p>
<hr>
<p><strong>Фильтры Conv/FC</strong>. Вторая распространенная стратегия заключается в визуализации весов. Обычно они наиболее интерпретируемы на первом слое <em>CONV</em>, который смотрит непосредственно на необработанные пиксельные данные, но также можно показать веса фильтров в более глубоких слоях сети. Весовые коэффициенты полезны для визуализации, потому что хорошо обученные сети обычно отображают красивые и плавные фильтры без каких-либо зашумленных узоров. Зашумленные паттерны могут быть индикатором сети, которая не обучалась достаточно долго, или, возможно, очень низкой интенсивности регуляризации, которая могла привести к переобучению.  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/cnnvis/filt1.jpeg"><br><img alt="" src="https://cs231n.github.io/assets/cnnvis/filt2.jpeg"><br>
Типичные фильтры на первом слое <em>CONV</em> (<strong>сверху</strong>) и на 2-м слое <em>CONV</em> (<strong>снизу</strong>) обученного <em>AlexNet</em>. Обратите внимание, что веса первого слоя очень красивые и гладкие, что указывает на хорошо сходящуюся сеть. Функции цвета/оттенков серого сгруппированы, потому что <em>AlexNet</em> содержит два отдельных потока обработки, и очевидным следствием такой архитектуры является то, что один поток развивает высокочастотные элементы оттенков серого, а другой — низкочастотные цветовые функции. Веса 2-го слоя <em>CONV</em> не так легко интерпретируемы, но очевидно, что они все еще гладкие, хорошо сформированные и лишены зашумленных узоров.  </p>
<hr>
<h3>Получение изображений, которые максимально активируют нейрон</h3>
<p>Еще один метод визуализации заключается в том, чтобы взять большой набор изображений, пропустить их через сеть и отслеживать, какие изображения максимально активируют тот или иной нейрон. Затем мы можем визуализировать изображения, чтобы понять, что нейрон ищет в своем рецептивном поле. Одна из таких визуализаций (среди прочих) показана в <a href="http://arxiv.org/abs/1311.2524">статье Богатые иерархии функций для точного обнаружения объектов и семантической сегментации</a> Росса Гиршика и др.:<br><img alt="" src="https://cs231n.github.io/assets/cnnvis/pool5max.jpeg"><br>
Максимально активизирующие изображения для некоторых нейронов <em>POOL5</em> (5-й слой пула) AlexNet. Значения активации и рецептивное поле конкретного нейрона показаны белым цветом. (В частности, обратите внимание, что нейроны <em>POOL5</em> являются функцией относительно большой части входного изображения!) Можно видеть, что некоторые нейроны реагируют на верхнюю часть тела, текст или зеркальные блики.  </p>
<hr>
<p>Одна из проблем с этим подходом заключается в том, что нейроны <em>ReLU</em> не обязательно имеют какое-либо семантическое значение сами по себе. Скорее, более уместно думать о множественных нейронах <em>ReLU</em> как о базисных векторах некоторого пространства, представленного в виде участков изображения. Другими словами, визуализация показывает участки на краю облака представлений, вдоль (произвольных) осей, которые соответствуют весам фильтра. Это также можно увидеть по тому факту, что нейроны в ConvNet работают линейно над входным пространством, поэтому любое произвольное вращение этого пространства является запретным. Этот момент был далее аргументирован в книге Сегеди и др. <a href="http://arxiv.org/abs/1312.6199">«Интригующие свойства нейронных сетей»</a>, где они выполняют аналогичную визуализацию вдоль произвольных направлений в пространстве представления.</p>
<h3>Встраивание кодов с помощью t-SNE</h3>
<p>ConvNet можно интерпретировать как постепенное преобразование изображений в представление, в котором классы разделяются линейным классификатором. Мы можем получить приблизительное представление о топологии этого пространства, встроив изображения в два измерения таким образом, чтобы их низкоразмерное представление имело примерно равные расстояния, чем их высокомерное представление. Существует множество методов вложения, которые были разработаны с помощью интуиции вложения векторов высокой размерности в пространство низкой размерности с сохранением парных расстояний точек. Среди них <a href="http://lvdmaaten.github.io/tsne/">t-SNE</a> является одним из самых известных методов, который неизменно дает визуально приятные результаты.  </p>
<p>Чтобы произвести встраивание, мы можем взять набор изображений и использовать ConvNet для извлечения кодов <em>CNN</em> (например, в <em>AlexNet</em> 4096-мерный вектор прямо перед классификатором, и, что особенно важно, включая нелинейность <em>ReLU</em>). Затем мы можем подключить их к <em>t-SNE</em> и получить двумерный вектор для каждого изображения. Соответствующие изображения могут быть визуализированы в виде сетки:  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/cnnvis/tsne.jpeg"><br>
Встраивание набора изображений в <em>t-SNE</em> на основе их кодов <em>CNN</em>. Изображения, которые находятся рядом друг с другом, также близки в пространстве репрезентации <em>CNN</em>, что подразумевает, что <em>CNN</em> «видит» их как очень похожие. Обратите внимание, что сходства чаще всего основаны на классах и семантике, а не на пикселях и цветах. Для получения более подробной информации о том, как была создана эта визуализация, связанный код, а также другие связанные визуализации в разных масштабах см. <a href="http://cs.stanford.edu/people/karpathy/cnnembed/">Визуализация кодов CNN в t-SNE</a>.  </p>
<hr>
<h3>Окклюзия частей изображения</h3>
<p>Предположим, что <em>ConvNet</em> классифицирует изображение как собаку. Как мы можем быть уверены, что он на самом деле улавливает собаку на изображении, а не какие-то контекстуальные подсказки на фоне или какой-то другой объект? Одним из способов исследования того, из какой части изображения исходит предсказание классификации, является построение графика вероятности интересующего класса (например, класса собаки) в зависимости от положения объекта-окклюдера. То есть, мы перебираем области изображения, устанавливаем участок изображения равным нулю и смотрим на вероятность класса. Мы можем визуализировать вероятность в виде двумерной тепловой карты. Этот подход был использован в книге Мэтью Цайлера <a href="http://arxiv.org/abs/1311.2901">«Визуализация и понимание сверточных сетей»</a>:  </p>
<hr>
<p><img alt="" src="https://cs231n.github.io/assets/cnnvis/occlude.jpeg"><br>
Три входных изображения (<strong>вверху</strong>). Обратите внимание, что окклюдерная область показана серым цветом. Когда мы проводим окклюдером по изображению, мы записываем вероятность правильного класса, а затем визуализируем его в виде тепловой карты (<em>показанной под каждым изображением</em>). Например, на крайнем левом изображении мы видим, что вероятность померанского шпица резко падает, когда окклюдер закрывает морду собаки, что дает нам некоторую степень уверенности в том, что морда собаки в первую очередь ответственна за высокий балл классификации. И наоборот, обнуление других частей изображения имеет относительно незначительное влияние.  </p>
<hr>
<h3>Визуализация градиента данных и его друзей</h3>
<p><strong>Градиент данных.|</strong></p>
<p><a href="http://arxiv.org/abs/1312.6034">Глубоко внутри сверточных сетей: визуализация моделей классификации изображений и карт заметности</a></p>
<p><strong>DeconvNet.</strong></p>
<p><a href="http://arxiv.org/abs/1311.2901">Визуализация и понимание сверточных сетей</a></p>
<p><strong>Управляемое обратное распространение.</strong></p>
<p><a href="http://arxiv.org/abs/1412.6806">Стремление к простоте: Всесвёрточная сеть</a></p>
<h3>Восстановление оригинальных изображений на основе кодов CNN</h3>
<p><a href="http://arxiv.org/abs/1412.0035">Понимание глубоких представлений изображений путем их инвертирования</a></p>
<h3>Какой объем пространственной информации сохраняется?</h3>
<p><a href="http://papers.nips.cc/paper/5420-do-convnets-learn-correspondence.pdf">Учатся ли ConvNet переписываться?</a> (Вкратце: да)</p>
<h3>Производительность построения графиков в зависимости от атрибутов изображения</h3>
<p><a href="http://arxiv.org/abs/1409.0575">ImageNet Wide Scale Visual Recognition Challenge</a></p>
<h3>Обман ConvNet</h3>
<p><a href="http://arxiv.org/abs/1412.6572">Объяснение и использование состязательных примеров</a></p>
<h3>Сравнение ConvNet с людьми-маркировщиками</h3>
<p><a href="http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/">Что я узнал, соревнуясь с ConvNet на ImageNet</a></p>
    </div>
    <aside class="postpromonav"><nav><ul class="pager hidden-print">
<li class="previous">
                <a href="../architecture/" rel="prev" title="Архитектура нейросетей ">Предыдущая запись</a>
            </li>
            <li class="next">
                <a href="../image-classification/" rel="next" title="Классификация изображений ">Следующая запись</a>
            </li>
        </ul></nav></aside><script src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script><script>
                renderMathInElement(document.body,
                    {
                        
delimiters: [
    {left: "$$", right: "$$", display: true},
    {left: "\\\\[", right: "\\\\]", display: true},
    {left: "\\\\begin{equation*}", right: "\\\\end{equation*}", display: true},
    {left: "$", right: "$", display: false},
    {left: "\\\\(", right: "\\\\)", display: false}
]

                    }
                );
            </script></article><!--End of body content--><footer id="footer">
            Contents © 2025         <a href="mailto:andrej.labintsev@yandex.ru">Андрей Лабинцев</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
            
        </footer>
</div>
</div>


        <script src="../../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
