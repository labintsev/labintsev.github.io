<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# " lang="ru">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Трансфер обучения | Заметки по ML, DL</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Playfair+Display:700,900" rel="stylesheet">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" hreflang="ru" href="../../rss.xml">
<link rel="canonical" href="https://mldl.ru/posts/transfer-learning/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Андрей Лабинцев">
<link rel="prev" href="../nlp-za-90-minut/" title="NLP за 90 минут" type="text/html">
<link rel="next" href="../linear-classifier/" title="Линейный классификатор " type="text/html">
<meta property="og:site_name" content="Заметки по ML, DL">
<meta property="og:title" content="Трансфер обучения">
<meta property="og:url" content="https://mldl.ru/posts/transfer-learning/">
<meta property="og:description" content="Трансфер обучения
(Эти заметки в настоящее время находятся в черновой форме и находятся в разработке)
Содержание:
- Трансферное обучение
- Дополнительные примечания
Трансферное обучение
На практике оч">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2025-02-14T19:42:16+03:00">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Перейти к главному содержимому</a>

<!-- Header and menu bar -->
<div class="container">
      <header class="blog-header py-3"><div class="row nbb-header align-items-center">
          <div class="col-md-3 col-xs-2 col-sm-2" style="width: auto;">
            <button class="navbar-toggler navbar-light bg-light nbb-navbar-toggler" type="button" data-toggle="collapse" data-target=".bs-nav-collapsible" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse bs-nav-collapsible bootblog4-search-form-holder">
                
            </div>
        </div>
          <div class="col-md-6 col-xs-10 col-sm-10 bootblog4-brand" style="width: auto;">
            <a class="navbar-brand blog-header-logo text-dark" href="../../">

            <span id="blog-title">Заметки по ML, DL</span>
        </a>
          </div>
            <div class="col-md-3 justify-content-end align-items-center bs-nav-collapsible collapse flex-collapse bootblog4-right-nav">
            <nav class="navbar navbar-light bg-white"><ul class="navbar-nav bootblog4-right-nav">
<li class="nav-item">
    <a href="index.md" id="sourcelink" class="nav-link">Источник</a>
    </li>


                    
            </ul></nav>
</div>
    </div>
</header><nav class="navbar navbar-expand-md navbar-light bg-white static-top"><div class="collapse navbar-collapse bs-nav-collapsible" id="bs-navbar">
            <ul class="navbar-nav nav-fill d-flex w-100">
<li class="nav-item">
<a href="../../archive.html" class="nav-link">Archive</a>
                </li>
<li class="nav-item">
<a href="../../categories/" class="nav-link">Tags</a>

                
            </li>
</ul>
</div>
<!-- /.navbar-collapse -->
</nav>
</div>

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        
        
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Трансфер обучения</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    Андрей Лабинцев
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2025-02-14T19:42:16+03:00" itemprop="datePublished" title="2025-02-14 19:42">2025-02-14 19:42</time></a>
            </p>
            
        <p class="sourceline"><a href="index.md" class="sourcelink">Источник</a></p>

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <h2>Трансфер обучения</h2>
<p><strong><em>(Эти заметки в настоящее время находятся в черновой форме и находятся в разработке)</em></strong></p>
<p>Содержание:
- <a href=".">Трансферное обучение</a>
- <a href=".">Дополнительные примечания</a></p>
<h3>Трансферное обучение</h3>
<p>На практике очень немногие обучают всю сверточную сеть с нуля (со случайной инициализацией), потому что относительно редко удается иметь набор данных достаточного размера. Вместо этого обычно предварительно обучают <em>ConvNet</em> на очень большом наборе данных (например, <em>ImageNet</em>, который содержит 1,2 миллиона изображений с 1000 категориями), а затем используют ConvNet либо в качестве инициализации, либо в качестве фиксированного экстрактора признаков для интересующей задачи. Три основных сценария трансферного обучения выглядят следующим образом:
- <strong>ConvNet в качестве фиксированного экстрактора признаков</strong>. Возьмите предварительно обученный <em>ConvNet</em> на <em>ImageNet</em>, удалите последний полностью подключенный слой (выходные данные этого слоя представляют собой 1000 баллов класса для другой задачи, такой как <em>ImageNet</em>), а затем обрабатывайте остальную часть <em>ConvNet</em> как фиксированный экстрактор признаков для нового набора данных. В <em>AlexNet</em> это позволило бы вычислить вектор <strong>4096-D</strong> для каждого изображения, содержащего активации скрытого слоя непосредственно перед классификатором. Мы называем эти функции <strong>кодами CNN</strong>. Для производительности важно, чтобы эти коды были <em>ReLUd</em> (т.е. пороговыми на нуле), если они также были пороговыми во время обучения <em>ConvNet</em> на <em>ImageNet</em> (как это обычно бывает). После извлечения кодов <strong>4096-D</strong> для всех изображений обучите линейный классификатор (например, Linear <em>SVM</em> или классификатор Softmax) для нового набора данных.
- <strong>Тонкая настройка ConvNet</strong>. Вторая стратегия заключается не только в замене и переобучении классификатора поверх <em>ConvNet</em> на новом наборе данных, но и в тонкой настройке весов предварительно обученной сети путем продолжения обратного распространения. Можно тонко настроить все уровни <em>ConvNet</em>, или можно оставить некоторые из более ранних уровней фиксированными (из-за опасений переобучения) и выполнить тонкую настройку только некоторой части сети более высокого уровня. Это мотивировано наблюдением, что более ранние функции <em>ConvNet</em> содержат более общие функции (например, детекторы краев или детекторы цветных пятен), которые должны быть полезны для многих задач, но более поздние уровни <em>ConvNet</em> становятся все более специфичными для деталей классов, содержащихся в исходном наборе данных. Например, в случае <em>ImageNet</em>, который содержит множество пород собак, значительная часть репрезентативной мощности <em>ConvNet</em> может быть направлена на функции, специфичные для дифференциации между породами собак.
- <strong>Предварительно обученные модели</strong>. Поскольку обучение современных <em>ConvNet</em> на нескольких графических процессорах <em>ImageNet</em> занимает 2–3 недели, часто можно увидеть, как люди выпускают свои окончательные контрольные точки <em>ConvNet</em> в пользу других пользователей, которые могут использовать сети для тонкой настройки. Например, в библиотеке <em>Caffe</em> есть <a href="https://github.com/BVLC/caffe/wiki/Model-Zoo">Model Zoo</a>, где люди делятся своими сетевыми весами.  </p>
<p><strong>Когда и как проводить тонкую настройку?</strong> Как вы решаете, какой тип переносного обучения вы должны выполнять на новом наборе данных? Это зависит от нескольких факторов, но два наиболее важных из них — это размер нового набора данных (маленький или большой) и его сходство с исходным набором данных (например, похожий на ImageNet с точки зрения содержимого изображений и классов, или сильно отличающийся, например, изображения микроскопа). Помня о том, что объекты <em>ConvNet</em> более универсальны в ранних слоях и более специфичны для исходного набора данных в более поздних слоях, вот некоторые общие эмпирические правила для навигации по <em>4</em> основным сценариям:<br>
1. <em>Новый набор данных имеет небольшой размер и похож на исходный набор данных</em>. Поскольку объем данных невелик, тонкая настройка <em>ConvNet</em> не является хорошей идеей из-за проблем с переобучением. Поскольку данные аналогичны исходным данным, мы ожидаем, что функции более высокого уровня в <em>ConvNet</em> также будут иметь отношение к этому набору данных. Следовательно, лучшей идеей может быть обучение линейного классификатора на кодах <em>CNN</em>.
2. <em>Новый набор данных имеет большой размер и похож на исходный набор данных</em>. Поскольку у нас больше данных, мы можем быть уверены в том, что не переучимся, если попытаемся выполнить тонкую настройку через всю сеть.
3. <em>Новый набор данных небольшой, но сильно отличается от исходного</em>. Поскольку данные невелики, вероятно, лучше всего обучить только линейный классификатор. Поскольку набор данных сильно отличается, возможно, не стоит обучать классификатор с вершины сети, которая содержит больше функций, специфичных для набора данных. Вместо этого, возможно, лучше обучить классификатор <em>SVM</em> от активаций где-то раньше в сети.
4. <em>Новый набор данных имеет большой размер и сильно отличается от исходного набора данных</em>. Поскольку набор данных очень большой, можно ожидать, что мы сможем позволить себе обучить <em>ConvNet</em> с нуля. Однако на практике очень часто все же полезно инициализировать весами из предварительно обученной модели. В этом случае у нас было бы достаточно данных и уверенности для тонкой настройки по всей сети.  </p>
<p><strong>Практические советы</strong>. Есть несколько дополнительных моментов, о которых следует помнить при выполнении <em>Transfer Learning</em>:</p>
<ul>
<li>
<em>Ограничения из предварительно обученных моделей</em>. Обратите внимание, что если вы хотите использовать предварительно обученную сеть, вы можете быть немного ограничены с точки зрения архитектуры, которую вы можете использовать для вашего нового набора данных. Например, вы не можете произвольно удалять слои Conv из предварительно обученной сети. Тем не менее, некоторые изменения просты: благодаря совместному использованию параметров вы можете легко запустить предварительно обученную сеть на изображениях разного пространственного размера. Это ясно видно в случае слоев Conv/Pool, потому что их прямая функция не зависит от пространственного размера входного объема (до тех пор, пока шаги «подходят»). В случае слоев FC это по-прежнему верно, потому что слои FC могут быть преобразованы в сверточный слой: например, в AlexNet окончательный объем пула перед первым слоем <em>FC</em> имеет размер <strong>[6x6x512]</strong>. Следовательно, слой <em>FC</em>, рассматривающий этот объем, эквивалентен наличию сверточного слоя, который имеет размер рецептивного поля 6x6 и применяется с отступом <strong>0</strong>.</li>
<li>
<em>Скорость обучения</em>. Обычно для тонко настраиваемых весов <em>ConvNet</em> используется меньшая скорость обучения по сравнению с весами (случайно инициализированными) для нового линейного классификатора, который вычисляет баллы классов нового набора данных. Это связано с тем, что мы ожидаем, что веса <em>ConvNet</em> относительно хороши, поэтому мы не хотим искажать их слишком быстро и слишком сильно (особенно когда новый линейный классификатор над ними обучается на основе случайной инициализации).  </li>
</ul>
<h3>Дополнительные примечания</h3>
<ul>
<li>
<a href="http://arxiv.org/abs/1403.6382">Готовые функции CNN: A Astounding Baseline for Recognition</a> обучает <em>SVM</em> функциям из предварительно обученного <em>ImageNet</em> <em>ConvNet</em> и сообщает о нескольких современных результатах.</li>
<li>
<a href="http://arxiv.org/abs/1310.1531">DeCAF</a> сообщал об аналогичных выводах в 2013 году. Фреймворк в этой статье (<em>DeCAF</em>) был предшественником библиотеки <em>C++</em> <em>Caffe</em> на основе <em>Python</em>.</li>
<li>
<a href="http://arxiv.org/abs/1411.1792">Насколько переносимы функции в глубоких нейронных сетях?</a> Подробно изучает эффективность обучения переносу, включая некоторые неинтуитивные выводы о коадаптациях слоев.</li>
</ul>
</div>
    <aside class="postpromonav"><nav><ul class="pager hidden-print">
<li class="previous">
                <a href="../nlp-za-90-minut/" rel="prev" title="NLP за 90 минут">Предыдущая запись</a>
            </li>
            <li class="next">
                <a href="../linear-classifier/" rel="next" title="Линейный классификатор ">Следующая запись</a>
            </li>
        </ul></nav></aside><script src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script><script>
                renderMathInElement(document.body,
                    {
                        
delimiters: [
    {left: "$$", right: "$$", display: true},
    {left: "\\\\[", right: "\\\\]", display: true},
    {left: "\\\\begin{equation*}", right: "\\\\end{equation*}", display: true},
    {left: "$", right: "$", display: false},
    {left: "\\\\(", right: "\\\\)", display: false}
]

                    }
                );
            </script></article><!--End of body content--><footer id="footer">
            Contents © 2025         <a href="mailto:andrej.labintsev@yandex.ru">Андрей Лабинцев</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         
            
            
        </footer>
</div>
</div>


        <script src="../../assets/js/all-nocdn.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element){var i=element.getElementsByTagName('img')[0];return i===undefined?'':i.alt;}});
    </script>
</body>
</html>
